<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>技术文章摘抄 – 极客专栏</title>
    <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/</link>
    <description>Recent content in 极客专栏 on 技术文章摘抄</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Fri, 27 May 2022 00:00:00 +0000</lastBuildDate>
    
	  <atom:link href="/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>极客专栏: 《数据结构与算法之美》学习指导手册</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%AF%BC%E6%89%8B%E5%86%8C/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%AF%BC%E6%89%8B%E5%86%8C/</guid>
      <description>
        
        
        &lt;p&gt;你好，我是王争。&lt;/p&gt;
&lt;p&gt;在设计专栏内容的时候，为了兼顾不同基础的同学，我在内容上做到了难易结合，既有简单的数组、链表、栈、队列这些基础内容，也有红黑树、BM、KMP 这些难度较大的算法。但是，对于初学者来说，一下子面对这么多知识，可能还是比较懵。&lt;/p&gt;
&lt;p&gt;我觉得，对于初学者来说，先把最简单、最基础、最重要的知识点掌握好，再去研究难度较高、更加高级的知识点，这样由易到难、循序渐进的学习路径，无疑是最合理的。&lt;/p&gt;
&lt;p&gt;基于这个路径，我对专栏内容，重新做了一次梳理，希望给你一份具体、明确、有效的学习指导。我会写清楚&lt;strong&gt;每个知识点的难易程度、需要你掌握到什么程度、具体如何来学习&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;如果你是数据结构和算法的初学者，或者你觉得自己的基础比较薄弱，希望这份学习指导，能够让你学起来能更加有的放矢，能把精力、时间花在刀刃上，获得更好的学习效果。&lt;/p&gt;
&lt;p&gt;下面，我先给出一个大致的学习路线。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/54/48/54163f16e152f71b8f91d3fba652cf48.jpg&#34; alt=&#34;&#34;&gt;
（建议保存后查看大图）&lt;/p&gt;
&lt;p&gt;现在，针对每个知识点，我再给你逐一解释一下。我这里先说明一下，下面标记的难易程度、是否重点、掌握程度，都只是针对初学者来说的，如果你已经有一定基础，可以根据自己的情况，安排自己的学习。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;复杂度分析&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;尽管在专栏中，我只用了两节课的内容，来讲复杂度分析这个知识点。但是，我想说的是，它真的非常重要。你必须要牢牢掌握这两节，基本上要做到，简单代码能很快分析出时间、空间复杂度；对于复杂点的代码，比如递归代码，你也要掌握专栏中讲到的两种分析方法：递推公式和递归树。&lt;/p&gt;
&lt;p&gt;对于初学者来说，光看入门篇的两节复杂度分析文章，可能还不足以完全掌握复杂度分析。不过，在后续讲解每种数据结构和算法的时候，我都有详细分析它们的时间、空间复杂度。所以，你可以在学习专栏中其他章节的时候，再不停地、有意识地去训练自己的复杂度分析能力。&lt;/p&gt;
&lt;p&gt;难易程度：Medium&lt;/p&gt;
&lt;p&gt;是否重点：10 分&lt;/p&gt;
&lt;p&gt;掌握程度：在不看我的分析的情况下，能自行分析专栏中大部分数据结构和算法的时间、空间复杂度&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;数组、栈、队列&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;这一部分内容非常简单，初学者学起来也不会很难。但是，作为基础的数据结构，数组、栈、队列，是后续很多复杂数据结构和算法的基础，所以，这些内容你一定要掌握。&lt;/p&gt;
&lt;p&gt;难易程度：Easy&lt;/p&gt;
&lt;p&gt;是否重点：8 分&lt;/p&gt;
&lt;p&gt;掌握程度：能自己实现动态数组、栈、队列&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;链表&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;链表非常重要！虽然理论内容不多，但链表上的操作却很复杂。所以，面试中经常会考察，你一定要掌握。而且，我这里说&amp;quot;掌握&amp;quot;不只是能看懂专栏中的内容，还能将专栏中提到的经典链表题目，比如链表反转、求中间结点等，轻松无 bug 地实现出来。&lt;/p&gt;
&lt;p&gt;难易程度：Medium&lt;/p&gt;
&lt;p&gt;是否重点：9 分&lt;/p&gt;
&lt;p&gt;掌握程度：能轻松写出经典链表题目代码&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;递归&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;对于初学者来说，递归代码非常难掌握，不管是读起来，还是写起来。但是，这道坎你必须要跨过，跨不过就不能算是入门数据结构和算法。我们后面讲到的很多数据结构和算法的代码实现，都要用到递归。&lt;/p&gt;
&lt;p&gt;递归相关的理论知识也不多，所以还是要多练。你可以先在网上找些简单的题目练手，比如斐波那契数列、求阶乘等，然后再慢慢过渡到更加有难度的，比如归并排序、快速排序、二叉树的遍历、求高度，最后是回溯八皇后、背包问题等。&lt;/p&gt;
&lt;p&gt;难易程度：Hard&lt;/p&gt;
&lt;p&gt;是否重点：10 分&lt;/p&gt;
&lt;p&gt;掌握程度：轻松写出二叉树遍历、八皇后、背包问题、DFS 的递归代码&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;排序、二分查找&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;这一部分并不难，你只需要能看懂我专栏里的内容即可。&lt;/p&gt;
&lt;p&gt;难易程度：Easy&lt;/p&gt;
&lt;p&gt;是否重点：7 分&lt;/p&gt;
&lt;p&gt;掌握程度：能自己把各种排序算法、二分查找及其变体代码写一遍就可以了&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;跳表&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;对于初学者来说，并不需要非得掌握跳表，所以，如果没有精力，这一章节可以先跳过。&lt;/p&gt;
&lt;p&gt;难易程度：Medium&lt;/p&gt;
&lt;p&gt;是否重点：6 分&lt;/p&gt;
&lt;p&gt;掌握程度：初学者可以先跳过。如果感兴趣，看懂专栏内容即可，不需要掌握代码实现&lt;/p&gt;
&lt;ol start=&#34;7&#34;&gt;
&lt;li&gt;散列表&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;尽管散列表的内容我讲了很多，有三节课。但是，总体上来讲，这块内容理解起来并不难。但是，作为一种应用非常广泛的数据结构，你还是要掌握牢固散列表。&lt;/p&gt;
&lt;p&gt;难易程度：Medium&lt;/p&gt;
&lt;p&gt;是否重点：8 分&lt;/p&gt;
&lt;p&gt;掌握程度：对于初学者来说，自己能代码实现一个拉链法解决冲突的散列表即可&lt;/p&gt;
&lt;ol start=&#34;8&#34;&gt;
&lt;li&gt;哈希算法&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;这部分纯粹是为了开拓思路，初学者可以略过。&lt;/p&gt;
&lt;p&gt;难易程度：Easy&lt;/p&gt;
&lt;p&gt;是否重点：3 分&lt;/p&gt;
&lt;p&gt;掌握程度：可以暂时不看&lt;/p&gt;
&lt;ol start=&#34;9&#34;&gt;
&lt;li&gt;二叉树&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;这一部分非常重要！二叉树在面试中经常会被考到，所以要重点掌握。但是我这里说的二叉树，并不包含专栏中红黑树的内容。红黑树我们待会再讲。&lt;/p&gt;
&lt;p&gt;难易程度：Medium&lt;/p&gt;
&lt;p&gt;是否重点：9 分&lt;/p&gt;
&lt;p&gt;掌握程度：能代码实现二叉树的三种遍历算法、按层遍历、求高度等经典二叉树题目&lt;/p&gt;
&lt;ol start=&#34;10&#34;&gt;
&lt;li&gt;红黑树&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;对于初学者来说，这一节课完全可以不看。&lt;/p&gt;
&lt;p&gt;难易程度：Hard&lt;/p&gt;
&lt;p&gt;是否重点：3 分&lt;/p&gt;
&lt;p&gt;掌握程度：初学者不用把时间浪费在上面&lt;/p&gt;
&lt;ol start=&#34;11&#34;&gt;
&lt;li&gt;B+ 树&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;虽然 B+ 树也算是比较高级的一种数据结构了，但是对初学者来说，也不是重点。有时候面试的时候还是会问的，所以这一部分内容，你能看懂专栏里的讲解就可以了。&lt;/p&gt;
&lt;p&gt;难易程度：Medium&lt;/p&gt;
&lt;p&gt;是否重点：5 分&lt;/p&gt;
&lt;p&gt;掌握程度：可看可不看&lt;/p&gt;
&lt;ol start=&#34;12&#34;&gt;
&lt;li&gt;堆与堆排序&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;这一部分内容不是很难，初学者也是要掌握的。&lt;/p&gt;
&lt;p&gt;难易程度：Medium&lt;/p&gt;
&lt;p&gt;是否重点：8 分&lt;/p&gt;
&lt;p&gt;掌握程度：能代码实现堆、堆排序，并且掌握堆的三种应用（优先级队列、Top k、中位数）&lt;/p&gt;
&lt;ol start=&#34;13&#34;&gt;
&lt;li&gt;图的表示&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;图的内容很多，但是初学者不需要掌握那么多。一般 BAT 等大厂面试，不怎么会面试有关图的内容，因为面试官可能也对这块不会很熟悉哈：）。但是，最基本图的概念、表示方法还是要掌握的。&lt;/p&gt;
&lt;p&gt;难易程度：Easy&lt;/p&gt;
&lt;p&gt;是否重点：8 分&lt;/p&gt;
&lt;p&gt;掌握程度：理解图的三种表示方法（邻接矩阵、邻接表、逆邻接表），能自己代码实现&lt;/p&gt;
&lt;ol start=&#34;14&#34;&gt;
&lt;li&gt;深度广度优先搜索&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;这算是图上最基础的遍历或者说是搜索算法了，所以还是要掌握一下。这两种算法的原理都不难哈，但是代码实现并不简单，一个用到了队列，另一个用到了递归。对于初学者来说，看懂这两个代码实现就是一个挑战！可以等到其他更重要的内容都掌握之后，再来挑战，也是可以的。&lt;/p&gt;
&lt;p&gt;难易程度：Hard&lt;/p&gt;
&lt;p&gt;是否重点：8 分&lt;/p&gt;
&lt;p&gt;掌握程度：能代码实现广度优先、深度优先搜索算法&lt;/p&gt;
&lt;ol start=&#34;15&#34;&gt;
&lt;li&gt;拓扑排序、最短路径、A* 算法&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;这几个算法稍微高级点。如果你能轻松实现深度、广度优先搜索，那看懂这三个算法不成问题。不过，这三种算法不是重点。面试不会考的。&lt;/p&gt;
&lt;p&gt;难易程度：Hard&lt;/p&gt;
&lt;p&gt;是否重点：5 分&lt;/p&gt;
&lt;p&gt;掌握程度：有时间再看，暂时可以不看&lt;/p&gt;
&lt;ol start=&#34;16&#34;&gt;
&lt;li&gt;字符串匹配（BF、RK）&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;BF 非常简单，RK 稍微复杂点，但都不难。这个最好还是掌握下。&lt;/p&gt;
&lt;p&gt;难易程度：Easy&lt;/p&gt;
&lt;p&gt;是否重点：7 分&lt;/p&gt;
&lt;p&gt;掌握程度：能实践 BF 算法，能看懂 RK 算法&lt;/p&gt;
&lt;ol start=&#34;17&#34;&gt;
&lt;li&gt;字符串匹配（BM、KMP、AC 自动机）&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;这三个算法都挺难的，对于算法有一定基础的人来说，看懂也不容易。所以，对于初学者来说，千万别浪费时间在这上面。即便有余力，看懂就好了，不用非得能自己实现。&lt;/p&gt;
&lt;p&gt;难易程度：Hard&lt;/p&gt;
&lt;p&gt;是否重点：3 分&lt;/p&gt;
&lt;p&gt;掌握程度：初学者不用把时间浪费在上面&lt;/p&gt;
&lt;ol start=&#34;18&#34;&gt;
&lt;li&gt;字符串匹配（Trie）&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;这个还是要能看懂，不过不需要能代码实现。有些面试官喜欢考这个东西，主要是结合应用场景来考察，只是看你知不知道要用 Trie 树这个东西。&lt;/p&gt;
&lt;p&gt;难易程度：Medium&lt;/p&gt;
&lt;p&gt;是否重点：7 分&lt;/p&gt;
&lt;p&gt;掌握程度：能看懂，知道特点、应用场景即可，不要求代码实现&lt;/p&gt;
&lt;ol start=&#34;19&#34;&gt;
&lt;li&gt;位图&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;位图不是重点，如果有余力最好掌握一下。&lt;/p&gt;
&lt;p&gt;难易程度：Easy&lt;/p&gt;
&lt;p&gt;是否重点：6 分&lt;/p&gt;
&lt;p&gt;掌握程度：看懂即可，能自己实现一个位图结构最好&lt;/p&gt;
&lt;ol start=&#34;20&#34;&gt;
&lt;li&gt;四种算法思想&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;这个是重点，也是难点。贪心、分治、回溯、动态规划，每一个都不简单，其中动态规划又是最难、最烧脑的。要应付 FLAG 这样公司的面试，必须拿下这块内容。但是呢，学习要循序渐进，这块能内容的学习可以放到最后，做个长时间的学习计划来攻克。&lt;/p&gt;
&lt;p&gt;这块内容理论的东西不多，要想真的掌握，还是要大量刷题。&lt;/p&gt;
&lt;p&gt;难易程度：Hard&lt;/p&gt;
&lt;p&gt;是否重点：10 分&lt;/p&gt;
&lt;p&gt;掌握程度：可以放到最后，但是一定要掌握！做到能实现 Leetcode 上 Medium 难度的题目&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;学而时习之，专栏虽然已经结束，但是学习的同学和留言依旧源源不断。希望这份学习指导手册对你有帮助，也欢迎你继续给我留言，和大家一起交流、学习、进步。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/8e/d3/8e603e3d795fc0ab2698f6f5eabf14d3.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 00丨开篇词丨从今天起，跨过“数据结构与算法”这道坎</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/00%E4%B8%A8%E5%BC%80%E7%AF%87%E8%AF%8D%E4%B8%A8%E4%BB%8E%E4%BB%8A%E5%A4%A9%E8%B5%B7%E8%B7%A8%E8%BF%87%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E8%BF%99%E9%81%93%E5%9D%8E/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/00%E4%B8%A8%E5%BC%80%E7%AF%87%E8%AF%8D%E4%B8%A8%E4%BB%8E%E4%BB%8A%E5%A4%A9%E8%B5%B7%E8%B7%A8%E8%BF%87%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E8%BF%99%E9%81%93%E5%9D%8E/</guid>
      <description>
        
        
        &lt;p&gt;你好，我是王争，毕业于西安交通大学计算机专业。现在回想起来，本科毕业的时候，我的编程水平其实是很差的。直到读研究生的时候，一个师兄给了我一本《算法导论》，说你可以看看，对你的编程会很有帮助。&lt;/p&gt;
&lt;p&gt;没想到，从此我对算法的&amp;quot;迷恋&amp;quot;便一发不可收拾。之后，我如饥似渴地把图书馆里几乎所有数据结构和算法书籍都读了一遍。&lt;/p&gt;
&lt;p&gt;我常常边读边练。没多久，我就发现，写代码的时候，我会不由自主考虑很多性能方面的问题。我写出时间复杂度高、空间复杂度高的垃圾代码越来越少了，算法能力提升了很多，编程能力也有了质的飞跃。得益于此，研究生毕业后，我直接进入 Google，从事 Google 翻译相关的开发工作。&lt;/p&gt;
&lt;p&gt;这是我自己学习数据结构与算法的经历，现在，你可以想想你的情况。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;是不是从学校开始，你就觉得数据结构难学，然后一直没认真学？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;工作中，一遇到数据结构这个坑，你又发自本能地迅速避让，因为你觉得自己不懂，所以也不想深究，反正看起来无关大局？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;当你想换工作面试，或者研究某个开源项目源码，亦或者和团队讨论某个非框架层面的高可用难题的时候，你又发现，自己的基础跟不上别人的节奏？&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果你是这种情况，其实你并不孤独，这不是你一个人遇到的问题。工作十年间，我见过许多程序员。他们有着各种各样的背景，有很多既有潜力又非常努力，但始终无法在自己现有水平上更进一步。&lt;/p&gt;
&lt;p&gt;在技术圈里，我们经常喜欢谈论高大上的架构，比如高可用、微服务、服务治理等等。鲜有人关注代码层面的编程能力，而愿意沉下心来，花几个月时间啃一啃计算机基础知识、认认真真夯实基础的人，简直就是凤毛麟角。&lt;/p&gt;
&lt;p&gt;我认识一位原来腾讯 T4 的技术大牛。在区块链大潮之前，他在腾讯工作了 10 多年，长期负责手机 QQ 后台整体建设。他经历了手机 QQ 从诞生到亿级用户在线的整个过程。后来他去了微众银行，有一天老板让他去做区块链。&lt;strong&gt;他用了不到半年时间，就把区块链的整个技术脉络摸清楚了。&lt;/strong&gt; 现在，他是微众银行的区块链负责人，微众科技创新产品部的老总。你说厉害不？你可以花半年时间就能精通一个新的领域吗？为什么他就可以做到？&lt;/p&gt;
&lt;p&gt;我觉得这其中最重要的就是基础足够扎实。他曾经跟我说，像区块链、人工智能这些看似很新的技术，其实一点儿都不&amp;quot;新&amp;quot;。最初学编程的时候，他就把那些基础的知识都学透了。当面临行业变动、新技术更迭的时候，他不断发现，那些所谓的新技术，核心和本质的东西其实就是当初学的那些知识。掌握了这个&amp;quot;规律&amp;quot;之后，他学任何东西都很快，任何新技术都能快速迎头赶上。这就是他快速学习并且获得成功的秘诀。&lt;/p&gt;
&lt;p&gt;所以说，&lt;strong&gt;基础知识就像是一座大楼的地基，它决定了我们的技术高度。而要想快速做出点事情，前提条件一定是基础能力过硬，&amp;ldquo;内功&amp;quot;要到位&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;那技术人究竟都需要修炼哪些&amp;quot;内功&amp;quot;呢？我觉得，无外乎就是大学里的那些基础课程，操作系统、计算机网络、编译原理等等，当然还有数据结构和算法。&lt;/p&gt;
&lt;p&gt;可是，我们都知道，像《算法导论》这些经典书籍，虽然很全面，但是过于理论，学起来非常枯燥；而市面很多课程大多缺失真实的开发场景，费劲学完感觉好像还是用不上，过不了几天就忘了。&lt;/p&gt;
&lt;p&gt;所以，我尝试做一个让你能真正受用的数据结构与算法课程，希望给你指明一个简洁、高效的学习路径，教你一个学习基础知识的通用方法 。那么，关于专栏内容，我是怎样设计的呢？&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;我根据自己研读数十本算法书籍和多年项目开发的经验，在众多的数据结构和算法中，精选了最实用的内容进行讲解。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;我不只会教你怎么用，还会告诉你，我们为什么需要这种数据结构和算法，一点点帮你捋清它们背后的设计思想，培养你举一反三的能力。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对于每种数据结构和算法，我都会结合真实的软件开发案例来讲解，让你知道，数据结构和算法，究竟应该如何应用到实际的编码中。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;为了&lt;strong&gt;由浅入深&lt;/strong&gt; 地带你学习，我把专栏分成四个&lt;strong&gt;递进&lt;/strong&gt;的模块。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;入门篇&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;时间、空间复杂度分析是数据结构和算法中非常重要的知识点，贯穿整个专栏的学习过程。但同时也是比较难掌握的，所以我用了 2 节课来讲这部分内容，而且还举了大量的实例，让你一边学一边练，真正能掌握复杂度分析，为后面的学习铺路。&lt;/p&gt;
&lt;p&gt;我希望通过这一模块，你能掌握时间、空间复杂度的概念，大 O 表示法的由来，各种复杂度分析技巧，以及最好、最坏、平均、均摊复杂度分析方法。之后，面对任何代码的复杂度分析，你都能游刃有余、毫不畏惧！&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;strong&gt;基础篇&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这部分是专栏中篇幅最大的内容，也是我们学习的重点，共有 26 节内容，涵盖了最基础、最常用的数据结构和算法。针对每种数据结构和算法，我都会结合具体的软件开发实例，由浅入深进行讲解，并适时总结一些实用&amp;quot;宝典&amp;rdquo;，保证你印象深刻、学有所用。&lt;/p&gt;
&lt;p&gt;比如递归这一节，我会讲到，为什么递归代码比较难写？如何避免堆栈溢出？如何避免递归冗余计算？如何将递归代码转化为非递归代码？&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;高级篇&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这部分我会讲一些不是那么常用的数据结构和算法。虽然不常用，但是这些内容你也需要知道。设置这一部分的目的，是为了让你开拓视野，强化训练算法思维、逻辑思维。如果说学完基础部分可以考 80 分，那掌握这一部分就能让你成为尖子生！&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;实战篇&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;我们整个专栏都是围绕数据结构和算法在具体软件实践中的应用来讲的，所以最后我会通过实战部分串讲一下前面讲到的数据结构和算法。我会拿一些开源项目、框架或者系统设计问题，剖析它们背后的数据结构和算法，让你有一个更加直观的感受。&lt;/p&gt;
&lt;p&gt;人生路上，我们会遇到很多的坎。跨过去，你就可以成长，跨不过去就是困难和停滞。而在后面很长的一段时间里，你都需要为这个困难买单。对于我们技术人来说，更是这样。&lt;strong&gt;既然数据结构和算法这个坎，我们总归是要跨过去，为什么不是现在呢？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我很感激师兄当年给我的那本《算法导论》，这是我人生中为数不多的转折点之一。没有那本书，也可能就没有今天的我。我希望这个专栏也能成为你的一个人生转折点。&lt;/p&gt;
&lt;p&gt;我希望，通过这个专栏，不仅能帮你跨过数据结构与算法这个坎，还能帮你掌握一种学习知识和技能的方法，帮你度过职场甚至人生的重要时刻！一起加油吧！&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/8e/d3/8e603e3d795fc0ab2698f6f5eabf14d3.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 00丨开篇词丨洞悉技术的本质，享受科技的乐趣</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/00%E4%B8%A8%E5%BC%80%E7%AF%87%E8%AF%8D%E4%B8%A8%E6%B4%9E%E6%82%89%E6%8A%80%E6%9C%AF%E7%9A%84%E6%9C%AC%E8%B4%A8%E4%BA%AB%E5%8F%97%E7%A7%91%E6%8A%80%E7%9A%84%E4%B9%90%E8%B6%A3/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/00%E4%B8%A8%E5%BC%80%E7%AF%87%E8%AF%8D%E4%B8%A8%E6%B4%9E%E6%82%89%E6%8A%80%E6%9C%AF%E7%9A%84%E6%9C%AC%E8%B4%A8%E4%BA%AB%E5%8F%97%E7%A7%91%E6%8A%80%E7%9A%84%E4%B9%90%E8%B6%A3/</guid>
      <description>
        
        
        &lt;p&gt;你好，我是陈皓，网名左耳朵耗子。我目前在创业，MegaEase 是我的公司，致力于为企业提供高可用、高并发、高性能的分布式技术产品，同时也提供物联网（IoT）方向的技术产品。&lt;/p&gt;
&lt;p&gt;我之前在阿里巴巴、亚马逊、汤森路透等公司任职，职业背景是金融和电子商务行业，主要研究的技术方向是一些大规模分布式系统的基础架构。&lt;/p&gt;
&lt;p&gt;从大学毕业一直做技术工作，到今天有 20 年了，还在写代码，因为我对技术有很大的热情。我从 2002 年开始写技术博客，到 2009 年左右开始在独立的域名 &lt;a href=&#34;http://CoolShell.cn&#34;&gt;CoolShell.cn&lt;/a&gt;（酷壳）上分享我对技术的一些见解和心得。&lt;/p&gt;
&lt;p&gt;本来只想记录一下，没想到得到了很多人的认可，这对我来说是一个不小的鼓励。我的文章和分享始终坚持观点鲜明的特点，因为我希望可以引发大家的讨论和批评，这样分享才更有意义。&lt;/p&gt;
&lt;p&gt;无论我的观点是否偏激、不成熟，或者言辞犀利，在经历过大家的批评和讨论后，我都能够从中得到不在我视角内的思考和认知，这对我来说是非常重要的补充，对我的个人成长非常重要。&lt;/p&gt;
&lt;p&gt;我相信，看到这些文章和讨论的人，也能从中收获到更多的东西。&lt;/p&gt;
&lt;p&gt;坦率地讲，刚收到专栏撰写邀请的时候，我心里面是拒绝的。正如前面所说的，我分享的目的是跟大家交流和讨论，我认为，全年付费专栏这样的方式可能并不好。而且，付费专栏还有文章更新频率的 KPI，这对于像我这样一定要有想法才会写文章的人来说是很痛苦的，因为我不想为了写而写。&lt;/p&gt;
&lt;p&gt;所以，最初，我是非常不情愿的。&lt;/p&gt;
&lt;p&gt;极客邦科技的编辑跟我沟通过很多次，也问过我是否在做一些收费的咨询或是培训，并表明这个专栏就是面对这样的场景的。我想想也是。我其实从 2003 年就开始为很多企业做内部的培训和分享了。&lt;/p&gt;
&lt;p&gt;这些培训涵盖了很多方面，如软件团队管理、架构技术、编程语言、操作系统等，以及一些为企业量身定制的咨询或软件开发，这些都是收费的。&lt;/p&gt;
&lt;p&gt;而我一直以来也没有把这些内容分享在我的博客里，主要原因是我觉得这些内容是有商业价值的，是适合收费的。它们都是实实在在的，是我多年来对实战经验的深入总结和思考，非常来之不易。&lt;/p&gt;
&lt;p&gt;我不太舍得拿出来大范围地分享，以前基本上仅小范围地在企业内部比较封闭的环境里讲讲。所以说，我这边其实是有两种分享，一种是企业内的分享，一种则是像 CoolShell 或是大会这样的公开分享。&lt;/p&gt;
&lt;p&gt;前者更企业化一些，后者更通俗化一些。&lt;/p&gt;
&lt;p&gt;在这个付费专栏中，除了继续保持观点鲜明的行文风格，我会分享一些与个人或企业切身利益更为相关的内容，或者说更具指导性、更有商业价值的东西。而 CoolShell，我还会保持现有的风格继续写下去。&lt;/p&gt;
&lt;p&gt;正如这个专栏的 Slogan 所说：&amp;ldquo;洞悉技术的本质，享受科技的乐趣&amp;rdquo;，我会在这个专栏里分享包括但不限于如下这些内容。&lt;/p&gt;
&lt;h1 id=&#34;技术&#34;&gt;技术&lt;/h1&gt;
&lt;p&gt;对于技术方面，我不会写太多关于知识点的东西，因为这些知识点你可以自行 Google 可以 RTFM。我要写的一定是以体系化的，而且要能直达技术的本质。入行这 20 年来，我最擅长的就是架构和开发各种大规模的系统，所以，我会有 2-3 个和分布式系统相关的系列文章。&lt;/p&gt;
&lt;p&gt;我学过也用过好多编程语言，所以，也会有一系列的关于编程本质的文章。而我对一些基础知识研究得也比较多，所以，还会有一系列与基础知识相关的文章。&lt;/p&gt;
&lt;p&gt;当然，其中还会穿插一些其它的技术文章，比如一些热点事件，还有一些经验之谈，包括我会把我的《程序员技术练级攻略》在这个专栏里重新再写一遍。这些东西一定会让你有醍醐灌顶的感觉。&lt;/p&gt;
&lt;h1 id=&#34;成长&#34;&gt;成长&lt;/h1&gt;
&lt;p&gt;在过去这 20 年中，我感觉到，很多人都非常在意自己的成长。所以，我会分享一堆我亲身经历的，也是我自己实验的与个人发展相关的文章。&lt;/p&gt;
&lt;p&gt;比如，如何利用技术变现、如何面试、如何选择新的技术、如何学习、如何管理自己的时间、如何管理自己的老板和工作、如何成为一个 Leader&amp;hellip;&amp;hellip;这些东西一定会对你有用。（但是，我这里一定不会有速成的东西。一切都是要花时间和精力的。如果你想要速成，你不应该来订阅我的专栏。）&lt;/p&gt;
&lt;h1 id=&#34;管理&#34;&gt;管理&lt;/h1&gt;
&lt;p&gt;这 20 年，我觉得做好技术工作的前提是，得做好技术的管理工作。只有管理好了软件工程和技术团队，技术才能发挥出最大的潜力。大多数的技术问题都是管理上的问题。&lt;/p&gt;
&lt;p&gt;所以，我会写上一系列的和管理相关的文章，涵盖管理三个要素：团队、项目和管理者自己。比如，人员招聘、绩效考核、提升士气、解决冲突、面对变化、沟通说服、项目管理、任务排期、会议、远程管理，等等。&lt;/p&gt;
&lt;p&gt;这些内容都是我在外企工作时，接受到的世界顶级管理培训机构培训内容，我会把我的实践写出来分享给你。这其中一定少不了亚马逊相关的各种实践。这些东西，我和很多公司和大佬都讲过，到目前为止还没有人不赞的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/7f/7b/7f428c8dd8f26668a727bd46227ec17b.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;为了对付费用户负责，保证文章能够达到收费的质量，我承诺这个专栏的每一篇文章一定是用心创作的，而且是可以让你从中受益的。&lt;/p&gt;
&lt;p&gt;但因为是第一次做全年专栏，收费也让我有一定的压力，所以，我非常希望你能够跟我分享你的感受和体会。&lt;/p&gt;
&lt;p&gt;我会根据你的反馈及时做出调整和修正，并不断努力提高文章的质量和思想高度，以满足你对有价值、有营养的文章的需求。&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 00丨开篇词丨这一次，让我们一起来搞懂MySQL</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/00%E4%B8%A8%E5%BC%80%E7%AF%87%E8%AF%8D%E4%B8%A8%E8%BF%99%E4%B8%80%E6%AC%A1%E8%AE%A9%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E6%9D%A5%E6%90%9E%E6%87%82mysql/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/00%E4%B8%A8%E5%BC%80%E7%AF%87%E8%AF%8D%E4%B8%A8%E8%BF%99%E4%B8%80%E6%AC%A1%E8%AE%A9%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E6%9D%A5%E6%90%9E%E6%87%82mysql/</guid>
      <description>
        
        
        &lt;p&gt;你好，我是林晓斌，网名&amp;quot;丁奇&amp;quot;，欢迎加入我的专栏，和我一起开始 MySQL 学习之旅。我曾先后在百度和阿里任职，从事 MySQL 数据库方面的工作，一步步地从一个数据库小白成为 MySQL 内核开发人员。回想起来，从我第一次带着疑问翻 MySQL 的源码查到答案至今，已经有十个年头了。在这个过程中，走了不少弯路，但同时也收获了很多的知识和思考，希望能在这个专栏里分享给你。&lt;/p&gt;
&lt;p&gt;记得刚开始接触 MySQL，是我在百度贴吧做权限系统的时候。我们遇到了一个奇怪的问题，一个正常 10 毫秒就能完成的 SQL 查询请求偶尔要执行 100 多毫秒才结束。当时主管问我是什么原因，我其实也搞不清楚，就上网查答案，但怎么找都找不到，又脸皮薄不想说自己不知道，只好硬着头皮翻源码。后来遇到了越来越多的问题，也是类似的情景，所以我逐步养成了通过分析源码理解原理的习惯。&lt;/p&gt;
&lt;p&gt;当时，我自己的感觉是，即使我只是一个开发工程师，只是 MySQL 的用户，在了解了一个个系统模块的原理后，再来使用它，感觉是完全不一样的。当在代码里写下一行数据库命令的时候，我就能想到它在数据库端将怎么执行，它的性能是怎么样的，怎样写能让我的应用程序访问数据库的性能最高。进一步，哪些数据处理让数据库系统来做性能会更好，哪些数据处理在缓存里做性能会更好，我心里也会更清楚。在建表和建索引的时候，我也会更有意识地为将来的查询优化做综合考虑，比如确定是否使用递增主键、主键的列怎样选择，等等。&lt;/p&gt;
&lt;p&gt;但随后我又有了一个新的困惑，我觉得自己了解的 MySQL 知识点是零散的，没有形成网络。于是解决完一个问题后，很容易忘记。再碰到类似的问题，我又得再翻一次代码。&lt;/p&gt;
&lt;p&gt;所幸在阿里工作的时候，我参与了阿里云关系型数据库服务内核的开发，并且负责开发开源分支 AliSQL，让我对 MySQL 内核和源码有了更深层次的研究和理解。在服务内部客户和公有云客户的过程中，我有机会面对和解决足够多的问题，再通过手册进行系统的学习，算是比较坎坷地将 MySQL 的知识网络补了起来。&lt;/p&gt;
&lt;p&gt;所以，在回顾这个过程的时候，我的第一个感受是，如果一开始就有一些从理论到实战的系统性指导，那该多好啊，也许我可以学习得更快些。&lt;/p&gt;
&lt;p&gt;在极客时间团队跟我联系策划这个专栏的时候，我还是持怀疑态度的。为什么呢？现在不比当年了，犹记得十余年前，你使用 MySQL 的过程中碰到问题的话，基本上都只能到代码里去找答案，因为那时网上的资料太少了。&lt;/p&gt;
&lt;p&gt;而近十年来，MySQL 在中国广泛普及，技术分享文章可以说是浩如烟海。所以，现在要系统地介绍一遍 MySQL 的话，恐怕里面提及的大多数知识点，都可以在社区文章中找到。那么我们做这个专栏的意义在哪里，而它又凭什么可以收费呢？&lt;/p&gt;
&lt;p&gt;直到收到极客时间团队的答复，我才开始对这个专栏&amp;quot;想做和可以做&amp;quot;的事情感觉清晰起来。数据库是一个综合系统，其背后是发展了几十年的数据库理论。同时，数据库系统也是一个应用系统，可能一个业务开发人员用了两三年 MySQL，还未必清楚那些自己一直在用的&amp;quot;最佳实践&amp;quot;为什么是最佳的。&lt;/p&gt;
&lt;p&gt;于是，我希望这个专栏能够帮助这样的一些开发者：他们正在使用 MySQL，知道如何写出逻辑正确的 SQL 语句来实现业务目标，却不确定这个语句是不是最优的；他们听说了一些使用数据库的最佳实践，但是更想了解为什么这么做；他们使用的数据库偶尔会出问题，亟需了解如何更快速、更准确地定位问题，甚至自己解决问题&amp;hellip;&amp;hellip;&lt;/p&gt;
&lt;p&gt;在过去的七年里，我带过十几个应届毕业生，看着他们成长，要求他们原理先行，再实践验证。几年下来，他们的成长速度都很快，其中好几个毕业没两年就成为团队的骨干力量了。我也在社招的时候面试过很多有着不错的运维实践经验和能力的候选人，但都因为对数据库原理仅有一知半解的了解，而最终遗憾地没有通过面试。&lt;/p&gt;
&lt;p&gt;因此，我希望这个专栏能够激发开发者对数据库原理的探索欲，从而更好地理解工作中遇到的问题，更能知道背后的为什么。所以&lt;strong&gt;我会选那些平时使用数据库时高频出现的知识，如事务、索引、锁等内容构成专栏的主线&lt;/strong&gt;。这些主线上是一个个的知识点。每个点就是一个概念、一个机制或者一个原理说明。在每个说明之后，我会和你讨论一个实践相关的问题。&lt;/p&gt;
&lt;p&gt;希望能以这样的方式，让你对 MySQL 的几条主线有一个整体的认识，并且了解基本概念。在之后的实践篇中，我会引用到这些主线的知识背景，并着力说明它们是怎样指导实践的。这样，&lt;strong&gt;你可以从点到线，再到面，形成自己的 MySQL 知识网络。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在这里，有一份目录，你也可以先了解下整个专栏的知识结构。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/a7/7e/a78db0b99bbf1149c39b7960f7183c7e.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;如前面说的，这几条主线上的每个知识点几乎都不是最新的，有些甚至十年前就这样，并没有改过。但我希望针对这些点的说明，可以让你在使用 MySQL 时心里更有底，知道怎么做选择，并且明白为什么。了解了原理，才能在实践中不断创新，提升个人的价值和工作输出。&lt;/p&gt;
&lt;p&gt;从这里开始，跟我一起搞懂 MySQL!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/ce/d9/ce7f4e35916ed1aa49206a53a0547bd9.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 01丨Java代码是怎么运行的？</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3jvm%E8%99%9A%E6%8B%9F%E6%9C%BA/01%E4%B8%A8java%E4%BB%A3%E7%A0%81%E6%98%AF%E6%80%8E%E4%B9%88%E8%BF%90%E8%A1%8C%E7%9A%84/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3jvm%E8%99%9A%E6%8B%9F%E6%9C%BA/01%E4%B8%A8java%E4%BB%A3%E7%A0%81%E6%98%AF%E6%80%8E%E4%B9%88%E8%BF%90%E8%A1%8C%E7%9A%84/</guid>
      <description>
        
        
        &lt;p&gt;我们学院的一位教授之前去美国开会，入境的时候海关官员就问他：既然你会计算机，那你说说你用的都是什么语言吧？&lt;/p&gt;
&lt;p&gt;教授随口就答了个 Java。海关一看是懂行的，也就放行了，边敲章还边说他们上学那会学的是 C+。我还特意去查了下，真有叫 C+ 的语言，但是这里海关官员应该指的是 C++。&lt;/p&gt;
&lt;p&gt;事后教授告诉我们，他当时差点就问海关，是否知道 Java 和 C++ 在运行方式上的区别。但是又担心海关官员拿他的问题来考别人，也就没问出口。那么，下次你去美国，不幸地被海关官员问这个问题，你懂得如何回答吗？&lt;/p&gt;
&lt;p&gt;作为一名 Java 程序员，你应该知道，Java 代码有很多种不同的运行方式。比如说可以在开发工具中运行，可以双击执行 jar 文件运行，也可以在命令行中运行，甚至可以在网页中运行。当然，这些执行方式都离不开 JRE，也就是 Java 运行时环境。&lt;/p&gt;
&lt;p&gt;实际上，JRE 仅包含运行 Java 程序的必需组件，包括 Java 虚拟机以及 Java 核心类库等。我们 Java 程序员经常接触到的 JDK（Java 开发工具包）同样包含了 JRE，并且还附带了一系列开发、诊断工具。&lt;/p&gt;
&lt;p&gt;然而，运行 C++ 代码则无需额外的运行时。我们往往把这些代码直接编译成 CPU 所能理解的代码格式，也就是机器码。&lt;/p&gt;
&lt;p&gt;比如下图的中间列，就是用 C 语言写的 Helloworld 程序的编译结果。可以看到，C 程序编译而成的机器码就是一个个的字节，它们是给机器读的。那么为了让开发人员也能够理解，我们可以用反汇编器将其转换成汇编代码（如下图的最右列所示）。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;; 最左列是偏移；中间列是给机器读的机器码；最右列是给人读的汇编代码
0x00:  55                    push   rbp
0x01:  48 89 e5              mov    rbp,rsp
0x04:  48 83 ec 10           sub    rsp,0x10
0x08:  48 8d 3d 3b 00 00 00  lea    rdi,[rip+0x3b] 
                                    ; 加载 &amp;quot;Hello, World!\n&amp;quot;
0x0f:  c7 45 fc 00 00 00 00  mov    DWORD PTR [rbp-0x4],0x0
0x16:  b0 00                 mov    al,0x0
0x18:  e8 0d 00 00 00        call   0x12
                                    ; 调用 printf 方法
0x1d:  31 c9                 xor    ecx,ecx
0x1f:  89 45 f8              mov    DWORD PTR [rbp-0x8],eax
0x22:  89 c8                 mov    eax,ecx
0x24:  48 83 c4 10           add    rsp,0x10
0x28:  5d                    pop    rbp
0x29:  c3                    ret
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;既然 C++ 的运行方式如此成熟，那么你有没有想过，为什么 Java 要在虚拟机中运行呢，Java 虚拟机具体又是怎样运行 Java 代码的呢，它的运行效率又如何呢？&lt;/p&gt;
&lt;p&gt;今天我便从这几个问题入手，和你探讨一下，Java 执行系统的主流实现以及设计决策。&lt;/p&gt;
&lt;h2 id=&#34;为什么-java-要在虚拟机里运行&#34;&gt;为什么 Java 要在虚拟机里运行？&lt;/h2&gt;
&lt;p&gt;Java 作为一门高级程序语言，它的语法非常复杂，抽象程度也很高。因此，直接在硬件上运行这种复杂的程序并不现实。所以呢，在运行 Java 程序之前，我们需要对其进行一番转换。&lt;/p&gt;
&lt;p&gt;这个转换具体是怎么操作的呢？当前的主流思路是这样子的，设计一个面向 Java 语言特性的虚拟机，并通过编译器将 Java 程序转换成该虚拟机所能识别的指令序列，也称 Java 字节码。这里顺便说一句，之所以这么取名，是因为 Java 字节码指令的操作码（opcode）被固定为一个字节。&lt;/p&gt;
&lt;p&gt;举例来说，下图的中间列，正是用 Java 写的 Helloworld 程序编译而成的字节码。可以看到，它与 C 版本的编译结果一样，都是由一个个字节组成的。&lt;/p&gt;
&lt;p&gt;并且，我们同样可以将其反汇编为人类可读的代码格式（如下图的最右列所示）。不同的是，Java 版本的编译结果相对精简一些。这是因为 Java 虚拟机相对于物理机而言，抽象程度更高。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 最左列是偏移；中间列是给虚拟机读的机器码；最右列是给人读的代码
0x00:  b2 00 02         getstatic java.lang.System.out
0x03:  12 03            ldc &amp;quot;Hello, World!&amp;quot;
0x05:  b6 00 04         invokevirtual java.io.PrintStream.println
0x08:  b1               return
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Java 虚拟机可以由硬件实现 [1]，但更为常见的是在各个现有平台（如 Windows_x64、Linux_aarch64）上提供软件实现。这么做的意义在于，一旦一个程序被转换成 Java 字节码，那么它便可以在不同平台上的虚拟机实现里运行。这也就是我们经常说的&amp;quot;一次编写，到处运行&amp;quot;。&lt;/p&gt;
&lt;p&gt;虚拟机的另外一个好处是它带来了一个托管环境（Managed Runtime）。这个托管环境能够代替我们处理一些代码中冗长而且容易出错的部分。其中最广为人知的当属自动内存管理与垃圾回收，这部分内容甚至催生了一波垃圾回收调优的业务。&lt;/p&gt;
&lt;p&gt;除此之外，托管环境还提供了诸如数组越界、动态类型、安全权限等等的动态检测，使我们免于书写这些无关业务逻辑的代码。&lt;/p&gt;
&lt;h2 id=&#34;java-虚拟机具体是怎样运行-java-字节码的&#34;&gt;Java 虚拟机具体是怎样运行 Java 字节码的？&lt;/h2&gt;
&lt;p&gt;下面我将以标准 JDK 中的 HotSpot 虚拟机为例，从虚拟机以及底层硬件两个角度，给你讲一讲 Java 虚拟机具体是怎么运行 Java 字节码的。&lt;/p&gt;
&lt;p&gt;从虚拟机视角来看，执行 Java 代码首先需要将它编译而成的 class 文件加载到 Java 虚拟机中。加载后的 Java 类会被存放于方法区（Method Area）中。实际运行时，虚拟机会执行方法区内的代码。&lt;/p&gt;
&lt;p&gt;如果你熟悉 X86 的话，你会发现这和段式内存管理中的代码段类似。而且，Java 虚拟机同样也在内存中划分出堆和栈来存储运行时数据。&lt;/p&gt;
&lt;p&gt;不同的是，Java 虚拟机会将栈细分为面向 Java 方法的 Java 方法栈，面向本地方法（用 C++ 写的 native 方法）的本地方法栈，以及存放各个线程执行位置的 PC 寄存器。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/ab/77/ab5c3523af08e0bf2f689c1d6033ef77.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;在运行过程中，每当调用进入一个 Java 方法，Java 虚拟机会在当前线程的 Java 方法栈中生成一个栈帧，用以存放局部变量以及字节码的操作数。这个栈帧的大小是提前计算好的，而且 Java 虚拟机不要求栈帧在内存空间里连续分布。&lt;/p&gt;
&lt;p&gt;当退出当前执行的方法时，不管是正常返回还是异常返回，Java 虚拟机均会弹出当前线程的当前栈帧，并将之舍弃。&lt;/p&gt;
&lt;p&gt;从硬件视角来看，Java 字节码无法直接执行。因此，Java 虚拟机需要将字节码翻译成机器码。&lt;/p&gt;
&lt;p&gt;在 HotSpot 里面，上述翻译过程有两种形式：第一种是解释执行，即逐条将字节码翻译成机器码并执行；第二种是即时编译（Just-In-Time compilation，JIT），即将一个方法中包含的所有字节码编译成机器码后再执行。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/5e/3b/5ee351091464de78eed75438b6f9183b.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;前者的优势在于无需等待编译，而后者的优势在于实际运行速度更快。HotSpot 默认采用混合模式，综合了解释执行和即时编译两者的优点。它会先解释执行字节码，而后将其中反复执行的热点代码，以方法为单位进行即时编译。&lt;/p&gt;
&lt;h2 id=&#34;java-虚拟机的运行效率究竟是怎么样的&#34;&gt;Java 虚拟机的运行效率究竟是怎么样的？&lt;/h2&gt;
&lt;p&gt;HotSpot 采用了多种技术来提升启动性能以及峰值性能，刚刚提到的即时编译便是其中最重要的技术之一。&lt;/p&gt;
&lt;p&gt;即时编译建立在程序符合二八定律的假设上，也就是百分之二十的代码占据了百分之八十的计算资源。&lt;/p&gt;
&lt;p&gt;对于占据大部分的不常用的代码，我们无需耗费时间将其编译成机器码，而是采取解释执行的方式运行；另一方面，对于仅占据小部分的热点代码，我们则可以将其编译成机器码，以达到理想的运行速度。&lt;/p&gt;
&lt;p&gt;理论上讲，即时编译后的 Java 程序的执行效率，是可能超过 C++ 程序的。这是因为与静态编译相比，即时编译拥有程序的运行时信息，并且能够根据这个信息做出相应的优化。&lt;/p&gt;
&lt;p&gt;举个例子，我们知道虚方法是用来实现面向对象语言多态性的。对于一个虚方法调用，尽管它有很多个目标方法，但在实际运行过程中它可能只调用其中的一个。&lt;/p&gt;
&lt;p&gt;这个信息便可以被即时编译器所利用，来规避虚方法调用的开销，从而达到比静态编译的 C++ 程序更高的性能。&lt;/p&gt;
&lt;p&gt;为了满足不同用户场景的需要，HotSpot 内置了多个即时编译器：C1、C2 和 Graal。Graal 是 Java 10 正式引入的实验性即时编译器，在专栏的第四部分我会详细介绍，这里暂不做讨论。&lt;/p&gt;
&lt;p&gt;之所以引入多个即时编译器，是为了在编译时间和生成代码的执行效率之间进行取舍。C1 又叫做 Client 编译器，面向的是对启动性能有要求的客户端 GUI 程序，采用的优化手段相对简单，因此编译时间较短。&lt;/p&gt;
&lt;p&gt;C2 又叫做 Server 编译器，面向的是对峰值性能有要求的服务器端程序，采用的优化手段相对复杂，因此编译时间较长，但同时生成代码的执行效率较高。&lt;/p&gt;
&lt;p&gt;从 Java 7 开始，HotSpot 默认采用分层编译的方式：热点方法首先会被 C1 编译，而后热点方法中的热点会进一步被 C2 编译。&lt;/p&gt;
&lt;p&gt;为了不干扰应用的正常运行，HotSpot 的即时编译是放在额外的编译线程中进行的。HotSpot 会根据 CPU 的数量设置编译线程的数目，并且按 1:2 的比例配置给 C1 及 C2 编译器。&lt;/p&gt;
&lt;p&gt;在计算资源充足的情况下，字节码的解释执行和即时编译可同时进行。编译完成后的机器码会在下次调用该方法时启用，以替换原本的解释执行。&lt;/p&gt;
&lt;h2 id=&#34;总结与实践&#34;&gt;总结与实践&lt;/h2&gt;
&lt;p&gt;今天我简单介绍了 Java 代码为何在虚拟机中运行，以及如何在虚拟机中运行。&lt;/p&gt;
&lt;p&gt;之所以要在虚拟机中运行，是因为它提供了可移植性。一旦 Java 代码被编译为 Java 字节码，便可以在不同平台上的 Java 虚拟机实现上运行。此外，虚拟机还提供了一个代码托管的环境，代替我们处理部分冗长而且容易出错的事务，例如内存管理。&lt;/p&gt;
&lt;p&gt;Java 虚拟机将运行时内存区域划分为五个部分，分别为方法区、堆、PC 寄存器、Java 方法栈和本地方法栈。Java 程序编译而成的 class 文件，需要先加载至方法区中，方能在 Java 虚拟机中运行。&lt;/p&gt;
&lt;p&gt;为了提高运行效率，标准 JDK 中的 HotSpot 虚拟机采用的是一种混合执行的策略。&lt;/p&gt;
&lt;p&gt;它会解释执行 Java 字节码，然后会将其中反复执行的热点代码，以方法为单位进行即时编译，翻译成机器码后直接运行在底层硬件之上。&lt;/p&gt;
&lt;p&gt;HotSpot 装载了多个不同的即时编译器，以便在编译时间和生成代码的执行效率之间做取舍。&lt;/p&gt;
&lt;p&gt;下面我给你留一个小作业，通过观察两个条件判断语句的运行结果，来思考 Java 语言和 Java 虚拟机看待 boolean 类型的方式是否不同。&lt;/p&gt;
&lt;p&gt;下载 asmtools.jar [2] ，并在命令行中运行下述指令（不包含提示符 $）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ echo &#39;
public class Foo {
 public static void main(String[] args) {
  boolean flag = true;
  if (flag) System.out.println(&amp;quot;Hello, Java!&amp;quot;);
  if (flag == true) System.out.println(&amp;quot;Hello, JVM!&amp;quot;);
 }
}&#39; &amp;gt; Foo.java
$ javac Foo.java
$ java Foo
$ java -cp /path/to/asmtools.jar org.openjdk.asmtools.jdis.Main Foo.class &amp;gt; Foo.jasm.1
$ awk &#39;NR==1,/iconst_1/{sub(/iconst_1/, &amp;quot;iconst_2&amp;quot;)} 1&#39; Foo.jasm.1 &amp;gt; Foo.jasm
$ java -cp /path/to/asmtools.jar org.openjdk.asmtools.jasm.Main Foo.jasm
$ java Foo
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;[1] : &lt;a href=&#34;https://en.wikipedia.org/wiki/Java_processor&#34;&gt;https://en.wikipedia.org/wiki/Java_processor&lt;/a&gt;&lt;br&gt;
[2]: &lt;a href=&#34;https://wiki.openjdk.java.net/display/CodeTools/asmtools&#34;&gt;https://wiki.openjdk.java.net/display/CodeTools/asmtools&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/2a/d5/2a62e58cbdf56a5dc40748567d346fd5.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 01丨为什么要学习数据结构和算法？</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/01%E4%B8%A8%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%AD%A6%E4%B9%A0%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/01%E4%B8%A8%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%AD%A6%E4%B9%A0%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/</guid>
      <description>
        
        
        &lt;p&gt;你是不是觉得数据结构和算法，跟操作系统、计算机网络一样，是脱离实际工作的知识？可能除了面试，这辈子也用不着？&lt;/p&gt;
&lt;p&gt;尽管计算机相关专业的同学在大学都学过这门课程，甚至很多培训机构也会培训这方面的知识，但是据我了解，很多程序员对数据结构和算法依旧一窍不通。还有一些人也只听说过数组、链表、快排这些最最基本的数据结构和算法，稍微复杂一点的就完全没概念。&lt;/p&gt;
&lt;p&gt;当然，也有很多人说，自己实际工作中根本用不到数据结构和算法。所以，就算不懂这块知识，只要 Java API、开发框架用得熟练，照样可以把代码写得&amp;quot;飞&amp;quot;起来。事实真的是这样吗？&lt;/p&gt;
&lt;p&gt;今天我们就来详细聊一聊，为什么要学习数据结构和算法。&lt;/p&gt;
&lt;h2 id=&#34;想要通关大厂面试千万别让数据结构和算法拖了后腿&#34;&gt;想要通关大厂面试，千万别让数据结构和算法拖了后腿&lt;/h2&gt;
&lt;p&gt;很多大公司，比如 BAT、Google、Facebook，面试的时候都喜欢考算法、让人现场写代码。有些人虽然技术不错，但每次去面试都会&amp;quot;跪&amp;quot;在算法上，很是可惜。那你有没有想过，为什么这些大公司都喜欢考算法呢？&lt;/p&gt;
&lt;p&gt;校招的时候，参加面试的学生通常没有实际项目经验，公司只能考察他们的基础知识是否牢固。社招就更不用说了，越是厉害的公司，越是注重考察数据结构与算法这类基础知识。相比短期能力，他们更看中你的长期潜力。&lt;/p&gt;
&lt;p&gt;你可能要说了，我不懂数据结构与算法，照样找到了好工作啊。那我是不是就不用学数据结构和算法呢？当然不是，你别忘了，&lt;strong&gt;我们学任何知识都是为了&amp;quot;用&amp;quot;的，是为了解决实际工作问题的&lt;/strong&gt;，学习数据结构和算法自然也不例外。&lt;/p&gt;
&lt;h2 id=&#34;业务开发工程师你真的愿意做一辈子-crud-boy-吗&#34;&gt;业务开发工程师，你真的愿意做一辈子 CRUD boy 吗？&lt;/h2&gt;
&lt;p&gt;如果你是一名业务开发工程师，你可能要说，我整天就是做数据库 CRUD（增删改查），哪里用得到数据结构和算法啊？&lt;/p&gt;
&lt;p&gt;是的，对于大部分业务开发来说，我们平时可能更多的是利用已经封装好的现成的接口、类库来堆砌、翻译业务逻辑，很少需要自己实现数据结构和算法。但是，&lt;strong&gt;不需要自己实现，并不代表什么都不需要了解&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;如果不知道这些类库背后的原理，不懂得时间、空间复杂度分析，你如何能用好、用对它们？存储某个业务数据的时候，你如何知道应该用 ArrayList，还是 Linked List 呢？调用了某个函数之后，你又该如何评估代码的性能和资源的消耗呢？&lt;/p&gt;
&lt;p&gt;作为业务开发，我们会用到各种框架、中间件和底层系统，比如 Spring、RPC 框架、消息中间件、Redis 等等。&lt;strong&gt;在这些基础框架中，一般都揉和了很多基础数据结构和算法的设计思想。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;比如，我们常用的 Key-Value 数据库 Redis 中，里面的有序集合是用什么数据结构来实现的呢？为什么要用跳表来实现呢？为什么不用二叉树呢？&lt;/p&gt;
&lt;p&gt;如果你能弄明白这些底层原理，你就能更好地使用它们。即便出现问题，也很容易就能定位。因此，&lt;strong&gt;掌握数据结构和算法，不管对于阅读框架源码，还是理解其背后的设计思想，都是非常有用的。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在平时的工作中，数据结构和算法的应用到处可见。我来举一个你非常熟悉的例子：如何实时地统计业务接口的 99% 响应时间？&lt;/p&gt;
&lt;p&gt;你可能最先想到，每次查询时，从小到大排序所有的响应时间，如果总共有 1200 个数据，那第 1188 个数据就是 99% 的响应时间。很显然，每次用这个方法查询的话都要排序，效率是非常低的。但是，如果你知道&amp;quot;堆&amp;quot;这个数据结构，用两个堆可以非常高效地解决这个问题。&lt;/p&gt;
&lt;h2 id=&#34;基础架构研发工程师写出达到开源水平的框架才是你的目标&#34;&gt;基础架构研发工程师，写出达到开源水平的框架才是你的目标！&lt;/h2&gt;
&lt;p&gt;现在互联网上的技术文章、架构分享、开源项目满天飞，照猫画虎做一套基础框架并不难。我就拿 RPC 框架举例。&lt;/p&gt;
&lt;p&gt;不同的公司、不同的人做出的 RPC 框架，架构设计思路都差不多，最后实现的功能也都差不多。但是有的人做出来的框架，Bug 很多、性能一般、扩展性也不好，只能在自己公司仅有的几个项目里面用一下。而有的人做的框架可以开源到 GitHub 上给很多人用，甚至被 Apache 收录。为什么会有这么大的差距呢？&lt;/p&gt;
&lt;p&gt;我觉得，高手之间的竞争其实就在细节。这些细节包括：你用的算法是不是够优化，数据存取的效率是不是够高，内存是不是够节省等等。这些累积起来，决定了一个框架是不是优秀。所以，如果你还不懂数据结构和算法，没听说过大 O 复杂度分析，不知道怎么分析代码的时间复杂度和空间复杂度，那肯定说不过去了，赶紧来补一补吧！&lt;/p&gt;
&lt;h2 id=&#34;对编程还有追求不想被行业淘汰那就不要只会写凑合能用的代码&#34;&gt;对编程还有追求？不想被行业淘汰？那就不要只会写凑合能用的代码！&lt;/h2&gt;
&lt;p&gt;何为编程能力强？是代码的可读性好、健壮？还是扩展性好？我觉得没法列，也列不全。但是，在我看来，&lt;strong&gt;性能好坏起码是其中一个非常重要的评判标准&lt;/strong&gt;。但是，如果你连代码的时间复杂度、空间复杂度都不知道怎么分析，怎么写出高性能的代码呢？&lt;/p&gt;
&lt;p&gt;你可能会说，我在小公司工作，用户量很少，需要处理的数据量也很少，开发中不需要考虑那么多性能的问题，完成功能就可以，用什么数据结构和算法，差别根本不大。但是你真的想&amp;quot;十年如一日&amp;quot;地做一样的工作吗？&lt;/p&gt;
&lt;p&gt;经常有人说，程序员 35 岁之后很容易陷入瓶颈，被行业淘汰，我觉得原因其实就在此。有的人写代码的时候，从来都不考虑非功能性的需求，只是完成功能，凑合能用就好；做事情的时候，也从来没有长远规划，只把眼前事情做好就满足了。&lt;/p&gt;
&lt;p&gt;我曾经面试过很多大龄候选人，简历能写十几页，经历的项目有几十个，但是细看下来，每个项目都是重复地堆砌业务逻辑而已，完全没有难度递进，看不出有能力提升。久而久之，十年的积累可能跟一年的积累没有任何区别。这样的人，怎么不会被行业淘汰呢？&lt;/p&gt;
&lt;p&gt;如果你在一家成熟的公司，或者 BAT 这样的大公司，面对的是千万级甚至亿级的用户，开发的是 TB、PB 级别数据的处理系统。性能几乎是开发过程中时刻都要考虑的问题。一个简单的 ArrayList、Linked List 的选择问题，就可能会产生成千上万倍的性能差别。这个时候，数据结构和算法的意义就完全凸显出来了。&lt;/p&gt;
&lt;p&gt;其实，我觉得，数据结构和算法这个东西，如果你不去学，可能真的这辈子都用不到，也感受不到它的好。但是一旦掌握，你就会常常被它的强大威力所折服。之前你可能需要费很大劲儿来优化的代码，需要花很多心思来设计的架构，用了数据结构和算法之后，很容易就可以解决了。&lt;/p&gt;
&lt;h2 id=&#34;内容小结&#34;&gt;内容小结&lt;/h2&gt;
&lt;p&gt;我们学习数据结构和算法，并不是为了死记硬背几个知识点。我们的目的是建立时间复杂度、空间复杂度意识，写出高质量的代码，能够设计基础架构，提升编程技能，训练逻辑思维，积攒人生经验，以此获得工作回报，实现你的价值，完善你的人生。&lt;/p&gt;
&lt;p&gt;所以，不管你是业务开发工程师，还是基础架构工程师；不管你是初入职场的初级工程师，还是工作多年的资深架构师，又或者是想转人工智能、区块链这些热门领域的程序员，数据结构与算法作为计算机的基础知识、核心知识，都是必须要掌握的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;掌握了数据结构与算法，你看待问题的深度，解决问题的角度就会完全不一样&lt;/strong&gt;。因为这样的你，就像是站在巨人的肩膀上，拿着生存利器行走世界。数据结构与算法，会为你的编程之路，甚至人生之路打开一扇通往新世界的大门。&lt;/p&gt;
&lt;h2 id=&#34;课后思考&#34;&gt;课后思考&lt;/h2&gt;
&lt;p&gt;你为什么要学习数据结构和算法呢？在过去的软件开发中，数据结构和算法在哪些地方帮到了你？&lt;/p&gt;
&lt;p&gt;欢迎留言和我分享，我会第一时间给你反馈。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/8e/d3/8e603e3d795fc0ab2698f6f5eabf14d3.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 01丨基础架构：一条SQL查询语句是如何执行的？</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/01%E4%B8%A8%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%E4%B8%80%E6%9D%A1sql%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/01%E4%B8%A8%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%E4%B8%80%E6%9D%A1sql%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/</guid>
      <description>
        
        
        &lt;p&gt;你好，我是林晓斌。&lt;/p&gt;
&lt;p&gt;这是专栏的第一篇文章，我想来跟你聊聊 MySQL 的基础架构。我们经常说，看一个事儿千万不要直接陷入细节里，你应该先鸟瞰其全貌，这样能够帮助你从高维度理解问题。同样，对于 MySQL 的学习也是这样。平时我们使用数据库，看到的通常都是一个整体。比如，你有个最简单的表，表里只有一个 ID 字段，在执行下面这个查询语句时：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; select * from T where ID=10；
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们看到的只是输入一条语句，返回一个结果，却不知道这条语句在 MySQL 内部的执行过程。&lt;/p&gt;
&lt;p&gt;所以今天我想和你一起把 MySQL 拆解一下，看看里面都有哪些&amp;quot;零件&amp;quot;，希望借由这个拆解过程，让你对 MySQL 有更深入的理解。这样当我们碰到 MySQL 的一些异常或者问题时，就能够直戳本质，更为快速地定位并解决问题。&lt;/p&gt;
&lt;p&gt;下面我给出的是 MySQL 的基本架构示意图，从中你可以清楚地看到 SQL 语句在 MySQL 的各个功能模块中的执行过程。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/0d/d9/0d2070e8f84c4801adbfa03bda1f98d9.png&#34; alt=&#34;&#34;&gt;
MySQL 的逻辑架构图&lt;/p&gt;
&lt;p&gt;大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。&lt;/p&gt;
&lt;p&gt;Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。&lt;/p&gt;
&lt;p&gt;而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。&lt;/p&gt;
&lt;p&gt;也就是说，你执行 create table 建表的时候，如果不指定引擎类型，默认使用的就是 InnoDB。不过，你也可以通过指定存储引擎的类型来选择别的引擎，比如在 create table 语句中使用 engine=memory, 来指定使用内存引擎创建表。不同存储引擎的表数据存取方式不同，支持的功能也不同，在后面的文章中，我们会讨论到引擎的选择。&lt;/p&gt;
&lt;p&gt;从图中不难看出，不同的存储引擎共用一个&lt;strong&gt;Server 层&lt;/strong&gt;，也就是从连接器到执行器的部分。你可以先对每个组件的名字有个印象，接下来我会结合开头提到的那条 SQL 语句，带你走一遍整个执行流程，依次看下每个组件的作用。&lt;/p&gt;
&lt;h1 id=&#34;连接器&#34;&gt;连接器&lt;/h1&gt;
&lt;p&gt;第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接命令一般是这么写的：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql -h$ip -P$port -u$user -p
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;输完命令之后，你就需要在交互对话里面输入密码。虽然密码也可以直接跟在 -p 后面写在命令行中，但这样可能会导致你的密码泄露。如果你连的是生产服务器，强烈建议你不要这么做。&lt;/p&gt;
&lt;p&gt;连接命令中的 mysql 是客户端工具，用来跟服务端建立连接。在完成经典的 TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果用户名或密码不对，你就会收到一个&amp;quot;Access denied for user&amp;quot;的错误，然后客户端程序结束执行。&lt;/li&gt;
&lt;li&gt;如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。&lt;/p&gt;
&lt;p&gt;连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 show processlist 命令中看到它。文本中这个图是 show processlist 的结果，其中的 Command 列显示为&amp;quot;Sleep&amp;quot;的这一行，就表示现在系统里面有一个空闲连接。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/f2/ed/f2da4aa3a672d48ec05df97b9f992fed.png&#34; alt=&#34;&#34;&gt;&lt;br&gt;
客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 wait_timeout 控制的，默认值是 8 小时。&lt;/p&gt;
&lt;p&gt;如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒： Lost connection to MySQL server during query。这时候如果你要继续，就需要重连，然后再执行请求了。&lt;/p&gt;
&lt;p&gt;数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。&lt;/p&gt;
&lt;p&gt;建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是尽量使用长连接。&lt;/p&gt;
&lt;p&gt;但是全部使用长连接后，你可能会发现，有些时候 MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了。&lt;/p&gt;
&lt;p&gt;怎么解决这个问题呢？你可以考虑以下两种方案。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;查询缓存&#34;&gt;查询缓存&lt;/h1&gt;
&lt;p&gt;连接建立完成后，你就可以执行 select 语句了。执行逻辑就会来到第二步：查询缓存。&lt;/p&gt;
&lt;p&gt;MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。&lt;/p&gt;
&lt;p&gt;如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。你可以看到，如果查询命中缓存，MySQL 不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。&lt;/p&gt;
&lt;p&gt;好在 MySQL 也提供了这种&amp;quot;按需使用&amp;quot;的方式。你可以将参数 query_cache_type 设置成 DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定，像下面这个语句一样：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; select SQL_CACHE * from T where ID=10；
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;需要注意的是，MySQL 8.0 版本直接将查询缓存的整块功能删掉了，也就是说 8.0 开始彻底没有这个功能了。&lt;/p&gt;
&lt;h1 id=&#34;分析器&#34;&gt;分析器&lt;/h1&gt;
&lt;p&gt;如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL 需要知道你要做什么，因此需要对 SQL 语句做解析。&lt;/p&gt;
&lt;p&gt;分析器先会做&amp;quot;词法分析&amp;quot;。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。&lt;/p&gt;
&lt;p&gt;MySQL 从你输入的&amp;quot;select&amp;quot;这个关键字识别出来，这是一个查询语句。它也要把字符串&amp;quot;T&amp;quot;识别成&amp;quot;表名 T&amp;quot;，把字符串&amp;quot;ID&amp;quot;识别成&amp;quot;列 ID&amp;quot;。&lt;/p&gt;
&lt;p&gt;做完了这些识别以后，就要做&amp;quot;语法分析&amp;quot;。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。&lt;/p&gt;
&lt;p&gt;如果你的语句不对，就会收到&amp;quot;You have an error in your SQL syntax&amp;quot;的错误提醒，比如下面这个语句 select 少打了开头的字母&amp;quot;s&amp;quot;。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; elect * from t where ID=1;
 
ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &#39;elect * from t where ID=1&#39; at line 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;一般语法错误会提示第一个出现错误的位置，所以你要关注的是紧接&amp;quot;use near&amp;quot;的内容。&lt;/p&gt;
&lt;h1 id=&#34;优化器&#34;&gt;优化器&lt;/h1&gt;
&lt;p&gt;经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。&lt;/p&gt;
&lt;p&gt;优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。比如你执行下面这样的语句，这个语句是执行两个表的 join：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; select * from t1 join t2 using(ID)  where t1.c=10 and t2.d=20;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;既可以先从表 t1 里面取出 c=10 的记录的 ID 值，再根据 ID 值关联到表 t2，再判断 t2 里面 d 的值是否等于 20。&lt;/li&gt;
&lt;li&gt;也可以先从表 t2 里面取出 d=20 的记录的 ID 值，再根据 ID 值关联到 t1，再判断 t1 里面 c 的值是否等于 10。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。&lt;/p&gt;
&lt;p&gt;优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段。如果你还有一些疑问，比如优化器是怎么选择索引的，有没有可能选择错等等，没关系，我会在后面的文章中单独展开说明优化器的内容。&lt;/p&gt;
&lt;h1 id=&#34;执行器&#34;&gt;执行器&lt;/h1&gt;
&lt;p&gt;MySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。&lt;/p&gt;
&lt;p&gt;开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示 (在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; select * from T where ID=10;
 
ERROR 1142 (42000): SELECT command denied to user &#39;b&#39;@&#39;localhost&#39; for table &#39;T&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。&lt;/p&gt;
&lt;p&gt;比如我们这个例子中的表 T 中，ID 字段没有索引，那么执行器的执行流程是这样的：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;调用引擎接口取&amp;quot;下一行&amp;quot;，重复相同的判断逻辑，直到取到这个表的最后一行。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;至此，这个语句就执行完成了。&lt;/p&gt;
&lt;p&gt;对于有索引的表，执行的逻辑也差不多。第一次调用的是&amp;quot;取满足条件的第一行&amp;quot;这个接口，之后循环取&amp;quot;满足条件的下一行&amp;quot;这个接口，这些接口都是引擎中已经定义好的。&lt;/p&gt;
&lt;p&gt;你会在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。&lt;/p&gt;
&lt;p&gt;在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此**引擎扫描行数跟 rows_examined 并不是完全相同的。**我们后面会专门有一篇文章来讲存储引擎的内部机制，里面会有详细的说明。&lt;/p&gt;
&lt;h1 id=&#34;小结&#34;&gt;小结&lt;/h1&gt;
&lt;p&gt;今天我给你介绍了 MySQL 的逻辑架构，希望你对一个 SQL 语句完整执行流程的各个阶段有了一个初步的印象。由于篇幅的限制，我只是用一个查询的例子将各个环节过了一遍。如果你还对每个环节的展开细节存有疑问，也不用担心，后续在实战章节中我还会再提到它们。&lt;/p&gt;
&lt;p&gt;我给你留一个问题吧，如果表 T 中没有字段 k，而你执行了这个语句 select * from T where k=1, 那肯定是会报&amp;quot;不存在这个列&amp;quot;的错误： &amp;ldquo;Unknown column &amp;lsquo;k&amp;rsquo; in &amp;lsquo;where clause&amp;rsquo;&amp;quot;。你觉得这个错误是在我们上面提到的哪个阶段报出来的呢？&lt;/p&gt;
&lt;p&gt;感谢你的收听，欢迎你给我留言，也欢迎分享给更多的朋友一起阅读。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/ce/d9/ce7f4e35916ed1aa49206a53a0547bd9.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 01丨是什么推动了单体应用到微服务架构的演进？</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/springclouod%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/01%E4%B8%A8%E6%98%AF%E4%BB%80%E4%B9%88%E6%8E%A8%E5%8A%A8%E4%BA%86%E5%8D%95%E4%BD%93%E5%BA%94%E7%94%A8%E5%88%B0%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E7%9A%84%E6%BC%94%E8%BF%9B/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/springclouod%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/01%E4%B8%A8%E6%98%AF%E4%BB%80%E4%B9%88%E6%8E%A8%E5%8A%A8%E4%BA%86%E5%8D%95%E4%BD%93%E5%BA%94%E7%94%A8%E5%88%B0%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E7%9A%84%E6%BC%94%E8%BF%9B/</guid>
      <description>
        
        
        &lt;p&gt;你好，我是姚秋辰。&lt;/p&gt;
&lt;p&gt;&amp;ldquo;微服务&amp;quot;是近些年在大型应用架构领域的一个热门话题，从实践领域来看，我们身边的一二线大厂也纷纷选择全面拥抱微服务。就拿国内 Java 系的一线大厂来说，如阿里系、美团点评、PDD 等，它们都将自己的核心业务系统构建在微服务架构之上。&lt;/p&gt;
&lt;p&gt;即便你是刚参加工作的萌新，也一定从铺天盖地的&amp;quot;微服务&amp;quot;相关信息流中了解到了这个名词的热度。谷歌搜索指数显示，自 2014 年起，微服务的搜索热度一路上升。&lt;br&gt;
&lt;img src=&#34;https://static001.geekbang.org/resource/image/61/2a/61efecb5f468ab50c767804cc8ea172a.jpg?wh=2284x1213&#34; alt=&#34;&#34;&gt;&lt;br&gt;
&amp;ldquo;微服务&amp;quot;的谷歌搜索指数&lt;/p&gt;
&lt;p&gt;其实，微服务并不是一个新兴的技术概念，很早之前它就已经进入了公众视野。&lt;/p&gt;
&lt;p&gt;早在 2012 年，一位叫做 Fred George 的技术专家就在一次大会上分享了自己的微服务落地经验，讲述他是如何带领团队将一个极度庞大的 J2EE 巨无霸程序，分解成 20 多个小服务的。作为微服务领域的先驱，他是这样描述微服务架构的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Micro Services Architecture - small, short lived services rather than SOA.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果你在工作中没有接触过微服务架构的系统，那么此时一定非常蒙圈，不明白大佬所说的微服务架构到底是什么。没关系，就让我带你去回顾微服务的发展历史，了解微服务解决了什么痛点；然后我们一道来分析微服务架构的优势，让你明白为什么如今一线大厂会采用微服务架构。&lt;/p&gt;
&lt;p&gt;那么，我们就从微服务架构的前世今生聊起吧。&lt;/p&gt;
&lt;h1 id=&#34;单体应用之殇&#34;&gt;单体应用之殇&lt;/h1&gt;
&lt;p&gt;在互联网技术发展的早期阶段，我们采用&amp;quot;单体应用&amp;quot;的方式来构建网络系统。你没看错，即便是如今的各大老牌互联网大厂，在当年也是从单体应用小作坊成长起来的。&lt;/p&gt;
&lt;p&gt;以 Java 单体应用为例，我们将业务逻辑打包在一起，做成一个 WAR 包部署到 Tomcat、JBoss 之类的容器中，对外提供服务。业务上了一定规模之后，再通过集群化水平扩展的方式，将单体应用部署到一个集群中，承接更大的用户访问量。&lt;/p&gt;
&lt;p&gt;然而，随着业务复杂度的进一步提升，单体应用在生产力和高可用性层面就面临了巨大的挑战。我在参加工作之初做过近五年的单体应用开发，深知其中的痛处。&lt;/p&gt;
&lt;p&gt;我刚毕业的时候，参与了一个巨无霸的电商套件的开发，那是一个标准的单体应用。整个开发加测试团队有 100 多号人，所有人的代码都提交到一个主干分支，每次 merge 代码都要面对各种代码冲突，开发过程中&lt;strong&gt;耗费了大量的沟通成本&lt;/strong&gt;。不仅如此，由于庞大的业务体系都部署在一个 WAR 包中，每一次提交代码都要执行 3 个小时的回归测试，不出错还好，一旦出错就要回炉重造。周而复始执行这套繁重的流程，研发效率非常低下，完全&lt;strong&gt;无法达到&amp;quot;快速迭代&amp;quot;的目的&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在上线阶段我们也经常碰到各类问题。我参与的这个单体应用的发布周期是 2 个月一次（这在单体应用中已经算是很快的发布节奏了），每次发布一旦出现 Bug，&lt;strong&gt;无法单独回滚&lt;/strong&gt;这个小改动，我必须将整个发布里所有的功能全部回滚，待问题修复之后再重新发布。更可悲的是，整个 WAR 包的服务经常因为一个小 Bug 导致团灭，曾经有一次，我提交了一个&amp;quot;数据批量导入导出&amp;quot;的代码改动，把一个隐蔽 Bug 发布到了线上，业务持续运行一段时间之后，JVM 内存发生了泄露，导致集群各节点的 HEALTHCHECK 失败服务被重启，进而影响到了所有服务。&lt;/p&gt;
&lt;p&gt;上面这些问题是不是很让人头痛？想要解决它们，我们就要用到一句老话，叫&amp;quot;大事化小，小事化了&amp;rdquo;。&lt;/p&gt;
&lt;p&gt;在架构领域，我的经验是&amp;quot;一切看似大到无法解决的问题，都可以通过逐一拆解、各个击破的方式来解决&amp;rdquo;。在&amp;quot;单体应用&amp;quot;这个问题上，我们可以采取&amp;quot;微服务&amp;quot;化的方式，通过将这个巨无霸应用拆分成各个独立的小型微服务应用，分而治之！&lt;/p&gt;
&lt;h1 id=&#34;微服务架构的优势&#34;&gt;微服务架构的优势&lt;/h1&gt;
&lt;p&gt;微服务架构是在 SOA（面向服务架构）之上做的进一步扩展。在一线实践中，我们通过领域建模等理论将一个大型应用拆分成了更细粒度且边界清晰的服务模块。而且，每个微服务都能被独立测试、独立部署，并借助 Docker 和 CI/CD（持续集成环境）完成快速上线，不必像单体应用一样经历繁琐的 release 流程和漫长的发布窗口。&lt;/p&gt;
&lt;p&gt;每个微服务就像一个&amp;quot;麻雀虽小、五脏俱全&amp;quot;的小王国，&lt;strong&gt;它拥有独立的代码库和数据库 Schema，通常由一个小规模的微服务技术团队全权负责，这个团队汇聚了产品、技术、架构等人员，采用 Scrum 之类的敏捷开发流程做快速迭代&lt;/strong&gt;。基于此，微服务具备了&amp;quot;独立演进&amp;quot;能力。&lt;/p&gt;
&lt;p&gt;如果你对微服务拆分比较感兴趣，我推荐你去了解&amp;quot;领域建模&amp;quot;和&amp;quot;领域模型驱动（DDD）&amp;ldquo;的相关知识，后续我也会在这个课程中写一篇扩展阅读，跟你分享互联网公司常用的服务拆分规划理论：主链路规划。&lt;/p&gt;
&lt;p&gt;你现在肯定在好奇，为什么能独立开发部署的&amp;quot;微服务&amp;quot;可以解决单体应用的痛点呢？从我自己的经验来说，我认为微服务架构有这样几个天然的优势：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;快速迭代 + 快速回滚&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;细粒度的可独立部署的小型服务，再加上敏捷开发模式的加持，可以让你对产品功能实现快速迭代。在互联网公司中，微服务团队通常以周甚至 0.5 周为时间单位进行快速迭代。如果迭代过程中发现线上 Bug，也可以在最短的时间内做线上回滚，并且不会影响到其他应用的正常发布。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;资源利用大大提高&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你可以将硬件等资源定向分配给需要用到资源的微服务，实现差异化的资源利用。在大厂的微服务体系中，我们会统计每个服务集群的线上压力水位，应用弹性计算技术在各个服务之间调配计算资源。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;大幅降低协作成本&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;代码库、数据库、编译打包从&amp;quot;共享&amp;quot;变为了&amp;quot;独享&amp;rdquo;，微服务团队也保持了小规模特战队的模式，进一步降低了组内组外的沟通协作成本。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;高可用&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;高可用是系统设计的第一目标，关于这一点，我想和你多介绍一些大厂微服务架构中的实践经验。通过这些介绍，让你对微服务化的必要性有更加深刻的认识。&lt;/p&gt;
&lt;p&gt;相比前牵一发而动全身的单体应用来说，我们可以通过很多技术手段对微服务施加个性化的保护措施，比如弹性机房水位调拨、流量整形、熔断降级。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;弹性机房水位调拨&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;弹性机房实现了计算资源的自动分配，这种弹性伸缩能力必须建立在微服务化的基础上。它可以根据每个微服务的重要程度（核心服务 vs 边缘业务）以及当前承接的用户访问压力，动态地将计算资源（如虚机、云存储）分配给需要资源的服务。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;流量整形&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;根据每个微服务承载能力的不同，控制外部流量抵达服务的速率。&amp;ldquo;限流&amp;quot;其实只是流量整形的一个场景，大型微服务的流量整形有很多种方式，比如匀速排队、流量预热、削峰填谷等等。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;熔断降级&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在流量高峰的时候，我们可以对边缘服务做人工降级，把计算资源腾挪给核心应用，降低核心服务的访问压力。除了人工降级以外，我们还可以为每个服务设置自动降级和熔断指标，比如当调用失败率达到某个阈值之后，开启自动降级措施，降低对下游业务的访问压力。&lt;/p&gt;
&lt;p&gt;我们只有把应用微服务化之后，才能更好地使用上面这些技术手段对业务系统做精细力度的保护，从而实现高可用的目标。&lt;/p&gt;
&lt;p&gt;到这里，相信你已经对微服务架构有了更深一步的认识。不过，任何事物都有其两面性，微服务不光有好的一面，也有很多问题等着我们去解决。比如集群环境下的服务治理、数据一致性、以及高并发场景下的服务容错等等。不过呢，你大可放心，这些问题都不算事儿，在实战环节我会教你如何使用 Spring Cloud 组件将其一一攻破。下节课，我们正式开启 Spring Cloud 的大门。&lt;/p&gt;
&lt;h1 id=&#34;总结&#34;&gt;总结&lt;/h1&gt;
&lt;p&gt;今天我带你了解了微服务架构，我们将单体应用和微服务架构做了个比较，分析了单体应用无法适应互联网快速迭代的痛点，以及微服务架构是如何利用灵巧敏捷的小规模服务，很好地适应了互联网行业的快速迭代和高可用保障的要求。&lt;/p&gt;
&lt;p&gt;总结来说，微服务架构是通过应用领域模型等理论，将庞大的单体应用拆分为更细粒度的小型服务，每个服务都可以独立部署、测试和发布，加之敏捷开发的推广，使得微服务很好地迎合了如今互联网行业快速试错、快速迭代的节奏，同时也保证了系统的可用性。&lt;/p&gt;
&lt;h1 id=&#34;思考题&#34;&gt;思考题&lt;/h1&gt;
&lt;p&gt;你的公司是否也采用了微服务架构呢？你能从技术角度分享一下公司项目的技术选型方案吗？欢迎你和我分享，我在留言区等你。&lt;/p&gt;
&lt;p&gt;好啦，这节课就结束啦，也欢迎你把这节课分享给更多对 Spring Cloud 感兴趣的朋友。我是姚秋辰，我们下节课再见！&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 01丨程序员如何用技术变现（上）</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/01%E4%B8%A8%E7%A8%8B%E5%BA%8F%E5%91%98%E5%A6%82%E4%BD%95%E7%94%A8%E6%8A%80%E6%9C%AF%E5%8F%98%E7%8E%B0%E4%B8%8A/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/01%E4%B8%A8%E7%A8%8B%E5%BA%8F%E5%91%98%E5%A6%82%E4%BD%95%E7%94%A8%E6%8A%80%E6%9C%AF%E5%8F%98%E7%8E%B0%E4%B8%8A/</guid>
      <description>
        
        
        &lt;p&gt;程序员用自己的技术变现，其实是一件天经地义的事儿。写程序是一门&amp;quot;手艺活儿&amp;quot;，那么作为手艺人，程序员当然可以做到靠自己的手艺和技能养活自己。&lt;/p&gt;
&lt;p&gt;然而，现在很多手艺人程序员却说自己是&amp;quot;码农&amp;quot;，编码的农民工，在工作上被各种使唤，各种加班，累得像个牲口。在职业发展上各种迷茫和彷徨，完全看不到未来的希望，更别说可以成为一个手艺人用自己的技能变现了。&lt;/p&gt;
&lt;p&gt;从大学时代帮人打字挣点零花钱，到逐渐通过自己的技能帮助别人，由此获得相对丰厚的收入，我在很早就意识到，从事编程这个事可以做到，完全靠自己的手艺、不依赖任何人或公司去生活的。&lt;/p&gt;
&lt;p&gt;这对于程序员来说，本就应该是件天经地义的事，只是好像并不是所有的程序员都能意识到自己的价值。这里，我想结合我的一些经历来跟你聊聊。当然，我的经历有限，也不一定全对，只希望能给你一个参考。&lt;/p&gt;
&lt;h1 id=&#34;学生时代&#34;&gt;学生时代&lt;/h1&gt;
&lt;p&gt;我是 1994 年上的大学，计算机科学软件专业。在 1996 年上大二的时候，因为五笔学得好打字很快，我应征到教务处帮忙，把一些文档录入到电脑里。打了三个月的字，学校按照每千字 10 元，给了我 1000 元钱。&lt;/p&gt;
&lt;p&gt;由于我的五笔越打越快，还会用 CCED 和 WPS 排版，于是引起了别人的注意，叫我帮忙去他的打字工作室，一个月收入 400 元。我的大学是在昆明上的，这相当于那会当地收入的中上水平了。&lt;/p&gt;
&lt;p&gt;后来，1997 年的时候，我帮一个开公司的老师写一些 MIS 软件，用 Delphi 和 PowerBuilder 写一些办公自动化和酒店管理的软件。一年后，老师给了我 2000 元钱。&lt;/p&gt;
&lt;p&gt;因为动手能力比较强，当时系上的老师要干个什么事都让我帮忙。而且，因为当时的计算机人才太少太少了，所以一些社会上的人需要开发软件或是解决技术问题也都会到大学来。基本上老师们也都推荐给我。&lt;/p&gt;
&lt;p&gt;还记得 1997 年老师推荐一个人来找我，问我会不会做网页？5 个静态页，10000 元钱。当时学校没教怎样做网页，我去书店找书看，结果发现书店里一本讲 HTML 的书都没有，只好回绝说&amp;quot;不会做&amp;quot;。一年后，我才发现原来这事简单得要命。&lt;/p&gt;
&lt;h1 id=&#34;初入职场&#34;&gt;初入职场&lt;/h1&gt;
&lt;p&gt;到了 1998 年，我毕业参加工作，在工商银行网络科。由于可以拨号上网，于是我做了一个个人主页，那时超级流行个人主页或个人网站。我一边收集网上的一些知识，一边学着做些花哨的东西，比如网页上的菜单什么的。&lt;/p&gt;
&lt;p&gt;在 2000 年时，机缘巧合我的网站被《电脑报》的编辑看到了，他写来邮件约我投稿。我就写了一些如何在网页上做菜单之类的小技术文章，每个月写个两三篇，这样每个月就有 300 元左右的稿费，当时我的月工资是 600 元。&lt;/p&gt;
&lt;p&gt;现在通过文章标题还能找到一两篇，比如《&lt;a href=&#34;http://www.yesky.com/251/142751all.shtml&#34;&gt;抽屉式菜单的设计&lt;/a&gt;》，已经是乱码一堆了。&lt;/p&gt;
&lt;p&gt;大学时代被人请去做事的经历对我影响很大，甚至在潜意识里完全影响了我如何规划自己的人生。虽然当时我还说不清楚，只是一种强烈的感觉&amp;mdash;&amp;mdash;我完全可以靠自己的手艺、不依赖任何人或公司去生活。&lt;/p&gt;
&lt;p&gt;我想这种感觉，我现在可以说清楚了，这种潜意识就是&amp;mdash;&amp;mdash;&lt;strong&gt;我完全没有必要通过打工听人安排而活着，而是反过来通过在公司工作提高自己的技能，让自己可以更为独立和自由地生活&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;因而，在工作当中，对于那些没什么技术含量的工作，我基本上就像是在学生时代那样交作业就好了。我想尽一切方法提高交作业的效率，比如，提高代码的重用度，能自动化的就自动化，和需求人员谈需求，简化掉需求，这样我就可以少干一些活了&amp;hellip;&amp;hellip;&lt;/p&gt;
&lt;p&gt;这样一来，&lt;strong&gt;我就可以有更多的时间，去研究公司里外那些更为核心更有技术含量的技术了&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在工作中，我总是能被别人和领导注意到，总是有比别人更多的时间去读书，去玩一些高技术含量的技术。当然，这种被&amp;quot;注意&amp;quot;，也不全然是一种好事。&lt;/p&gt;
&lt;p&gt;2002 年，我被外包到银行里做业务开发时，因为我完成项目的速度太快，所以，没事干，整天在用户那边看书，写别的代码练手，而被用户投诉&amp;quot;不务正业&amp;quot;。我当然对这样的投诉置之不理，还是我行我素，因为我的作业已交了，所以用户也就是说说罢了。&lt;/p&gt;
&lt;p&gt;同年，我到了一家新的很有技术含量的公司，他们在用 C 语言写一个可以把一堆 PC 机组成一个超级计算机，进行并行计算的公司项目。&lt;/p&gt;
&lt;p&gt;当我做完第一个项目时，有个公司里的牛人和我说，你用 Purify 测试一下你的代码有没有内存问题。Purify 是以前一个叫 Rational 的公司（后来被 IBM 收购）做的一个神器，有点像 Linux 开源的 Valgrind。&lt;/p&gt;
&lt;p&gt;用完以后，我觉得 Purify 太厉害了，于是把它的英文技术文档通读了一遍。经理看我很喜欢这个东西，就让我给公司里的人做个分享。我认真地准备了个 PPT，结果只来了一个 QA。&lt;/p&gt;
&lt;p&gt;我在一个大会议室就对着她一个人讲了一个半小时。这个 QA 对我说，&amp;ldquo;你的分享做得真好，条理性很强，也很清楚，我学到了很多东西&amp;rdquo;。&lt;/p&gt;
&lt;p&gt;有了这个正向反馈，我就把关于 Purify 的文章分享到了我的 CSDN 博客上，标题为《&lt;a href=&#34;http://blog.csdn.net/haoel/article/details/2900&#34;&gt;C/C++ 内存问题检查利器&amp;mdash;Purify&lt;/a&gt;》。可能因为这个软件是收费的，用的人不多，这篇文章的读者反响并不大。&lt;/p&gt;
&lt;p&gt;但是，2003 年的一天我很意外地接到了一个电话，是一个公司请我帮忙去给客户培训 Purify 这个软件。IBM 的培训太贵了，所以代理这个软件的公司为了成本问题，想找一个便宜的讲师。&lt;/p&gt;
&lt;p&gt;他们搜遍整个中国的互联网，只看到我的这篇文章，便通过 CSDN 找到我的联系方式，给我打了电话。最终，两天的培训价格税后一共 10000 元，而我当时的月薪只有 6000 元，还是税前。&lt;/p&gt;
&lt;p&gt;这件事儿让我在入行的时候就明白了一些道理。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;要去经历大多数人经历不到的，要把学习时间花在那些比较难的地方。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;要写文章就要写没有人写过的，或是别人写过，但我能写得更好的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;更重要的是，技术和知识完全是可以变现的。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;现在回想一下，技术和知识变现这件事儿，在 15 年前我就明白了，哈哈。&lt;/p&gt;
&lt;p&gt;随后，我在 CSDN 博客上发表了很多文章，有谈 C 语言编程修养的文章，也有一些 makefile/gdb 手册性的文章，还有在工作中遇到的各种坑。&lt;/p&gt;
&lt;p&gt;因为我分享的东西比较系统，也是独一份，所以，搜索引擎自然是最优化的（最好的 SEO 就是独一份）。我的文章经常因为访问量大被推到 CSDN 首页。因此，引来了各种培训公司和出版社，还有一些别的公司主动发来的招聘，以及其他一些程序员想伙同创业的各种信息。&lt;/p&gt;
&lt;p&gt;紧接着我了解到，出书作者收入太低（作者的收入有两种：一种是稿费，一页 30 元；一种是版税，也就 5% 左右），而培训公司的投入产出比明显高很多后，于是我开始接一些培训的事（频率不高），一年有个七八次。当时需求比较强的培训主要是在这几个技术方面，C/C++/Java、Unix 系统编程、多层软件架构、软件测试、软件工程等。&lt;/p&gt;
&lt;p&gt;我喜欢做企业内训，还有一个主要原因是，可以走到内部去了解各个企业在做的事和他们遇到的技术痛点，以及身在其中的工程师的想法。这极大地增加了我对社会的了解和认识。而同时，让我这个原本不善表达的技术人员，在语言组织和表达方面有了极大的提升。&lt;/p&gt;
&lt;p&gt;其间也有一些软件开发的私活儿，但我基本全部拒绝了。最主要的原因是，这些软件开发基本上都是功能性的开发，我从中无法得到成长。而且后期会有很多维护工作，虽然一个小项目可以挣十几万，但为此花费的时间都是我人生中最宝贵的时光，得不偿失。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;25~35 岁是每个人最宝贵的时光，应该用在刀刃上&lt;/strong&gt;。&lt;/p&gt;
&lt;h1 id=&#34;职业上升期&#34;&gt;职业上升期&lt;/h1&gt;
&lt;p&gt;因为有了这些经历，我感受到了一个人知识和技能的价值。我开始把我的时间投在一些主流、高级和比较有挑战性的技术上，这可以让我保持两件事儿：一个是技术和技能的领先，二是对技术本质和趋势的敏感度。&lt;/p&gt;
&lt;p&gt;因此，我有强烈的意愿去前沿的公司经历和学习这些东西。比如，我在汤森路透学到了人员团队管理上的各种知识和技巧，而亚马逊是让我提升最快的公司。虽说，亚马逊也有很多不好的东西，但是它的一些理念，的确让我的思维方式和思考问题的角度有了质的飞跃。&lt;/p&gt;
&lt;p&gt;所以后来，我开始对外输出的不仅仅是技术了，还有一些技术价值观上的东西。&lt;/p&gt;
&lt;p&gt;而从亚马逊到阿里巴巴是我在互联网行业的工作经历，这两段经历让我对这两家看似类似但内部完全不同的成功大公司，有了更为全面的了解和看法。&lt;/p&gt;
&lt;p&gt;这两种完全不一样甚至有些矛盾的玩法让我时常在思考着，大脑里就像两个小人在扳手腕一样，这可能是我从小被灌输的&amp;quot;标准答案&amp;quot;的思维方式所致。其实，这个世界本来就没什么标准答案，或是说，一个题目本来就可以有若干个正确答案，而且这些&amp;quot;正确答案&amp;quot;还很矛盾。&lt;/p&gt;
&lt;p&gt;于是，在我把一些价值观和思考记录下来的同时，我自然又被很多人关注到了，还吸引很多不同的思路在其中交织讨论。而从另外一方面来说，这对我来说是一个很好地补充，无论别人骂我也好，教育我也罢，他们都对我有帮助，大大地丰富了我思考问题的角度。&lt;/p&gt;
&lt;p&gt;这些经历从质上改善了我的思考方式，让我思考技术问题的角度都随之有了一个比较大的转变。而这个转变让我有了更高的思维高度和更为开阔的视野。&lt;/p&gt;
&lt;p&gt;可能是因为我有一些&amp;quot;独特&amp;quot;的想法，而且经历比较丰富，基础也比较扎实，使得我对技术人的认识和理解会更为透彻和深入。所以，也有了一些小名气。来找我做咨询和帮助解决问题的人越来越多，而我也开始收费收得越来越贵了。这里需要注意的是，我完全是被动收费高的。&lt;/p&gt;
&lt;p&gt;因为父亲的身体原因，我没有办法全职，所以成了一个自由人。而也正因如此，我才得以有机会可以为更多公司解决技术问题。2015 年，有家公司的后端系统一推广就挂，性能有问题，请我去看。&lt;/p&gt;
&lt;p&gt;我花了两天时间跟他们的工程师一起简单处理了一下，直接在生产线上重构，性能翻了 10 倍。虽然这么做有点 low，但当时完全是为了救急。公司老板很高兴，觉得他投的几百万推广费用有救了，一下给了我 10 万元。我说不用这么多的，1 万元就好了，结果他说就是这么多。&lt;strong&gt;我欣然接受了，当时心里有一种技术被尊重的感动&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;2016 年，某个公司需要做一个高并发方案，大概需要 2000 万 QPS，但是他们只能实现到 1200 万 QPS 左右。&lt;/p&gt;
&lt;p&gt;我花了两天时间做调研，分析性能原因，然后一天写了 700 多行代码。因为不想进入业务，所以我主要是优化了网络数据传输，让数据包尽量小，确保一个请求的响应在一个 MTU 内就传完。&lt;/p&gt;
&lt;p&gt;测试的时候，达到了 2500 万 QPS。于是老板给了我 20 万。&lt;/p&gt;
&lt;p&gt;这样的例子还有很多。上面的例子，我连钱都没谈就去做了，本来想着，也就最多 1 万元左右，没想到给我的酬劳大大超出了我的期望。&lt;/p&gt;
&lt;p&gt;这里，我想说的是，&lt;strong&gt;并不是社会不尊重程序员，只要你能帮上大忙，就一定会赢得别人的尊重&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;所以，我和一些人开玩笑说，&lt;strong&gt;我们可能都是在写一样的 for(int i=0; i&amp;lt;n; i++) 语句，但是，你写在那个地方一文不值，而我写在这个地方，这行代码就值 2000 元&lt;/strong&gt;。不要误会，我只是想用这种&amp;quot;鲜明的对比方式&amp;quot;来加强我的观点。&lt;/p&gt;
&lt;p&gt;上面就是我这 20 年来的经历。相信这类经历你也有过，或者你正在经历中，欢迎你也分享一下自己的经历和心得。&lt;/p&gt;
&lt;p&gt;那么，怎样能让自己的技术被尊重？如何通过技术和技能赚钱？下一篇文章中，我将对此做一些总结，希望对你有帮助。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/fc/e9/fcc761001867c60f526665e237f831e9.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 01丨预习篇·小鲸鱼大事记（一）：初出茅庐</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90-kubernetes/01%E4%B8%A8%E9%A2%84%E4%B9%A0%E7%AF%87%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%A4%A7%E4%BA%8B%E8%AE%B0%E4%B8%80%E5%88%9D%E5%87%BA%E8%8C%85%E5%BA%90/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90-kubernetes/01%E4%B8%A8%E9%A2%84%E4%B9%A0%E7%AF%87%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%A4%A7%E4%BA%8B%E8%AE%B0%E4%B8%80%E5%88%9D%E5%87%BA%E8%8C%85%E5%BA%90/</guid>
      <description>
        
        
        &lt;p&gt;你好，我是张磊。我今天分享的主题是：小鲸鱼大事记之初出茅庐。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如果我问你，现今最热门的服务器端技术是什么？想必你不假思索就能回答上来：当然是容器！可是，如果现在不是 2018 年而是 2013 年，你的回答还能这么斩钉截铁么？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;现在就让我们把时间拨回到五年前去看看吧。&lt;/p&gt;
&lt;p&gt;2013 年的后端技术领域，已经太久没有出现过令人兴奋的东西了。曾经被人们寄予厚望的云计算技术，也已经从当初虚无缥缈的概念蜕变成了实实在在的虚拟机和账单。而相比于的如日中天 AWS 和盛极一时的 OpenStack，以 Cloud Foundry 为代表的开源 PaaS 项目，却成为了当时云计算技术中的一股清流。&lt;/p&gt;
&lt;p&gt;这时，Cloud Foundry 项目已经基本度过了最艰难的概念普及和用户教育阶段，吸引了包括百度、京东、华为、IBM 等一大批国内外技术厂商，开启了以开源 PaaS 为核心构建平台层服务能力的变革。如果你有机会问问当时的云计算从业者们，他们十有八九都会告诉你：PaaS 的时代就要来了！&lt;/p&gt;
&lt;p&gt;这个说法其实一点儿没错，如果不是后来一个叫 Docker 的开源项目突然冒出来的话。&lt;/p&gt;
&lt;p&gt;事实上，当时还名叫 dotCloud 的 Docker 公司，也是这股 PaaS 热潮中的一份子。只不过相比于 Heroku、Pivotal、Red Hat 等 PaaS 弄潮儿们，dotCloud 公司实在是太微不足道了，而它的主打产品由于跟主流的 Cloud Foundry 社区脱节，长期以来也无人问津。眼看就要被如火如荼的 PaaS 风潮抛弃，dotCloud 公司却做出了这样一个决定：开源自己的容器项目 Docker。&lt;/p&gt;
&lt;p&gt;显然，这个决定在当时根本没人在乎。&lt;/p&gt;
&lt;p&gt;&amp;ldquo;容器&amp;quot;这个概念从来就不是什么新鲜的东西，也不是 Docker 公司发明的。即使在当时最热门的 PaaS 项目 Cloud Foundry 中，容器也只是其最底层、最没人关注的那一部分。说到这里，我正好以当时的事实标准 Cloud Foundry 为例，来解说一下 PaaS 技术。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;PaaS 项目被大家接纳的一个主要原因，就是它提供了一种名叫&amp;quot;应用托管&amp;quot;的能力。&lt;/strong&gt; 在当时，虚拟机和云计算已经是比较普遍的技术和服务了，那时主流用户的普遍用法，就是租一批 AWS 或者 OpenStack 的虚拟机，然后像以前管理物理服务器那样，用脚本或者手工的方式在这些机器上部署应用。&lt;/p&gt;
&lt;p&gt;当然，这个部署过程难免会碰到云端虚拟机和本地环境不一致的问题，所以当时的云计算服务，比的就是谁能更好地模拟本地服务器环境，能带来更好的&amp;quot;上云&amp;quot;体验。而 PaaS 开源项目的出现，就是当时解决这个问题的一个最佳方案。&lt;/p&gt;
&lt;p&gt;举个例子，虚拟机创建好之后，运维人员只需要在这些机器上部署一个 Cloud Foundry 项目，然后开发者只要执行一条命令就能把本地的应用部署到云上，这条命令就是：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cf push &amp;quot; 我的应用 &amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;是不是很神奇？&lt;/p&gt;
&lt;p&gt;事实上，&lt;strong&gt;像 Cloud Foundry 这样的 PaaS 项目，最核心的组件就是一套应用的打包和分发机制。&lt;/strong&gt; Cloud Foundry 为每种主流编程语言都定义了一种打包格式，而&amp;quot;cf push&amp;quot;的作用，基本上等同于用户把应用的可执行文件和启动脚本打进一个压缩包内，上传到云上 Cloud Foundry 的存储中。接着，Cloud Foundry 会通过调度器选择一个可以运行这个应用的虚拟机，然后通知这个机器上的 Agent 把应用压缩包下载下来启动。&lt;/p&gt;
&lt;p&gt;这时候关键来了，由于需要在一个虚拟机上启动很多个来自不同用户的应用，Cloud Foundry 会调用操作系统的 Cgroups 和 Namespace 机制为每一个应用单独创建一个称作&amp;quot;沙盒&amp;quot;的隔离环境，然后在&amp;quot;沙盒&amp;quot;中启动这些应用进程。这样，就实现了把多个用户的应用互不干涉地在虚拟机里批量地、自动地运行起来的目的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;这，正是 PaaS 项目最核心的能力。&lt;/strong&gt; 而这些 Cloud Foundry 用来运行应用的隔离环境，或者说&amp;quot;沙盒&amp;rdquo;，就是所谓的&amp;quot;容器&amp;quot;。&lt;/p&gt;
&lt;p&gt;而 Docker 项目，实际上跟 Cloud Foundry 的容器并没有太大不同，所以在它发布后不久，Cloud Foundry 的首席产品经理 James Bayer 就在社区里做了一次详细对比，告诉用户 Docker 实际上只是一个同样使用 Cgroups 和 Namespace 实现的&amp;quot;沙盒&amp;quot;而已，没有什么特别的黑科技，也不需要特别关注。&lt;/p&gt;
&lt;p&gt;然而，短短几个月，Docker 项目就迅速崛起了。它的崛起速度如此之快，以至于 Cloud Foundry 以及所有的 PaaS 社区还没来得及成为它的竞争对手，就直接被宣告出局了。那时候，一位多年的 PaaS 从业者曾经如此感慨道：这简直就是一场&amp;quot;降维打击&amp;quot;啊。&lt;/p&gt;
&lt;p&gt;难道这一次，连闯荡多年的&amp;quot;老江湖&amp;quot;James Bayer 也看走眼了么？&lt;/p&gt;
&lt;p&gt;并没有。&lt;/p&gt;
&lt;p&gt;事实上，Docker 项目确实与 Cloud Foundry 的容器在大部分功能和实现原理上都是一样的，可偏偏就是这剩下的一小部分不一样的功能，成了 Docker 项目接下来&amp;quot;呼风唤雨&amp;quot;的不二法宝。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;这个功能，就是 Docker 镜像。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;恐怕连 Docker 项目的作者 Solomon Hykes 自己当时都没想到，这个小小的创新，在短短几年内就如此迅速地改变了整个云计算领域的发展历程。&lt;/p&gt;
&lt;p&gt;我前面已经介绍过，PaaS 之所以能够帮助用户大规模部署应用到集群里，是因为它提供了一套应用打包的功能。可偏偏就是这个打包功能，却成了 PaaS 日后不断遭到用户诟病的一个&amp;quot;软肋&amp;quot;。&lt;/p&gt;
&lt;p&gt;出现这个问题的根本原因是，一旦用上了 PaaS，用户就必须为每种语言、每种框架，甚至每个版本的应用维护一个打好的包。这个打包过程，没有任何章法可循，更麻烦的是，明明在本地运行得好好的应用，却需要做很多修改和配置工作才能在 PaaS 里运行起来。而这些修改和配置，并没有什么经验可以借鉴，基本上得靠不断试错，直到你摸清楚了本地应用和远端 PaaS 匹配的&amp;quot;脾气&amp;quot;才能够搞定。&lt;/p&gt;
&lt;p&gt;最后结局就是，&amp;ldquo;cf push&amp;quot;确实是能一键部署了，但是为了实现这个一键部署，用户为每个应用打包的工作可谓一波三折，费尽心机。&lt;/p&gt;
&lt;p&gt;而&lt;strong&gt;Docker 镜像解决的，恰恰就是打包这个根本性的问题。&lt;/strong&gt; 所谓 Docker 镜像，其实就是一个压缩包。但是这个压缩包里的内容，比 PaaS 的应用可执行文件 + 启停脚本的组合就要丰富多了。实际上，大多数 Docker 镜像是直接由一个完整操作系统的所有文件和目录构成的，所以这个压缩包里的内容跟你本地开发和测试环境用的操作系统是完全一样的。&lt;/p&gt;
&lt;p&gt;这就有意思了：假设你的应用在本地运行时，能看见的环境是 CentOS 7.2 操作系统的所有文件和目录，那么只要用 CentOS 7.2 的 ISO 做一个压缩包，再把你的应用可执行文件也压缩进去，那么无论在哪里解压这个压缩包，都可以得到与你本地测试时一样的环境。当然，你的应用也在里面！&lt;/p&gt;
&lt;p&gt;这就是 Docker 镜像最厉害的地方：只要有这个压缩包在手，你就可以使用某种技术创建一个&amp;quot;沙盒&amp;rdquo;，在&amp;quot;沙盒&amp;quot;中解压这个压缩包，然后就可以运行你的程序了。&lt;/p&gt;
&lt;p&gt;更重要的是，这个压缩包包含了完整的操作系统文件和目录，也就是包含了这个应用运行所需要的所有依赖，所以你可以先用这个压缩包在本地进行开发和测试，完成之后，再把这个压缩包上传到云端运行。&lt;/p&gt;
&lt;p&gt;在这个过程中，你完全不需要进行任何配置或者修改，因为这个压缩包赋予了你一种极其宝贵的能力：本地环境和云端环境的高度一致！&lt;/p&gt;
&lt;p&gt;这，&lt;strong&gt;正是 Docker 镜像的精髓。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;那么，有了 Docker 镜像这个利器，PaaS 里最核心的打包系统一下子就没了用武之地，最让用户抓狂的打包过程也随之消失了。相比之下，在当今的互联网里，Docker 镜像需要的操作系统文件和目录，可谓唾手可得。&lt;/p&gt;
&lt;p&gt;所以，你只需要提供一个下载好的操作系统文件与目录，然后使用它制作一个压缩包即可，这个命令就是：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker build &amp;quot; 我的镜像 &amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;一旦镜像制作完成，用户就可以让 Docker 创建一个&amp;quot;沙盒&amp;quot;来解压这个镜像，然后在&amp;quot;沙盒&amp;quot;中运行自己的应用，这个命令就是：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker run &amp;quot; 我的镜像 &amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当然，docker run 创建的&amp;quot;沙盒&amp;quot;，也是使用 Cgroups 和 Namespace 机制创建出来的隔离环境。我会在后面的文章中，详细介绍这个机制的实现原理。&lt;/p&gt;
&lt;p&gt;所以，&lt;strong&gt;Docker 项目给 PaaS 世界带来的&amp;quot;降维打击&amp;quot;，其实是提供了一种非常便利的打包机制。这种机制直接打包了应用运行所需要的整个操作系统，从而保证了本地环境和云端环境的高度一致，避免了用户通过&amp;quot;试错&amp;quot;来匹配两种不同运行环境之间差异的痛苦过程。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;而对于开发者们来说，在终于体验到了生产力解放所带来的痛快之后，他们自然选择了用脚投票，直接宣告了 PaaS 时代的结束。&lt;/p&gt;
&lt;p&gt;不过，Docker 项目固然解决了应用打包的难题，但正如前面所介绍的那样，它并不能代替 PaaS 完成大规模部署应用的职责。&lt;/p&gt;
&lt;p&gt;遗憾的是，考虑到 Docker 公司是一个与自己有潜在竞争关系的商业实体，再加上对 Docker 项目普及程度的错误判断，Cloud Foundry 项目并没有第一时间使用 Docker 作为自己的核心依赖，去替换自己那套饱受诟病的打包流程。&lt;/p&gt;
&lt;p&gt;反倒是一些机敏的创业公司，纷纷在第一时间推出了 Docker 容器集群管理的开源项目（比如 Deis 和 Flynn），它们一般称自己为 CaaS，即 Container-as-a-Service，用来跟&amp;quot;过时&amp;quot;的 PaaS 们划清界限。&lt;/p&gt;
&lt;p&gt;而在 2014 年底的 DockerCon 上，Docker 公司雄心勃勃地对外发布了自家研发的&amp;quot;Docker 原生&amp;quot;容器集群管理项目 Swarm，不仅将这波&amp;quot;CaaS&amp;quot;热推向了一个前所未有的高潮，更是寄托了整个 Docker 公司重新定义 PaaS 的宏伟愿望。&lt;/p&gt;
&lt;p&gt;在 2014 年的这段巅峰岁月里，Docker 公司离自己的理想真的只有一步之遥。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;2013~2014 年，以 Cloud Foundry 为代表的 PaaS 项目，逐渐完成了教育用户和开拓市场的艰巨任务，也正是在这个将概念逐渐落地的过程中，应用&amp;quot;打包&amp;quot;困难这个问题，成了整个后端技术圈子的一块心病。&lt;/p&gt;
&lt;p&gt;Docker 项目的出现，则为这个根本性的问题提供了一个近乎完美的解决方案。这正是 Docker 项目刚刚开源不久，就能够带领一家原本默默无闻的 PaaS 创业公司脱颖而出，然后迅速占领了所有云计算领域头条的技术原因。&lt;/p&gt;
&lt;p&gt;而在成为了基础设施领域近十年难得一见的技术明星之后，dotCloud 公司则在 2013 年底大胆改名为 Docker 公司。不过，这个在当时就颇具争议的改名举动，也成为了日后容器技术圈风云变幻的一个关键伏笔。&lt;/p&gt;
&lt;h2 id=&#34;思考题&#34;&gt;思考题&lt;/h2&gt;
&lt;p&gt;你是否曾经研发过类似 PaaS 的项目？你碰到过应用打包的问题吗，又是如何解决的呢？&lt;/p&gt;
&lt;p&gt;感谢收听，欢迎你给我留言，也欢迎分享给更多的朋友一起阅读。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/47/55/47a6f3bf6b92d58512d5a2ed0a556f55.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 02丨Java的基本类型</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3jvm%E8%99%9A%E6%8B%9F%E6%9C%BA/02%E4%B8%A8java%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3jvm%E8%99%9A%E6%8B%9F%E6%9C%BA/02%E4%B8%A8java%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B/</guid>
      <description>
        
        
        &lt;p&gt;如果你了解面向对象语言的发展史，那你可能听说过 Smalltalk 这门语言。它的影响力之大，以至于之后诞生的面向对象语言，或多或少都借鉴了它的设计和实现。&lt;/p&gt;
&lt;p&gt;在 Smalltalk 中，所有的值都是对象。因此，许多人认为它是一门纯粹的面向对象语言。&lt;/p&gt;
&lt;p&gt;Java 则不同，它引进了八个基本类型，来支持数值计算。Java 这么做的原因主要是工程上的考虑，因为使用基本类型能够在执行效率以及内存使用两方面提升软件性能。&lt;/p&gt;
&lt;p&gt;今天，我们就来了解一下基本类型在 Java 虚拟机中的实现。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class Foo {
  public static void main(String[] args) {
    boolean 吃过饭没 = 2; // 直接编译的话 javac 会报错
    if (吃过饭没) System.out.println(&amp;quot; 吃了 &amp;quot;);
    if (true == 吃过饭没) System.out.println(&amp;quot; 真吃了 &amp;quot;);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在上一篇结尾的小作业里，我构造了这么一段代码，它将一个 boolean 类型的局部变量赋值为 2。为了方便记忆，我们给这个变量起个名字，就叫&amp;quot;吃过饭没&amp;quot;。&lt;/p&gt;
&lt;p&gt;赋值语句后边我设置了两个看似一样的 if 语句。第一个 if 语句，也就是直接判断&amp;quot;吃过饭没&amp;quot;，在它成立的情况下，代码会打印&amp;quot;吃了&amp;quot;。&lt;/p&gt;
&lt;p&gt;第二个 if 语句，也就是判断&amp;quot;吃过饭没&amp;quot;和 true 是否相等，在它成立的情况下，代码会打印&amp;quot;真吃了&amp;quot;。&lt;/p&gt;
&lt;p&gt;当然，直接编译这段代码，编译器是会报错的。所以，我迂回了一下，采用一个 Java 字节码的汇编工具，直接对字节码进行更改。&lt;/p&gt;
&lt;p&gt;那么问题就来了：当一个 boolean 变量的值是 2 时，它究竟是 true 还是 false 呢？&lt;/p&gt;
&lt;p&gt;如果你跑过这段代码，你会发现，问虚拟机&amp;quot;吃过饭没&amp;quot;，它会回答&amp;quot;吃了&amp;quot;，而问虚拟机&amp;quot;真（==）吃过饭没&amp;quot;，虚拟机则不会回答&amp;quot;真吃了&amp;quot;。&lt;/p&gt;
&lt;p&gt;那么虚拟机到底吃过没，下面我们来一起分析一下这背后的细节。&lt;/p&gt;
&lt;h2 id=&#34;java-虚拟机的-boolean-类型&#34;&gt;Java 虚拟机的 boolean 类型&lt;/h2&gt;
&lt;p&gt;首先，我们来看看 Java 语言规范以及 Java 虚拟机规范是怎么定义 boolean 类型的。&lt;/p&gt;
&lt;p&gt;在 Java 语言规范中，boolean 类型的值只有两种可能，它们分别用符号&amp;quot;true&amp;quot;和&amp;quot;false&amp;quot;来表示。显然，这两个符号是不能被虚拟机直接使用的。&lt;/p&gt;
&lt;p&gt;在 Java 虚拟机规范中，boolean 类型则被映射成 int 类型。具体来说，&amp;ldquo;true&amp;quot;被映射为整数 1，而&amp;quot;false&amp;quot;被映射为整数 0。这个编码规则约束了 Java 字节码的具体实现。&lt;/p&gt;
&lt;p&gt;举个例子，对于存储 boolean 数组的字节码，Java 虚拟机需保证实际存入的值是整数 1 或者 0。&lt;/p&gt;
&lt;p&gt;Java 虚拟机规范同时也要求 Java 编译器遵守这个编码规则，并且用整数相关的字节码来实现逻辑运算，以及基于 boolean 类型的条件跳转。这样一来，在编译而成的 class 文件中，除了字段和传入参数外，基本看不出 boolean 类型的痕迹了。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Foo.main 编译后的字节码
 0: iconst_2       // 我们用 AsmTools 更改了这一指令
 1: istore_1
 2: iload_1
 3: ifeq 14        // 第一个 if 语句，即操作数栈上数值为 0 时跳转
 6: getstatic java.lang.System.out
 9: ldc &amp;quot; 吃了 &amp;quot;
11: invokevirtual java.io.PrintStream.println
14: iload_1
15: iconst_1
16: if_icmpne 27   // 第二个 if 语句，即操作数栈上两个数值不相同时跳转
19: getstatic java.lang.System.out
22: ldc &amp;quot; 真吃了 &amp;quot;
24: invokevirtual java.io.PrintStream.println
27: return
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在前面的例子中，第一个 if 语句会被编译成条件跳转字节码 ifeq，翻译成人话就是说，如果局部变量&amp;quot;吃过饭没&amp;quot;的值为 0，那么跳过打印&amp;quot;吃了&amp;quot;的语句。&lt;/p&gt;
&lt;p&gt;而第二个 if 语句则会被编译成条件跳转字节码 if_icmpne，也就是说，如果局部变量的值和整数 1 不相等，那么跳过打印&amp;quot;真吃了&amp;quot;的语句。&lt;/p&gt;
&lt;p&gt;可以看到，Java 编译器的确遵守了相同的编码规则。当然，这个约束很容易绕开。除了我们小作业中用到的汇编工具 AsmTools 外，还有许多可以修改字节码的 Java 库，比如说 ASM &lt;a href=&#34;https://asm.ow2.io/&#34;&gt;[1]&lt;/a&gt;等。&lt;/p&gt;
&lt;p&gt;对于 Java 虚拟机来说，它看到的 boolean 类型，早已被映射为整数类型。因此，将原本声明为 boolean 类型的局部变量，赋值为除了 0、1 之外的整数值，在 Java 虚拟机看来是&amp;quot;合法&amp;quot;的。&lt;/p&gt;
&lt;p&gt;在我们的例子中，经过编译器编译之后，Java 虚拟机看到的不是在问&amp;quot;吃过饭没&amp;rdquo;，而是在问&amp;quot;吃过几碗饭&amp;quot;。也就是说，第一个 if 语句变成：你不会一碗饭都没吃吧。第二个 if 语句则变成：你吃过一碗饭了吗。&lt;/p&gt;
&lt;p&gt;如果我们约定俗成，每人每顿只吃一碗，那么第二个 if 语句还是有意义的。但如果我们打破常规，吃了两碗，那么较真的 Java 虚拟机就会将第二个 if 语句判定为假了。&lt;/p&gt;
&lt;h2 id=&#34;java-的基本类型&#34;&gt;Java 的基本类型&lt;/h2&gt;
&lt;p&gt;除了上面提到的 boolean 类型外，Java 的基本类型还包括整数类型 byte、short、char、int 和 long，以及浮点类型 float 和 double。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/77/45/77dfb788a8ad5877e77fc28ed2d51745.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Java 的基本类型都有对应的值域和默认值。可以看到，byte、short、int、long、float 以及 double 的值域依次扩大，而且前面的值域被后面的值域所包含。因此，从前面的基本类型转换至后面的基本类型，无需强制转换。另外一点值得注意的是，尽管他们的默认值看起来不一样，但在内存中都是 0。&lt;/p&gt;
&lt;p&gt;在这些基本类型中，boolean 和 char 是唯二的无符号类型。在不考虑违反规范的情况下，boolean 类型的取值范围是 0 或者 1。char 类型的取值范围则是 [0, 65535]。通常我们可以认定 char 类型的值为非负数。这种特性十分有用，比如说作为数组索引等。&lt;/p&gt;
&lt;p&gt;在前面的例子中，我们能够将整数 2 存储到一个声明为 boolean 类型的局部变量中。那么，声明为 byte、char 以及 short 的局部变量，是否也能够存储超出它们取值范围的数值呢？&lt;/p&gt;
&lt;p&gt;答案是可以的。而且，这些超出取值范围的数值同样会带来一些麻烦。比如说，声明为 char 类型的局部变量实际上有可能为负数。当然，在正常使用 Java 编译器的情况下，生成的字节码会遵守 Java 虚拟机规范对编译器的约束，因此你无须过分担心局部变量会超出它们的取值范围。&lt;/p&gt;
&lt;p&gt;Java 的浮点类型采用 IEEE 754 浮点数格式。以 float 为例，浮点类型通常有两个 0，+0.0F 以及 -0.0F。&lt;/p&gt;
&lt;p&gt;前者在 Java 里是 0，后者是符号位为 1、其他位均为 0 的浮点数，在内存中等同于十六进制整数 0x8000000（即 -0.0F 可通过 Float.intBitsToFloat(0x8000000) 求得）。尽管它们的内存数值不同，但是在 Java 中 +0.0F == -0.0F 会返回真。&lt;/p&gt;
&lt;p&gt;在有了 +0.0F 和 -0.0F 这两个定义后，我们便可以定义浮点数中的正无穷及负无穷。正无穷就是任意正浮点数（不包括 +0.0F）除以 +0.0F 得到的值，而负无穷是任意正浮点数除以 -0.0F 得到的值。在 Java 中，正无穷和负无穷是有确切的值，在内存中分别等同于十六进制整数 0x7F800000 和 0xFF800000。&lt;/p&gt;
&lt;p&gt;你也许会好奇，既然整数 0x7F800000 等同于正无穷，那么 0x7F800001 又对应什么浮点数呢？&lt;/p&gt;
&lt;p&gt;这个数字对应的浮点数是 NaN（Not-a-Number）。&lt;/p&gt;
&lt;p&gt;不仅如此，[0x7F800001, 0x7FFFFFFF] 和 [0xFF800001, 0xFFFFFFFF] 对应的都是 NaN。当然，一般我们计算得出的 NaN，比如说通过 +0.0F/+0.0F，在内存中应为 0x7FC00000。这个数值，我们称之为标准的 NaN，而其他的我们称之为不标准的 NaN。&lt;/p&gt;
&lt;p&gt;NaN 有一个有趣的特性：除了&amp;quot;!=&amp;ldquo;始终返回 true 之外，所有其他比较结果都会返回 false。&lt;/p&gt;
&lt;p&gt;举例来说，&amp;ldquo;NaN&amp;lt;1.0F&amp;quot;返回 false，而&amp;quot;NaN&amp;gt;=1.0F&amp;quot;同样返回 false。对于任意浮点数 f，不管它是 0 还是 NaN，&amp;ldquo;f!=NaN&amp;quot;始终会返回 true，而&amp;quot;f==NaN&amp;quot;始终会返回 false。&lt;/p&gt;
&lt;p&gt;因此，我们在程序里做浮点数比较的时候，需要考虑上述特性。在本专栏的第二部分，我会介绍这个特性给向量化比较带来什么麻烦。&lt;/p&gt;
&lt;h2 id=&#34;java-基本类型的大小&#34;&gt;Java 基本类型的大小&lt;/h2&gt;
&lt;p&gt;在第一篇中我曾经提到，Java 虚拟机每调用一个 Java 方法，便会创建一个栈帧。为了方便理解，这里我只讨论供解释器使用的解释栈帧（interpreted frame）。&lt;/p&gt;
&lt;p&gt;这种栈帧有两个主要的组成部分，分别是局部变量区，以及字节码的操作数栈。这里的局部变量是广义的，除了普遍意义下的局部变量之外，它还包含实例方法的&amp;quot;this 指针&amp;quot;以及方法所接收的参数。&lt;/p&gt;
&lt;p&gt;在 Java 虚拟机规范中，局部变量区等价于一个数组，并且可以用正整数来索引。除了 long、double 值需要用两个数组单元来存储之外，其他基本类型以及引用类型的值均占用一个数组单元。&lt;/p&gt;
&lt;p&gt;也就是说，boolean、byte、char、short 这四种类型，在栈上占用的空间和 int 是一样的，和引用类型也是一样的。因此，在 32 位的 HotSpot 中，这些类型在栈上将占用 4 个字节；而在 64 位的 HotSpot 中，他们将占 8 个字节。&lt;/p&gt;
&lt;p&gt;当然，这种情况仅存在于局部变量，而并不会出现在存储于堆中的字段或者数组元素上。对于 byte、char 以及 short 这三种类型的字段或者数组单元，它们在堆上占用的空间分别为一字节、两字节，以及两字节，也就是说，跟这些类型的值域相吻合。&lt;/p&gt;
&lt;p&gt;因此，当我们将一个 int 类型的值，存储到这些类型的字段或数组时，相当于做了一次隐式的掩码操作。举例来说，当我们把 0xFFFFFFFF（-1）存储到一个声明为 char 类型的字段里时，由于该字段仅占两字节，所以高两位的字节便会被截取掉，最终存入&amp;rdquo;\uFFFF&amp;rdquo;。&lt;/p&gt;
&lt;p&gt;boolean 字段和 boolean 数组则比较特殊。在 HotSpot 中，boolean 字段占用一字节，而 boolean 数组则直接用 byte 数组来实现。为了保证堆中的 boolean 值是合法的，HotSpot 在存储时显式地进行掩码操作，也就是说，只取最后一位的值存入 boolean 字段或数组中。&lt;/p&gt;
&lt;p&gt;讲完了存储，现在我来讲讲加载。Java 虚拟机的算数运算几乎全部依赖于操作数栈。也就是说，我们需要将堆中的 boolean、byte、char 以及 short 加载到操作数栈上，而后将栈上的值当成 int 类型来运算。&lt;/p&gt;
&lt;p&gt;对于 boolean、char 这两个无符号类型来说，加载伴随着零扩展。举个例子，char 的大小为两个字节。在加载时 char 的值会被复制到 int 类型的低二字节，而高二字节则会用 0 来填充。&lt;/p&gt;
&lt;p&gt;对于 byte、short 这两个类型来说，加载伴随着符号扩展。举个例子，short 的大小为两个字节。在加载时 short 的值同样会被复制到 int 类型的低二字节。如果该 short 值为非负数，即最高位为 0，那么该 int 类型的值的高二字节会用 0 来填充，否则用 1 来填充。&lt;/p&gt;
&lt;h2 id=&#34;总结与实践&#34;&gt;总结与实践&lt;/h2&gt;
&lt;p&gt;今天我介绍了 Java 里的基本类型。&lt;/p&gt;
&lt;p&gt;其中，boolean 类型在 Java 虚拟机中被映射为整数类型：&amp;ldquo;true&amp;quot;被映射为 1，而&amp;quot;false&amp;quot;被映射为 0。Java 代码中的逻辑运算以及条件跳转，都是用整数相关的字节码来实现的。&lt;/p&gt;
&lt;p&gt;除 boolean 类型之外，Java 还有另外 7 个基本类型。它们拥有不同的值域，但默认值在内存中均为 0。这些基本类型之中，浮点类型比较特殊。基于它的运算或比较，需要考虑 +0.0F、-0.0F 以及 NaN 的情况。&lt;/p&gt;
&lt;p&gt;除 long 和 double 外，其他基本类型与引用类型在解释执行的方法栈帧中占用的大小是一致的，但它们在堆中占用的大小确不同。在将 boolean、byte、char 以及 short 的值存入字段或者数组单元时，Java 虚拟机会进行掩码操作。在读取时，Java 虚拟机则会将其扩展为 int 类型。&lt;/p&gt;
&lt;p&gt;今天的动手环节，你可以观测一下，将 boolean 类型的值存入字段中时，Java 虚拟机所做的掩码操作。&lt;/p&gt;
&lt;p&gt;你可以将下面代码中 boolValue = true 里的 true 换为 2 或者 3，看看打印结果与你的猜测是否相符合。&lt;/p&gt;
&lt;p&gt;熟悉 Unsafe 的同学，可以使用 Unsafe.putBoolean 和 Unsafe.putByte 方法，看看还会不会做掩码操作。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class Foo {
  static boolean boolValue;
  public static void main(String[] args) {
    boolValue = true; // 将这个 true 替换为 2 或者 3，再看看打印结果
    if (boolValue) System.out.println(&amp;quot;Hello, Java!&amp;quot;);
    if (boolValue == true) System.out.println(&amp;quot;Hello, JVM!&amp;quot;);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/2a/d5/2a62e58cbdf56a5dc40748567d346fd5.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 02丨如何抓住重点，系统高效地学习数据结构与算法？</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/02%E4%B8%A8%E5%A6%82%E4%BD%95%E6%8A%93%E4%BD%8F%E9%87%8D%E7%82%B9%E7%B3%BB%E7%BB%9F%E9%AB%98%E6%95%88%E5%9C%B0%E5%AD%A6%E4%B9%A0%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/02%E4%B8%A8%E5%A6%82%E4%BD%95%E6%8A%93%E4%BD%8F%E9%87%8D%E7%82%B9%E7%B3%BB%E7%BB%9F%E9%AB%98%E6%95%88%E5%9C%B0%E5%AD%A6%E4%B9%A0%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/</guid>
      <description>
        
        
        &lt;p&gt;你是否曾跟我一样，因为看不懂数据结构和算法，而一度怀疑是自己太笨？实际上，很多人在第一次接触这门课时，都会有这种感觉，觉得数据结构和算法很抽象，晦涩难懂，宛如天书。正是这个原因，让很多初学者对这门课望而却步。&lt;/p&gt;
&lt;p&gt;我个人觉得，其实真正的原因是你&lt;strong&gt;没有找到好的学习方法&lt;/strong&gt; ，&lt;strong&gt;没有抓住学习的重点&lt;/strong&gt;。实际上，数据结构和算法的东西并不多，常用的、基础的知识点更是屈指可数。只要掌握了正确的学习方法，学起来并没有看上去那么难，更不需要什么高智商、厚底子。&lt;/p&gt;
&lt;p&gt;还记得大学里每次考前老师都要划重点吗？今天，我就给你划划我们这门课的重点，再告诉你一些我总结的学习小窍门。相信有了这些之后，你学起来就会有的放矢、事半功倍了。&lt;/p&gt;
&lt;h2 id=&#34;什么是数据结构什么是算法&#34;&gt;什么是数据结构？什么是算法？&lt;/h2&gt;
&lt;p&gt;大部分数据结构和算法教材，在开篇都会给这两个概念下一个明确的定义。但是，这些定义都很抽象，对理解这两个概念并没有实质性的帮助，反倒会让你陷入死抠定义的误区。毕竟，我们现在学习，并不是为了考试，所以，概念背得再牢，不会用也就没什么用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;虽然我们说没必要深挖严格的定义，但是这并不等于不需要理解概念。&lt;/strong&gt; 下面我就从广义和狭义两个层面，来帮你理解数据结构与算法这两个概念。&lt;/p&gt;
&lt;p&gt;从广义上讲，数据结构就是指一组数据的存储结构。算法就是操作数据的一组方法。&lt;/p&gt;
&lt;p&gt;图书馆储藏书籍你肯定见过吧？为了方便查找，图书管理员一般会将书籍分门别类进行&amp;quot;存储&amp;quot;。按照一定规律编号，就是书籍这种&amp;quot;数据&amp;quot;的存储结构。&lt;/p&gt;
&lt;p&gt;那我们如何来查找一本书呢？有很多种办法，你当然可以一本一本地找，也可以先根据书籍类别的编号，是人文，还是科学、计算机，来定位书架，然后再依次查找。笼统地说，这些查找方法都是算法。&lt;/p&gt;
&lt;p&gt;从狭义上讲，也就是我们专栏要讲的，是指某些著名的数据结构和算法，比如队列、栈、堆、二分查找、动态规划等。这些都是前人智慧的结晶，我们可以直接拿来用。我们要讲的这些经典数据结构和算法，都是前人从很多实际操作场景中抽象出来的，经过非常多的求证和检验，可以高效地帮助我们解决很多实际的开发问题。&lt;/p&gt;
&lt;p&gt;那数据结构和算法有什么关系呢？为什么大部分书都把这两个东西放到一块儿来讲呢？&lt;/p&gt;
&lt;p&gt;这是因为，数据结构和算法是相辅相成的。&lt;strong&gt;数据结构是为算法服务的，算法要作用在特定的数据结构之上。&lt;/strong&gt; 因此，我们无法孤立数据结构来讲算法，也无法孤立算法来讲数据结构。&lt;/p&gt;
&lt;p&gt;比如，因为数组具有随机访问的特点，常用的二分查找算法需要用数组来存储数据。但如果我们选择链表这种数据结构，二分查找算法就无法工作了，因为链表并不支持随机访问。&lt;/p&gt;
&lt;p&gt;数据结构是静态的，它只是组织数据的一种方式。如果不在它的基础上操作、构建算法，孤立存在的数据结构就是没用的。&lt;/p&gt;
&lt;p&gt;现在你对数据结构与算法是不是有了比较清晰的理解了呢？有了这些储备，下面我们来看看，究竟该怎么学数据结构与算法。&lt;/p&gt;
&lt;h2 id=&#34;学习这个专栏需要什么基础&#34;&gt;学习这个专栏需要什么基础？&lt;/h2&gt;
&lt;p&gt;看到数据结构和算法里的&amp;quot;算法&amp;quot;两个字，很多人就会联想到&amp;quot;数学&amp;quot;，觉得算法会涉及到很多深奥的数学知识。那我数学基础不是很好，学起来会不会很吃力啊？&lt;/p&gt;
&lt;p&gt;数据结构和算法课程确实会涉及一些数学方面的推理、证明，尤其是在分析某个算法的时间、空间复杂度的时候，但是这个你完全不需要担心。&lt;/p&gt;
&lt;p&gt;这个专栏不会像《算法导论》那样，里面有非常复杂的数学证明和推理。我会由浅入深，从概念到应用，一点一点给你解释清楚。你只要有高中数学水平，就完全可以学习。&lt;/p&gt;
&lt;p&gt;当然，我希望你最好有些编程基础，如果有项目经验就更好了。这样我给你讲数据结构和算法如何提高效率、如何节省存储空间，你就会有很直观的感受。因为，对于每个概念和实现过程，我都会从实际场景出发，不仅教你&amp;quot;&lt;strong&gt;是什么&lt;/strong&gt; &amp;ldquo;，还会教你&amp;rdquo;&lt;strong&gt;为什么&lt;/strong&gt; &amp;ldquo;，并且告诉你遇到同类型问题应该&amp;rdquo;&lt;strong&gt;怎么做&lt;/strong&gt;&amp;quot;。&lt;/p&gt;
&lt;h2 id=&#34;学习的重点在什么地方&#34;&gt;学习的重点在什么地方？&lt;/h2&gt;
&lt;p&gt;提到数据结构和算法，很多人就很头疼，因为这里面的内容实在是太多了。这里，我就帮你梳理一下，应该先学什么，后学什么。你可以对照看看，你属于哪个阶段，然后有针对地进行学习。&lt;/p&gt;
&lt;p&gt;想要学习数据结构与算法，&lt;strong&gt;首先要掌握一个数据结构与算法中最重要的概念&amp;mdash;&amp;mdash;复杂度分析。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这个概念究竟有多重要呢？可以这么说，它几乎占了数据结构和算法这门课的半壁江山，是数据结构和算法学习的精髓。&lt;/p&gt;
&lt;p&gt;数据结构和算法解决的是如何更省、更快地存储和处理数据的问题，因此，我们就需要一个考量效率和资源消耗的方法，这就是复杂度分析方法。所以，如果你只掌握了数据结构和算法的特点、用法，但是没有学会复杂度分析，那就相当于只知道操作口诀，而没掌握心法。只有把心法了然于胸，才能做到无招胜有招！&lt;/p&gt;
&lt;p&gt;所以，复杂度分析这个内容，我会用很大篇幅给你讲透。你也一定要花大力气来啃，必须要拿下，并且要搞得非常熟练。否则，后面的数据结构和算法也很难学好。&lt;/p&gt;
&lt;p&gt;搞定复杂度分析，下面就要进入&lt;strong&gt;数据结构与算法的正文内容&lt;/strong&gt;了。&lt;/p&gt;
&lt;p&gt;为了让你对数据结构和算法能有个全面的认识，我画了一张图，里面几乎涵盖了所有数据结构和算法书籍中都会讲到的知识点。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/91/a7/913e0ababe43a2d57267df5c5f0832a7.jpg&#34; alt=&#34;&#34;&gt;&lt;br&gt;
（图谱内容较多，建议长按保存后浏览）&lt;/p&gt;
&lt;p&gt;但是，作为初学者，或者一个非算法工程师来说，你并不需要掌握图里面的所有知识点。很多高级的数据结构与算法，比如二分图、最大流等，这些在我们平常的开发中很少会用到。所以，你暂时可以不用看。我还是那句话，咱们学习要学会找重点。如果不分重点地学习，眉毛胡子一把抓，学起来肯定会比较吃力。&lt;/p&gt;
&lt;p&gt;所以，结合我自己的学习心得，还有这些年的面试、开发经验，我总结了&lt;strong&gt;20 个最常用的、最基础&lt;/strong&gt; 数据结构与算法，&lt;strong&gt;不管是应付面试还是工作需要，只要集中精力逐一攻克这 20 个知识点就足够了。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这里面有 10 个数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie 树；10 个算法：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。&lt;/p&gt;
&lt;p&gt;掌握了这些基础的数据结构和算法，再学更加复杂的数据结构和算法，就会非常容易、非常快。&lt;/p&gt;
&lt;p&gt;在学习数据结构和算法的过程中，你也要注意，不要只是死记硬背，不要为了学习而学习，而是&lt;strong&gt;要学习它的&amp;quot;来历&amp;quot;&amp;ldquo;自身的特点&amp;quot;&amp;ldquo;适合解决的问题&amp;quot;以及&amp;quot;实际的应用场景&amp;rdquo;&lt;/strong&gt;。对于每一种数据结构或算法，我都会从这几个方面进行详细讲解。只要你掌握了我每节课里讲的内容，就能在开发中灵活应用。&lt;/p&gt;
&lt;p&gt;学习数据结构和算法的过程，是非常好的思维训练的过程，所以，千万不要被动地记忆，要多辩证地思考，多问为什么。如果你一直这么坚持做，你会发现，等你学完之后，写代码的时候就会不由自主地考虑到很多性能方面的事情，时间复杂度、空间复杂度非常高的垃圾代码出现的次数就会越来越少。你的编程内功就真正得到了修炼。&lt;/p&gt;
&lt;h2 id=&#34;一些可以让你事半功倍的学习技巧&#34;&gt;一些可以让你事半功倍的学习技巧&lt;/h2&gt;
&lt;p&gt;前面我给你划了学习的重点，也讲了学习这门课需要具备的基础。作为一个过来人，现在我就给你分享一下，专栏学习的一些技巧。掌握了这些技巧，可以让你化被动为主动，学起来更加轻松，更加有动力！&lt;/p&gt;
&lt;h3 id=&#34;1-边学边练适度刷题&#34;&gt;1. 边学边练，适度刷题&lt;/h3&gt;
&lt;p&gt;&amp;ldquo;边学边练&amp;quot;这一招非常有用。建议你每周花 1～2 个小时的时间，集中把这周的三节内容涉及的数据结构和算法，全都自己写出来，用代码实现一遍。这样一定会比单纯地看或者听的效果要好很多！&lt;/p&gt;
&lt;p&gt;有面试需求的同学，可能会问了，那我还要不要去刷题呢？&lt;/p&gt;
&lt;p&gt;我个人的观点是&lt;strong&gt;可以&amp;quot;适度&amp;quot;刷题，但一定不要浪费太多时间在刷题上&lt;/strong&gt; 。我们&lt;strong&gt;学习的目的还是掌握，然后应用&lt;/strong&gt;。除非你要面试 Google、Facebook 这样的公司，它们的算法题目非常非常难，必须大量刷题，才能在短期内提升应试正确率。如果是应对国内公司的技术面试，即便是 BAT 这样的公司，你只要彻底掌握这个专栏的内容，就足以应对。&lt;/p&gt;
&lt;h3 id=&#34;2-多问多思考多互动&#34;&gt;2. 多问、多思考、多互动&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;学习最好的方法是，找到几个人一起学习，一块儿讨论切磋，有问题及时寻求老师答疑。&lt;/strong&gt; 但是，离开大学之后，既没有同学也没有老师，这个条件就比较难具备了。&lt;/p&gt;
&lt;p&gt;不过，这也就是咱们专栏学习的优势。专栏里有很多跟你一样的学习者。你可以多在留言区写下自己的疑问、思考和总结，也可以经常看看别人的留言，和他们进行互动。&lt;/p&gt;
&lt;p&gt;除此之外，如果你有疑问，你可以随时在留言区给我留言，我只要有空就会及时回复你。你不要担心问的问题太小白。因为我初学的时候，也常常会被一些小白问题困扰。不懂一点都不丢人，只要你勇敢提出来，我们一起解决了就可以了。&lt;/p&gt;
&lt;p&gt;我也会力争每节课都最大限度地给你讲透，帮你扫除知识盲点，而你要做的就是，避免一知半解，要想尽一切办法去搞懂我讲的所有内容。&lt;/p&gt;
&lt;h3 id=&#34;3-打怪升级学习法&#34;&gt;3. 打怪升级学习法&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;学习的过程中，我们碰到最大的问题就是，坚持不下来。&lt;/strong&gt; 是的，很多基础课程学起来都非常枯燥。为此，我自己总结了一套&amp;quot;打怪升级学习法&amp;rdquo;。&lt;/p&gt;
&lt;p&gt;游戏你肯定玩过吧？为什么很多看起来非常简单又没有乐趣的游戏，你会玩得不亦乐乎呢？这是因为，当你努力打到一定级别之后，每天看着自己的经验值、战斗力在慢慢提高，那种每天都在一点一点成长的成就感就不由自主地产生了。&lt;/p&gt;
&lt;p&gt;所以，&lt;strong&gt;我们在枯燥的学习过程中，也可以给自己设立一个切实可行的目标&lt;/strong&gt;，就像打怪升级一样。&lt;/p&gt;
&lt;p&gt;比如，针对这个专栏，你就可以设立这样一个目标：每节课后的思考题都认真思考，并且回复到留言区。当你看到很多人给你点赞之后，你就会为了每次都能发一个漂亮的留言，而更加认真地学习。&lt;/p&gt;
&lt;p&gt;当然，还有很多其他的目标，比如，每节课后都写一篇学习笔记或者学习心得；或者你还可以每节课都找一下我讲得不对、不合理的地方&amp;hellip;&amp;hellip;诸如此类，你可以总结一个适合你的&amp;quot;打怪升级攻略&amp;rdquo;。&lt;/p&gt;
&lt;p&gt;如果你能这样学习一段时间，不仅能收获到知识，你还会有意想不到的成就感。因为，这其实帮你改掉了一点学习的坏习惯。这个习惯一旦改掉了，你的人生也会变得不一样。&lt;/p&gt;
&lt;h3 id=&#34;4-知识需要沉淀不要想试图一下子掌握所有&#34;&gt;4. 知识需要沉淀，不要想试图一下子掌握所有&lt;/h3&gt;
&lt;p&gt;在学习的过程中，一定会碰到&amp;quot;拦路虎&amp;quot;。如果哪个知识点没有怎么学懂，不要着急，这是正常的。因为，想听一遍、看一遍就把所有知识掌握，这肯定是不可能的。&lt;strong&gt;学习&lt;strong&gt;&lt;strong&gt;知识的&lt;/strong&gt;&lt;/strong&gt;过程是反复迭代、不断沉淀的过程。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果碰到&amp;quot;拦路虎&amp;quot;，你可以尽情地在留言区问我，也可以先沉淀一下，过几天再重新学一遍。所谓，书读百遍其义自见，我觉得是很有道理的！&lt;/p&gt;
&lt;p&gt;我讲的这些学习方法，不仅仅针对咱们这一个课程的学习，其实完全适用任何知识的学习过程。你可以通过这个专栏的学习，实践一下这些方法。如果效果不错，再推广到之后的学习过程中。&lt;/p&gt;
&lt;h2 id=&#34;内容小结&#34;&gt;内容小结&lt;/h2&gt;
&lt;p&gt;今天，我带你划了划数据结构和算法的学习重点，复杂度分析，以及 10 个数据结构和 10 个算法。&lt;/p&gt;
&lt;p&gt;这些内容是我根据平时的学习和工作、面试经验积累，精心筛选出来的。只要掌握这些内容，应付日常的面试、工作，基本不会有问题。&lt;/p&gt;
&lt;p&gt;除此之外，我还给你分享了我总结的一些学习技巧，比如边学边练、多问、多思考，还有两个比较通用的学习方法，打怪升级法和沉淀法。掌握了这些学习技巧，可以让你学习过程中事半功倍。所以，你一定要好好实践哦！&lt;/p&gt;
&lt;h2 id=&#34;课后思考&#34;&gt;课后思考&lt;/h2&gt;
&lt;p&gt;今天的内容是一个准备课，从下节开始，我们就要正式开始学习精心筛选出的这 20 个数据结构和算法了。所以，今天给你布置一个任务，对照我上面讲的&amp;quot;打怪升级学习法&amp;quot;，请思考一下你自己学习这个专栏的方法，让我们一起在留言区立下 Flag，相互鼓励！&lt;/p&gt;
&lt;p&gt;另外，你在之前学习数据结构和算法的过程中，遇到过什么样的困难或者疑惑吗？&lt;/p&gt;
&lt;p&gt;欢迎留言和我分享，我会第一时间给你反馈。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/8e/d3/8e603e3d795fc0ab2698f6f5eabf14d3.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 02丨微服务全家桶：走进SpringCloud的世界</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/springclouod%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/02%E4%B8%A8%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%85%A8%E5%AE%B6%E6%A1%B6%E8%B5%B0%E8%BF%9Bspringcloud%E7%9A%84%E4%B8%96%E7%95%8C/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/springclouod%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/02%E4%B8%A8%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%85%A8%E5%AE%B6%E6%A1%B6%E8%B5%B0%E8%BF%9Bspringcloud%E7%9A%84%E4%B8%96%E7%95%8C/</guid>
      <description>
        
        
        &lt;p&gt;你好，我是姚秋辰。&lt;/p&gt;
&lt;p&gt;上一节课，我向你介绍了微服务架构的特点和优势。今天我就来带你了解 Spring Cloud 框架，看一看被称为微服务全家桶的 Spring Cloud 提供了哪些强大的工具。&lt;/p&gt;
&lt;p&gt;通过今天的学习，你将会了解 Spring Cloud 框架的功能定位，以及它和 Spring Boot 之间的关系。除此之外，我还会详细讲解 Spring Cloud 的发展历史，并介绍 Netflix 和 Alibaba 两大核心组件库，以及 Spring Cloud 的版本更新策略。这样一来，你就对 Spring Cloud 框架有了一个全面的认识。&lt;/p&gt;
&lt;p&gt;那我首先来带你了解一下什么是 Spring Cloud。&lt;/p&gt;
&lt;h1 id=&#34;大话-spring-cloud&#34;&gt;大话 Spring Cloud&lt;/h1&gt;
&lt;p&gt;Spring Cloud 可谓出身名门，它由 Spring 开源社区主导孵化的，专门为了解决微服务架构难题而诞生的一款微&amp;quot;微服务全家桶&amp;quot;框架。难能可贵的是，Spring Cloud 走了一条博采众家之长的道路，除了 Spring 开源社区的研发力量以外，它还吸纳了很多业界一线互联网大厂的开源组件为己用，将这些经过大厂真实业务锤炼的组件孵化成为了 Spring Cloud 组件的一部分。&lt;/p&gt;
&lt;p&gt;我们通过 Spring 社区发布的一张简化的架构图来看一下 Spring Cloud 的技能加点。&lt;br&gt;
&lt;img src=&#34;https://static001.geekbang.org/resource/image/50/36/50dc50b943a1d68e1b9682f573e51736.jpg?wh=2000x1194&#34; alt=&#34;&#34;&gt;&lt;br&gt;
Spring社区发布的一张简化的架构图&lt;/p&gt;
&lt;p&gt;在上面这幅图中，我们可以看到有几个 Spring Boot Apps 的应用集群，这就是经过拆分后的微服务。Spring Cloud 和 Spring Boot 达成了一种默契的配合：Spring Boot 主内，通过自动装配和各种开箱即用的特性，搞定了数据层访问、RESTful 接口、日志组件、内置容器等等基础功能，让开发人员不费吹灰之力就可以搭建起一个应用；Spring Cloud 主外，在应用集群之外提供了各种分布式系统的支持特性，帮助你轻松实现负载均衡、熔断降级、配置管理等诸多微服务领域的功能。&lt;/p&gt;
&lt;p&gt;从 Spring Boot 和 Spring Cloud 的分工中我们可以看出，Spring Boot 忙活的是底层的柴米油盐酱醋茶，Spring Boot 后勤保障做得好，才能让 Spring Cloud 毫无顾虑地投身于微服务的星辰大海，两者合二为一完整构建了微服务领域的全家桶解决方案。&lt;/p&gt;
&lt;p&gt;到这里，相信你已经可以理解 Spring Boot 和 Spring Cloud 的侧重点，以及 Spring Cloud 的功能定位。那么接下来，让我带你去了解一下 Spring Cloud 内部都有哪些重要组件。&lt;/p&gt;
&lt;h1 id=&#34;spring-cloud-组件库的朝代更替&#34;&gt;Spring Cloud 组件库的朝代更替&lt;/h1&gt;
&lt;p&gt;在我们开始了解 Spring Cloud 组件库之前，我得先介绍在 Spring Cloud 历史上举足轻重的两家公司 Netflix 和 Alibaba，以及它们的恩怨情仇。这两家公司分别为开源社区贡献了 Spring Cloud Netflix 组件库和 Spring Cloud Alibaba 组件库。&lt;/p&gt;
&lt;p&gt;说起 Netflix 可能你并不知道，但提起《纸牌屋》你一定看过或者听过，这部高分美剧就是由这家我们俗称&amp;quot;奈飞&amp;quot;的公司出品的。Netflix 是一家美国的流媒体巨头，它靠着自己强大的技术实力，开发沉淀了一系列优秀的组件，这些组件经历了 Netflix 线上庞大业务规模的考验，功能特性和稳定性过硬。如 Eureka 服务注册中心、Ribbon 负载均衡器、Hystrix 服务容错组件等。后来发生的故事可能你已经猜到了，Netflix 将这些组件贡献给了 Spring 开源社区，构成了 Netflix 组件库。可以这么说，在 Spring Cloud 的早期阶段，是 Netflix 打下了的半壁江山。&lt;/p&gt;
&lt;p&gt;Netflix 和 Spring Cloud 度过了蜜月期之后，矛盾就逐渐发生了。先是 Eureka 2.0 开源计划的搁浅，而后 Netflix 宣布 Hystrix 进入维护状态，Eureka 和 Hystrix 这两款 Netflix 组件库的明星项目停止了新功能的研发，Spring 社区不得不开始思考替代方案，在后续的新版本中走向了&amp;quot;去 Netflix 化&amp;quot;。以至于 Netflix 的网关组件 Zuul 2.0 历经几次跳票千呼万唤始出来后，Spring Cloud 社区已经不打算集成 Zuul 2.0，而是掏出了自己的 Gateway 网关。在最新版本的 Spring Cloud 中，Netflix 的踪迹已经逐渐消散，只有 Eureka 组件形单影只待在 Netflix 组件库中，回忆着昔日的辉煌。&lt;/p&gt;
&lt;p&gt;Spring Cloud Alibaba 是由 Alibaba 贡献的组件库，随着阿里在开源路线上的持续投入，近几年阿里系在开源领域的声音非常响亮。&lt;strong&gt;Spring Cloud Alibaba 凝聚了阿里系在电商领域超高并发经验的重量级组件，保持了旺盛的更新活力，成为了 Spring Cloud 社区的一股新生代力量，逐渐取代了旧王 Netflix 的江湖地位&lt;/strong&gt;。Spring Cloud Alibaba 组件秉承了&amp;quot;大而全&amp;quot;的特点，就像一个大中台应用一般包罗万象，在功能特性的丰富程度上做到了应有尽有，待我们学到 Spring Cloud 章节后你就能体会到了。这也是本课程选择 Spring Cloud Alibaba 组件的一个重要原因。&lt;/p&gt;
&lt;h1 id=&#34;spring-cloud-全家桶组件库&#34;&gt;Spring Cloud 全家桶组件库&lt;/h1&gt;
&lt;p&gt;我整理归纳了一个表格，将 Spring Cloud 中的核心组件库根据功能点做了分类，让你对每个特性功能的可选组件一目了然，&lt;strong&gt;其中红色加粗的，是我们在课程实战环节将要集成的组件&lt;/strong&gt;，你可以参考一下。&lt;br&gt;
&lt;img src=&#34;https://static001.geekbang.org/resource/image/68/d2/6802f52d2fc50af6cfc02cf561a99bd2.jpg?wh=2000x1332&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;上面表格中列出的是业务开发过程中的常用功能性组件，除了这些以外，Spring Cloud 官方还提供了很多可扩展组件，比如用来支持构建集群的 Spring Cloud Cluster、提供安全特性支持的 Spring Cloud Security、云原生的流处理数据管道 Spring Cloud Data Flow 等等，你可以在这个Spring Cloud 官方文档中找到完整的列表。&lt;/p&gt;
&lt;p&gt;如果你想了解 Spring Cloud Alibaba 组件的更多细节，我推荐你阅读 spring-cloud-alibaba 的官方 GitHub 首页或者开源社区文档。&lt;/p&gt;
&lt;p&gt;到这里，我们对 Spring Cloud 的核心组件库有了一个比较全面的了解，接下来，我带你去了解一下 Spring Cloud 的版本更新策略。&lt;/p&gt;
&lt;h1 id=&#34;spring-cloud-版本更新策略&#34;&gt;Spring Cloud 版本更新策略&lt;/h1&gt;
&lt;p&gt;大部分开源项目以数字版本进行更新迭代，Spring Cloud 在诞生之初就别出心裁使用了字母序列，以字母 A 开头，按顺序使用字母表中的字母标识重大迭代发布的大版本号。&lt;/p&gt;
&lt;p&gt;我整理了一个表格，包含了 Spring Cloud 编年史各个版本的代号以及 Release 版的发布时间，我们来感受一下 Spring Cloud 的更新节奏：&lt;br&gt;
&lt;img src=&#34;https://static001.geekbang.org/resource/image/bd/7d/bddab8d6db40951fd5e9c1af0e06807d.jpg?wh=2000x1077&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;从上面的表格中我们可以看出，&lt;strong&gt;Spring Cloud 自 2015 年发布之始就保持了极其旺盛的生命力&lt;/strong&gt;，&lt;strong&gt;早期版本每半年就有一个大的版本号迭代&lt;/strong&gt;，即便发展至今，也保持着几乎一年一升版的快速更新节奏。正是由于开源社区的持续输出，以及像 Alibaba 这类大型公司的助力，才有了今天微服务领域最为完善的 Spring Cloud 全家桶组件库。&lt;/p&gt;
&lt;p&gt;我们看完了 Spring Cloud 的大版本迭代更新策略，在大版本发布之前，还要经历很多小版本的迭代，接下来我带你了解一下 Spring Cloud 的小版本更新策略。如果你不清楚这里面的门道，很容易就会误用非稳定版本。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;SNAPSHOT 版本&lt;/strong&gt;：正在开发中的快照版本，例如 2021.0.0-SNAPSHOT，快照版代表当前分支最新的代码进度，也是更新最为频繁的小版本类型，不推荐在线上正式环境使用；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Milestone 版本&lt;/strong&gt;：在大版本正式发布前的里程碑版本，例如 2021.0.0-M1，M1 代表当前大版本的第一个里程碑版本，M2 代表第二个迭代里程碑，以此类推。在正式版本发布之前要经历多个里程碑的迭代，像 Spring Cloud Finchley 版足足经历了 9 个 M 版本之后，才过渡到了 RC 版。同样地，我也不推荐你在正式项目中使用 Milestone 版本；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Release Candidate 版本&lt;/strong&gt;：这就是我们俗称的 RC 版，例如 2021.0.0-RC1。当一个版本迭代到 RC 版的时候，意味着离正式发布已经不远了。但是你要注意，RC 版是发布前的候选版本，走到这一步通常已经没有新的功能开发，RC 主要目的是开放出来让大家试用并尽量修复严重 Bug。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Release 版&lt;/strong&gt;：稳定的正式发布版，比如 2020.0.1。你可以在自己的线上业务中放心使用 Release 稳定版。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;到这里，我们就完整了解了 Spring Cloud 的发展历史、核心组件库、版本更新策略。现在，我们来回顾一下这节课的重点内容。&lt;/p&gt;
&lt;h1 id=&#34;总结&#34;&gt;总结&lt;/h1&gt;
&lt;p&gt;今天我带你了解了 Spring Cloud 框架的定位和它的核心组件库。以史为镜，我们了解了 Netflix 组件库和 Alibaba 组件库朝代更替的背景故事，以帮助我们在做技术选型的时候尽可能避开已经进入&amp;quot;维护状态&amp;quot;的组件。&lt;/p&gt;
&lt;p&gt;此外，我想再和你分享一些新旧工具应用的经验。我周围很多的技术人员在做项目的时候容易进入一个误区，那就是&amp;quot;为新而新&amp;quot;，什么意思呢？每当一个新版本出来的时候，他们就迫不及待地把自己的业务升级到最新版本，盲目追新，殊不知这样做很容易翻车。作为一名老司机，我推荐你这样做：&lt;strong&gt;当你心仪的框架有重大版本更新时，我还是建议你先按兵不动，等大版本做了一两次迭代之后，明显的 Bug 修复得七七八八了，再应用到自己的项目中也不迟&lt;/strong&gt;。&lt;/p&gt;
&lt;h1 id=&#34;思考题&#34;&gt;思考题&lt;/h1&gt;
&lt;p&gt;当你考虑给自己的项目做底层技术框架升版的时候，你会基于哪些因素做出&amp;quot;升级版本&amp;quot;的决定呢？欢迎你与我交流讨论，我在留言区等你。&lt;/p&gt;
&lt;p&gt;好啦，这节课就结束啦。也欢迎你把这节课分享给更多对 Spring Cloud 感兴趣的朋友。我是姚秋辰，我们下节课再见！&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 02丨日志系统：一条SQL更新语句是如何执行的？</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/02%E4%B8%A8%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E4%B8%80%E6%9D%A1sql%E6%9B%B4%E6%96%B0%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/02%E4%B8%A8%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E4%B8%80%E6%9D%A1sql%E6%9B%B4%E6%96%B0%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/</guid>
      <description>
        
        
        &lt;p&gt;前面我们系统了解了一个查询语句的执行流程，并介绍了执行过程中涉及的处理模块。相信你还记得，一条查询语句的执行过程一般是经过连接器、分析器、优化器、执行器等功能模块，最后到达存储引擎。&lt;/p&gt;
&lt;p&gt;那么，一条更新语句的执行流程又是怎样的呢？&lt;/p&gt;
&lt;p&gt;之前你可能经常听 DBA 同事说，MySQL 可以恢复到半个月内任意一秒的状态，惊叹的同时，你是不是心中也会不免会好奇，这是怎样做到的呢？&lt;/p&gt;
&lt;p&gt;我们还是从一个表的一条更新语句说起，下面是这个表的创建语句，这个表有一个主键 ID 和一个整型字段 c：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; create table T(ID int primary key, c int);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果要将 ID=2 这一行的值加 1，SQL 语句就会这么写：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; update T set c=c+1 where ID=2;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;前面我有跟你介绍过 SQL 语句基本的执行链路，这里我再把那张图拿过来，你也可以先简单看看这个图回顾下。首先，可以确定的说，查询语句的那一套流程，更新语句也是同样会走一遍。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/0d/d9/0d2070e8f84c4801adbfa03bda1f98d9.png&#34; alt=&#34;&#34;&gt;
MySQL 的逻辑架构图&lt;/p&gt;
&lt;p&gt;你执行语句前要先连接数据库，这是连接器的工作。&lt;/p&gt;
&lt;p&gt;前面我们说过，在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表 T 上所有缓存结果都清空。这也就是我们一般不建议使用查询缓存的原因。&lt;/p&gt;
&lt;p&gt;接下来，分析器会通过词法和语法解析知道这是一条更新语句。优化器决定要使用 ID 这个索引。然后，执行器负责具体执行，找到这一行，然后更新。&lt;/p&gt;
&lt;p&gt;与查询流程不一样的是，更新流程还涉及两个重要的日志模块，它们正是我们今天要讨论的主角：redo log（重做日志）和 binlog（归档日志）。如果接触 MySQL，那这两个词肯定是绕不过的，我后面的内容里也会不断地和你强调。不过话说回来，redo log 和 binlog 在设计上有很多有意思的地方，这些设计思路也可以用到你自己的程序里。&lt;/p&gt;
&lt;h1 id=&#34;重要的日志模块redo-log&#34;&gt;重要的日志模块：redo log&lt;/h1&gt;
&lt;p&gt;不知道你还记不记得《孔乙己》这篇文章，酒店掌柜有一个粉板，专门用来记录客人的赊账记录。如果赊账的人不多，那么他可以把顾客名和账目写在板上。但如果赊账的人多了，粉板总会有记不下的时候，这个时候掌柜一定还有一个专门记录赊账的账本。&lt;/p&gt;
&lt;p&gt;如果有人要赊账或者还账的话，掌柜一般有两种做法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一种做法是直接把账本翻出来，把这次赊的账加上去或者扣除掉；&lt;/li&gt;
&lt;li&gt;另一种做法是先在粉板上记下这次的账，等打烊以后再把账本翻出来核算。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在生意红火柜台很忙时，掌柜一定会选择后者，因为前者操作实在是太麻烦了。首先，你得找到这个人的赊账总额那条记录。你想想，密密麻麻几十页，掌柜要找到那个名字，可能还得带上老花镜慢慢找，找到之后再拿出算盘计算，最后再将结果写回到账本上。&lt;/p&gt;
&lt;p&gt;这整个过程想想都麻烦。相比之下，还是先在粉板上记一下方便。你想想，如果掌柜没有粉板的帮助，每次记账都得翻账本，效率是不是低得让人难以忍受？&lt;/p&gt;
&lt;p&gt;同样，在 MySQL 里也有这个问题，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL 的设计者就用了类似酒店掌柜粉板的思路来提升更新效率。&lt;/p&gt;
&lt;p&gt;而粉板和账本配合的整个过程，其实就是 MySQL 里经常说到的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘，也就是先写粉板，等不忙的时候再写账本。&lt;/p&gt;
&lt;p&gt;具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事。&lt;/p&gt;
&lt;p&gt;如果今天赊账的不多，掌柜可以等打烊后再整理。但如果某天赊账的特别多，粉板写满了，又怎么办呢？这个时候掌柜只好放下手中的活儿，把粉板中的一部分赊账记录更新到账本中，然后把这些记录从粉板上擦掉，为记新账腾出空间。&lt;/p&gt;
&lt;p&gt;与此类似，InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块&amp;quot;粉板&amp;quot;总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/16/a7/16a7950217b3f0f4ed02db5db59562a7.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。&lt;/p&gt;
&lt;p&gt;write pos 和 checkpoint 之间的是&amp;quot;粉板&amp;quot;上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示&amp;quot;粉板&amp;quot;满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。&lt;/p&gt;
&lt;p&gt;有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为&lt;strong&gt;crash-safe&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;要理解 crash-safe 这个概念，可以想想我们前面赊账记录的例子。只要赊账记录记在了粉板上或写在了账本上，之后即使掌柜忘记了，比如突然停业几天，恢复生意后依然可以通过账本和粉板上的数据明确赊账账目。&lt;/p&gt;
&lt;h1 id=&#34;重要的日志模块binlog&#34;&gt;重要的日志模块：binlog&lt;/h1&gt;
&lt;p&gt;前面我们讲过，MySQL 整体来看，其实就有两块：一块是 Server 层，它主要做的是 MySQL 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。上面我们聊到的粉板 redo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog（归档日志）。&lt;/p&gt;
&lt;p&gt;我想你肯定会问，为什么会有两份日志呢？&lt;/p&gt;
&lt;p&gt;因为最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统&amp;mdash;&amp;mdash;也就是 redo log 来实现 crash-safe 能力。&lt;/p&gt;
&lt;p&gt;这两种日志有以下三点不同。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;redo log 是物理日志，记录的是&amp;quot;在某个数据页上做了什么修改&amp;quot;；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如&amp;quot;给 ID=2 这一行的 c 字段加 1 &amp;ldquo;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。&amp;ldquo;追加写&amp;quot;是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;有了对这两个日志的概念性理解，我们再来看执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;执行器生成这个操作的 binlog，并把 binlog 写入磁盘。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这里我给出这个 update 语句的执行流程图，图中浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/2e/be/2e5bff4910ec189fe1ee6e2ecc7b4bbe.png&#34; alt=&#34;&#34;&gt;
update 语句执行流程&lt;/p&gt;
&lt;p&gt;你可能注意到了，最后三步看上去有点&amp;quot;绕&amp;rdquo;，将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是&amp;quot;两阶段提交&amp;rdquo;。&lt;/p&gt;
&lt;h1 id=&#34;两阶段提交&#34;&gt;两阶段提交&lt;/h1&gt;
&lt;p&gt;为什么必须有&amp;quot;两阶段提交&amp;quot;呢？这是为了让两份日志之间的逻辑一致。要说明这个问题，我们得从文章开头的那个问题说起：&lt;strong&gt;怎样让数据库恢复到半个月内任意一秒的状态？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;前面我们说过了，binlog 会记录所有的逻辑操作，并且是采用&amp;quot;追加写&amp;quot;的形式。如果你的 DBA 承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有 binlog，同时系统会定期做整库备份。这里的&amp;quot;定期&amp;quot;取决于系统的重要性，可以是一天一备，也可以是一周一备。&lt;/p&gt;
&lt;p&gt;当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库；&lt;/li&gt;
&lt;li&gt;然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这样你的临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。&lt;/p&gt;
&lt;p&gt;好了，说完了数据恢复过程，我们回来说说，为什么日志需要&amp;quot;两阶段提交&amp;quot;。这里不妨用反证法来进行解释。&lt;/p&gt;
&lt;p&gt;由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。&lt;/p&gt;
&lt;p&gt;仍然用前面的 update 语句来做例子。假设当前 ID=2 的行，字段 c 的值是 0，再假设执行 update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了 crash，会出现什么情况呢？&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;先写 redo log 后写 binlog&lt;/strong&gt; 。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。&lt;br&gt;
但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。&lt;br&gt;
然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;先写 binlog 后写 redo log&lt;/strong&gt;。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了&amp;quot;把 c 从 0 改成 1&amp;quot;这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;可以看到，如果不使用&amp;quot;两阶段提交&amp;quot;，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。&lt;/p&gt;
&lt;p&gt;你可能会说，这个概率是不是很低，平时也没有什么动不动就需要恢复临时库的场景呀？&lt;/p&gt;
&lt;p&gt;其实不是的，不只是误操作后需要用这个过程来恢复数据。当你需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用 binlog 来实现的，这个&amp;quot;不一致&amp;quot;就会导致你的线上出现主从数据库不一致的情况。&lt;/p&gt;
&lt;p&gt;简单说，redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。&lt;/p&gt;
&lt;h1 id=&#34;小结&#34;&gt;小结&lt;/h1&gt;
&lt;p&gt;今天，我介绍了 MySQL 里面最重要的两个日志，即物理日志 redo log 和逻辑日志 binlog。&lt;/p&gt;
&lt;p&gt;redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。&lt;/p&gt;
&lt;p&gt;sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。&lt;/p&gt;
&lt;p&gt;我还跟你介绍了与 MySQL 日志系统密切相关的&amp;quot;两阶段提交&amp;quot;。两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案，即使你不做数据库内核开发，日常开发中也有可能会用到。&lt;/p&gt;
&lt;p&gt;文章的最后，我给你留一个思考题吧。前面我说到定期全量备份的周期&amp;quot;取决于系统重要性，有的是一天一备，有的是一周一备&amp;quot;。那么在什么场景下，一天一备会比一周一备更有优势呢？或者说，它影响了这个数据库系统的哪个指标？&lt;/p&gt;
&lt;p&gt;你可以把你的思考和观点写在留言区里，我会在下一篇文章的末尾给出我的答案。&lt;/p&gt;
&lt;p&gt;感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/ce/d9/ce7f4e35916ed1aa49206a53a0547bd9.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 02丨程序员如何用技术变现（下）</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/02%E4%B8%A8%E7%A8%8B%E5%BA%8F%E5%91%98%E5%A6%82%E4%BD%95%E7%94%A8%E6%8A%80%E6%9C%AF%E5%8F%98%E7%8E%B0%E4%B8%8B/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/02%E4%B8%A8%E7%A8%8B%E5%BA%8F%E5%91%98%E5%A6%82%E4%BD%95%E7%94%A8%E6%8A%80%E6%9C%AF%E5%8F%98%E7%8E%B0%E4%B8%8B/</guid>
      <description>
        
        
        &lt;p&gt;我不算是聪明的人，经历也不算特别成功，但一步一步走来，我认为，我能做到的，你一定也能做到，而且应该还能做得比我更好。&lt;/p&gt;
&lt;h1 id=&#34;如何让自己的技能变现&#34;&gt;如何让自己的技能变现&lt;/h1&gt;
&lt;p&gt;还是那句话，本质上来说，程序员是个手艺人，有手艺的人就能做出别人做不出来的东西，而付费也是一件很自然的事了。那么，这个问题就变成如何让自己的&amp;quot;手艺&amp;quot;更为值钱的问题了。&lt;/p&gt;
&lt;p&gt;第一，&lt;strong&gt;千里之行，积于跬步&lt;/strong&gt;。任何一件成功的大事，都是通过一个一个的小成功达到的。所以，你得确保你有一个一个的小成功。&lt;/p&gt;
&lt;p&gt;具体说来，首先，你得让自己身边的人有求于你，或是向别人推荐你。这就需要你能够掌握大多数人不能掌握的技能或技术，需要你更多地学习，并要有更多的别人没有的经验和经历。&lt;/p&gt;
&lt;p&gt;一旦你身边的人开始有求于你，或是向别人推荐你，你就会被外部的人注意到，于是其他人就会付费来获取你的帮助。而一旦你的帮忙对别人来说有效果，那就会产生效益，无论是经济效益还是社会效益，都会为你开拓更大的空间。&lt;/p&gt;
&lt;p&gt;你也会因为这样的正向反馈而鼓励自己去学习和钻研更多的东西，从而得到一个正向的循环。而且这个正向循环，一旦开始就停不下来了。&lt;/p&gt;
&lt;p&gt;第二，&lt;strong&gt;关注有价值的东西&lt;/strong&gt;。什么是有价值的东西？价值其实是受供需关系影响的，供大于求，就没什么价值，供不应求，就有价值。这意味着你不仅要看到市场，还要看到技术的趋势，能够分辨出什么是主流技术，什么是过渡式的技术。当你比别人有更好的嗅觉时，你就能启动得更快，也就比别人有先发优势。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;关于市场需求&lt;/strong&gt;。你要看清市场，就需要看看各个公司都在做什么，他们的难题是什么。简单来说，现在的每家公司无论大小都缺人。但是真的缺人吗？中国是人口大国，从不缺少写代码搬砖的人，真正缺的其实是有能力能够解决技术难题的人，能够提高团队人效的人。所以，从这些方面思考，你会知道哪些技能才是真正的&amp;quot;供不应求&amp;quot;，这样可以让你更有价值。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;关于技术趋势&lt;/strong&gt;。要看清技术趋势，你需要了解历史，就像一个球运动一样，你要知道这个球未来运动的地方，是需要观察球的已经完成运动的轨迹才知道的。因此，了解技术发展轨迹是一件很重要的事。要看一个新的技术是否顺应技术发展趋势，你需要将一些老技术的本质吃得很透。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，在学习技术的过程一定要多问自己两个问题：&amp;ldquo;一，这个技术解决什么问题？为什么别的同类技术做不到？二，为什么是这样解决的？有没有更好的方式？&amp;ldquo;另外，还有一个简单的判断方法，如果一个新的技术顺应技术发展趋势，那么在这个新的技术出现时，后面一定会有大型的商业公司支持，这类公司支持得越多，就说明你越需要关注。&lt;/p&gt;
&lt;p&gt;第三，&lt;strong&gt;找到能体现价值的地方&lt;/strong&gt; 。&lt;strong&gt;在一家高速发展的公司中，技术人员的价值可以达到最大化&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;试想，在一家大公司中，技术架构和业务已经定型，基本上没有什么太多的事可以做的。而且对于已经发展起来的大公司来说，往往稳定的重要性超过了创新。此外，大公司的高级技术人员很多，多你一个不多，少你一个不少，所以你的价值很难被体现出来。&lt;/p&gt;
&lt;p&gt;而刚起步的公司，业务还没有跑顺，公司的主要精力会放在业务拓展上，这个时候也不太需要高精尖的技术，所以，技术人员的价值也体现不出来。&lt;/p&gt;
&lt;p&gt;只有那些在高速发展的公司，技术人员的价值才能被最大化地体现出来。比较好的成长路径是，先进入大公司学习大公司的技术和成功的经验方法，然后再找到高速成长的公司，这样你就可以实现自己更多的价值。当然，这里并不排除在大公司中找到高速发展的业务。&lt;/p&gt;
&lt;p&gt;第四，&lt;strong&gt;动手能力很重要&lt;/strong&gt;。成为一个手艺人，动手能力是很重要的，因为在解决任何一个具体问题的时候，有没有动手能力就成为了关键。这也是我一直在写代码的原因，代码里全是细节，细节是魔鬼，只有了解了细节，你才能提出更好或是更靠谱、可以落地的解决方案。而不是一些笼统和模糊的东西。这太重要了。&lt;/p&gt;
&lt;p&gt;第五，&lt;strong&gt;关注技术付费点&lt;/strong&gt; 。技术付费点基本体现在两个地方，&lt;strong&gt;一个是，能帮别人&amp;quot;挣钱&amp;quot;的地方；另一个是，能帮别人&amp;quot;省钱&amp;quot;的地方&lt;/strong&gt;。也就是说，能够帮助别人更流畅地挣钱，或是能够帮助别人提高效率，能节省更多的成本，越直接越好。而且这个技术或解决方案最好还是大多数人做不到的。&lt;/p&gt;
&lt;p&gt;第六，&lt;strong&gt;提升自己的能力和经历&lt;/strong&gt;。付费的前提是信任，只有你提升自己的能力和经历后，别人才会对你有一定的信任，才会觉得你靠谱，才会给你机会。而这个信任需要用你的能力和经历来填补。比如，你是一个很知名的开源软件的核心开发人员，或是你是某知名公司核心项目的核心开发人员，等等。&lt;/p&gt;
&lt;p&gt;第七，&lt;strong&gt;找到有价值的信息源&lt;/strong&gt;。信息社会，如果你比别人有更好的信息源，那么你就可以比别人成长得更快。对于技术人员来说，我们知道，几乎所有的技术都源自西方世界，所以，你应该走到信息的源头去。&lt;/p&gt;
&lt;p&gt;如果你的信息来自朋友圈、微博、知乎、百度或是今日头条，那么我觉得你完蛋了。因为这些渠道有价值的信息不多，有营养的可能只有 1%，而为了这 1%，你需要读完 99% 的信息，太不划算了。&lt;/p&gt;
&lt;p&gt;那么如何找到这些信息源呢？用好 Google 就是一个关键，比如你在 Google 搜索引擎里输入&amp;quot;XXX Best Practice&amp;rdquo;，或是&amp;quot;Best programming resource&amp;rdquo;&amp;hellip;&amp;hellip;你就会找到很多。而用好这个更好的信息源需要你的英文能力，因此不断提升英文能力很关键。&lt;/p&gt;
&lt;p&gt;第八，&lt;strong&gt;输出观点和价值观&lt;/strong&gt;。真正伟大的公司或是产品都是要输出价值观的。只有输出了更先进的价值观，才会获得真正的影响力。但是，你要能输出观点和价值观，并不是一件容易的事，这需要你的积累和经历，而不是一朝之功。因此，如果想要让你的技能变现，这本质上是一个厚积薄发的过程。&lt;/p&gt;
&lt;p&gt;第九，&lt;strong&gt;朋友圈很重要&lt;/strong&gt;。一个人的朋友圈很重要，你在什么样的朋友圈，就会被什么样的朋友圈所影响。如果你的朋友圈比较优质，那么给你介绍过来的事儿和活儿也会好一些。&lt;/p&gt;
&lt;p&gt;优质的朋友圈基本上都有这样的特性。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;这些人都比较有想法、有观点，经验也比较丰富；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;这些人涉猎的面比较广；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;这些人都有或多或少的成功；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;这些人都是喜欢折腾喜欢搞事的人；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;这些人都对现状有些不满，并想做一些改变；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;这些人都有一定的影响力。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最后有个关键的问题是，物以类聚，人以群分。如果你不做到这些，你怎么能进入到这样的朋友圈呢？&lt;/p&gt;
&lt;p&gt;总之，就一句话，&lt;strong&gt;会挣钱的人一定是会投资的人&lt;/strong&gt; 。我一直认为，&lt;strong&gt;最宝贵的财富并不是钱，而是你的时间，时间比钱更宝贵，因为钱你不用还在那里，而时间你不用就浪费掉了。你把你的时间投资在哪些地方，就意味着你未来会走什么样的路。所以，利用好你的时间，投到一些有意义的地方吧&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;我的经历有限，只能看到这些，还希望大家一起来讨论，分享你的经验和心得，也让我可以学习和提高。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/fc/e9/fcc761001867c60f526665e237f831e9.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 02丨预习篇·小鲸鱼大事记（二）：崭露头角</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90-kubernetes/02%E4%B8%A8%E9%A2%84%E4%B9%A0%E7%AF%87%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%A4%A7%E4%BA%8B%E8%AE%B0%E4%BA%8C%E5%B4%AD%E9%9C%B2%E5%A4%B4%E8%A7%92/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90-kubernetes/02%E4%B8%A8%E9%A2%84%E4%B9%A0%E7%AF%87%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%A4%A7%E4%BA%8B%E8%AE%B0%E4%BA%8C%E5%B4%AD%E9%9C%B2%E5%A4%B4%E8%A7%92/</guid>
      <description>
        
        
        &lt;p&gt;你好，我是张磊。我今天分享的主题是：小鲸鱼大事记之崭露头角。&lt;/p&gt;
&lt;p&gt;在上一篇文章中，我说到，伴随着 PaaS 概念的逐步普及，以 Cloud Foundry 为代表的经典 PaaS 项目，开始进入基础设施领域的视野，平台化和 PaaS 化成了这个生态中的一个最为重要的进化趋势。&lt;/p&gt;
&lt;p&gt;就在对开源 PaaS 项目落地的不断尝试中，这个领域的从业者们发现了 PaaS 中最为棘手也最亟待解决的一个问题：究竟如何给应用打包？&lt;/p&gt;
&lt;p&gt;遗憾的是，无论是 Cloud Foundry、OpenShift，还是 Clodify，面对这个问题都没能给出一个完美的答案，反而在竞争中走向了碎片化的歧途。&lt;/p&gt;
&lt;p&gt;而就在这时，一个并不引人瞩目的 PaaS 创业公司 dotCloud，却选择了开源自家的一个容器项目 Docker。更出人意料的是，&lt;strong&gt;就是这样一个普通到不能再普通的技术，却开启了一个名为&amp;quot;Docker&amp;quot;的全新时代。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;你可能会有疑问，Docker 项目的崛起，是不是偶然呢？&lt;/p&gt;
&lt;p&gt;事实上，&lt;strong&gt;这个以&amp;quot;鲸鱼&amp;quot;为注册商标的技术创业公司，最重要的战略之一就是：坚持把&amp;quot;开发者&amp;quot;群体放在至高无上的位置。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;相比于其他正在企业级市场里厮杀得头破血流的经典 PaaS 项目们，Docker 项目的推广策略从一开始就呈现出一副&amp;quot;憨态可掬&amp;quot;的亲人姿态，把每一位后端技术人员（而不是他们的老板）作为主要的传播对象。&lt;/p&gt;
&lt;p&gt;简洁的 UI，有趣的 demo，&amp;ldquo;1 分钟部署一个 WordPress 网站&amp;quot;&amp;ldquo;3 分钟部署一个 Nginx 集群&amp;rdquo;，这种同开发者之间与生俱来的亲近关系，使 Docker 项目迅速成为了全世界 Meetup 上最受欢迎的一颗新星。&lt;/p&gt;
&lt;p&gt;在过去的很长一段时间里，相较于前端和互联网技术社区，服务器端技术社区一直是一个相对沉闷而小众的圈子。在这里，从事 Linux 内核开发的极客们自带&amp;quot;不合群&amp;quot;的&amp;quot;光环&amp;rdquo;，后端开发者们啃着多年不变的 TCP/IP 发着牢骚，运维更是天生注定的幕后英雄。&lt;/p&gt;
&lt;p&gt;而 Docker 项目，却给后端开发者提供了走向聚光灯的机会。就比如 Cgroups 和 Namespace 这种已经存在多年却很少被人们关心的特性，在 2014 年和 2015 年竟然频繁入选各大技术会议的分享议题，就因为听众们想要知道 Docker 这个东西到底是怎么一回事儿。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;而 Docker 项目之所以能取得如此高的关注，一方面正如前面我所说的那样，它解决了应用打包和发布这一困扰运维人员多年的技术难题；而另一方面，就是因为它第一次把一个纯后端的技术概念，通过非常友好的设计和封装，交到了最广大的开发者群体手里。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在这种独特的氛围烘托下，你不需要精通 TCP/IP，也无需深谙 Linux 内核原理，哪怕只是一个前端或者网站的 PHP 工程师，都会对如何把自己的代码打包成一个随处可以运行的 Docker 镜像充满好奇和兴趣。&lt;/p&gt;
&lt;p&gt;这种受众群体的变革，正是 Docker 这样一个后端开源项目取得巨大成功的关键。这也是经典 PaaS 项目想做却没有做好的一件事情：PaaS 的最终用户和受益者，一定是为这个 PaaS 编写应用的开发者们，而在 Docker 项目开源之前，PaaS 与开发者之间的关系却从未如此紧密过。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解决了应用打包这个根本性的问题，同开发者与生俱来的的亲密关系，再加上 PaaS 概念已经深入人心的完美契机，成为 Docker 这个技术上看似平淡无奇的项目一举走红的重要原因。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一时之间，&amp;ldquo;容器化&amp;quot;取代&amp;quot;PaaS 化&amp;quot;成为了基础设施领域最炙手可热的关键词，一个以&amp;quot;容器&amp;quot;为中心的、全新的云计算市场，正呼之欲出。而作为这个生态的一手缔造者，此时的 dotCloud 公司突然宣布将公司名称改为&amp;quot;Docker&amp;rdquo;。&lt;/p&gt;
&lt;p&gt;这个举动，在当时颇受质疑。在大家印象中，Docker 只是一个开源项目的名字。可是现在，这个单词却成了 Docker 公司的注册商标，任何人在商业活动中使用这个单词，以及鲸鱼的 Logo，都会立刻受到法律警告。&lt;/p&gt;
&lt;p&gt;那么，Docker 公司这个举动到底卖的什么药？这个问题，我不妨后面再做解读，因为相较于这件&amp;quot;小事儿&amp;quot;，Docker 公司在 2014 年发布 Swarm 项目才是真正的&amp;quot;大事儿&amp;quot;。&lt;/p&gt;
&lt;p&gt;那么，Docker 公司为什么一定要发布 Swarm 项目呢？&lt;/p&gt;
&lt;p&gt;通过我对 Docker 项目崛起背后原因的分析，你应该能发现这样一个有意思的事实：虽然通过&amp;quot;容器&amp;quot;这个概念完成了对经典 PaaS 项目的&amp;quot;降维打击&amp;quot;，但是 Docker 项目和 Docker 公司，兜兜转转了一年多，却还是回到了 PaaS 项目原本深耕了多年的那个战场：&lt;strong&gt;如何让开发者把应用部署在我的项目上。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;没错，Docker 项目从发布之初就全面发力，从技术、社区、商业、市场全方位争取到的开发者群体，实际上是为此后吸引整个生态到自家&amp;quot;PaaS&amp;quot;上的一个铺垫。&lt;strong&gt;只不过这时，&amp;ldquo;PaaS&amp;quot;的定义已经全然不是 Cloud Foundry 描述的那个样子，而是变成了一套以 Docker 容器为技术核心，以 Docker 镜像为打包标准的、全新的&amp;quot;容器化&amp;quot;思路。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;这，正是 Docker 项目从一开始悉心运作&amp;quot;容器化&amp;quot;理念和经营整个 Docker 生态的主要目的。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;而 Swarm 项目，正是接下来承接 Docker 公司所有这些努力的关键所在。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;今天，我着重介绍了 Docker 项目在短时间内迅速崛起的三个重要原因：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Docker 镜像通过技术手段解决了 PaaS 的根本性问题；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Docker 容器同开发者之间有着与生俱来的密切关系；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PaaS 概念已经深入人心的完美契机。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;崭露头角的 Docker 公司，也终于能够以一个更加强硬的姿态来面对这个曾经无比强势，但现在却完全不知所措的云计算市场。而 2014 年底的 DockerCon 欧洲峰会，则正式拉开了 Docker 公司扩张的序幕。&lt;/p&gt;
&lt;h2 id=&#34;思考题&#34;&gt;思考题&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;你是否认同 dotCloud 公司改名并开启扩张道路的战略选择？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Docker 公司凭借&amp;quot;开源&amp;quot;和&amp;quot;开发者社群&amp;quot;这两个关键词完成崛起的过程，对你和你所在的团队有什么启发？&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;感谢收听，欢迎你给我留言，也欢迎分享给更多的朋友一起阅读。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/47/55/47a6f3bf6b92d58512d5a2ed0a556f55.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 03丨Equifax信息泄露始末</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/03%E4%B8%A8equifax%E4%BF%A1%E6%81%AF%E6%B3%84%E9%9C%B2%E5%A7%8B%E6%9C%AB/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/03%E4%B8%A8equifax%E4%BF%A1%E6%81%AF%E6%B3%84%E9%9C%B2%E5%A7%8B%E6%9C%AB/</guid>
      <description>
        
        
        &lt;p&gt;相信你一定有所耳闻，9 月份美国知名征信公司 Equifax 出现了大规模数据泄露事件，致使 1.43 亿美国用户及大量的英国和加拿大用户受到影响。今天，我就来跟你聊聊 Equifax 信息泄露始末，并对造成本次事件的原因进行简单的分析。&lt;/p&gt;
&lt;h1 id=&#34;equifax-信息泄露始末&#34;&gt;Equifax 信息泄露始末&lt;/h1&gt;
&lt;p&gt;Equifax 日前确认，黑客利用了其系统中未修复的 Apache Struts 漏洞（CVE-2017-5638，2017 年 3 月 6 日曝光）来发起攻击，导致了最近这次影响恶劣的大规模数据泄露事件。&lt;/p&gt;
&lt;p&gt;作为美国三大信用报告公司中历史最悠久的一家，Equifax 的主营业务是为客户提供美国、加拿大和其他多个国家的公民信用信息。保险公司就是其服务的主要客户之一，涉及生命、汽车、火灾、医疗保险等多个方面。&lt;/p&gt;
&lt;p&gt;此外，Equifax 还提供入职背景调查、保险理赔调查，以及针对企业的信用调查等服务。由于 Equifax 掌握了多个国家公民的信用档案，包括公民的学前、学校经历、婚姻、工作、健康、政治参与等大量隐私信息，所以这次的信息泄露，影响面积很大，而且性质特别恶劣。&lt;/p&gt;
&lt;p&gt;受这次信息泄露影响的美国消费者有 1.43 亿左右，另估计约有 4400 万的英国客户和大量加拿大客户受到影响。事件导致 Equifax 市值瞬间蒸发掉逾 30 亿美元。&lt;/p&gt;
&lt;p&gt;根据《华尔街日报》（The Wall Street Journal）的观察，自 Equifax 在 9 月 8 日披露黑客进入该公司部分系统以来，全美联邦法院接到的诉讼已经超过百起。针对此次事件，Equifax 首席执行官理查德·史密斯（Richard Smith）表示，公司正在对整体安全操作进行全面彻底的审查。&lt;/p&gt;
&lt;p&gt;事件发生之初，Equifax 在声明中指出，黑客是利用了某个&amp;quot;U.S. website application&amp;quot;中的漏洞获取文件。后经调查，黑客是利用了 Apache Struts 的 CVE-2017-5638 漏洞。&lt;/p&gt;
&lt;p&gt;戏剧性的是，该漏洞于今年 3 月份就已被披露，其危险系数定为最高分 10 分，Apache 随后发布的 Struts 2.3.32 和 2.5.10.1 版本特针对此漏洞进行了修复。而 Equifax 在漏洞公布后的两个月内都没有升级 Struts 版本，导致 5 月份黑客利用这个漏洞进行攻击，泄露其敏感数据。&lt;/p&gt;
&lt;p&gt;事实上，除了 Apache 的漏洞，黑客还使用了一些其他手段绕过 WAF（Web 应用程序防火墙）。有些管理面板居然位于 Shodan 搜索引擎上。更让人大跌眼镜的是，据研究人员分析，Equifax 所谓的&amp;quot;管理面板&amp;quot;都没有采取任何安保措施。安全专家布莱恩·克雷布斯（Brian Krebs）在其博客中爆料，Equifax 的一个管理面板使用的用户名和密码都是&amp;quot;admin&amp;quot;。&lt;/p&gt;
&lt;p&gt;由于管理面板能被随意访问，获取数据库密码就轻而易举了&amp;mdash;&amp;mdash;虽然管理面板会加密数据库密码之类的东西，但是密钥却和管理面板保存在了一起。虽然是如此重要的征信机构，但 Equifax 的安全意识之弱可见一斑。&lt;/p&gt;
&lt;p&gt;据悉，Equifax 某阿根廷员工门户也泄露了 14000 条记录，包括员工凭证和消费者投诉。本次事件发生后，好事者列举了 Equifax 系统中的一系列漏洞，包括一年以前向公司报告的未修补的跨站脚本（XSS）漏洞，更将 Equifax 推向了风口浪尖。&lt;/p&gt;
&lt;h1 id=&#34;apache-struts-漏洞相关&#34;&gt;Apache Struts 漏洞相关&lt;/h1&gt;
&lt;p&gt;Apache Struts 是世界上最流行的 Java Web 服务器框架之一，它最初是 Jakarta 项目中的一个子项目，并在 2004 年 3 月成为 Apache 基金会的顶级项目。&lt;/p&gt;
&lt;p&gt;Struts 通过采用 Java Servlet/JSP 技术，实现了基于 Java EE Web 应用的 MVC 设计模式的应用框架，也是当时第一个采用 MVC 模式的 Web 项目开发框架。随着技术的发展和认知的提升，Struts 的设计者意识到 Struts 的一些缺陷，于是有了重新设计的想法。&lt;/p&gt;
&lt;p&gt;2006 年，另外一个 MVC 框架 WebWork 的设计者与 Struts 团队一起开发了新一代的 Struts 框架，它整合了 WebWork 与 Struts 的优点，同时命名为&amp;quot;Struts 2&amp;quot;，原来的 Struts 框架改名为 Struts 1。&lt;/p&gt;
&lt;p&gt;因为两个框架都有强大的用户基础，所以 Struts 2 一发布就迅速流行开来。在 2013 年 4 月，Apache Struts 项目团队发布正式通知，宣告 Struts 1.x 开发框架结束其使命，并表示接下来官方将不会继续提供支持。自此 Apache Struts 1 框架正式退出历史舞台。&lt;/p&gt;
&lt;p&gt;同期，Struts 社区表示他们将专注于推动 Struts 2 框架的发展。从这几年的版本发布情况来看，Struts 2 的迭代速度确实不慢，仅仅在 2017 年就发布了 9 个版本，平均一个月一个。&lt;/p&gt;
&lt;p&gt;但从安全角度来看，Struts 2 可谓是漏洞百出，因为框架的功能基本已经健全，所以这些年 Struts 2 的更新和迭代基本也是围绕漏洞和 Bug 进行修复。仅从官方披露的安全公告中就可以看到，这些年就有 53 个漏洞预警，包括大家熟知的远程代码执行高危漏洞。&lt;/p&gt;
&lt;p&gt;根据网络上一份未被确认的数据显示，中国的 Struts 应用分布在全球范围内排名第一，第二是美国，然后是日本，而中国没有打补丁的 Struts 的数量几乎是其它国家的总和。特别是在浙江、北京、广东、山东、四川等地，涉及教育、金融、互联网、通信等行业。&lt;/p&gt;
&lt;p&gt;所以在今年 7 月，国家信息安全漏洞共享平台还发布过关于做好 Apache Struts 2 高危漏洞管理和应急工作的安全公告，大致意思是希望企业能够加强学习，提高安全认识，同时完善相关流程，协同自律。&lt;/p&gt;
&lt;p&gt;而这次 Equifax 中招的漏洞编号是 CVE-2017-5638，官方披露的信息见下图。简单来说，这是一个 RCE 的远程代码执行漏洞，最初是被安恒信息的 Nike Zheng 发现的，并于 3 月 7 日上报。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/00/cc/009ecfbac5741ea7ffd7fa3079a8c8cc.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;从介绍中可以看出，此次漏洞的原因是 Apache Struts 2 的 Jakarta Multipart parser 插件存在远程代码执行漏洞，攻击者可以在使用该插件上传文件时，修改 HTTP 请求头中的 Content-Type 值来触发漏洞，最后远程执行代码。&lt;/p&gt;
&lt;p&gt;说白了，就是在 Content-Type 注入 OGNL 语言，进而执行命令。代码如下（一行 Python 命令就可以执行服务器上的 shell 命令）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import requests
requests.get(&amp;quot;https://target&amp;quot;, headers={&amp;quot;Connection&amp;quot;: &amp;quot;close&amp;quot;, &amp;quot;Accept&amp;quot;: &amp;quot;*/*&amp;quot;, &amp;quot;User-Agent&amp;quot;: &amp;quot;Mozilla/5.0&amp;quot;, &amp;quot;Content-Type&amp;quot;: &amp;quot;%{(#_=&#39;multipart/form-data&#39;).(#dm=@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS).(#_memberAccess?(#_memberAccess=#dm):((#container=#context[&#39;com.opensymphony.xwork2.ActionContext.container&#39;]).(#ognlUtil=#container.getInstance(@com.opensymphony.xwork2.ognl.OgnlUtil@class)).(#ognlUtil.getExcludedPackageNames().clear()).(#ognlUtil.getExcludedClasses().clear()).(#context.setMemberAccess(#dm)))).(#cmd=&#39;dir&#39;).(#iswin=(@java.lang.System@getProperty(&#39;os.name&#39;).toLowerCase().contains(&#39;win&#39;))).(#cmds=(#iswin?{&#39;cmd.exe&#39;,&#39;/c&#39;,#cmd}:{&#39;/bin/bash&#39;,&#39;-c&#39;,#cmd})).(#p=new java.lang.ProcessBuilder(#cmds)).(#p.redirectErrorStream(true)).(#process=#p.start()).(#ros=(@org.apache.struts2.ServletActionContext@getResponse().getOutputStream())).(@org.apache.commons.io.IOUtils@copy(#process.getInputStream(),#ros)).(#ros.flush())}&amp;quot;})
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在 GitHub 上有相关的代码，链接为：&lt;a href=&#34;https://github.com/mazen160/struts-pwn&#34;&gt;https://github.com/mazen160/struts-pwn&lt;/a&gt; 或 &lt;a href=&#34;https://github.com/xsscx/cve-2017-5638&#34;&gt;https://github.com/xsscx/cve-2017-5638&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;注入点是在 JakartaMultiPartRequest.java 的 buildErrorMessage 函数中，这个函数里的 localizedTextUtil.findText 会执行 OGNL 表达式，从而导致命令执行（注：可以参看 Struts 两个版本的补丁&amp;quot;2.5.10.1 版补丁&amp;quot;&amp;ldquo;2.3.32 版补丁&amp;rdquo;），使客户受到影响。&lt;/p&gt;
&lt;p&gt;因为默认情况下 Jakarta 是启用的，所以该漏洞的影响范围甚广。当时官方给出的解决方案是尽快升级到不受影响的版本，看来 Equifax 的同学并没有注意到，或者也没有认识到它的严重性。&lt;/p&gt;
&lt;p&gt;另外，在 9 月 5 日和 7 日，Struts 官方又接连发布了几个严重级别的安全漏洞公告，分别是 CVE-2017-9804、CVE-2017-9805、CVE-2017-9793 和 CVE-2017-12611。&lt;/p&gt;
&lt;p&gt;这里面最容易被利用的当属 CVE-2017-9805，它是由国外安全研究组织 lgtm.com 的安全研究人员发现的又一个远程代码执行漏洞。漏洞原因是 Struts 2 REST 插件使用带有 XStream 程序的 XStream Handler 进行未经任何代码过滤的反序列化操作，所以在反序列化 XML payloads 时就可能导致远程代码执行。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/f8/02/f8a10b42faf789018e0a5dfadbbd0c02.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;不过在 Apache 软件基金会的项目管理委员会的回应文章中，官方也对事故原因进行了分析和讨论。首先，依然不能确定泄露的源头是 Struts 的漏洞导致的。其次，如果确实是源于 Struts 的漏洞，那么原因&amp;quot;或是 Equifax 服务器未打补丁，使得一些更早期公布的漏洞被攻击者利用，或者是攻击者利用了一个目前尚未被发现的漏洞&amp;quot;。&lt;/p&gt;
&lt;p&gt;根据推测，该声明提出黑客所使用的软件漏洞可能就是 CVE-2017-9805 漏洞，该漏洞虽然是在 9 月 4 日才由官方正式公布，但早在 7 月时就有人公布在网络上了，并且这个漏洞的存在已有 9 年。&lt;/p&gt;
&lt;p&gt;相信通过今天的分享，你一定对 Equifax 的数据泄露始末及造成原因有了清楚的了解。欢迎您把你的收获和想法，分享给我。下篇文章中，我们将回顾一下互联网时代的! 其他大规模数据泄露事件，并结合这些事件给出应对方案和技术手段。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/fc/e9/fcc761001867c60f526665e237f831e9.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 03丨Java虚拟机是如何加载Java类的？</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3jvm%E8%99%9A%E6%8B%9F%E6%9C%BA/03%E4%B8%A8java%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%98%AF%E5%A6%82%E4%BD%95%E5%8A%A0%E8%BD%BDjava%E7%B1%BB%E7%9A%84/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3jvm%E8%99%9A%E6%8B%9F%E6%9C%BA/03%E4%B8%A8java%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%98%AF%E5%A6%82%E4%BD%95%E5%8A%A0%E8%BD%BDjava%E7%B1%BB%E7%9A%84/</guid>
      <description>
        
        
        &lt;p&gt;听我的意大利同事说，他们那边有个习俗，就是父亲要帮儿子盖栋房子。&lt;/p&gt;
&lt;p&gt;这事要放在以前还挺简单，亲朋好友搭把手，盖个小砖房就可以住人了。现在呢，整个过程要耗费好久的时间。首先你要请建筑师出个方案，然后去市政部门报备、验证，通过后才可以开始盖房子。盖好房子还要装修，之后才能住人。&lt;/p&gt;
&lt;p&gt;盖房子这个事，和 Java 虚拟机中的类加载还是挺像的。从 class 文件到内存中的类，按先后顺序需要经过加载、链接以及初始化三大步骤。其中，链接过程中同样需要验证；而内存中的类没有经过初始化，同样不能使用。那么，是否所有的 Java 类都需要经过这几步呢？&lt;/p&gt;
&lt;p&gt;我们知道 Java 语言的类型可以分为两大类：基本类型（primitive types）和引用类型（reference types）。在上一篇中，我已经详细介绍过了 Java 的基本类型，它们是由 Java 虚拟机预先定义好的。&lt;/p&gt;
&lt;p&gt;至于另一大类引用类型，Java 将其细分为四种：类、接口、数组类和泛型参数。由于泛型参数会在编译过程中被擦除（我会在专栏的第二部分详细介绍），因此 Java 虚拟机实际上只有前三种。在类、接口和数组类中，数组类是由 Java 虚拟机直接生成的，其他两种则有对应的字节流。&lt;/p&gt;
&lt;p&gt;说到字节流，最常见的形式要属由 Java 编译器生成的 class 文件。除此之外，我们也可以在程序内部直接生成，或者从网络中获取（例如网页中内嵌的小程序 Java applet）字节流。这些不同形式的字节流，都会被加载到 Java 虚拟机中，成为类或接口。为了叙述方便，下面我就用&amp;quot;类&amp;quot;来统称它们。&lt;/p&gt;
&lt;p&gt;无论是直接生成的数组类，还是加载的类，Java 虚拟机都需要对其进行链接和初始化。接下来，我会详细给你介绍一下每个步骤具体都在干些什么。&lt;/p&gt;
&lt;h2 id=&#34;加载&#34;&gt;加载&lt;/h2&gt;
&lt;p&gt;加载，是指查找字节流，并且据此创建类的过程。前面提到，对于数组类来说，它并没有对应的字节流，而是由 Java 虚拟机直接生成的。对于其他的类来说，Java 虚拟机则需要借助类加载器来完成查找字节流的过程。&lt;/p&gt;
&lt;p&gt;以盖房子为例，村里的 Tony 要盖个房子，那么按照流程他得先找个建筑师，跟他说想要设计一个房型，比如说&amp;quot;一房、一厅、四卫&amp;quot;。你或许已经听出来了，这里的房型相当于类，而建筑师，就相当于类加载器。&lt;/p&gt;
&lt;p&gt;村里有许多建筑师，他们等级森严，但有着共同的祖师爷，叫启动类加载器（bootstrap class loader）。启动类加载器是由 C++ 实现的，没有对应的 Java 对象，因此在 Java 中只能用 null 来指代。换句话说，祖师爷不喜欢像 Tony 这样的小角色来打扰他，所以谁也没有祖师爷的联系方式。&lt;/p&gt;
&lt;p&gt;除了启动类加载器之外，其他的类加载器都是 java.lang.ClassLoader 的子类，因此有对应的 Java 对象。这些类加载器需要先由另一个类加载器，比如说启动类加载器，加载至 Java 虚拟机中，方能执行类加载。&lt;/p&gt;
&lt;p&gt;村里的建筑师有一个潜规则，就是接到单子自己不能着手干，得先给师傅过过目。师傅不接手的情况下，才能自己来。在 Java 虚拟机中，这个潜规则有个特别的名字，叫双亲委派模型。每当一个类加载器接收到加载请求时，它会先将请求转发给父类加载器。在父类加载器没有找到所请求的类的情况下，该类加载器才会尝试去加载。&lt;/p&gt;
&lt;p&gt;在 Java 9 之前，启动类加载器负责加载最为基础、最为重要的类，比如存放在 JRE 的 lib 目录下 jar 包中的类（以及由虚拟机参数 -Xbootclasspath 指定的类）。除了启动类加载器之外，另外两个重要的类加载器是扩展类加载器（extension class loader）和应用类加载器（application class loader），均由 Java 核心类库提供。&lt;/p&gt;
&lt;p&gt;扩展类加载器的父类加载器是启动类加载器。它负责加载相对次要、但又通用的类，比如存放在 JRE 的 lib/ext 目录下 jar 包中的类（以及由系统变量 java.ext.dirs 指定的类）。&lt;/p&gt;
&lt;p&gt;应用类加载器的父类加载器则是扩展类加载器。它负责加载应用程序路径下的类。（这里的应用程序路径，便是指虚拟机参数 -cp/-classpath、系统变量 java.class.path 或环境变量 CLASSPATH 所指定的路径。）默认情况下，应用程序中包含的类便是由应用类加载器加载的。&lt;/p&gt;
&lt;p&gt;Java 9 引入了模块系统，并且略微更改了上述的类加载器&lt;a href=&#34;https://docs.oracle.com/javase/9/migrate/toc.htm#JSMIG-GUID-A868D0B9-026F-4D46-B979-901834343F9E&#34;&gt;1&lt;/a&gt;。扩展类加载器被改名为平台类加载器（platform class loader）。Java SE 中除了少数几个关键模块，比如说 java.base 是由启动类加载器加载之外，其他的模块均由平台类加载器所加载。&lt;/p&gt;
&lt;p&gt;除了由 Java 核心类库提供的类加载器外，我们还可以加入自定义的类加载器，来实现特殊的加载方式。举例来说，我们可以对 class 文件进行加密，加载时再利用自定义的类加载器对其解密。&lt;/p&gt;
&lt;p&gt;除了加载功能之外，类加载器还提供了命名空间的作用。这个很好理解，打个比方，咱们这个村不讲究版权，如果你剽窃了另一个建筑师的设计作品，那么只要你标上自己的名字，这两个房型就是不同的。&lt;/p&gt;
&lt;p&gt;在 Java 虚拟机中，类的唯一性是由类加载器实例以及类的全名一同确定的。即便是同一串字节流，经由不同的类加载器加载，也会得到两个不同的类。在大型应用中，我们往往借助这一特性，来运行同一个类的不同版本。&lt;/p&gt;
&lt;h2 id=&#34;链接&#34;&gt;链接&lt;/h2&gt;
&lt;p&gt;链接，是指将创建成的类合并至 Java 虚拟机中，使之能够执行的过程。它可分为验证、准备以及解析三个阶段。&lt;/p&gt;
&lt;p&gt;验证阶段的目的，在于确保被加载类能够满足 Java 虚拟机的约束条件。这就好比 Tony 需要将设计好的房型提交给市政部门审核。只有当审核通过，才能继续下面的建造工作。&lt;/p&gt;
&lt;p&gt;通常而言，Java 编译器生成的类文件必然满足 Java 虚拟机的约束条件。因此，这部分我留到讲解字节码注入时再详细介绍。&lt;/p&gt;
&lt;p&gt;准备阶段的目的，则是为被加载类的静态字段分配内存。Java 代码中对静态字段的具体初始化，则会在稍后的初始化阶段中进行。过了这个阶段，咱们算是盖好了毛坯房。虽然结构已经完整，但是在没有装修之前是不能住人的。&lt;/p&gt;
&lt;p&gt;除了分配内存外，部分 Java 虚拟机还会在此阶段构造其他跟类层次相关的数据结构，比如说用来实现虚方法的动态绑定的方法表。&lt;/p&gt;
&lt;p&gt;在 class 文件被加载至 Java 虚拟机之前，这个类无法知道其他类及其方法、字段所对应的具体地址，甚至不知道自己方法、字段的地址。因此，每当需要引用这些成员时，Java 编译器会生成一个符号引用。在运行阶段，这个符号引用一般都能够无歧义地定位到具体目标上。&lt;/p&gt;
&lt;p&gt;举例来说，对于一个方法调用，编译器会生成一个包含目标方法所在类的名字、目标方法的名字、接收参数类型以及返回值类型的符号引用，来指代所要调用的方法。&lt;/p&gt;
&lt;p&gt;解析阶段的目的，正是将这些符号引用解析成为实际引用。如果符号引用指向一个未被加载的类，或者未被加载类的字段或方法，那么解析将触发这个类的加载（但未必触发这个类的链接以及初始化。）&lt;/p&gt;
&lt;p&gt;如果将这段话放在盖房子的语境下，那么符号引用就好比&amp;quot;Tony 的房子&amp;quot;这种说法，不管它存在不存在，我们都可以用这种说法来指代 Tony 的房子。实际引用则好比实际的通讯地址，如果我们想要与 Tony 通信，则需要启动盖房子的过程。&lt;/p&gt;
&lt;p&gt;Java 虚拟机规范并没有要求在链接过程中完成解析。它仅规定了：如果某些字节码使用了符号引用，那么在执行这些字节码之前，需要完成对这些符号引用的解析。&lt;/p&gt;
&lt;h2 id=&#34;初始化&#34;&gt;初始化&lt;/h2&gt;
&lt;p&gt;在 Java 代码中，如果要初始化一个静态字段，我们可以在声明时直接赋值，也可以在静态代码块中对其赋值。&lt;/p&gt;
&lt;p&gt;如果直接赋值的静态字段被 final 所修饰，并且它的类型是基本类型或字符串时，那么该字段便会被 Java 编译器标记成常量值（ConstantValue），其初始化直接由 Java 虚拟机完成。除此之外的直接赋值操作，以及所有静态代码块中的代码，则会被 Java 编译器置于同一方法中，并把它命名为 &amp;lt; clinit &amp;gt;。&lt;/p&gt;
&lt;p&gt;类加载的最后一步是初始化，便是为标记为常量值的字段赋值，以及执行 &amp;lt; clinit &amp;gt; 方法的过程。Java 虚拟机会通过加锁来确保类的 &amp;lt; clinit &amp;gt; 方法仅被执行一次。&lt;/p&gt;
&lt;p&gt;只有当初始化完成之后，类才正式成为可执行的状态。这放在我们盖房子的例子中就是，只有当房子装修过后，Tony 才能真正地住进去。&lt;/p&gt;
&lt;p&gt;那么，类的初始化何时会被触发呢？JVM 规范枚举了下述多种触发情况：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;当虚拟机启动时，初始化用户指定的主类；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;当遇到用以新建目标类实例的 new 指令时，初始化 new 指令的目标类；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;当遇到调用静态方法的指令时，初始化该静态方法所在的类；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;当遇到访问静态字段的指令时，初始化该静态字段所在的类；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;子类的初始化会触发父类的初始化；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果一个接口定义了 default 方法，那么直接实现或者间接实现该接口的类的初始化，会触发该接口的初始化；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用反射 API 对某个类进行反射调用时，初始化这个类；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;当初次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的方法所在的类。&lt;/p&gt;
&lt;p&gt;public class Singleton {
private Singleton() {}
private static class LazyHolder {
static final Singleton INSTANCE = new Singleton();
}
public static Singleton getInstance() {
return LazyHolder.INSTANCE;
}
}&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;我在文章中贴了一段代码，这段代码是在著名的单例延迟初始化例子中&lt;a href=&#34;https://en.wikipedia.org/wiki/Initialization-on-demand_holder_idiom&#34;&gt;2&lt;/a&gt;，只有当调用 Singleton.getInstance 时，程序才会访问 LazyHolder.INSTANCE，才会触发对 LazyHolder 的初始化（对应第 4 种情况），继而新建一个 Singleton 的实例。&lt;/p&gt;
&lt;p&gt;由于类初始化是线程安全的，并且仅被执行一次，因此程序可以确保多线程环境下有且仅有一个 Singleton 实例。&lt;/p&gt;
&lt;h2 id=&#34;总结与实践&#34;&gt;总结与实践&lt;/h2&gt;
&lt;p&gt;今天我介绍了 Java 虚拟机将字节流转化为 Java 类的过程。这个过程可分为加载、链接以及初始化三大步骤。&lt;/p&gt;
&lt;p&gt;加载是指查找字节流，并且据此创建类的过程。加载需要借助类加载器，在 Java 虚拟机中，类加载器使用了双亲委派模型，即接收到加载请求时，会先将请求转发给父类加载器。&lt;/p&gt;
&lt;p&gt;链接，是指将创建成的类合并至 Java 虚拟机中，使之能够执行的过程。链接还分验证、准备和解析三个阶段。其中，解析阶段为非必须的。&lt;/p&gt;
&lt;p&gt;初始化，则是为标记为常量值的字段赋值，以及执行 &amp;lt; clinit &amp;gt; 方法的过程。类的初始化仅会被执行一次，这个特性被用来实现单例的延迟初始化。&lt;/p&gt;
&lt;p&gt;今天的实践环节，你可以来验证一下本篇中的理论知识。&lt;/p&gt;
&lt;p&gt;通过 JVM 参数 -verbose:class 来打印类加载的先后顺序，并且在 LazyHolder 的初始化方法中打印特定字样。在命令行中运行下述指令（不包含提示符 $）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ echo &#39;
public class Singleton {
  private Singleton() {}
  private static class LazyHolder {
    static final Singleton INSTANCE = new Singleton();
    static {
      System.out.println(&amp;quot;LazyHolder.&amp;lt;clinit&amp;gt;&amp;quot;);
    }
  }
  public static Object getInstance(boolean flag) {
    if (flag) return new LazyHolder[2];
    return LazyHolder.INSTANCE;
  }
  public static void main(String[] args) {
    getInstance(true);
    System.out.println(&amp;quot;----&amp;quot;);
    getInstance(false);
  }
}&#39; &amp;gt; Singleton.java
$ javac Singleton.java
$ java -verbose:class Singleton
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;问题 1：新建数组（第 11 行）会导致 LazyHolder 的加载吗？会导致它的初始化吗？&lt;/p&gt;
&lt;p&gt;在命令行中运行下述指令（不包含提示符 $）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ java -cp /path/to/asmtools.jar org.openjdk.asmtools.jdis.Main Singleton\$LazyHolder.class &amp;gt; Singleton\$LazyHolder.jasm.1
$ awk &#39;NR==1,/stack 1/{sub(/stack 1/, &amp;quot;stack 0&amp;quot;)} 1&#39; Singleton\$LazyHolder.jasm.1 &amp;gt; Singleton\$LazyHolder.jasm
$ java -cp /path/to/asmtools.jar org.openjdk.asmtools.jasm.Main Singleton\$LazyHolder.jasm
$ java -verbose:class Singleton
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;问题 2：新建数组会导致 LazyHolder 的链接吗？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/2a/d5/2a62e58cbdf56a5dc40748567d346fd5.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 03丨事务隔离：为什么你改了我还看不见？</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/03%E4%B8%A8%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%A0%E6%94%B9%E4%BA%86%E6%88%91%E8%BF%98%E7%9C%8B%E4%B8%8D%E8%A7%81/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/03%E4%B8%A8%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%A0%E6%94%B9%E4%BA%86%E6%88%91%E8%BF%98%E7%9C%8B%E4%B8%8D%E8%A7%81/</guid>
      <description>
        
        
        &lt;p&gt;提到事务，你肯定不陌生，和数据库打交道的时候，我们总是会用到事务。最经典的例子就是转账，你要给朋友小王转 100 块钱，而此时你的银行卡只有 100 块钱。&lt;/p&gt;
&lt;p&gt;转账过程具体到程序里会有一系列的操作，比如查询余额、做加减法、更新余额等，这些操作必须保证是一体的，不然等程序查完之后，还没做减法之前，你这 100 块钱，完全可以借着这个时间差再查一次，然后再给另外一个朋友转账，如果银行这么整，不就乱了么？这时就要用到&amp;quot;事务&amp;quot;这个概念了。&lt;/p&gt;
&lt;p&gt;简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的。你现在知道，MySQL 是一个支持多引擎的系统，但并不是所有的引擎都支持事务。比如 MySQL 原生的 MyISAM 引擎就不支持事务，这也是 MyISAM 被 InnoDB 取代的重要原因之一。&lt;/p&gt;
&lt;p&gt;今天的文章里，我将会以 InnoDB 为例，剖析 MySQL 在事务支持方面的特定实现，并基于原理给出相应的实践建议，希望这些案例能加深你对 MySQL 事务原理的理解。&lt;/p&gt;
&lt;h1 id=&#34;隔离性与隔离级别&#34;&gt;隔离性与隔离级别&lt;/h1&gt;
&lt;p&gt;提到事务，你肯定会想到 ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性），今天我们就来说说其中 I，也就是&amp;quot;隔离性&amp;quot;。&lt;/p&gt;
&lt;p&gt;当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，为了解决这些问题，就有了&amp;quot;隔离级别&amp;quot;的概念。&lt;/p&gt;
&lt;p&gt;在谈隔离级别之前，你首先要知道，你隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点。SQL 标准的事务隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ）。下面我逐一为你解释：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。&lt;/li&gt;
&lt;li&gt;读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。&lt;/li&gt;
&lt;li&gt;可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。&lt;/li&gt;
&lt;li&gt;串行化，顾名思义是对于同一行记录，&amp;ldquo;写&amp;quot;会加&amp;quot;写锁&amp;rdquo;，&amp;ldquo;读&amp;quot;会加&amp;quot;读锁&amp;rdquo;。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其中&amp;quot;读提交&amp;quot;和&amp;quot;可重复读&amp;quot;比较难理解，所以我用一个例子说明这几种隔离级别。假设数据表 T 中只有一列，其中一行的值为 1，下面是按照时间顺序执行两个事务的行为。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; create table T(c int) engine=InnoDB;
insert into T(c) values(1);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/7d/f8/7dea45932a6b722eb069d2264d0066f8.png&#34; alt=&#34;&#34;&gt;&lt;br&gt;
我们来看看在不同的隔离级别下，事务 A 会有哪些不同的返回结果，也就是图里面 V1、V2、V3 的返回值分别是什么。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;若隔离级别是&amp;quot;读未提交&amp;quot;， 则 V1 的值就是 2。这时候事务 B 虽然还没有提交，但是结果已经被 A 看到了。因此，V2、V3 也都是 2。&lt;/li&gt;
&lt;li&gt;若隔离级别是&amp;quot;读提交&amp;quot;，则 V1 是 1，V2 的值是 2。事务 B 的更新在提交后才能被 A 看到。所以， V3 的值也是 2。&lt;/li&gt;
&lt;li&gt;若隔离级别是&amp;quot;可重复读&amp;quot;，则 V1、V2 是 1，V3 是 2。之所以 V2 还是 1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。&lt;/li&gt;
&lt;li&gt;若隔离级别是&amp;quot;串行化&amp;quot;，则在事务 B 执行&amp;quot;将 1 改成 2&amp;quot;的时候，会被锁住。直到事务 A 提交后，事务 B 才可以继续执行。所以从 A 的角度看， V1、V2 值是 1，V3 的值是 2。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在&amp;quot;可重复读&amp;quot;隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在&amp;quot;读提交&amp;quot;隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。这里需要注意的是，&amp;ldquo;读未提交&amp;quot;隔离级别下直接返回记录上的最新值，没有视图概念；而&amp;quot;串行化&amp;quot;隔离级别下直接用加锁的方式来避免并行访问。&lt;/p&gt;
&lt;p&gt;我们可以看到在不同的隔离级别下，数据库行为是有所不同的。Oracle 数据库的默认隔离级别其实就是&amp;quot;读提交&amp;rdquo;，因此对于一些从 Oracle 迁移到 MySQL 的应用，为保证数据库隔离级别的一致，你一定要记得将 MySQL 的隔离级别设置为&amp;quot;读提交&amp;quot;。&lt;/p&gt;
&lt;p&gt;配置的方式是，将启动参数 transaction-isolation 的值设置成 READ-COMMITTED。你可以用 show variables 来查看当前的值。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; show variables like &#39;transaction_isolation&#39;;
 
+-----------------------+----------------+
 
| Variable_name | Value |
 
+-----------------------+----------------+
 
| transaction_isolation | READ-COMMITTED |
 
+-----------------------+----------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;总结来说，存在即合理，哪个隔离级别都有它自己的使用场景，你要根据自己的业务情况来定。我想&lt;strong&gt;你可能会问那什么时候需要&amp;quot;可重复读&amp;quot;的场景呢&lt;/strong&gt;？我们来看一个数据校对逻辑的案例。&lt;/p&gt;
&lt;p&gt;假设你在管理一个个人银行账户表。一个表存了每个月月底的余额，一个表存了账单明细。这时候你要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。&lt;/p&gt;
&lt;p&gt;这时候使用&amp;quot;可重复读&amp;quot;隔离级别就很方便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响。&lt;/p&gt;
&lt;h1 id=&#34;事务隔离的实现&#34;&gt;事务隔离的实现&lt;/h1&gt;
&lt;p&gt;理解了事务的隔离级别，我们再来看看事务隔离具体是怎么实现的。这里我们展开说明&amp;quot;可重复读&amp;quot;。&lt;/p&gt;
&lt;p&gt;在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。&lt;/p&gt;
&lt;p&gt;假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/d9/ee/d9c313809e5ac148fc39feff532f0fee.png&#34; alt=&#34;&#34;&gt;&lt;br&gt;
当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。&lt;/p&gt;
&lt;p&gt;同时你会发现，即使现在有另外一个事务正在将 4 改成 5，这个事务跟 read-view A、B、C 对应的事务是不会冲突的。&lt;/p&gt;
&lt;p&gt;你一定会问，回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。&lt;/p&gt;
&lt;p&gt;什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的 read-view 的时候。&lt;/p&gt;
&lt;p&gt;基于上面的说明，我们来讨论一下为什么建议你尽量不要使用长事务。&lt;/p&gt;
&lt;p&gt;长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。&lt;/p&gt;
&lt;p&gt;在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。我见过数据只有 20GB，而回滚段有 200GB 的库。最终只好为了清理回滚段，重建整个库。&lt;/p&gt;
&lt;p&gt;除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库，这个我们会在后面讲锁的时候展开。&lt;/p&gt;
&lt;h1 id=&#34;事务的启动方式&#34;&gt;事务的启动方式&lt;/h1&gt;
&lt;p&gt;如前面所述，长事务有这些潜在风险，我当然是建议你尽量避免。其实很多时候业务开发同学并不是有意使用长事务，通常是由于误用所致。MySQL 的事务启动方式有以下几种：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;有些客户端连接框架会默认连接成功后先执行一个 set autocommit=0 的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。&lt;/p&gt;
&lt;p&gt;因此，我会建议你总是使用 set autocommit=1, 通过显式语句的方式来启动事务。&lt;/p&gt;
&lt;p&gt;但是有的开发同学会纠结&amp;quot;多一次交互&amp;quot;的问题。对于一个需要频繁使用事务的业务，第二种方式每个事务在开始时都不需要主动执行一次 &amp;ldquo;begin&amp;rdquo;，减少了语句的交互次数。如果你也有这个顾虑，我建议你使用 commit work and chain 语法。&lt;/p&gt;
&lt;p&gt;在 autocommit 为 1 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。&lt;/p&gt;
&lt;p&gt;你可以在 information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&amp;gt;60
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;小结&#34;&gt;小结&lt;/h1&gt;
&lt;p&gt;这篇文章里面，我介绍了 MySQL 的事务隔离级别的现象和实现，根据实现原理分析了长事务存在的风险，以及如何用正确的方式避免长事务。希望我举的例子能够帮助你理解事务，并更好地使用 MySQL 的事务特性。&lt;/p&gt;
&lt;p&gt;我给你留一个问题吧。你现在知道了系统里面应该避免长事务，如果你是业务开发负责人同时也是数据库负责人，你会有什么方案来避免出现或者处理这种情况呢？&lt;/p&gt;
&lt;p&gt;你可以把你的思考和观点写在留言区里，我会在下一篇文章的末尾和你讨论这个问题。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。&lt;/p&gt;
&lt;h1 id=&#34;上期问题时间&#34;&gt;上期问题时间&lt;/h1&gt;
&lt;p&gt;在上期文章的最后，我给你留下的问题是一天一备跟一周一备的对比。&lt;/p&gt;
&lt;p&gt;好处是&amp;quot;最长恢复时间&amp;quot;更短。&lt;/p&gt;
&lt;p&gt;在一天一备的模式里，最坏情况下需要应用一天的 binlog。比如，你每天 0 点做一次全量备份，而要恢复出一个到昨天晚上 23 点的备份。&lt;/p&gt;
&lt;p&gt;一周一备最坏情况就要应用一周的 binlog 了。&lt;/p&gt;
&lt;p&gt;系统的对应指标就是 @尼古拉斯·赵四 @慕塔 提到的 RTO（恢复目标时间）。&lt;/p&gt;
&lt;p&gt;当然这个是有成本的，因为更频繁全量备份需要消耗更多存储空间，所以这个 RTO 是成本换来的，就需要你根据业务重要性来评估了。&lt;/p&gt;
&lt;p&gt;同时也感谢 @super blue cat、@高枕、@Jason 留下了高质量的评论。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/ce/d9/ce7f4e35916ed1aa49206a53a0547bd9.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 03丨初窥门径：我们要搭建一个怎样的微服务实战项目</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/springclouod%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/03%E4%B8%A8%E5%88%9D%E7%AA%A5%E9%97%A8%E5%BE%84%E6%88%91%E4%BB%AC%E8%A6%81%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%80%8E%E6%A0%B7%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/springclouod%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/03%E4%B8%A8%E5%88%9D%E7%AA%A5%E9%97%A8%E5%BE%84%E6%88%91%E4%BB%AC%E8%A6%81%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%80%8E%E6%A0%B7%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/</guid>
      <description>
        
        
        &lt;p&gt;你好，我是姚秋辰。&lt;/p&gt;
&lt;p&gt;在上一节课，我跟你介绍了 Spring Cloud 的发展背景以及各个组件库，此刻，你一定已经跃跃欲试想要立马开始动手编写实战项目了吧？别着急，今天咱先别忙着敲代码，让我先为你勾画出实战项目的全景蓝图。&lt;/p&gt;
&lt;p&gt;这节课，我会跟你聊一聊我们这个优惠券平台项目的整体功能和模块，以及每个功能点的技术选型和背后的依据，让你从宏观的角度来了解一下我们整个项目的概貌和大致的走向，帮助你更轻松地学习后面的课程。首先，我来带你了解一下这个实战项目的业务功能。&lt;/p&gt;
&lt;h1 id=&#34;优惠券平台项目介绍&#34;&gt;优惠券平台项目介绍&lt;/h1&gt;
&lt;p&gt;相信你一定参与过双 11 或者 618 之类的电商大促活动，体验过各种眼花缭乱的优惠券和营销规则计算。而我们的实战项目，就是要搭建一个简化版的营销优惠计算系统，实现优惠券模板的创建、用户领取优惠券、下单核销优惠券和订单价格试计算等功能。&lt;/p&gt;
&lt;p&gt;我曾经参与了一线电商新零售平台营销中心业务从 0 到 1 的搭建，与淘系营销优惠平台 UMP 对接过很多花式营销玩法。根据我过去的经验，如果我要实现一个&amp;quot;领取优惠券&amp;quot;的功能，那么我首先是要创建一个营销规则模板。这个模板就像是一个模具一样，每张优惠券都通过这个模具来铸造，并最终发放到用户手中。&lt;/p&gt;
&lt;p&gt;使用模板的好处是可以对优惠券消费规则做一层抽象，比如满减类、打折类这些优惠券只是具体的优惠金额不同，但是玩法类似，我们把相类似的玩法功能抽象成一个模板，就可以简化具体优惠券的创建和核销流程。&lt;/p&gt;
&lt;p&gt;在这个实战项目中，我也借鉴了之前的工作经验，把整个项目划分为了优惠券模板服务、计算服务、用户服务和平台类组件这四大模块。它们的功能是这样的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;优惠券模板服务&lt;/strong&gt;：模板规则是创建具体优惠券的前置条件，每种类型的模板都是一个计算公式，这个公式约定了优惠计算的方式。在这个项目中，模板服务实现了模板规则的创建、克隆、分页查找等功能。另外，我将在项目里定义满减、随机立减、满折、晚间双倍优惠等多种券模板类型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优惠计算服务&lt;/strong&gt;：这个模块是根据用户购物车中的商品信息（单价、数量、所属门店）和优惠券信息，来计算当前订单优惠后的价格。另外，如果用户有多张优惠券，我还提供了&amp;quot;优惠金额试算&amp;quot;服务，帮助用户挑选最省钱的优惠券。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;用户服务&lt;/strong&gt;：这是暴露给外部用户使用的接口，它依赖于模板服务和优惠计算服务完成底层逻辑，主要业务场景是用户领券、订单价格试算、下单核销和订单金额试算等功能。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;平台类组件&lt;/strong&gt;：主要包括一些业务无关的中心化组件，比如 Gateway 网关等等，你将在 Spring Cloud 课程中逐渐接触到平台类组件的搭建。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;从整体来看，优惠券模板服务和优惠计算服务是基础服务，用户服务是对用户开放的接口，它依赖于这两个基础服务来完成业务逻辑。而平台类组件则提供了横向的微服务特性支持，比如微服务网关、链路追踪功能等等，你可以把它们理解为&amp;quot;微服务中间件&amp;quot;。我们通过下面这幅图来看一下这四个模块之间的关联关系：&lt;br&gt;
&lt;img src=&#34;https://static001.geekbang.org/resource/image/b0/01/b06e7ba06965b497f07285b571f8fa01.jpg?wh=2000x1039&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;我们在开篇词中提到，为了帮你顺利过渡到 Spring Cloud 实战，我会先用 Spring Boot 搭建出这个优惠券平台的单体应用，然后在这个基础上做 Spring Cloud 改造。&lt;/p&gt;
&lt;h1 id=&#34;spring-boot-实战项目规划&#34;&gt;Spring Boot 实战项目规划&lt;/h1&gt;
&lt;p&gt;从项目实施的角度来看，Spring Boot 阶段的任务相对简单。我们会用两节课搭建起优惠券平台的三个业务模块，并按照模块之间的先后依赖顺序进行改造。在第一节课中，我将带你搭建一个单体应用版的优惠券模板服务，在这个过程中我们会使用 spring-data-jpa 和 spring-web 实现系统搭建。其中，spring-data-jpa 是用来实现数据库 CRUD 操作的组件，而 spring-web 是开发 RESTFul 风格的 API 接口所需要用到的组件。接着在第二节课中，我们将使用同样的技术搭建订单优惠计算服务和用户服务。&lt;/p&gt;
&lt;p&gt;这里你要注意，在 Spring Boot 的阶段，用户服务是一个&amp;quot;超级单体应用&amp;quot;，我把优惠券模板服务和订单优惠计算服务都打包到了用户服务中，跨模块的服务调用都是通过本地方法完成的，因此你只用启动用户服务就可以执行所有模块的业务功能。&lt;/p&gt;
&lt;p&gt;在搭建项目的过程中，我会带你重点掌握以下这三个技术点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;项目搭建&lt;/strong&gt;：分层构建项目结构，并借助 Maven 实现依赖项管理；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据操作&lt;/strong&gt;：我会带你快速入门 spring-data-jpa 实战，分别通过接口声明、自定义 SQL 和 JpaRepository 三种方式实现数据库 CRUD 操作；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;开放对外 API&lt;/strong&gt;：快速入门 spring-web 实战，通过注解对外暴露 RESTful 风格的 API。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此外，我还会不断跟你分享一些我平时工作中积累的小技巧，比如防御型编程、如何借助插件自动生成代码和数据校验、JPA 级联关系的误区、计算密集型服务的特点、模板设计模式的应用等等，相信这些内容可以给你一些工作上的启发。&lt;/p&gt;
&lt;p&gt;Spring Boot 的官方社区提供了一个非常简单的 Hello World 教程，如果你没有太多 Spring Boot 的使用经验，那么可以通过这个教程链接Spring Quickstart Guide来了解 Spring Boot 的搭建过程。&lt;/p&gt;
&lt;p&gt;在 Spring Boot 阶段我们搭建好优惠券平台的单体应用后，接下来就可以进行 Spring Cloud 微服务化改造了。&lt;/p&gt;
&lt;h1 id=&#34;spring-cloud-实战项目全景规划&#34;&gt;Spring Cloud 实战项目全景规划&lt;/h1&gt;
&lt;p&gt;我们先来看一下优惠券平台采用微服务架构，整体的技术方案规划和技术选型是怎样的。下面这张图里列举的技术框架都是目前一线广泛使用的开源组件。&lt;br&gt;
&lt;img src=&#34;https://static001.geekbang.org/resource/image/65/a7/65a733f0e38c0a374bd1d0ecbf2d18a7.jpg?wh=2000x1039&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;看到图中的这些技术点，我想此刻的你一定很懵，不知道这些技术框架的用途，也不知道该从何处下手来做改造。那么，接下来让我跟你聊聊我如何设计 Spring Cloud 实战课程的技术选型以及总体的搭建流程，这样你就能做到心中有数，学起来也能得心应手了。&lt;/p&gt;
&lt;p&gt;根据微服务学习的路径以及各个组件的难易程度，我把整个微服务框架由浅入深分为了三个不同的阶段：&lt;/p&gt;
&lt;p&gt;第一阶段：搭建基础的微服务功能，实现&lt;strong&gt;微服务之间的通信&lt;/strong&gt;；&lt;/p&gt;
&lt;p&gt;第二阶段：为各个模块构建&lt;strong&gt;服务容错&lt;/strong&gt;、&lt;strong&gt;分布式配置中心&lt;/strong&gt;、&lt;strong&gt;分布式链路追踪能力&lt;/strong&gt;；&lt;/p&gt;
&lt;p&gt;第三阶段：进一步实现&lt;strong&gt;微服务网关&lt;/strong&gt;、&lt;strong&gt;消息驱动&lt;/strong&gt;和&lt;strong&gt;分布式事务&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;下面我们来看下每个阶段主要做些什么以及对应的技术选型。&lt;/p&gt;
&lt;h1 id=&#34;第一阶段&#34;&gt;第一阶段&lt;/h1&gt;
&lt;p&gt;在第一阶段，我们主要实现&lt;strong&gt;微服务之间的通信&lt;/strong&gt;，将用户微服务、优惠券模板服务和订单优惠计算服务拆分为独立部署的业务系统，通过注册中心来实现服务注册和服务发现，让各个微服务之间可以互相调用。这个阶段涉及的关键技术是 Nacos 注册中心、Loadbalancer 客户端负载均衡组件和 OpenFeign 服务间调用组件。&lt;/p&gt;
&lt;p&gt;我们知道，微服务之间的服务通信有一个前提条件，就是你要知道将要调用的服务器地址是什么。这个寻址的任务是交由 Nacos 注册中心和 Loadbalancer 负载均衡器共同来完成的。&lt;/p&gt;
&lt;p&gt;Nacos 是 Alibaba 出品的服务治理组件，它作为一个注册中心组件，负责收集所有服务节点的地址信息并维护服务注册表，所有服务上线之后都会向它汇报状态。Loadbalancer 则承担了负载均衡的任务，在客户端发起服务调用的时候，它会负责从 Nacos 的注册表中挑选一台目标服务器。而 OpenFeign 组件是一个&amp;quot;锦上添花&amp;quot;的组件，它能够简化基于 HTTP 的远程服务调用，让我们就像使用本地接口一样方便地发起远程服务调用。&lt;/p&gt;
&lt;p&gt;为什么我会选择 Nacos+Loadbalancer 作为选型方案呢？其实，在早期版本的 Spring Cloud 微服务架构选型中，Eureka + Ribbon 是一个使用最为广泛的组合，它们是 Netflix 公司贡献给 Spring Cloud 项目的服务治理 + 负载均衡组件。&lt;/p&gt;
&lt;p&gt;我们在上节课中讲过，Netflix 正在退出 Spring Cloud 的历史舞台。Eureka 和 Ribbon 已经进入了维护状态。其中，Ribbon 更是在 Spring Cloud I 版之后，就从官方组件库中被移除了。这意味着 Eureka 和 Ribbon 已经进入了&amp;quot;暮年&amp;quot;，不会再有重大的功能更新，如果你在项目中使用 Netflix 组件库，那么在未来将无法享受 Spring Cloud 社区发布的新功能。&lt;/p&gt;
&lt;p&gt;因此，在考虑技术选型的时候，我选择了&lt;strong&gt;后劲更足、功能更为强大&lt;/strong&gt;的 Nacos 和 Spring Cloud 官方开源的 Loadbalancer 组件。大致来讲，在第一阶段，我会分为三个部分来带你搭建起微服务之间的通信：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;服务治理&lt;/strong&gt;：服务治理的重点是搭建基础的跨服务调用功能。我会把用户服务、优惠计算服务和订单服务改造成可以独立启动的微服务，并借助 Nacos 的服务发现功能，通过 Webflux 组件中的 WebClient 实现基于 HTTP 的跨服务间的调用；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;负载均衡&lt;/strong&gt;：在这部分，我们将在服务治理的基础上，引入 Loadbalancer 组件为跨服务调用添加负载均衡的能力。除此之外，我会对 Loadbalancer 组件的扩展接口做自定义开发，实现一个金丝雀测试的负载均衡场景；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;简化服务调用&lt;/strong&gt;：我将使用 OpenFeign 组件对用户服务进行改造，将原先复杂的 WebClient 调用替换为简洁的 OpenFeign 调用。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;第二阶段&#34;&gt;第二阶段&lt;/h1&gt;
&lt;p&gt;在第二阶段，我们的实战重点有三个：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;利用服务容错提高微服务架构的可用性；&lt;/li&gt;
&lt;li&gt;搭建全链路的分布式链路追踪能力；&lt;/li&gt;
&lt;li&gt;实现统一的配置管理和动态属性推送。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这个阶段涉及的技术组件是 Nacos Config、Sentinel、Sleuth+Zipkin+ELK。&lt;/p&gt;
&lt;p&gt;在微服务架构中，&lt;strong&gt;服务容错&lt;/strong&gt;是保障服务高可用的一个重要手段。在这个项目中，我们选择用 Sentinel 作为服务容错组件，它也是 Alibaba 贡献给 Spring Cloud 的。Sentinel 秉承了阿里系&amp;quot;大而全&amp;quot;的传统，只这一款组件就可以实现&lt;strong&gt;降级&lt;/strong&gt;、&lt;strong&gt;熔断&lt;/strong&gt;、&lt;strong&gt;流量整形&lt;/strong&gt;等多种服务容错途径。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;链路追踪&lt;/strong&gt;也是微服务架构中一个很重要的功能，线上异常排查全靠它提供线索。我使用了 Spring Cloud 官方开源的 Sleuth 实现了日志打标功能，使用全局唯一标记将一次跨微服务调用链上的各个环节全部串联起来。&lt;/p&gt;
&lt;p&gt;光打标还没用，我还结合了 Zipkin 组件实现&lt;strong&gt;调用链的可视化检索&lt;/strong&gt;，将调用链上各个阶段的请求按顺序显示在页面上，这样，我们就可以一目了然定位到线上异常发生在哪个环节。另外，我使用了目前业界主流的 ELK 组合（Elastic Search + Logstash + Kibana）作为日志检索系统。&lt;/p&gt;
&lt;p&gt;在&lt;strong&gt;配置项管理&lt;/strong&gt;的技术选型方面，我使用了 Nacos Config 作为最终方案。借助 Nacos Config 我们可以轻松实现配置项的远程获取和动态推送，在配置项的应用隔离和环境隔离方面 Nacos 也是一把好手，我将会在配置管理的实战环节讲述更多的配置项花式玩法。相比较 Spring Cloud 的另一款配置管理组件 Spring Cloud Config 来说，Nacos 的搭建更加容易且更易于上手，而且可以更好地支持&amp;quot;配置项&amp;quot;回滚的功能。&lt;/p&gt;
&lt;p&gt;在后面的课程中，我将按照下面的顺序来实现这些能力：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;配置管理&lt;/strong&gt;：配置管理的重点是将三个微服务应用接入到 Nacos Config 配置中心，使用远程配置中心存储部分配置项。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;服务容错&lt;/strong&gt;：搭建 Sentinel Dashboard 控制台，通过控制台将降级规则和流量整形规则应用到业务埋点中。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;链路追踪&lt;/strong&gt;：这部分的重点是搭建分布式链路追踪与日志系统。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;第三阶段&#34;&gt;第三阶段&lt;/h1&gt;
&lt;p&gt;在第三阶段，我们的实战重点有三个：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;搭建微服务网关作为统一流量入口；&lt;/li&gt;
&lt;li&gt;使用消息驱动组件对接 RabbitMQ；&lt;/li&gt;
&lt;li&gt;通过分布式事务保证数据一致性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这个阶段涉及的技术组件是 Gateway、Stream 和 Seata。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;微服务网关&lt;/strong&gt;是架设在外部网关（如 Ngnix）和内部微服务之间的一座桥梁，我选用 Spring Cloud Gateway 作为网关组件。Gateway 不光担任了路由转发的重任，同时它提供了丰富的谓词组合实现复杂的路由判断逻辑。除此以外，你还可以在网关层定义拦截器，对来访请求执行一段特殊的业务逻辑。&lt;/p&gt;
&lt;p&gt;曾经微服务网关的头把交椅是 Netflix 贡献的 Zuul 组件，但 Zuul 2.0 的开源发布一拖再拖，且性能并未达到预期效果。Spring Cloud 官方迫不得已，还没等到 Zuul 2.0 发布，就自己发布了一款开源网关组件 Spring Cloud Gateway。基于这些原因，Gateway 当之无愧成为了网关层的不二选择。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;消息队列和消息驱动&lt;/strong&gt;是老牌技术了，它并不是微服务特有的功能，我之所以在课程中加入了消息驱动这个内容，主要有两个原因。一是我想让你了解 Spring Cloud 开源的消息驱动组件&amp;quot;Stream&amp;quot;，它可以大幅降低应用系统和消息组件之间的对接流程。二是消息组件在如今有非常丰富的使用场景，我希望将&amp;quot;&lt;strong&gt;消息组件的应用场景&lt;/strong&gt;&amp;ldquo;作为一个知识拓展点，帮助你开阔眼界。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;分布式事务&lt;/strong&gt;是微服务环境下保证事务一致性的终极手段。在课程中我将主要介绍两种比较有代表性的 Seata 分布式事务解决方案，一种是没有代码侵入的 Seata AT 方案，另一种是蚂蚁金服贡献的资源锁定 + 补偿型的 Seata TCC 方案。&lt;/p&gt;
&lt;p&gt;好，到这里，我们就完整了解了整个项目的全景规划，以及对应的技术选型。现在，我们来回顾一下这节课的重点内容。&lt;/p&gt;
&lt;h1 id=&#34;总结&#34;&gt;总结&lt;/h1&gt;
&lt;p&gt;在整个项目中，我们先通过 Spring Boot 快速落地了优惠券平台的三个业务模块，然后，在 Spring Cloud 实战阶段，我们分为三个阶段对 Spring Boot 项目进行微服务化改造：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一个阶段使用 Nacos、Loadbalancer 和 OpenFeign 实现了跨服务的调用；&lt;/li&gt;
&lt;li&gt;第二阶段使用 Sentinel、Nacos Config 和 Sleuth 实现了服务容错、配置管理和分布式链路追踪；&lt;/li&gt;
&lt;li&gt;第三阶段使用 Gateway、Stream 和 Seata 实现了微服务网关、消息事件驱动和分布式事务。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在学习专栏的过程中，我不建议你&amp;quot;跳章节&amp;quot;学习，正确的姿势是顺着专栏的各个阶段稳步推进。因为每一个阶段的内容都有前后关系，后一个技术组件或多或少都依赖于前面课程中用到的组件，如果跳跃了几个章节，很容易漏掉一些关键步骤的配置和搭建过程，导致项目无法启动。&lt;/p&gt;
&lt;p&gt;学习过程中我们难免会碰到各种问题，需要求助于搜索引擎。你也许用得比较多的是国内的搜索引擎，但经常查到千篇一律的文章，又或者看一个解决方案还需要注册会员或者付费，体验相当不好。&lt;/p&gt;
&lt;p&gt;因此，我推荐你偶尔尝试使用 Google 和stackoverflow两个网站来查询解决方案。这两个网站是对我的工作最有帮助的两位老师，不仅能帮助你解决问题，还可以锻炼你的英文阅读能力。要知道英文能力对技术人员来说还是相当重要的，尤其是当你想要了解一些前沿技术或者阅读一些论文的时候。所以，提高英文阅读能力要靠你平时的不断积累才行。&lt;/p&gt;
&lt;h1 id=&#34;思考题&#34;&gt;思考题&lt;/h1&gt;
&lt;p&gt;最后，请你思考一下，还有哪些微服务的技术点是你想了解的，你可以在留言区提出感兴趣的技术，在后期我可以把呼声比较高的技术点通过加餐的形式分享给你，让我们这个课程能够持续更新和演进。我在留言区等你。&lt;/p&gt;
&lt;p&gt;好啦，这节课就结束啦。欢迎你把这节课分享给更多对 Spring Cloud 感兴趣的朋友。我是姚秋辰，我们下节课再见！&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 03丨复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/03%E4%B8%A8%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90%E4%B8%8A%E5%A6%82%E4%BD%95%E5%88%86%E6%9E%90%E7%BB%9F%E8%AE%A1%E7%AE%97%E6%B3%95%E7%9A%84%E6%89%A7%E8%A1%8C%E6%95%88%E7%8E%87%E5%92%8C%E8%B5%84%E6%BA%90%E6%B6%88%E8%80%97/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/03%E4%B8%A8%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90%E4%B8%8A%E5%A6%82%E4%BD%95%E5%88%86%E6%9E%90%E7%BB%9F%E8%AE%A1%E7%AE%97%E6%B3%95%E7%9A%84%E6%89%A7%E8%A1%8C%E6%95%88%E7%8E%87%E5%92%8C%E8%B5%84%E6%BA%90%E6%B6%88%E8%80%97/</guid>
      <description>
        
        
        &lt;p&gt;我们都知道，数据结构和算法本身解决的是&amp;quot;快&amp;quot;和&amp;quot;省&amp;quot;的问题，即如何让代码运行得更快，如何让代码更省存储空间。所以，执行效率是算法一个非常重要的考量指标。那如何来衡量你编写的算法代码的执行效率呢？这里就要用到我们今天要讲的内容：时间、空间复杂度分析。&lt;/p&gt;
&lt;p&gt;其实，只要讲到数据结构与算法，就一定离不开时间、空间复杂度分析。而且，我个人认为，&lt;strong&gt;复杂度分析是整个算法学习的精髓，只要掌握了它，数据结构和算法的内容基本上就掌握了一半&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;复杂度分析实在太重要了，因此我准备用两节内容来讲。希望你学完这个内容之后，无论在任何场景下，面对任何代码的复杂度分析，你都能做到&amp;quot;庖丁解牛&amp;quot;般游刃有余。&lt;/p&gt;
&lt;h2 id=&#34;为什么需要复杂度分析&#34;&gt;为什么需要复杂度分析？&lt;/h2&gt;
&lt;p&gt;你可能会有些疑惑，我把代码跑一遍，通过统计、监控，就能得到算法执行的时间和占用的内存大小。为什么还要做时间、空间复杂度分析呢？这种分析方法能比我实实在在跑一遍得到的数据更准确吗？&lt;/p&gt;
&lt;p&gt;首先，我可以肯定地说，你这种评估算法执行效率的方法是正确的。很多数据结构和算法书籍还给这种方法起了一个名字，叫&lt;strong&gt;事后统计法&lt;/strong&gt;。但是，这种统计方法有非常大的局限性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. 测试结果非常依赖测试环境&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;测试环境中硬件的不同会对测试结果有很大的影响。比如，我们拿同样一段代码，分别用 Intel Core i9 处理器和 Intel Core i3 处理器来运行，不用说，i9 处理器要比 i3 处理器执行的速度快很多。还有，比如原本在这台机器上 a 代码执行的速度比 b 代码要快，等我们换到另一台机器上时，可能会有截然相反的结果。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. 测试结果受数据规模的影响很大&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;后面我们会讲排序算法，我们先拿它举个例子。对同一个排序算法，待排序数据的有序度不一样，排序的执行时间就会有很大的差别。极端情况下，如果数据已经是有序的，那排序算法不需要做任何操作，执行时间就会非常短。除此之外，如果测试数据规模太小，测试结果可能无法真实地反应算法的性能。比如，对于小规模的数据排序，插入排序可能反倒会比快速排序要快！&lt;/p&gt;
&lt;p&gt;所以，&lt;strong&gt;我们需要一个不用具体的测试数据来测试，就可以粗略地估计算法的执行效率的方法&lt;/strong&gt;。这就是我们今天要讲的时间、空间复杂度分析方法。&lt;/p&gt;
&lt;h2 id=&#34;大-o-复杂度表示法&#34;&gt;大 O 复杂度表示法&lt;/h2&gt;
&lt;p&gt;算法的执行效率，粗略地讲，就是算法代码执行的时间。但是，如何在不运行代码的情况下，用&amp;quot;肉眼&amp;quot;得到一段代码的执行时间呢？&lt;/p&gt;
&lt;p&gt;这里有段非常简单的代码，求 1,2,3&amp;hellip;n 的累加和。现在，我就带你一块来估算一下这段代码的执行时间。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; int cal(int n) {
   int sum = 0;
   int i = 1;
   for (; i &amp;lt;= n; ++i) {
     sum = sum + i;
   }
   return sum;
 }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;从 CPU 的角度来看，这段代码的每一行都执行着类似的操作：&lt;strong&gt;读数据&lt;/strong&gt; -&lt;strong&gt;运算&lt;/strong&gt; -&lt;strong&gt;写数据&lt;/strong&gt;。尽管每行代码对应的 CPU 执行的个数、执行的时间都不一样，但是，我们这里只是粗略估计，所以可以假设每行代码执行的时间都一样，为 unit_time。在这个假设的基础之上，这段代码的总执行时间是多少呢？&lt;/p&gt;
&lt;p&gt;第 2、3 行代码分别需要 1 个 unit_time 的执行时间，第 4、5 行都运行了 n 遍，所以需要 2n*unit_time 的执行时间，所以这段代码总的执行时间就是 (2n+2)*unit_time。可以看出来，&lt;strong&gt;所有代码的执行时间 T(n) 与每行代码的执行次数成正比&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;按照这个分析思路，我们再来看这段代码。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; int cal(int n) {
   int sum = 0;
   int i = 1;
   int j = 1;
   for (; i &amp;lt;= n; ++i) {
     j = 1;
     for (; j &amp;lt;= n; ++j) {
       sum = sum +  i * j;
     }
   }
 }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们依旧假设每个语句的执行时间是 unit_time。那这段代码的总执行时间 T(n) 是多少呢？&lt;/p&gt;
&lt;p&gt;第 2、3、4 行代码，每行都需要 1 个 unit_time 的执行时间，第 5、6 行代码循环执行了 n 遍，需要 2n * unit_time 的执行时间，第 7、8 行代码循环执行了 n^2^遍，所以需要 2n^2^ * unit_time 的执行时间。所以，整段代码总的执行时间 T(n) = (2n^2^+2n+3)*unit_time。&lt;/p&gt;
&lt;p&gt;尽管我们不知道 unit_time 的具体值，但是通过这两段代码执行时间的推导过程，我们可以得到一个非常重要的规律，那就是，&lt;strong&gt;所有代码的执行时间 T(n) 与每行代码的执行次数 n 成正比&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;我们可以把这个规律总结成一个公式。注意，大 O 就要登场了！&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/22/ef/22900968aa2b190072c985a08b0e92ef.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;我来具体解释一下这个公式。其中，T(n) 我们已经讲过了，它表示代码执行的时间；n 表示数据规模的大小；f(n) 表示每行代码执行的次数总和。因为这是一个公式，所以用 f(n) 来表示。公式中的 O，表示代码的执行时间 T(n) 与 f(n) 表达式成正比。&lt;/p&gt;
&lt;p&gt;所以，第一个例子中的 T(n) = O(2n+2)，第二个例子中的 T(n) = O(2n^2^+2n+3)。这就是&lt;strong&gt;大 O 时间复杂度表示法&lt;/strong&gt; 。大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是表示&lt;strong&gt;代码执行时间随数据规模增长的变化趋势&lt;/strong&gt; ，所以，也叫作&lt;strong&gt;渐进时间复杂度&lt;/strong&gt; （asymptotic time complexity），简称&lt;strong&gt;时间复杂度&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;当 n 很大时，你可以把它想象成 10000、100000。而公式中的低阶、常量、系数三部分并不左右增长趋势，所以都可以忽略。我们只需要记录一个最大量级就可以了，如果用大 O 表示法表示刚讲的那两段代码的时间复杂度，就可以记为：T(n) = O(n)； T(n) = O(n^2^)。&lt;/p&gt;
&lt;h2 id=&#34;时间复杂度分析&#34;&gt;时间复杂度分析&lt;/h2&gt;
&lt;p&gt;前面介绍了大 O 时间复杂度的由来和表示方法。现在我们来看下，如何分析一段代码的时间复杂度？我这儿有三个比较实用的方法可以分享给你。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. 只关注循环执行次数最多的一段代码&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我刚才说了，大 O 这种复杂度表示方法只是表示一种变化趋势。我们通常会忽略掉公式中的常量、低阶、系数，只需要记录一个最大阶的量级就可以了。所以，&lt;strong&gt;我们在分析一个算法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以了&lt;/strong&gt;。这段核心代码执行次数的 n 的量级，就是整段要分析代码的时间复杂度。&lt;/p&gt;
&lt;p&gt;为了便于你理解，我还拿前面的例子来说明。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; int cal(int n) {
   int sum = 0;
   int i = 1;
   for (; i &amp;lt;= n; ++i) {
     sum = sum + i;
   }
   return sum;
 }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中第 2、3 行代码都是常量级的执行时间，与 n 的大小无关，所以对于复杂度并没有影响。循环执行次数最多的是第 4、5 行代码，所以这块代码要重点分析。前面我们也讲过，这两行代码被执行了 n 次，所以总的时间复杂度就是 O(n)。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. 加法法则：总复杂度等于量级最大的那段代码的复杂度&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我这里还有一段代码。你可以先试着分析一下，然后再往下看跟我的分析思路是否一样。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int cal(int n) {
   int sum_1 = 0;
   int p = 1;
   for (; p &amp;lt; 100; ++p) {
     sum_1 = sum_1 + p;
   }
 
   int sum_2 = 0;
   int q = 1;
   for (; q &amp;lt; n; ++q) {
     sum_2 = sum_2 + q;
   }
 
   int sum_3 = 0;
   int i = 1;
   int j = 1;
   for (; i &amp;lt;= n; ++i) {
     j = 1; 
     for (; j &amp;lt;= n; ++j) {
       sum_3 = sum_3 +  i * j;
     }
   }
 
   return sum_1 + sum_2 + sum_3;
 }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个代码分为三部分，分别是求 sum_1、sum_2、sum_3。我们可以分别分析每一部分的时间复杂度，然后把它们放到一块儿，再取一个量级最大的作为整段代码的复杂度。&lt;/p&gt;
&lt;p&gt;第一段的时间复杂度是多少呢？这段代码循环执行了 100 次，所以是一个常量的执行时间，跟 n 的规模无关。&lt;/p&gt;
&lt;p&gt;这里我要再强调一下，即便这段代码循环 10000 次、100000 次，只要是一个已知的数，跟 n 无关，照样也是常量级的执行时间。当 n 无限大的时候，就可以忽略。尽管对代码的执行时间会有很大影响，但是回到时间复杂度的概念来说，它表示的是一个算法执行效率与数据规模增长的变化趋势，所以不管常量的执行时间多大，我们都可以忽略掉。因为它本身对增长趋势并没有影响。&lt;/p&gt;
&lt;p&gt;那第二段代码和第三段代码的时间复杂度是多少呢？答案是 O(n) 和 O(n^2^)，你应该能容易就分析出来，我就不啰嗦了。&lt;/p&gt;
&lt;p&gt;综合这三段代码的时间复杂度，我们取其中最大的量级。所以，整段代码的时间复杂度就为 O(n^2^)。也就是说：&lt;strong&gt;总的时间复杂度&lt;strong&gt;&lt;strong&gt;就&lt;/strong&gt;&lt;/strong&gt;等于量级最大的那段代码的时间复杂度&lt;/strong&gt;。那我们将这个规律抽象成公式就是：&lt;/p&gt;
&lt;p&gt;如果 T1(n)=O(f(n))，T2(n)=O(g(n))；那么 T(n)=T1(n)+T2(n)=max(O(f(n)), O(g(n))) =O(max(f(n), g(n))).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我刚讲了一个复杂度分析中的加法法则，这儿还有一个&lt;strong&gt;乘法法则&lt;/strong&gt;。类比一下，你应该能&amp;quot;猜到&amp;quot;公式是什么样子的吧？&lt;/p&gt;
&lt;p&gt;如果 T1(n)=O(f(n))，T2(n)=O(g(n))；那么 T(n)=T1(n)*T2(n)=O(f(n))*O(g(n))=O(f(n)*g(n)).&lt;/p&gt;
&lt;p&gt;也就是说，假设 T1(n) = O(n)，T2(n) = O(n^2^)，则 T1(n) * T2(n) = O(n^3^)。落实到具体的代码上，我们可以把乘法法则看成是&lt;strong&gt;嵌套循环&lt;/strong&gt;，我举个例子给你解释一下。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int cal(int n) {
   int ret = 0; 
   int i = 1;
   for (; i &amp;lt; n; ++i) {
     ret = ret + f(i);
   } 
 } 
 
 int f(int n) {
  int sum = 0;
  int i = 1;
  for (; i &amp;lt; n; ++i) {
    sum = sum + i;
  } 
  return sum;
 }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们单独看 cal() 函数。假设 f() 只是一个普通的操作，那第 4～6 行的时间复杂度就是，T1(n) = O(n)。但 f() 函数本身不是一个简单的操作，它的时间复杂度是 T2(n) = O(n)，所以，整个 cal() 函数的时间复杂度就是，T(n) = T1(n) * T2(n) = O(n*n) = O(n^2^)。&lt;/p&gt;
&lt;p&gt;我刚刚讲了三种复杂度的分析技巧。不过，你并不用刻意去记忆。实际上，复杂度分析这个东西关键在于&amp;quot;熟练&amp;quot;。你只要多看案例，多分析，就能做到&amp;quot;无招胜有招&amp;quot;。&lt;/p&gt;
&lt;h2 id=&#34;几种常见时间复杂度实例分析&#34;&gt;几种常见时间复杂度实例分析&lt;/h2&gt;
&lt;p&gt;虽然代码千差万别，但是常见的复杂度量级并不多。我稍微总结了一下，这些复杂度量级几乎涵盖了你今后可以接触的所有代码的复杂度量级。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/37/0a/3723793cc5c810e9d5b06bc95325bf0a.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;对于刚罗列的复杂度量级，我们可以粗略地分为两类，&lt;strong&gt;多项式量级&lt;/strong&gt; 和&lt;strong&gt;非多项式量级&lt;/strong&gt; 。其中，非多项式量级只有两个：O(2^n^) 和 O(n!)。&lt;/p&gt;
&lt;p&gt;当数据规模 n 越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。所以，非多项式时间复杂度的算法其实是非常低效的算法。因此，关于 NP 时间复杂度我就不展开讲了。我们主要来看几种常见的&lt;strong&gt;多项式时间复杂度&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. O(1)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;首先你必须明确一个概念，O(1) 只是常量级时间复杂度的一种表示方法，并不是指只执行了一行代码。比如这段代码，即便有 3 行，它的时间复杂度也是 O(1），而不是 O(3)。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; int i = 8;
 int j = 6;
 int sum = i + j;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我稍微总结一下，只要代码的执行时间不随 n 的增大而增长，这样代码的时间复杂度我们都记作 O(1)。或者说，&lt;strong&gt;一般&lt;strong&gt;&lt;strong&gt;情况下&lt;/strong&gt;&lt;/strong&gt;，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. O(logn)、O(nlogn)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对数阶时间复杂度非常常见，同时也是最难分析的一种时间复杂度。我通过一个例子来说明一下。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; i=1;
 while (i &amp;lt;= n)  {
   i = i * 2;
 }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;根据我们前面讲的复杂度分析方法，第三行代码是循环执行次数最多的。所以，我们只要能计算出这行代码被执行了多少次，就能知道整段代码的时间复杂度。&lt;/p&gt;
&lt;p&gt;从代码中可以看出，变量 i 的值从 1 开始取，每循环一次就乘以 2。当大于 n 时，循环结束。还记得我们高中学过的等比数列吗？实际上，变量 i 的取值就是一个等比数列。如果我把它一个一个列出来，就应该是这个样子的：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/9b/9a/9b1c88264e7a1a20b5954be9bc4bec9a.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;所以，我们只要知道 x 值是多少，就知道这行代码执行的次数了。通过 2^x^=n 求解 x 这个问题我们想高中应该就学过了，我就不多说了。x=log~2~n，所以，这段代码的时间复杂度就是 O(log~2~n)。&lt;/p&gt;
&lt;p&gt;现在，我把代码稍微改下，你再看看，这段代码的时间复杂度是多少？&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; i=1;
 while (i &amp;lt;= n)  {
   i = i * 3;
 }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;根据我刚刚讲的思路，很简单就能看出来，这段代码的时间复杂度为 O(log~3~n)。&lt;/p&gt;
&lt;p&gt;实际上，不管是以 2 为底、以 3 为底，还是以 10 为底，我们可以把所有对数阶的时间复杂度都记为 O(logn)。为什么呢？&lt;/p&gt;
&lt;p&gt;我们知道，对数之间是可以互相转换的，log~3~n 就等于 log~3~2 * log~2~n，所以 O(log~3~n) = O(C * log~2~n)，其中 C=log~3~2 是一个常量。基于我们前面的一个理论：&lt;strong&gt;在采用大 O 标记复杂度的时候，可以忽略系数，即 O(Cf(n)) = O(f(n))&lt;/strong&gt; 。所以，O(log~2~n) 就等于 O(log~3~n)。因此，在对数阶时间复杂度的表示方法里，我们忽略对数的&amp;quot;底&amp;quot;，统一表示为 O(logn)。&lt;/p&gt;
&lt;p&gt;如果你理解了我前面讲的 O(logn)，那 O(nlogn) 就很容易理解了。还记得我们刚讲的乘法法则吗？如果一段代码的时间复杂度是 O(logn)，我们循环执行 n 遍，时间复杂度就是 O(nlogn) 了。而且，O(nlogn) 也是一种非常常见的算法时间复杂度。比如，归并排序、快速排序的时间复杂度都是 O(nlogn)。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. O(m+n)、O(m*n)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们再来讲一种跟前面都不一样的时间复杂度，代码的复杂度&lt;strong&gt;由两个数据的规模&lt;/strong&gt;来决定。老规矩，先看代码！&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int cal(int m, int n) {
  int sum_1 = 0;
  int i = 1;
  for (; i &amp;lt; m; ++i) {
    sum_1 = sum_1 + i;
  }
 
  int sum_2 = 0;
  int j = 1;
  for (; j &amp;lt; n; ++j) {
    sum_2 = sum_2 + j;
  }
 
  return sum_1 + sum_2;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;从代码中可以看出，m 和 n 是表示两个数据规模。我们无法事先评估 m 和 n 谁的量级大，所以我们在表示复杂度的时候，就不能简单地利用加法法则，省略掉其中一个。所以，上面代码的时间复杂度就是 O(m+n)。&lt;/p&gt;
&lt;p&gt;针对这种情况，原来的加法法则就不正确了，我们需要将加法规则改为：T1(m) + T2(n) = O(f(m) + g(n))。但是乘法法则继续有效：T1(m)*T2(n) = O(f(m) * f(n))。&lt;/p&gt;
&lt;h2 id=&#34;空间复杂度分析&#34;&gt;空间复杂度分析&lt;/h2&gt;
&lt;p&gt;前面，咱们花了很长时间讲大 O 表示法和时间复杂度分析，理解了前面讲的内容，空间复杂度分析方法学起来就非常简单了。&lt;/p&gt;
&lt;p&gt;前面我讲过，时间复杂度的全称是&lt;strong&gt;渐进时间复杂度&lt;/strong&gt; ，&lt;strong&gt;表示算法的执行时间与数据规模之间的增长关系&lt;/strong&gt; 。类比一下，空间复杂度全称就是&lt;strong&gt;渐进空间复杂度&lt;/strong&gt; （asymptotic space complexity），&lt;strong&gt;表示算法的存储空间与数据规模之间的增长关系&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;我还是拿具体的例子来给你说明。（这段代码有点&amp;quot;傻&amp;quot;，一般没人会这么写，我这么写只是为了方便给你解释。）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void print(int n) {
  int i = 0;
  int[] a = new int[n];
  for (i; i &amp;lt;n; ++i) {
    a[i] = i * i;
  }
 
  for (i = n-1; i &amp;gt;= 0; --i) {
    print out a[i]
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;跟时间复杂度分析一样，我们可以看到，第 2 行代码中，我们申请了一个空间存储变量 i，但是它是常量阶的，跟数据规模 n 没有关系，所以我们可以忽略。第 3 行申请了一个大小为 n 的 int 类型数组，除此之外，剩下的代码都没有占用更多的空间，所以整段代码的空间复杂度就是 O(n)。&lt;/p&gt;
&lt;p&gt;我们常见的空间复杂度就是 O(1)、O(n)、O(n^2^ )，像 O(logn)、O(nlogn) 这样的对数阶复杂度平时都用不到。而且，空间复杂度分析比时间复杂度分析要简单很多。所以，对于空间复杂度，掌握刚我说的这些内容已经足够了。&lt;/p&gt;
&lt;h2 id=&#34;内容小结&#34;&gt;内容小结&lt;/h2&gt;
&lt;p&gt;基础复杂度分析的知识到此就讲完了，我们来总结一下。&lt;/p&gt;
&lt;p&gt;复杂度也叫渐进复杂度，包括时间复杂度和空间复杂度，用来分析算法执行效率与数据规模之间的增长关系，可以粗略地表示，越高阶复杂度的算法，执行效率越低。常见的复杂度并不多，从低阶到高阶有：O(1)、O(logn)、O(n)、O(nlogn)、O(n^2^ )。等你学完整个专栏之后，你就会发现几乎所有的数据结构和算法的复杂度都跑不出这几个。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/49/04/497a3f120b7debee07dc0d03984faf04.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;复杂度分析并不难，关键在于多练。&lt;/strong&gt; 之后讲后面的内容时，我还会带你详细地分析每一种数据结构和算法的时间、空间复杂度。只要跟着我的思路学习、练习，你很快就能和我一样，每次看到代码的时候，简单的一眼就能看出其复杂度，难的稍微分析一下就能得出答案。&lt;/p&gt;
&lt;h2 id=&#34;课后思考&#34;&gt;课后思考&lt;/h2&gt;
&lt;p&gt;有人说，我们项目之前都会进行性能测试，再做代码的时间复杂度、空间复杂度分析，是不是多此一举呢？而且，每段代码都分析一下时间复杂度、空间复杂度，是不是很浪费时间呢？你怎么看待这个问题呢？&lt;/p&gt;
&lt;p&gt;欢迎留言和我分享，我会第一时间给你反馈。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/8e/d3/8e603e3d795fc0ab2698f6f5eabf14d3.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 03丨预习篇·小鲸鱼大事记（三）：群雄并起</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90-kubernetes/03%E4%B8%A8%E9%A2%84%E4%B9%A0%E7%AF%87%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%A4%A7%E4%BA%8B%E8%AE%B0%E4%B8%89%E7%BE%A4%E9%9B%84%E5%B9%B6%E8%B5%B7/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90-kubernetes/03%E4%B8%A8%E9%A2%84%E4%B9%A0%E7%AF%87%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%A4%A7%E4%BA%8B%E8%AE%B0%E4%B8%89%E7%BE%A4%E9%9B%84%E5%B9%B6%E8%B5%B7/</guid>
      <description>
        
        
        &lt;p&gt;你好，我是张磊。我今天分享的主题是：小鲸鱼大事记之群雄并起。&lt;/p&gt;
&lt;p&gt;在上一篇文章中，我剖析了 Docker 项目迅速走红背后的技术与非技术原因，也介绍了 Docker 公司开启平台化战略的野心。可是，Docker 公司为什么在 Docker 项目已经取得巨大成功之后，却执意要重新走回那条已经让无数先驱们尘沙折戟的 PaaS 之路呢？&lt;/p&gt;
&lt;p&gt;实际上，Docker 项目一日千里的发展势头，一直伴随着公司管理层和股东们的阵阵担忧。他们心里明白，虽然 Docker 项目备受追捧，但用户们最终要部署的，还是他们的网站、服务、数据库，甚至是云计算业务。&lt;/p&gt;
&lt;p&gt;这就意味着，只有那些能够为用户提供平台层能力的工具，才会真正成为开发者们关心和愿意付费的产品。而 Docker 项目这样一个只能用来创建和启停容器的小工具，最终只能充当这些平台项目的&amp;quot;幕后英雄&amp;quot;。&lt;/p&gt;
&lt;p&gt;而谈到 Docker 项目的定位问题，就不得不说说 Docker 公司的老朋友和老对手 CoreOS 了。&lt;/p&gt;
&lt;p&gt;CoreOS 是一个基础设施领域创业公司。 它的核心产品是一个定制化的操作系统，用户可以按照分布式集群的方式，管理所有安装了这个操作系统的节点。从而，用户在集群里部署和管理应用就像使用单机一样方便了。&lt;/p&gt;
&lt;p&gt;Docker 项目发布后，CoreOS 公司很快就认识到可以把&amp;quot;容器&amp;quot;的概念无缝集成到自己的这套方案中，从而为用户提供更高层次的 PaaS 能力。所以，CoreOS 很早就成了 Docker 项目的贡献者，并在短时间内成为了 Docker 项目中第二重要的力量。&lt;/p&gt;
&lt;p&gt;然而，这段短暂的蜜月期到 2014 年底就草草结束了。CoreOS 公司以强烈的措辞宣布与 Docker 公司停止合作，并直接推出了自己研制的 Rocket（后来叫 rkt）容器。&lt;/p&gt;
&lt;p&gt;这次决裂的根本原因，正是源于 Docker 公司对 Docker 项目定位的不满足。Docker 公司解决这种不满足的方法就是，让 Docker 项目提供更多的平台层能力，即向 PaaS 项目进化。而这，显然与 CoreOS 公司的核心产品和战略发生了严重冲突。&lt;/p&gt;
&lt;p&gt;也就是说，Docker 公司在 2014 年就已经定好了平台化的发展方向，并且绝对不会跟 CoreOS 在平台层面开展任何合作。这样看来，Docker 公司在 2014 年 12 月的 DockerCon 上发布 Swarm 的举动，也就一点都不突然了。&lt;/p&gt;
&lt;p&gt;相较于 CoreOS 是依托于一系列开源项目（比如 Container Linux 操作系统、Fleet 作业调度工具、systemd 进程管理和 rkt 容器），一层层搭建起来的平台产品，Swarm 项目则是以一个完整的整体来对外提供集群管理功能。而 Swarm 的最大亮点，则是它完全使用 Docker 项目原本的容器管理 API 来完成集群管理，比如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;单机 Docker 项目：&lt;/p&gt;
&lt;p&gt;$ docker run &amp;quot; 我的容器&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;多机 Docker 项目：&lt;/p&gt;
&lt;p&gt;$ docker run -H &amp;quot; 我的 Swarm 集群 API 地址 &amp;quot; &amp;quot; 我的容器 &amp;quot;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以在部署了 Swarm 的多机环境下，用户只需要使用原先的 Docker 指令创建一个容器，这个请求就会被 Swarm 拦截下来处理，然后通过具体的调度算法找到一个合适的 Docker Daemon 运行起来。&lt;/p&gt;
&lt;p&gt;这个操作方式简洁明了，对于已经了解过 Docker 命令行的开发者们也很容易掌握。所以，这样一个&amp;quot;原生&amp;quot;的 Docker 容器集群管理项目一经发布，就受到了已有 Docker 用户群的热捧。而相比之下，CoreOS 的解决方案就显得非常另类，更不用说用户还要去接受完全让人摸不着头脑、新造的容器项目 rkt 了。&lt;/p&gt;
&lt;p&gt;当然，Swarm 项目只是 Docker 公司重新定义&amp;quot;PaaS&amp;quot;的关键一环而已。在 2014 年到 2015 年这段时间里，Docker 项目的迅速走红催生出了一个非常繁荣的&amp;quot;Docker 生态&amp;quot;。在这个生态里，围绕着 Docker 在各个层次进行集成和创新的项目层出不穷。&lt;/p&gt;
&lt;p&gt;而此时已经大红大紫到&amp;quot;不差钱&amp;quot;的&lt;strong&gt;Docker 公司，开始及时地借助这波浪潮通过并购来完善自己的平台层能力&lt;/strong&gt;。其中一个最成功的案例，莫过于对 Fig 项目的收购。&lt;/p&gt;
&lt;p&gt;要知道，Fig 项目基本上只是靠两个人全职开发和维护的，可它却是当时 GitHub 上热度堪比 Docker 项目的明星。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fig 项目之所以受欢迎，在于它在开发者面前第一次提出了&amp;quot;容器编排&amp;quot;（Container Orchestration）的概念。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;其实，&amp;ldquo;编排&amp;rdquo;（Orchestration）在云计算行业里不算是新词汇，它主要是指用户如何通过某些工具或者配置来完成一组虚拟机以及关联资源的定义、配置、创建、删除等工作，然后由云计算平台按照这些指定的逻辑来完成的过程。&lt;/p&gt;
&lt;p&gt;而容器时代，&amp;ldquo;编排&amp;quot;显然就是对 Docker 容器的一系列定义、配置和创建动作的管理。而 Fig 的工作实际上非常简单：假如现在用户需要部署的是应用容器 A、数据库容器 B、负载均衡容器 C，那么 Fig 就允许用户把 A、B、C 三个容器定义在一个配置文件中，并且可以指定它们之间的关联关系，比如容器 A 需要访问数据库容器 B。&lt;/p&gt;
&lt;p&gt;接下来，你只需要执行一条非常简单的指令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ fig up
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Fig 就会把这些容器的定义和配置交给 Docker API 按照访问逻辑依次创建，你的一系列容器就都启动了；而容器 A 与 B 之间的关联关系，也会交给 Docker 的 Link 功能通过写入 hosts 文件的方式进行配置。更重要的是，你还可以在 Fig 的配置文件里定义各种容器的副本个数等编排参数，再加上 Swarm 的集群管理能力，一个活脱脱的 PaaS 呼之欲出。&lt;/p&gt;
&lt;p&gt;Fig 项目被收购后改名为 Compose，它成了 Docker 公司到目前为止第二大受欢迎的项目，一直到今天也依然被很多人使用。&lt;/p&gt;
&lt;p&gt;当时的这个容器生态里，还有很多令人眼前一亮的开源项目或公司。比如，专门负责处理容器网络的 SocketPlane 项目（后来被 Docker 公司收购），专门负责处理容器存储的 Flocker 项目（后来被 EMC 公司收购），专门给 Docker 集群做图形化管理界面和对外提供云服务的 Tutum 项目（后来被 Docker 公司收购）等等。&lt;/p&gt;
&lt;p&gt;一时之间，整个后端和云计算领域的聪明才俊都汇集在了这个&amp;quot;小鲸鱼&amp;quot;的周围，为 Docker 生态的蓬勃发展献上了自己的智慧。&lt;/p&gt;
&lt;p&gt;而除了这个异常繁荣的、围绕着 Docker 项目和公司的生态之外，还有一个势力在当时也是风头无两，这就是老牌集群管理项目 Mesos 和它背后的创业公司 Mesosphere。&lt;/p&gt;
&lt;p&gt;Mesos 作为 Berkeley 主导的大数据套件之一，是大数据火热时最受欢迎的资源管理项目，也是跟 Yarn 项目杀得难舍难分的实力派选手。&lt;/p&gt;
&lt;p&gt;不过，大数据所关注的计算密集型离线业务，其实并不像常规的 Web 服务那样适合用容器进行托管和扩容，也没有对应用打包的强烈需求，所以 Hadoop、Spark 等项目到现在也没在容器技术上投下更大的赌注；但是对于 Mesos 来说，天生的两层调度机制让它非常容易从大数据领域抽身，转而去支持受众更加广泛的 PaaS 业务。&lt;/p&gt;
&lt;p&gt;在这种思路的指导下，Mesosphere 公司发布了一个名为 Marathon 的项目，而这个项目很快就成为了 Docker Swarm 的一个有力竞争对手。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;虽然不能提供像 Swarm 那样的原生 Docker API，Mesos 社区却拥有一个独特的竞争力：超大规模集群的管理经验。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;早在几年前，Mesos 就已经通过了万台节点的验证，2014 年之后又被广泛使用在 eBay 等大型互联网公司的生产环境中。而这次通过 Marathon 实现了诸如应用托管和负载均衡的 PaaS 功能之后，Mesos+Marathon 的组合实际上进化成了一个高度成熟的 PaaS 项目，同时还能很好地支持大数据业务。&lt;/p&gt;
&lt;p&gt;所以，在这波容器化浪潮中，Mesosphere 公司不失时机地提出了一个名叫&amp;quot;DC/OS&amp;rdquo;（数据中心操作系统）的口号和产品，旨在使用户能够像管理一台机器那样管理一个万级别的物理机集群，并且使用 Docker 容器在这个集群里自由地部署应用。而这，对很多大型企业来说具有着非同寻常的吸引力。&lt;/p&gt;
&lt;p&gt;这时，如果你再去审视当时的容器技术生态，就不难发现 CoreOS 公司竟然显得有些尴尬了。它的 rkt 容器完全打不开局面，Fleet 集群管理项目更是少有人问津，CoreOS 完全被 Docker 公司压制了。&lt;/p&gt;
&lt;p&gt;而处境同样不容乐观的似乎还有 RedHat，作为 Docker 项目早期的重要贡献者，RedHat 也是因为对 Docker 公司平台化战略不满而愤愤退出。但此时，它竟只剩下 OpenShift 这个跟 Cloud Foundry 同时代的经典 PaaS 一张牌可以打，跟 Docker Swarm 和转型后的 Mesos 完全不在同一个&amp;quot;竞技水平&amp;quot;之上。&lt;/p&gt;
&lt;p&gt;那么，事实果真如此吗？&lt;/p&gt;
&lt;p&gt;2014 年注定是一个神奇的年份。就在这一年的 6 月，基础设施领域的翘楚 Google 公司突然发力，正式宣告了一个名叫 Kubernetes 项目的诞生。而这个项目，不仅挽救了当时的 CoreOS 和 RedHat，还如同当年 Docker 项目的横空出世一样，再一次改变了整个容器市场的格局。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;我分享了 Docker 公司平台化战略的来龙去脉，阐述了 Docker Swarm 项目发布的意义和它背后的设计思想，介绍了 Fig（后来的 Compose）项目如何成为了继 Docker 之后最受瞩目的新星。&lt;/p&gt;
&lt;p&gt;同时，我也和你一起回顾了 2014~2015 年间如火如荼的容器化浪潮里群雄并起的繁荣姿态。在这次生态大爆发中，Docker 公司和 Mesosphere 公司，依托自身优势率先占据了有利位置。&lt;/p&gt;
&lt;p&gt;但是，更强大的挑战者们，即将在不久后纷至沓来。&lt;/p&gt;
&lt;h2 id=&#34;思考题&#34;&gt;思考题&lt;/h2&gt;
&lt;p&gt;你所在团队有没有在 2014~2015 年 Docker 热潮中，推出过相关的容器产品或者项目？现在结局如何呢？&lt;/p&gt;
&lt;p&gt;欢迎你给我留言，也欢迎分享给更多的朋友一起阅读。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/47/55/47a6f3bf6b92d58512d5a2ed0a556f55.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 04丨JVM是如何执行方法调用的？（上）</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3jvm%E8%99%9A%E6%8B%9F%E6%9C%BA/04%E4%B8%A8jvm%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%E7%9A%84%E4%B8%8A/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3jvm%E8%99%9A%E6%8B%9F%E6%9C%BA/04%E4%B8%A8jvm%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%E7%9A%84%E4%B8%8A/</guid>
      <description>
        
        
        &lt;p&gt;前不久在写代码的时候，我不小心踩到一个可变长参数的坑。你或许已经猜到了，它正是可变长参数方法的重载造成的。（注：官方文档建议避免重载可变长参数方法，见 [1] 的最后一段。）&lt;/p&gt;
&lt;p&gt;我把踩坑的过程放在了文稿里，你可以点击查看。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void invoke(Object obj, Object... args) { ... }
void invoke(String s, Object obj, Object... args) { ... }
 
invoke(null, 1);    // 调用第二个 invoke 方法
invoke(null, 1, 2); // 调用第二个 invoke 方法
invoke(null, new Object[]{1}); // 只有手动绕开可变长参数的语法糖，
                               // 才能调用第一个 invoke 方法
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当时情况是这样子的，某个 API 定义了两个同名的重载方法。其中，第一个接收一个 Object，以及声明为 Object&amp;hellip;的变长参数；而第二个则接收一个 String、一个 Object，以及声明为 Object&amp;hellip;的变长参数。&lt;/p&gt;
&lt;p&gt;这里我想调用第一个方法，传入的参数为 (null, 1)。也就是说，声明为 Object 的形式参数所对应的实际参数为 null，而变长参数则对应 1。&lt;/p&gt;
&lt;p&gt;通常来说，之所以不提倡可变长参数方法的重载，是因为 Java 编译器可能无法决定应该调用哪个目标方法。&lt;/p&gt;
&lt;p&gt;在这种情况下，编译器会报错，并且提示这个方法调用有二义性。然而，Java 编译器直接将我的方法调用识别为调用第二个方法，这究竟是为什么呢？&lt;/p&gt;
&lt;p&gt;带着这个问题，我们来看一看 Java 虚拟机是怎么识别目标方法的。&lt;/p&gt;
&lt;h2 id=&#34;重载与重写&#34;&gt;重载与重写&lt;/h2&gt;
&lt;p&gt;在 Java 程序里，如果同一个类中出现多个名字相同，并且参数类型相同的方法，那么它无法通过编译。也就是说，在正常情况下，如果我们想要在同一个类中定义名字相同的方法，那么它们的参数类型必须不同。这些方法之间的关系，我们称之为重载。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;小知识：这个限制可以通过字节码工具绕开。也就是说，在编译完成之后，我们可以再向 class 文件中添加方法名和参数类型相同，而返回类型不同的方法。当这种包括多个方法名相同、参数类型相同，而返回类型不同的方法的类，出现在 Java 编译器的用户类路径上时，它是怎么确定需要调用哪个方法的呢？当前版本的 Java 编译器会直接选取第一个方法名以及参数类型匹配的方法。并且，它会根据所选取方法的返回类型来决定可不可以通过编译，以及需不需要进行值转换等。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;重载的方法在编译过程中即可完成识别。具体到每一个方法调用，Java 编译器会根据所传入参数的声明类型（注意与实际类型区分）来选取重载方法。选取的过程共分为三个阶段：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在不考虑对基本类型自动装拆箱（auto-boxing，auto-unboxing），以及可变长参数的情况下选取重载方法；&lt;/li&gt;
&lt;li&gt;如果在第 1 个阶段中没有找到适配的方法，那么在允许自动装拆箱，但不允许可变长参数的情况下选取重载方法；&lt;/li&gt;
&lt;li&gt;如果在第 2 个阶段中没有找到适配的方法，那么在允许自动装拆箱以及可变长参数的情况下选取重载方法。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果 Java 编译器在同一个阶段中找到了多个适配的方法，那么它会在其中选择一个最为贴切的，而决定贴切程度的一个关键就是形式参数类型的继承关系。&lt;/p&gt;
&lt;p&gt;在开头的例子中，当传入 null 时，它既可以匹配第一个方法中声明为 Object 的形式参数，也可以匹配第二个方法中声明为 String 的形式参数。由于 String 是 Object 的子类，因此 Java 编译器会认为第二个方法更为贴切。&lt;/p&gt;
&lt;p&gt;除了同一个类中的方法，重载也可以作用于这个类所继承而来的方法。也就是说，如果子类定义了与父类中非私有方法同名的方法，而且这两个方法的参数类型不同，那么在子类中，这两个方法同样构成了重载。&lt;/p&gt;
&lt;p&gt;那么，如果子类定义了与父类中非私有方法同名的方法，而且这两个方法的参数类型相同，那么这两个方法之间又是什么关系呢？&lt;/p&gt;
&lt;p&gt;如果这两个方法都是静态的，那么子类中的方法隐藏了父类中的方法。如果这两个方法都不是静态的，且都不是私有的，那么子类的方法重写了父类中的方法。&lt;/p&gt;
&lt;p&gt;众所周知，Java 是一门面向对象的编程语言，它的一个重要特性便是多态。而方法重写，正是多态最重要的一种体现方式：它允许子类在继承父类部分功能的同时，拥有自己独特的行为。&lt;/p&gt;
&lt;p&gt;打个比方，如果你经常漫游，那么你可能知道，拨打 10086 会根据你当前所在地，连接到当地的客服。重写调用也是如此：它会根据调用者的动态类型，来选取实际的目标方法。&lt;/p&gt;
&lt;h2 id=&#34;jvm-的静态绑定和动态绑定&#34;&gt;JVM 的静态绑定和动态绑定&lt;/h2&gt;
&lt;p&gt;接下来，我们来看看 Java 虚拟机是怎么识别方法的。&lt;/p&gt;
&lt;p&gt;Java 虚拟机识别方法的关键在于类名、方法名以及方法描述符（method descriptor）。前面两个就不做过多的解释了。至于方法描述符，它是由方法的参数类型以及返回类型所构成。在同一个类中，如果同时出现多个名字相同且描述符也相同的方法，那么 Java 虚拟机会在类的验证阶段报错。&lt;/p&gt;
&lt;p&gt;可以看到，Java 虚拟机与 Java 语言不同，它并不限制名字与参数类型相同，但返回类型不同的方法出现在同一个类中，对于调用这些方法的字节码来说，由于字节码所附带的方法描述符包含了返回类型，因此 Java 虚拟机能够准确地识别目标方法。&lt;/p&gt;
&lt;p&gt;Java 虚拟机中关于方法重写的判定同样基于方法描述符。也就是说，如果子类定义了与父类中非私有、非静态方法同名的方法，那么只有当这两个方法的参数类型以及返回类型一致，Java 虚拟机才会判定为重写。&lt;/p&gt;
&lt;p&gt;对于 Java 语言中重写而 Java 虚拟机中非重写的情况，编译器会通过生成桥接方法 [2] 来实现 Java 中的重写语义。&lt;/p&gt;
&lt;p&gt;由于对重载方法的区分在编译阶段已经完成，我们可以认为 Java 虚拟机不存在重载这一概念。因此，在某些文章中，重载也被称为静态绑定（static binding），或者编译时多态（compile-time polymorphism）；而重写则被称为动态绑定（dynamic binding）。&lt;/p&gt;
&lt;p&gt;这个说法在 Java 虚拟机语境下并非完全正确。这是因为某个类中的重载方法可能被它的子类所重写，因此 Java 编译器会将所有对非私有实例方法的调用编译为需要动态绑定的类型。&lt;/p&gt;
&lt;p&gt;确切地说，Java 虚拟机中的静态绑定指的是在解析时便能够直接识别目标方法的情况，而动态绑定则指的是需要在运行过程中根据调用者的动态类型来识别目标方法的情况。&lt;/p&gt;
&lt;p&gt;具体来说，Java 字节码中与调用相关的指令共有五种。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;invokestatic：用于调用静态方法。&lt;/li&gt;
&lt;li&gt;invokespecial：用于调用私有实例方法、构造器，以及使用 super 关键字调用父类的实例方法或构造器，和所实现接口的默认方法。&lt;/li&gt;
&lt;li&gt;invokevirtual：用于调用非私有实例方法。&lt;/li&gt;
&lt;li&gt;invokeinterface：用于调用接口方法。&lt;/li&gt;
&lt;li&gt;invokedynamic：用于调用动态方法。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;由于 invokedynamic 指令较为复杂，我将在后面的篇章中单独介绍。这里我们只讨论前四种。&lt;/p&gt;
&lt;p&gt;我在文章中贴了一段代码，展示了编译生成这四种调用指令的情况。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;interface 客户 {
  boolean isVIP();
}
 
class 商户 {
  public double 折后价格 (double 原价, 客户 某客户) {
    return 原价 * 0.8d;
  }
}
 
class 奸商 extends 商户 {
  @Override
  public double 折后价格 (double 原价, 客户 某客户) {
    if (某客户.isVIP()) {                         // invokeinterface      
      return 原价 * 价格歧视 ();                    // invokestatic
    } else {
      return super. 折后价格 (原价, 某客户);          // invokespecial
    }
  }
  public static double 价格歧视 () {
    // 咱们的杀熟算法太粗暴了，应该将客户城市作为随机数生成器的种子。
    return new Random()                          // invokespecial
           .nextDouble()                         // invokevirtual
           + 0.8d;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在代码中，&amp;ldquo;商户&amp;quot;类定义了一个成员方法，叫做&amp;quot;折后价格&amp;rdquo;，它将接收一个 double 类型的参数，以及一个&amp;quot;客户&amp;quot;类型的参数。这里&amp;quot;客户&amp;quot;是一个接口，它定义了一个接口方法，叫&amp;quot;isVIP&amp;quot;。&lt;/p&gt;
&lt;p&gt;我们还定义了另一个叫做&amp;quot;奸商&amp;quot;的类，它继承了&amp;quot;商户&amp;quot;类，并且重写了&amp;quot;折后价格&amp;quot;这个方法。如果客户是 VIP，那么它会被给到一个更低的折扣。&lt;/p&gt;
&lt;p&gt;在这个方法中，我们首先会调用&amp;quot;客户&amp;quot;接口的&amp;quot;isVIP&amp;quot;方法。该调用会被编译为 invokeinterface 指令。&lt;/p&gt;
&lt;p&gt;如果客户是 VIP，那么我们会调用奸商类的一个名叫&amp;quot;价格歧视&amp;quot;的静态方法。该调用会被编译为 invokestatic 指令。如果客户不是 VIP，那么我们会通过 super 关键字调用父类的&amp;quot;折后价格&amp;quot;方法。该调用会被编译为 invokespecial 指令。&lt;/p&gt;
&lt;p&gt;在静态方法&amp;quot;价格歧视&amp;quot;中，我们会调用 Random 类的构造器。该调用会被编译为 invokespecial 指令。然后我们会以这个新建的 Random 对象为调用者，调用 Random 类中的 nextDouble 方法。该调用会被编译为 invokevirutal 指令。&lt;/p&gt;
&lt;p&gt;对于 invokestatic 以及 invokespecial 而言，Java 虚拟机能够直接识别具体的目标方法。&lt;/p&gt;
&lt;p&gt;而对于 invokevirtual 以及 invokeinterface 而言，在绝大部分情况下，虚拟机需要在执行过程中，根据调用者的动态类型，来确定具体的目标方法。&lt;/p&gt;
&lt;p&gt;唯一的例外在于，如果虚拟机能够确定目标方法有且仅有一个，比如说目标方法被标记为 final[3][4]，那么它可以不通过动态类型，直接确定目标方法。&lt;/p&gt;
&lt;h2 id=&#34;调用指令的符号引用&#34;&gt;调用指令的符号引用&lt;/h2&gt;
&lt;p&gt;在编译过程中，我们并不知道目标方法的具体内存地址。因此，Java 编译器会暂时用符号引用来表示该目标方法。这一符号引用包括目标方法所在的类或接口的名字，以及目标方法的方法名和方法描述符。&lt;/p&gt;
&lt;p&gt;符号引用存储在 class 文件的常量池之中。根据目标方法是否为接口方法，这些引用可分为接口符号引用和非接口符号引用。我在文章中贴了一个例子，利用&amp;quot;javap -v&amp;quot;打印某个类的常量池，如果你感兴趣的话可以到文章中查看。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 在奸商.class 的常量池中，#16 为接口符号引用，指向接口方法 &amp;quot; 客户.isVIP()&amp;quot;。而 #22 为非接口符号引用，指向静态方法 &amp;quot; 奸商. 价格歧视 ()&amp;quot;。
$ javap -v 奸商.class ...
Constant pool:
...
  #16 = InterfaceMethodref #27.#29        // 客户.isVIP:()Z
...
  #22 = Methodref          #1.#33         // 奸商. 价格歧视:()D
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上一篇中我曾提到过，在执行使用了符号引用的字节码前，Java 虚拟机需要解析这些符号引用，并替换为实际引用。&lt;/p&gt;
&lt;p&gt;对于非接口符号引用，假定该符号引用所指向的类为 C，则 Java 虚拟机会按照如下步骤进行查找。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在 C 中查找符合名字及描述符的方法。&lt;/li&gt;
&lt;li&gt;如果没有找到，在 C 的父类中继续搜索，直至 Object 类。&lt;/li&gt;
&lt;li&gt;如果没有找到，在 C 所直接实现或间接实现的接口中搜索，这一步搜索得到的目标方法必须是非私有、非静态的。并且，如果目标方法在间接实现的接口中，则需满足 C 与该接口之间没有其他符合条件的目标方法。如果有多个符合条件的目标方法，则任意返回其中一个。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;从这个解析算法可以看出，静态方法也可以通过子类来调用。此外，子类的静态方法会隐藏（注意与重写区分）父类中的同名、同描述符的静态方法。&lt;/p&gt;
&lt;p&gt;对于接口符号引用，假定该符号引用所指向的接口为 I，则 Java 虚拟机会按照如下步骤进行查找。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在 I 中查找符合名字及描述符的方法。&lt;/li&gt;
&lt;li&gt;如果没有找到，在 Object 类中的公有实例方法中搜索。&lt;/li&gt;
&lt;li&gt;如果没有找到，则在 I 的超接口中搜索。这一步的搜索结果的要求与非接口符号引用步骤 3 的要求一致。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;经过上述的解析步骤之后，符号引用会被解析成实际引用。对于可以静态绑定的方法调用而言，实际引用是一个指向方法的指针。对于需要动态绑定的方法调用而言，实际引用则是一个方法表的索引。具体什么是方法表，我会在下一篇中做出解答。&lt;/p&gt;
&lt;h2 id=&#34;总结与实践&#34;&gt;总结与实践&lt;/h2&gt;
&lt;p&gt;今天我介绍了 Java 以及 Java 虚拟机是如何识别目标方法的。&lt;/p&gt;
&lt;p&gt;在 Java 中，方法存在重载以及重写的概念，重载指的是方法名相同而参数类型不相同的方法之间的关系，重写指的是方法名相同并且参数类型也相同的方法之间的关系。&lt;/p&gt;
&lt;p&gt;Java 虚拟机识别方法的方式略有不同，除了方法名和参数类型之外，它还会考虑返回类型。&lt;/p&gt;
&lt;p&gt;在 Java 虚拟机中，静态绑定指的是在解析时便能够直接识别目标方法的情况，而动态绑定则指的是需要在运行过程中根据调用者的动态类型来识别目标方法的情况。由于 Java 编译器已经区分了重载的方法，因此可以认为 Java 虚拟机中不存在重载。&lt;/p&gt;
&lt;p&gt;在 class 文件中，Java 编译器会用符号引用指代目标方法。在执行调用指令前，它所附带的符号引用需要被解析成实际引用。对于可以静态绑定的方法调用而言，实际引用为目标方法的指针。对于需要动态绑定的方法调用而言，实际引用为辅助动态绑定的信息。&lt;/p&gt;
&lt;p&gt;在文中我曾提到，Java 的重写与 Java 虚拟机中的重写并不一致，但是编译器会通过生成桥接方法来弥补。今天的实践环节，我们来看一下两个生成桥接方法的例子。你可以通过&amp;quot;javap -v&amp;quot;来查看 class 文件所包含的方法。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;重写方法的返回类型不一致：&lt;/p&gt;
&lt;p&gt;interface Customer {
boolean isVIP();
}&lt;/p&gt;
&lt;p&gt;class Merchant {
public Number actionPrice(double price, Customer customer) {
&amp;hellip;
}
}&lt;/p&gt;
&lt;p&gt;class NaiveMerchant extends Merchant {
@Override
public Double actionPrice(double price, Customer customer) {
&amp;hellip;
}
}&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;范型参数类型造成的方法参数类型不一致：&lt;/p&gt;
&lt;p&gt;interface Customer {
boolean isVIP();
}&lt;/p&gt;
&lt;p&gt;class Merchant&lt;T extends Customer&gt; {
public double actionPrice(double price, T customer) {
&amp;hellip;
}
}&lt;/p&gt;
&lt;p&gt;class VIPOnlyMerchant extends Merchant&lt;VIP&gt; {
@Override
public double actionPrice(double price, VIP customer) {
&amp;hellip;
}
}&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://docs.oracle.com/javase/8/docs/technotes/guides/language/varargs.html&#34;&gt;https://docs.oracle.com/javase/8/docs/technotes/guides/language/varargs.html&lt;/a&gt;&lt;br&gt;
[2]&lt;br&gt;
&lt;a href=&#34;https://docs.oracle.com/javase/tutorial/java/generics/bridgeMethods.html&#34;&gt;https://docs.oracle.com/javase/tutorial/java/generics/bridgeMethods.html&lt;/a&gt;&lt;br&gt;
[3]&lt;br&gt;
&lt;a href=&#34;https://wiki.openjdk.java.net/display/HotSpot/VirtualCalls&#34;&gt;https://wiki.openjdk.java.net/display/HotSpot/VirtualCalls&lt;/a&gt;&lt;br&gt;
[4]&lt;br&gt;
&lt;a href=&#34;https://wiki.openjdk.java.net/display/HotSpot/InterfaceCalls&#34;&gt;https://wiki.openjdk.java.net/display/HotSpot/InterfaceCalls&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/2a/d5/2a62e58cbdf56a5dc40748567d346fd5.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 04丨从Equifax信息泄露看数据安全</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/04%E4%B8%A8%E4%BB%8Eequifax%E4%BF%A1%E6%81%AF%E6%B3%84%E9%9C%B2%E7%9C%8B%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/04%E4%B8%A8%E4%BB%8Eequifax%E4%BF%A1%E6%81%AF%E6%B3%84%E9%9C%B2%E7%9C%8B%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8/</guid>
      <description>
        
        
        &lt;p&gt;上篇文章中，我们讲了 Equifax 信息泄露始末，并对造成此次事件的漏洞进行了分析。今天，我们就来回顾一下互联网时代的其他几次大规模数据泄露事件，分析背后的原因，给出解决这类安全问题的技术手段和方法。&lt;/p&gt;
&lt;h1 id=&#34;数据泄露介绍以及历史回顾&#34;&gt;数据泄露介绍以及历史回顾&lt;/h1&gt;
&lt;p&gt;类似于 Equifax 这样的大规模数据泄露事件在互联网时代时不时地会发生。上一次如此大规模的数据泄露事件主角应该是雅虎。&lt;/p&gt;
&lt;p&gt;继 2013 年大规模数据泄露之后，雅虎在 2014 年又遭遇攻击，泄露出 5 亿用户的密码，直到 2016 年有人在黑市公开交易这些数据时才为大众所知。雅虎股价在事件爆出的第二天就下跌了 2.4%。而此次 Equifax 的股价下跌超过 30%，市值缩水约 53 亿。这让各大企业不得不警惕。&lt;/p&gt;
&lt;p&gt;类似的，LinkedIn 在 2012 年也泄露了 6500 万用户名和密码。事件发生后，LinkedIn 为了亡羊补牢，及时阻止被黑账户的登录，强制被黑用户修改密码，并改进了登录措施，从单步认证增强为带短信验证的两步认证。&lt;/p&gt;
&lt;p&gt;国内也有类似的事件。2014 年携程网安全支付日志存在漏洞，导致大量用户信息如姓名、身份证号、银行卡类别、银行卡号、银行卡 CVV 码等信息泄露。这意味着，一旦这些信息被黑客窃取，在网络上盗刷银行卡消费将易如反掌。&lt;/p&gt;
&lt;p&gt;如果说网络运维安全是一道防线，那么社会工程学攻击则可能攻破另一道防线&amp;mdash;&amp;mdash;人。2011 年，RSA 公司声称他们被一种复杂的网络攻击所侵害，起因是有两个小组的员工收到一些钓鱼邮件。邮件的附件是带有恶意代码的 Excel 文件。&lt;/p&gt;
&lt;p&gt;当一个 RSA 员工打开该 Excel 文件时，恶意代码攻破了 Adobe Flash 中的一个漏洞。该漏洞让黑客能用 Poison Ivy 远程管理工具来取得对机器的管理权，并访问 RSA 内网中的服务器。这次攻击主要威胁的是 SecurID 系统，最终导致了其母公司 EMC 花费 6630 万美元来调查、加固系统，并最终召回和重新分发了 30000 家企业客户的 SecurID 卡片。&lt;/p&gt;
&lt;h1 id=&#34;数据泄露攻击&#34;&gt;数据泄露攻击&lt;/h1&gt;
&lt;p&gt;以这些公司为例，我们来看看这些攻击是怎样实现的。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;利用程序框架或库的已知漏洞。比如这次 Equifax 被攻击，就是通过 Apache Struts 的已知漏洞。RSA 被攻击，也利用了 Adobe Flash 的已知漏洞。还有之前的&amp;quot;心脏流血&amp;quot;也是使用了 OpenSSL 的漏洞&amp;hellip;&amp;hellip;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;暴力破解密码。利用密码字典库或是已经泄露的密码来&amp;quot;撞库&amp;quot;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;代码注入。通过程序员代码的安全性问题，如 SQL 注入、XSS 攻击、CSRF 攻击等取得用户的权限。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;利用程序日志不小心泄露的信息。携程的信息泄露就是本不应该能被读取的日志没有权限保护被读到了。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;社会工程学。RSA 被攻击，第一道防线是人&amp;mdash;&amp;mdash;RSA 的员工。只有员工的安全意识增强了，才能抵御此类攻击。其它的如钓鱼攻击也属于此类。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;然后，除了表面的攻击之外，窃取到的信息也显示了一些数据管理上的问题。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;只有一层安全。Equifax 只是被黑客攻破了管理面板和数据库，就造成了数据泄露。显然这样只有一层安全防护是不够的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;弱密码。Equifax 数据泄露事件绝对是管理问题。至少，密码系统应该不能让用户设置如此简单的密码，而且还要定期更换。最好的方式是通过数据证书、VPN、双因子验证的方式来登录。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;向公网暴露了内部系统。在公司网络管理上出现了非常严重的问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对系统及时打安全补丁。监控业内的安全漏洞事件，及时做出响应，这是任何一个有高价值数据的公司都需要干的事。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;安全日志被暴露。安全日志往往包含大量信息，被暴露是非常危险的。携程的 CVV 泄露就是从日志中被读到的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;保存了不必要保存的用户数据。携程保存了用户的信用卡号、有效期、姓名和 CVV 码，这些信息足以让人在网上盗刷信用卡。其实对于临时支付来说，这些信息完全可以不保存在磁盘上，临时在内存中处理完毕立即销毁，是最安全的做法。即便是快捷支付，也没有必要保存 CVV 码。安全日志也没有必要将所有信息都保存下来，比如可以只保存卡号后四位，也同样可以用于处理程序故障。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;密码没有被合理地散列。以现代的安全观念来说，以明文方式保存密码是很不专业的做法。进一步的是只保存密码的散列值（用安全散列算法），LinkedIn 就是这样做的。但是，散列一则需要用目前公认安全的算法（比如 SHA-2 256），而已知被攻破的算法则最好不要使用（如 MD5，能人为找到碰撞，对密码验证来说问题不大），二则要加一个安全随机数作为盐（salt）。LinkedIn 的问题正在于没有加盐，导致密码可以通过预先计算的彩虹表（rainbow table）反查出明文。这些密码明文可以用来做什么事，就不好说了，撞库什么的都有可能了。对用户来说，最好是不同网站用不同密码。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;专家建议&#34;&gt;专家建议&lt;/h1&gt;
&lt;p&gt;Contrast Security 是一家安全公司，其 CTO 杰夫·威廉姆斯（ Jeff Williams）在博客中表示，虽说最佳实践是确保不使用有漏洞的程序库，但是在现实中并不容易做到这一点，因为安全更新来得比较频繁。&lt;/p&gt;
&lt;p&gt;&amp;ldquo;经常，为了做这些安全性方面的更改，需要重新编写、测试和部署整个应用程序，而整个周期可能要花费几个月。我最近和几个大的组织机构聊过，他们在应对 CVE-2017-5638 这件事上花了至少四个月的时间。即便是在运营得最好的组织机构中，也经常在漏洞被发布和应用程序被更新之间有几个月的时间差。&amp;ldquo;威廉姆斯写道。&lt;/p&gt;
&lt;p&gt;Apache Struts 的副总裁雷内·吉伦（René Gielen）在 Apache 软件基金会的官方博客中写道，为了避免被攻击，对于使用了开源或闭源的支持性程序库的软件产品或服务，建议如下的 5 条最佳实践。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;理解你的软件产品中使用了哪些支持性框架和库，它们的版本号分别是多少。时刻跟踪影响这些产品和版本的最新安全性声明。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;建立一个流程，来快速地部署带有安全补丁的软件产品发布版，这样一旦需要因为安全方面的原因而更新支持性框架或库，就可以快速地发布。最好能在几个小时或几天内完成，而不是几周或几个月。我们发现，绝大多数被攻破的情况是因为几个月或几年都没有更新有漏洞的软件组件而引起的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;所有复杂的软件都有漏洞。不要基于&amp;quot;支持性软件产品没有安全性漏洞&amp;quot;这样的假设来建立安全策略。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;建立多个安全层。在一个面向公网的表示层（比如 Apache Struts 框架）后面建立多级有安全防护的层次，是一种良好的软件工程实践。就算表示层被攻破，也不会直接提供出重要（或所有）后台信息资源的访问权。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;针对公网资源，建立对异常访问模式的监控机制。现在有很多侦测这些行为模式的开源和商业化产品，一旦发现异常访问就能发出警报。作为一种良好的运维实践，我们建议针对关键业务的网页服务应用一定要有这些监控机制。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在吉伦提的第二点中说到，理想的更新时间是在几个小时到几天。我们知道，作为企业，部署了一个版本的程序库，在更新前需要在测试系统上测试各个业务模块，确保兼容以后才能上线。否则，盲目上线一个新版本，一旦遇到不兼容的情况，业务会部分或全部停滞，给客户留下不良印象，经济损失将是不可避免的。因此，这个更新周期必须通过软件工程手段来保证。&lt;/p&gt;
&lt;p&gt;一个有力的解决方案是自动化测试。对以数据库为基础的程序库，设置专门的、初始时全空的测试用数据库来进行 API 级别的测试。对于 UI 框架，使用 UI 自动化测试工具进行自动化测试。测试在原则上必须覆盖上层业务模块所有需要的功能，并对其兼容性加以验证。业务模块要连同程序库一起做集成的自动化测试，同时也要有单元测试。&lt;/p&gt;
&lt;p&gt;升级前的人工测试也有必要，但由于安全性更新的紧迫性，覆盖主要和重要路径即可。&lt;/p&gt;
&lt;p&gt;如果测试发现不兼容性，无法立即升级，那么要考虑的第二点是缓解措施（mitigation）。比如，能否禁用有漏洞的部分而不影响业务？如果不可行，那么是否可以通过 WAF 的设置来把一定特征的攻击载荷挡在门外？这些都是临时解决方案，要到开发部门把业务程序更新为能用新版本库，才能上线新版本的应用程序。&lt;/p&gt;
&lt;h1 id=&#34;技术上的安全做法&#34;&gt;技术上的安全做法&lt;/h1&gt;
&lt;p&gt;除了上面所说的，那些安全防范的方法，我想在这里再加入一些我自己的经验。&lt;/p&gt;
&lt;p&gt;从技术上来说，安全防范最好是做到连自己内部员工都能防，因为无论是程序的 BUG 还是漏洞，都是为了取得系统的权限而获得数据。如果我们能够连内部人都能防的话，那么就可以不用担心绝大多数的系统漏洞了。所谓&amp;quot;家贼难防&amp;rdquo;，如果要做到这一点，一般来说，有如下的一些方式。&lt;/p&gt;
&lt;p&gt;首先，我们需要把我们的关键数据定义出来，然后把这些关键数据隔离出来，隔离到一个安全级别非常高的地方。所谓安全级别非常高的地方，即这个地方需要有各种如安全审计、安全监控、安全访问的区域。&lt;/p&gt;
&lt;p&gt;一般来说，在这个区域内，这些敏感数据只入不出。通过提供服务接口来让别的系统只能在这个区域内操作这些数据，而不是把数据传出去，让别的系统在外部来操作这些数据。&lt;/p&gt;
&lt;p&gt;举个例子，用户的手机号是敏感信息。如果有外部系统需要使用手机号，一般来说是想发个短信，那么我们这个掌管手机号数据的系统就对外提供发短信的功能，而外部系统通过 UID 或是别的抽像字段来调用这个系统的发短信的 API。信用卡也一样，提供信用卡的扣款 API 而不是把卡号返回给外部系统。&lt;/p&gt;
&lt;p&gt;另外，如果业务必需返回用户的数据，一般来说，最终用户可能需要读取自己的数据，那么，对于像信用卡这样的关键数据是死也不能返回全部数据的，只能返回一个被&amp;quot;马赛克&amp;quot;了的数据（隐藏掉部分信息）。就算需要返回一些数据（如用户的地址），那么也需要在传输层上加密返回。&lt;/p&gt;
&lt;p&gt;而用户加密的算法一定要采用非对称加密的方式，而且还要加上密钥的自动化更换，比如：在外部系统调用 100 次或是第一个小时后就自动更换加密的密钥。这样，整个系统在运行时就完全是自动化的了，而就算黑客得到了密钥，密匙也会过期，这样可以控制泄露范围。&lt;/p&gt;
&lt;p&gt;通过上述手段，我们可以把数据控制在一个比较小的区域内。&lt;/p&gt;
&lt;p&gt;而在这个区域内，我们依然会有相关的内部员工可以访问，因此，这个区域中的数据也是需要加密存放的，而加密使用的密钥则需要放在另外一个区域中。&lt;/p&gt;
&lt;p&gt;也就是说，被加密的数据和用于加密的密钥是由不同的人来管理的，有密钥的人没有数据，有数据的人没有密钥，这两拨人可以有访问自己系统的权限，但是没有访问对方系统的权限。这样可以让这两拨人互相审计，互相牵制，从而提高数据的安全性。比如，这两拨人是不同公司的。&lt;/p&gt;
&lt;p&gt;而密钥一定要做到随机生成，最好是对于不同用户的数据有不同的密钥，并且时不时地就能自动化更新一下，这样就可以做到内部防范。注明一下，按道理来说，用户自己的私钥应该由用户自己来保管，而公司的系统是不存的。而用户需要更新密钥时，需要对用户做身份鉴别，可以通过双因子认证，也可以通过更为严格的物理身份验证。例如，到银行柜台拿身份证重置密码。&lt;/p&gt;
&lt;p&gt;最后，每当这些关键信息传到外部系统，需要做通知，最好是通知用户和自己的管理员。并且限制外部系统的数据访问量，超过访问量后，需要报警或是拒绝访问。&lt;/p&gt;
&lt;p&gt;上述的这些技术手段是比较常见的做法，虽然也不能确保 100% 防止住，但基本上来说已经将安全级别提得非常高了。&lt;/p&gt;
&lt;p&gt;不管怎么样，安全在今天是一个非常严肃的事，能做到绝对的安全基本上是不可能的，我们只能不断提高黑客入侵的门槛。当黑客的投入和收益大大不相符时，黑客也就失去了入侵的意义。&lt;/p&gt;
&lt;p&gt;此外，安全还在于&amp;quot;风控&amp;rdquo;，任何系统就算你做得再完美，也会出现数据泄露的情况，只是我们可以把数据泄露的范围控制在一个什么样的比例，而这个比例就是我们的&amp;quot;风控&amp;quot;。&lt;/p&gt;
&lt;p&gt;所谓的安全方案基本上来说就是能够把这个风险控制在一个很小的范围。对于在这个很小范围出现的一些数据安全的泄露，我们可以通过&amp;quot;风控基金&amp;quot;来做业务上的补偿，比如赔偿用户损失，等等。因为从经济利益上来说，如果风险可以控制在一个&amp;mdash;&amp;mdash;我防范它的成本远高于我赔偿它的成本，那么，还不如赔偿了。&lt;/p&gt;
&lt;p&gt;最后，如果你还有什么样的问题或是心得，欢迎和我交流！&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/fc/e9/fcc761001867c60f526665e237f831e9.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 04丨十八般兵器：如何搭建项目所需的开发环境？</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/springclouod%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/04%E4%B8%A8%E5%8D%81%E5%85%AB%E8%88%AC%E5%85%B5%E5%99%A8%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E9%A1%B9%E7%9B%AE%E6%89%80%E9%9C%80%E7%9A%84%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/springclouod%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/04%E4%B8%A8%E5%8D%81%E5%85%AB%E8%88%AC%E5%85%B5%E5%99%A8%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E9%A1%B9%E7%9B%AE%E6%89%80%E9%9C%80%E7%9A%84%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</guid>
      <description>
        
        
        &lt;p&gt;你好，我是姚秋辰。&lt;/p&gt;
&lt;p&gt;工欲善其事，必先利其器。在你跃跃欲试想要进入实战环节前，让我先带你把实战项目需要用到的十八般兵器准备好，也就是搭建好项目的开发环境。&lt;/p&gt;
&lt;p&gt;为了避免在项目实战环节碰到一些棘手的兼容性问题，在你开始写代码前就要约定好各个组件的安装版本，包括 Java、Maven 和各个中间件的版本。&lt;/p&gt;
&lt;p&gt;我们的微服务实战项目会用到很多中间件，其中也包括了 Spring Cloud 的中心化组件，如 Nacos、Sentinel、Zipkin 和 Seata 等等，这些 Spring Cloud 组件我会放在后面的实战环节边讲解边搭建。&lt;/p&gt;
&lt;p&gt;今天我们主要来看下集成开发环境的搭建、数据库的安装和 DB 脚本的导入，此外，我还会手把手带你安装几个通用的中间件。这节课要安装的工具比较多，你一定要耐心看完，不然后面的课程可能会卡壳哦。&lt;/p&gt;
&lt;p&gt;闲话少叙，我们现在就开工吧。&lt;/p&gt;
&lt;h1 id=&#34;环境准备&#34;&gt;环境准备&lt;/h1&gt;
&lt;p&gt;我推荐你使用 &lt;strong&gt;Mac 笔记本或者是 Linux 系统&lt;/strong&gt;来编写、运行本课程的实战项目，如果你使用的是 Windows 系统，可以尝试做个双系统，或者用 Cygwin、Ubuntu 虚拟机等方式尽量模拟 Linux 环境的开发。一来可以学习 Linux 命令，二来可以尽量保持本地开发环境与线上生产环境的一致，毕竟工作中你所开发的 Java 程序最终还是部署在 Linux 服务器环境。&lt;/p&gt;
&lt;p&gt;以下是我在本地 Mac 系统上的安装方式，如果你使用的是 Windows 系统，我也提供了相关组件的官网下载地址，相信对于程序员来说，安装软件是小菜一碟。因为安装的工具比较多，所以我建议你按照课程中介绍的顺序来安装。&lt;/p&gt;
&lt;h1 id=&#34;homebrew&#34;&gt;Homebrew&lt;/h1&gt;
&lt;p&gt;Homebrew 是 Mac 系统上的一款非常便利的软件安装工具，可以帮你安装大部分开发工作所需的各种工具软件。这节课中的很多工具，我们也可以使用它来安装。你可以在Homebrew 的官网查看 Homebrew 的详细安装方法。&lt;/p&gt;
&lt;p&gt;你可能发现在国内网络下安装 Homebrew 比较缓慢，这里我给你提供两种解决办法：一种是使用 VPN 连接，也就是我们俗称的翻墙，可以大幅提高安装速度；另一种方式是将 Homebrew 指向国内镜像获取安装脚本，替换镜像的命令可以在官方的安装文档中找到。&lt;/p&gt;
&lt;p&gt;安装完成之后，你可以在命令行输入 brew -v 命令查看版本信息，来验证安装是否成功：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;vincent@LM-SHB-40513998 ~ % brew -v
Homebrew 3.2.17
Homebrew/homebrew-core (git revision 5fbb5bcf8d9; last commit 2021-10-24)
Homebrew/homebrew-cask (git revision b08f2eff16; last commit 2021-10-24)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;当 Homebrew 准备就绪，你就可以使用 brew install 命令安装所需要的软件了。在实际工作中，你可以使用清华大学或者中科大的国内镜像源，来大幅提高各软件的下载速度。&lt;/p&gt;
&lt;p&gt;在你使用国内镜像源的时候，可能会碰到软件无法安装成功的问题，这往往是因为软件所依赖的某个工具包无法下载，你只要从日志信息中找到卡住安装流程的工具包叫什么，然后使用 brew install xxx 命令（xxx 是工具名称）单独安装这个工具包，之后再重新安装你需要的软件就可以了。这个办法屡试不爽。&lt;/p&gt;
&lt;p&gt;安装好 Homebrew 后，我们再来安装 Java 和 Maven。&lt;/p&gt;
&lt;h1 id=&#34;java-和-maven&#34;&gt;Java 和 Maven&lt;/h1&gt;
&lt;p&gt;这两样工具可是我们 Java 工程师吃饭的家伙，安装过程我就不唠叨了。为了避免兼容性的问题，你只要注意安装正确的版本就可以：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Java&lt;/strong&gt;：推荐使用 JDK8 最新小版本或者 OpenJDK16 的最新小版本（我本地安装的是 OpenJDK 16.0.1）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Maven&lt;/strong&gt;：推荐使用 Maven 3.6 或以上的版本（我本地使用 3.8.1 版本）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于国内网络访问 Maven 中央仓库比较慢，在编译项目的时候，你会发现下载 Maven 依赖项的时间会比较久，你可以修改 Maven 的 settings.xml 文件，将其默认镜像指向国内的镜像（比如阿里云镜像），这样可以大大加快依赖项下载速度。&lt;/p&gt;
&lt;p&gt;安装完 Java 和 Maven 之后，我们再来安装集成开发工具。&lt;/p&gt;
&lt;h1 id=&#34;intellij-idea&#34;&gt;IntelliJ IDEA&lt;/h1&gt;
&lt;p&gt;IntelliJ IDEA 是 JetBrains 全家桶中的一款应用，它是目前公认最强大的 Java 语言开发集成环境。如果你已经受不了 Eclipse 的卡顿，那不妨借此机会转向 IDEA 的怀抱。&lt;/p&gt;
&lt;p&gt;你可以在JetBrains 的官网下载 IntelliJ IDEA，IDEA 的免费社区版已经足够你完成复杂的开发任务了。如果你想体验更多的产品功能特性，也可以选择购买商业版 license。要是你有高校教育邮箱（edu 邮箱）就更方便了，你可以使用 edu 邮箱注册 JetBrains 账号，并免费申请商业版使用权用于教学和学习。&lt;/p&gt;
&lt;h1 id=&#34;lombok&#34;&gt;Lombok&lt;/h1&gt;
&lt;p&gt;为了提高编程效率和代码可读性，我在实战项目中还使用了 Lomkok 插件自动生成代码。不过，你需要在自己的开发环境中安装 Lombok 插件，这样你的 IDE 才能识别 Lomkok 的注解。&lt;/p&gt;
&lt;p&gt;在 IntelliJ IDEA 中安装 Lombok 非常简单，你只需要在 IDEA 的插件安装界面搜索 Lomkob 这款插件并安装即可，如下图所示：&lt;br&gt;
&lt;img src=&#34;https://static001.geekbang.org/resource/image/10/07/10e527baf30bfec2c28yy1e864f25507.jpg?wh=2000x1089&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;如果你使用 Eclipse 作为开发工具，需要在 Plugins 界面安装 Lombok 插件，或者将 Lombok 插件的安装文件复制到 Eclipse 安装路径下的 Plugin 文件夹。不管你使用的是 Eclipse 还是 IntelliJ IDEA，记得在装完插件后重启开发环境。&lt;/p&gt;
&lt;p&gt;下面，我们再来安装实战项目需要用到的数据库。&lt;/p&gt;
&lt;h1 id=&#34;mysql-和-db-可视化工具&#34;&gt;MySQL 和 DB 可视化工具&lt;/h1&gt;
&lt;p&gt;我们的实战课程采用 MySQL 数据库，当然，如果你在本地已经安装了 MariaDB 也是可以的，因为 MariaDB 是 MySQL 的作者参与制作的开源版数据库，它可以全面兼容 MySQL 的功能。&lt;/p&gt;
&lt;p&gt;我本地安装的 MySQL 服务器版本为 8.0.27，你可以使用 brew 命令安装最新版的 MySQL，具体命令为：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;brew install mysql
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;当然，你也可以选择从MySQL 官方网站下载安装包，免费的社区版就足以满足我们实战项目的需要。&lt;/p&gt;
&lt;p&gt;安装完成之后，我们再使用下面的命令来启动 MySQL：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;mysql.server start
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;待 MySQL 成功安装并启动后，我们来验证一下是否可以登录数据库。在命令行输入：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;mysql -uroot -p
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后，我们使用默认的 root 用户登录数据库（密码默认为空），如果你可以在命令行看到以下内容，就表示数据库安装成功。&lt;br&gt;
&lt;img src=&#34;https://static001.geekbang.org/resource/image/02/35/0253e5a5e914bacdb881e99c7e6b8e35.jpg?wh=2000x870&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;如果你还没有安装可视化 DB 工具，那么我推荐你使用 DataGrip，它也是 JetBrains 全家桶的一款软件。你可以选择通过DataGrip 官网下载安装包。&lt;/p&gt;
&lt;p&gt;下载 DataGrip 并安装成功后，你可以在 DataGrip 中添加一个 MySQL 数据源指向本地 MySQL 数据库，用户名为默认的 root，密码为空，JDBC URL 是 jdbc:mysql://localhost:3306。在添加数据源之前，我们还需要在弹窗界面上点击下载 MySQL Driver：&lt;br&gt;
&lt;img src=&#34;https://static001.geekbang.org/resource/image/f5/01/f57c7f01a4ac038e1092d41727562501.jpg?wh=2000x1254&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;到这里，MySQL 和 DataGrip 就安装好了。&lt;/p&gt;
&lt;p&gt;在开始项目实战之前，我们还需要在 MySQL 中执行数据库建表语句，将实战项目所需要用到的数据库表导入到 MySQL。建表语句所在的 SQL 文件，位于Gitee 项目源代码仓库下的&amp;quot;资源文件&amp;quot;目录中的&amp;quot;Coupon 项目建表语句.sql&amp;quot;文件里。&lt;/p&gt;
&lt;p&gt;你可以在数据库命令行中执行 SQL 文件，或者将文件内容 copy 到 DataGrid 中执行。在建表语句的第一行中，我指定了数据库名称为 geekbang_coupon_db，我们在稍后的实战项目中会将这个数据库名称配置在 JDBC URL 中。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;CREATE DATABASE IF NOT EXISTS geekbang_coupon_db;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;当然，你也可以给这个数据库起一个更响亮的名字，替换掉 SQL 脚本中的名称 geekbang_coupon_db。执行完数据库脚本后，我们再来安装实战项目所需要用到的消息中间件。&lt;/p&gt;
&lt;h1 id=&#34;安装-rabbitmq&#34;&gt;安装 RabbitMQ&lt;/h1&gt;
&lt;p&gt;RabbitMQ 是目前使用最广泛的消息组件之一，在后面的 Spring Cloud 课程中我会使用 Stream 组件搭配 RabbitMQ 发送异步消息。&lt;/p&gt;
&lt;p&gt;你可以直接使用下面这个命令安装 RabbitMQ，也可以在RabbitMQ 官网下载安装包。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;brew install rabbitmq
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;我本地安装的 RabbitMQ 版本是 3.9.8，这里我推荐你直接安装 RabbitMQ 最新的稳定版本，因为某些 RabbitMQ 的早期版本缺少必要的插件支持，如果你已经安装了较早年代的 RabbitMQ，可以趁这个机会替换成最新版。&lt;/p&gt;
&lt;p&gt;如果你想了解 RabbitMQ 的更多功能特性，RabbitMQ 的官网上提供的技术文档是一个很好的学习途径，你可以去看看。&lt;/p&gt;
&lt;p&gt;在安装完成之后，你可以直接通过在命令行执行下面这条代码来启动 RabbitMQ。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;rabbitmq-server
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果你是使用安装包安装的话，那么你还需要将 RabbitMQ 的安装路径加入到 PATH 系统变量。成功启动后，你可以在命令行中看到 RabbitMQ 版本和启动成功的日志，这表示 RabbitMQ 后台服务已处于运行状态。&lt;br&gt;
&lt;img src=&#34;https://static001.geekbang.org/resource/image/2f/70/2f1896ba0ab606ffbc0864d10a8d7970.jpg?wh=2000x1254&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;接着，我们在浏览器中打开 RabbitMQ 的本地操作界面http://localhost:15672/，其中的&amp;quot;15672&amp;quot;是 RabbitMQ 启动时的默认窗口。你可以使用默认的内置用户登录系统，用户名和密码都是 guest。顺利登录后你会看到如下页面：&lt;br&gt;
&lt;img src=&#34;https://static001.geekbang.org/resource/image/2d/b1/2d3fa13c527dbc979646f8cab42bbcb1.jpg?wh=2000x1089&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;到这里，RabbitMQ 就算是安装好了。下面，我们再来安装最后一个软件，Redis。&lt;/p&gt;
&lt;h1 id=&#34;安装-redis&#34;&gt;安装 Redis&lt;/h1&gt;
&lt;p&gt;Redis 是一个 key-value 数据库，我们在学习微服务网关的时候将会用 Redis 实现网关层限流。安装 Redis 的方式非常简单，你可以选择使用下面这条命令安装最新版 Redis Brew。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;w install redis
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;当然，你也可以选择从Redis 官网下载源码并在本地完成编译和安装。&lt;/p&gt;
&lt;p&gt;安装完成并成功启动 Redis 服务后，我们可以通过命令行验证 Redis 是否运行正常。在命令行直接执行这条命令：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;redis-cli
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;执行完成后，默认情况下会连接到 Redis 的默认地址 localhost:6379，这样我们就来到了 Redis 控制台。&lt;/p&gt;
&lt;p&gt;在控制台中，你可以尝试通过 set 命令设置一个 key-value 键值对，并使用 get 命令读取 key 对应的值，通过这种方式来验证 Redis 是否正常工作。在下面的图中，我通过 set 命令设置了一个 key=geekbang，value=955 的键值对，然后使用 get 命令去读取 geekbang 的值。&lt;br&gt;
&lt;img src=&#34;https://static001.geekbang.org/resource/image/8f/34/8f6c2850fd72f04d5937337c86325234.jpg?wh=2000x831&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;到这里，我们的工具安装就结束了，后续进入到 Spring Cloud 微服务实战环节的时候，我们还会用到更多的中间件，比如注册中心、微服务网关、链路追踪组件、ELK 日志查询系统、分布式事务协调器等等，到时候我再带你手把手安装这些软件。&lt;/p&gt;
&lt;h1 id=&#34;总结&#34;&gt;总结&lt;/h1&gt;
&lt;p&gt;今天这节课，我带你安装了编译环境、本地开发环境、MySQL 数据库和一些常用的中间件，这些组件足够我们搭建起一个 Spring Boot 的单体应用了。&lt;/p&gt;
&lt;p&gt;环境的安装看似简单，实则遍地是坑，&lt;strong&gt;很多兼容性问题就是由于组件版本导致的&lt;/strong&gt;。我这里给你举两个兼容性问题的例子：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MySQL 版本：不同 MySQL 版本对 JDBC 连接串的要求是不一样的，有的版本需要你在 JDBC URL 中额外指定 Timezone 等信息。你会发现，原先得得好好的应用，某一天升级了数据库之后很可能会挂掉；&lt;/li&gt;
&lt;li&gt;Maven 版本：有些 Maven 插件要求高版本的 Maven 支持，有时你会发现在一台电脑上可以编译通过的源码，换了一台电脑可能就编译失败，这很有可能是 Maven 版本的问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这些兼容性问题往往都很隐蔽，不好排查。所以呢，才有了程序员圈子里的硬梗&amp;quot;一定是环境问题&amp;quot;。那么，当你碰到一些棘手的异常情况的时候，比如某个应用在没有代码改动的情况下突然不正常了，不妨先抱着怀疑的态度，去检查一下是否有外部环境的变化，比如中间件版本、编译环境等等。&lt;/p&gt;
&lt;p&gt;下一讲我将带你体验 Spring Boot 急速落地的过程，和你手把手搭建一个 Spring Boot 实战项目，为后面的 Spring Cloud 章节的学习做好前置功课。&lt;/p&gt;
&lt;h1 id=&#34;思考题&#34;&gt;思考题&lt;/h1&gt;
&lt;p&gt;最后，请你思考两个问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;你在学习新技术、安装新的组件的过程中，通常都是通过什么途径来摸索的呢？在这个过程中你有哪些提升效率的小窍门（比如使用 homebrew 软件）可以分享吗？&lt;/li&gt;
&lt;li&gt;你曾经碰到过最棘手的线上 Bug 或者兼容性问题是什么？最后又是如何被发现并解决的？我们在留言区来一场疑难 Bug 大 Battle 吧！&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;好啦，这节课就结束啦。欢迎你把这节课分享给更多对 Spring Cloud 感兴趣的朋友。我是姚秋辰，我们下节课再见！&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 04丨复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/04%E4%B8%A8%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90%E4%B8%8B%E6%B5%85%E6%9E%90%E6%9C%80%E5%A5%BD%E6%9C%80%E5%9D%8F%E5%B9%B3%E5%9D%87%E5%9D%87%E6%91%8A%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/04%E4%B8%A8%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90%E4%B8%8B%E6%B5%85%E6%9E%90%E6%9C%80%E5%A5%BD%E6%9C%80%E5%9D%8F%E5%B9%B3%E5%9D%87%E5%9D%87%E6%91%8A%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6/</guid>
      <description>
        
        
        &lt;p&gt;上一节，我们讲了复杂度的大 O 表示法和几个分析技巧，还举了一些常见复杂度分析的例子，比如 O(1)、O(logn)、O(n)、O(nlogn) 复杂度分析。掌握了这些内容，对于复杂度分析这个知识点，你已经可以到及格线了。但是，我想你肯定不会满足于此。&lt;/p&gt;
&lt;p&gt;今天我会继续给你讲四个复杂度分析方面的知识点，&lt;strong&gt;最好情况时间复杂度&lt;/strong&gt; （best case time complexity）、&lt;strong&gt;最坏情况时间复杂度&lt;/strong&gt; （worst case time complexity）、&lt;strong&gt;平均情况时间复杂度&lt;/strong&gt; （average case time complexity）、&lt;strong&gt;均摊时间复杂度&lt;/strong&gt;（amortized time complexity）。如果这几个概念你都能掌握，那对你来说，复杂度分析这部分内容就没什么大问题了。&lt;/p&gt;
&lt;h2 id=&#34;最好最坏情况时间复杂度&#34;&gt;最好、最坏情况时间复杂度&lt;/h2&gt;
&lt;p&gt;上一节我举的分析复杂度的例子都很简单，今天我们来看一个稍微复杂的。你可以用我上节教你的分析技巧，自己先试着分析一下这段代码的时间复杂度。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// n 表示数组 array 的长度
int find(int[] array, int n, int x) {
  int i = 0;
  int pos = -1;
  for (; i &amp;lt; n; ++i) {
    if (array[i] == x) pos = i;
  }
  return pos;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;你应该可以看出来，这段代码要实现的功能是，在一个无序的数组（array）中，查找变量 x 出现的位置。如果没有找到，就返回 -1。按照上节课讲的分析方法，这段代码的复杂度是 O(n)，其中，n 代表数组的长度。&lt;/p&gt;
&lt;p&gt;我们在数组中查找一个数据，并不需要每次都把整个数组都遍历一遍，因为有可能中途找到就可以提前结束循环了。但是，这段代码写得不够高效。我们可以这样优化一下这段查找代码。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// n 表示数组 array 的长度
int find(int[] array, int n, int x) {
  int i = 0;
  int pos = -1;
  for (; i &amp;lt; n; ++i) {
    if (array[i] == x) {
       pos = i;
       break;
    }
  }
  return pos;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个时候，问题就来了。我们优化完之后，这段代码的时间复杂度还是 O(n) 吗？很显然，咱们上一节讲的分析方法，解决不了这个问题。&lt;/p&gt;
&lt;p&gt;因为，要查找的变量 x 可能出现在数组的任意位置。如果数组中第一个元素正好是要查找的变量 x，那就不需要继续遍历剩下的 n-1 个数据了，那时间复杂度就是 O(1)。但如果数组中不存在变量 x，那我们就需要把整个数组都遍历一遍，时间复杂度就成了 O(n)。所以，不同的情况下，这段代码的时间复杂度是不一样的。&lt;/p&gt;
&lt;p&gt;为了表示代码在不同情况下的不同时间复杂度，我们需要引入三个概念：最好情况时间复杂度、最坏情况时间复杂度和平均情况时间复杂度。&lt;/p&gt;
&lt;p&gt;顾名思义，&lt;strong&gt;最好情况时间复杂度就是，在最理想的情况下，执行这段代码的时间复杂度&lt;/strong&gt;。就像我们刚刚讲到的，在最理想的情况下，要查找的变量 x 正好是数组的第一个元素，这个时候对应的时间复杂度就是最好情况时间复杂度。&lt;/p&gt;
&lt;p&gt;同理，&lt;strong&gt;最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度&lt;/strong&gt;。就像刚举的那个例子，如果数组中没有要查找的变量 x，我们需要把整个数组都遍历一遍才行，所以这种最糟糕情况下对应的时间复杂度就是最坏情况时间复杂度。&lt;/p&gt;
&lt;h2 id=&#34;平均情况时间复杂度&#34;&gt;平均情况时间复杂度&lt;/h2&gt;
&lt;p&gt;我们都知道，最好情况时间复杂度和最坏情况时间复杂度对应的都是极端情况下的代码复杂度，发生的概率其实并不大。为了更好地表示平均情况下的复杂度，我们需要引入另一个概念：平均情况时间复杂度，后面我简称为平均时间复杂度。&lt;/p&gt;
&lt;p&gt;平均时间复杂度又该怎么分析呢？我还是借助刚才查找变量 x 的例子来给你解释。&lt;/p&gt;
&lt;p&gt;要查找的变量 x 在数组中的位置，有 n+1 种情况：&lt;strong&gt;在数组的 0～n-1 位置中&lt;/strong&gt; 和&lt;strong&gt;不在数组中&lt;/strong&gt;。我们把每种情况下，查找需要遍历的元素个数累加起来，然后再除以 n+1，就可以得到需要遍历的元素个数的平均值，即：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/d8/2f/d889a358b8eccc5bbb90fc16e327a22f.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;我们知道，时间复杂度的大 O 标记法中，可以省略掉系数、低阶、常量，所以，咱们把刚刚这个公式简化之后，得到的平均时间复杂度就是 O(n)。&lt;/p&gt;
&lt;p&gt;这个结论虽然是正确的，但是计算过程稍微有点儿问题。究竟是什么问题呢？我们刚讲的这 n+1 种情况，出现的概率并不是一样的。我带你具体分析一下。（这里要稍微用到一点儿概率论的知识，不过非常简单，你不用担心。）&lt;/p&gt;
&lt;p&gt;我们知道，要查找的变量 x，要么在数组里，要么就不在数组里。这两种情况对应的概率统计起来很麻烦，为了方便你理解，我们假设在数组中与不在数组中的概率都为 1/2。另外，要查找的数据出现在 0～n-1 这 n 个位置的概率也是一样的，为 1/n。所以，根据概率乘法法则，要查找的数据出现在 0～n-1 中任意位置的概率就是 1/(2n)。&lt;/p&gt;
&lt;p&gt;因此，前面的推导过程中存在的最大问题就是，没有将各种情况发生的概率考虑进去。如果我们把每种情况发生的概率也考虑进去，那平均时间复杂度的计算过程就变成了这样：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/36/7f/36c0aabdac69032f8a43368f5e90c67f.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;这个值就是概率论中的&lt;strong&gt;加权平均值&lt;/strong&gt; ，也叫作&lt;strong&gt;期望值&lt;/strong&gt; ，所以平均时间复杂度的全称应该叫&lt;strong&gt;加权平均时间复杂度&lt;/strong&gt; 或者&lt;strong&gt;期望时间复杂度&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;引入概率之后，前面那段代码的加权平均值为 (3n+1)/4。用大 O 表示法来表示，去掉系数和常量，这段代码的加权平均时间复杂度仍然是 O(n)。&lt;/p&gt;
&lt;p&gt;你可能会说，平均时间复杂度分析好复杂啊，还要涉及概率论的知识。实际上，在大多数情况下，我们并不需要区分最好、最坏、平均情况时间复杂度三种情况。像我们上一节课举的那些例子那样，很多时候，我们使用一个复杂度就可以满足需求了。只有同一块代码在不同的情况下，时间复杂度有量级的差距，我们才会使用这三种复杂度表示法来区分。&lt;/p&gt;
&lt;h2 id=&#34;均摊时间复杂度&#34;&gt;均摊时间复杂度&lt;/h2&gt;
&lt;p&gt;到此为止，你应该已经掌握了算法复杂度分析的大部分内容了。下面我要给你讲一个更加高级的概念，均摊时间复杂度，以及它对应的分析方法，摊还分析（或者叫平摊分析）。&lt;/p&gt;
&lt;p&gt;均摊时间复杂度，听起来跟平均时间复杂度有点儿像。对于初学者来说，这两个概念确实非常容易弄混。我前面说了，大部分情况下，我们并不需要区分最好、最坏、平均三种复杂度。平均复杂度只在某些特殊情况下才会用到，而均摊时间复杂度应用的场景比它更加特殊、更加有限。&lt;/p&gt;
&lt;p&gt;老规矩，我还是借助一个具体的例子来帮助你理解。（当然，这个例子只是我为了方便讲解想出来的，实际上没人会这么写。）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; // array 表示一个长度为 n 的数组
 // 代码中的 array.length 就等于 n
 int[] array = new int[n];
 int count = 0;
 
 void insert(int val) {
    if (count == array.length) {
       int sum = 0;
       for (int i = 0; i &amp;lt; array.length; ++i) {
          sum = sum + array[i];
       }
       array[0] = sum;
       count = 1;
    }
 
    array[count] = val;
    ++count;
 }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我先来解释一下这段代码。这段代码实现了一个往数组中插入数据的功能。当数组满了之后，也就是代码中的 count == array.length 时，我们用 for 循环遍历数组求和，并清空数组，将求和之后的 sum 值放到数组的第一个位置，然后再将新的数据插入。但如果数组一开始就有空闲空间，则直接将数据插入数组。&lt;/p&gt;
&lt;p&gt;那这段代码的时间复杂度是多少呢？你可以先用我们刚讲到的三种时间复杂度的分析方法来分析一下。&lt;/p&gt;
&lt;p&gt;最理想的情况下，数组中有空闲空间，我们只需要将数据插入到数组下标为 count 的位置就可以了，所以最好情况时间复杂度为 O(1)。最坏的情况下，数组中没有空闲空间了，我们需要先做一次数组的遍历求和，然后再将数据插入，所以最坏情况时间复杂度为 O(n)。&lt;/p&gt;
&lt;p&gt;那平均时间复杂度是多少呢？答案是 O(1)。我们还是可以通过前面讲的概率论的方法来分析。&lt;/p&gt;
&lt;p&gt;假设数组的长度是 n，根据数据插入的位置的不同，我们可以分为 n 种情况，每种情况的时间复杂度是 O(1)。除此之外，还有一种&amp;quot;额外&amp;quot;的情况，就是在数组没有空闲空间时插入一个数据，这个时候的时间复杂度是 O(n)。而且，这 n+1 种情况发生的概率一样，都是 1/(n+1)。所以，根据加权平均的计算方法，我们求得的平均时间复杂度就是：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/6d/ed/6df62366a60336d9de3bc34f488d8bed.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;至此为止，前面的最好、最坏、平均时间复杂度的计算，理解起来应该都没有问题。但是这个例子里的平均复杂度分析其实并不需要这么复杂，不需要引入概率论的知识。这是为什么呢？我们先来对比一下这个 insert() 的例子和前面那个 find() 的例子，你就会发现这两者有很大差别。&lt;/p&gt;
&lt;p&gt;首先，find() 函数在极端情况下，复杂度才为 O(1)。但 insert() 在大部分情况下，时间复杂度都为 O(1)。只有个别情况下，复杂度才比较高，为 O(n)。这是 insert()&lt;strong&gt;第一个&lt;/strong&gt;区别于 find() 的地方。&lt;/p&gt;
&lt;p&gt;我们再来看&lt;strong&gt;第二个&lt;/strong&gt;不同的地方。对于 insert() 函数来说，O(1) 时间复杂度的插入和 O(n) 时间复杂度的插入，出现的频率是非常有规律的，而且有一定的前后时序关系，一般都是一个 O(n) 插入之后，紧跟着 n-1 个 O(1) 的插入操作，循环往复。&lt;/p&gt;
&lt;p&gt;所以，针对这样一种特殊场景的复杂度分析，我们并不需要像之前讲平均复杂度分析方法那样，找出所有的输入情况及相应的发生概率，然后再计算加权平均值。&lt;/p&gt;
&lt;p&gt;针对这种特殊的场景，我们引入了一种更加简单的分析方法：&lt;strong&gt;摊还分析法&lt;/strong&gt; ，通过摊还分析得到的时间复杂度我们起了一个名字，叫&lt;strong&gt;均摊时间复杂度&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;那究竟如何使用摊还分析法来分析算法的均摊时间复杂度呢？&lt;/p&gt;
&lt;p&gt;我们还是继续看在数组中插入数据的这个例子。每一次 O(n) 的插入操作，都会跟着 n-1 次 O(1) 的插入操作，所以把耗时多的那次操作均摊到接下来的 n-1 次耗时少的操作上，均摊下来，这一组连续的操作的均摊时间复杂度就是 O(1)。这就是均摊分析的大致思路。你都理解了吗？&lt;/p&gt;
&lt;p&gt;均摊时间复杂度和摊还分析应用场景比较特殊，所以我们并不会经常用到。为了方便你理解、记忆，我这里简单总结一下它们的应用场景。如果你遇到了，知道是怎么回事儿就行了。&lt;/p&gt;
&lt;p&gt;对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上。而且，在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度。&lt;/p&gt;
&lt;p&gt;尽管很多数据结构和算法书籍都花了很大力气来区分平均时间复杂度和均摊时间复杂度，但其实我个人认为，&lt;strong&gt;均摊时间复杂度就是一种特殊的平均时间复杂度&lt;/strong&gt;，我们没必要花太多精力去区分它们。你最应该掌握的是它的分析方法，摊还分析。至于分析出来的结果是叫平均还是叫均摊，这只是个说法，并不重要。&lt;/p&gt;
&lt;h2 id=&#34;内容小结&#34;&gt;内容小结&lt;/h2&gt;
&lt;p&gt;今天我们学习了几个复杂度分析相关的概念，分别有：最好情况时间复杂度、最坏情况时间复杂度、平均情况时间复杂度、均摊时间复杂度。之所以引入这几个复杂度概念，是因为，同一段代码，在不同输入的情况下，复杂度量级有可能是不一样的。&lt;/p&gt;
&lt;p&gt;在引入这几个概念之后，我们可以更加全面地表示一段代码的执行效率。而且，这几个概念理解起来都不难。最好、最坏情况下的时间复杂度分析起来比较简单，但平均、均摊两个复杂度分析相对比较复杂。如果你觉得理解得还不是很深入，不用担心，在后续具体的数据结构和算法学习中，我们可以继续慢慢实践！&lt;/p&gt;
&lt;h2 id=&#34;课后思考&#34;&gt;课后思考&lt;/h2&gt;
&lt;p&gt;我们今天学的几个复杂度分析方法，你都掌握了吗？你可以用今天学习的知识，来分析一下下面这个 add() 函数的时间复杂度。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 全局变量，大小为 10 的数组 array，长度 len，下标 i。
int array[] = new int[10]; 
int len = 10;
int i = 0;
 
// 往数组中添加一个元素
void add(int element) {
   if (i &amp;gt;= len) { // 数组空间不够了
     // 重新申请一个 2 倍大小的数组空间
     int new_array[] = new int[len*2];
     // 把原来 array 数组中的数据依次 copy 到 new_array
     for (int j = 0; j &amp;lt; len; ++j) {
       new_array[j] = array[j];
     }
     // new_array 复制给 array，array 现在大小就是 2 倍 len 了
     array = new_array;
     len = 2 * len;
   }
   // 将 element 放到下标为 i 的位置，下标 i 加一
   array[i] = element;
   ++i;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;欢迎留言和我分享，我会第一时间给你反馈。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/8e/d3/8e603e3d795fc0ab2698f6f5eabf14d3.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 04丨深入浅出索引（上）</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/04%E4%B8%A8%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%B4%A2%E5%BC%95%E4%B8%8A/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/04%E4%B8%A8%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%B4%A2%E5%BC%95%E4%B8%8A/</guid>
      <description>
        
        
        &lt;p&gt;提到数据库索引，我想你并不陌生，在日常工作中会经常接触到。比如某一个 SQL 查询比较慢，分析完原因之后，你可能就会说&amp;quot;给某个字段加个索引吧&amp;quot;之类的解决方案。但到底什么是索引，索引又是如何工作的呢？今天就让我们一起来聊聊这个话题吧。&lt;/p&gt;
&lt;p&gt;数据库索引的内容比较多，我分成了上下两篇文章。索引是数据库系统里面最重要的概念之一，所以我希望你能够耐心看完。在后面的实战文章中，我也会经常引用这两篇文章中提到的知识点，加深你对数据库索引的理解。&lt;/p&gt;
&lt;p&gt;一句话简单来说，索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。一本 500 页的书，如果你想快速找到其中的某一个知识点，在不借助目录的情况下，那我估计你可得找一会儿。同样，对于数据库的表而言，索引其实就是它的&amp;quot;目录&amp;quot;。&lt;/p&gt;
&lt;h1 id=&#34;索引的常见模型&#34;&gt;索引的常见模型&lt;/h1&gt;
&lt;p&gt;索引的出现是为了提高查询效率，但是实现索引的方式却有很多种，所以这里也就引入了索引模型的概念。可以用于提高读写效率的数据结构很多，这里我先给你介绍三种常见、也比较简单的数据结构，它们分别是哈希表、有序数组和搜索树。&lt;/p&gt;
&lt;p&gt;下面我主要从使用的角度，为你简单分析一下这三种模型的区别。&lt;/p&gt;
&lt;p&gt;哈希表是一种以键 - 值（key-value）存储数据的结构，我们只要输入待查找的值即 key，就可以找到其对应的值即 Value。哈希的思路很简单，把值放在数组里，用一个哈希函数把 key 换算成一个确定的位置，然后把 value 放在数组的这个位置。&lt;/p&gt;
&lt;p&gt;不可避免地，多个 key 值经过哈希函数的换算，会出现同一个值的情况。处理这种情况的一种方法是，拉出一个链表。&lt;/p&gt;
&lt;p&gt;假设，你现在维护着一个身份证信息和姓名的表，需要根据身份证号查找对应的名字，这时对应的哈希索引的示意图如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/0c/57/0c62b601afda86fe5d0fe57346ace957.png&#34; alt=&#34;&#34;&gt;
图 1 哈希表示意图&lt;/p&gt;
&lt;p&gt;图中，User2 和 User4 根据身份证号算出来的值都是 N，但没关系，后面还跟了一个链表。假设，这时候你要查 ID_card_n2 对应的名字是什么，处理步骤就是：首先，将 ID_card_n2 通过哈希函数算出 N；然后，按顺序遍历，找到 User2。&lt;/p&gt;
&lt;p&gt;需要注意的是，图中四个 ID_card_n 的值并不是递增的，这样做的好处是增加新的 User 时速度会很快，只需要往后追加。但缺点是，因为不是有序的，所以哈希索引做区间查询的速度是很慢的。&lt;/p&gt;
&lt;p&gt;你可以设想下，如果你现在要找身份证号在 [ID_card_X, ID_card_Y] 这个区间的所有用户，就必须全部扫描一遍了。&lt;/p&gt;
&lt;p&gt;所以，&lt;strong&gt;哈希表这种结构适用于只有等值查询的场景&lt;/strong&gt;，比如 Memcached 及其他一些 NoSQL 引擎。&lt;/p&gt;
&lt;p&gt;而&lt;strong&gt;有序数组在等值查询和范围查询场景中的性能就都非常优秀&lt;/strong&gt;。还是上面这个根据身份证号查名字的例子，如果我们使用有序数组来实现的话，示意图如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/bf/49/bfc907a92f99cadf5493cf0afac9ca49.png&#34; alt=&#34;&#34;&gt;
图 2 有序数组示意图&lt;/p&gt;
&lt;p&gt;这里我们假设身份证号没有重复，这个数组就是按照身份证号递增的顺序保存的。这时候如果你要查 ID_card_n2 对应的名字，用二分法就可以快速得到，这个时间复杂度是 O(log(N))。&lt;/p&gt;
&lt;p&gt;同时很显然，这个索引结构支持范围查询。你要查身份证号在 [ID_card_X, ID_card_Y] 区间的 User，可以先用二分法找到 ID_card_X（如果不存在 ID_card_X，就找到大于 ID_card_X 的第一个 User），然后向右遍历，直到查到第一个大于 ID_card_Y 的身份证号，退出循环。&lt;/p&gt;
&lt;p&gt;如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。&lt;/p&gt;
&lt;p&gt;所以，&lt;strong&gt;有序数组索引只适用于静态存储引擎&lt;/strong&gt;，比如你要保存的是 2017 年某个城市的所有人口信息，这类不会再修改的数据。&lt;/p&gt;
&lt;p&gt;二叉搜索树也是课本里的经典数据结构了。还是上面根据身份证号查名字的例子，如果我们用二叉搜索树来实现的话，示意图如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/04/68/04fb9d24065635a6a637c25ba9ddde68.png&#34; alt=&#34;&#34;&gt;
图 3 二叉搜索树示意图&lt;/p&gt;
&lt;p&gt;二叉搜索树的特点是：每个节点的左儿子小于父节点，父节点又小于右儿子。这样如果你要查 ID_card_n2 的话，按照图中的搜索顺序就是按照 UserA -&amp;gt; UserC -&amp;gt; UserF -&amp;gt; User2 这个路径得到。这个时间复杂度是 O(log(N))。&lt;/p&gt;
&lt;p&gt;当然为了维持 O(log(N)) 的查询复杂度，你就需要保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是 O(log(N))。&lt;/p&gt;
&lt;p&gt;树可以有二叉，也可以有多叉。多叉树就是每个节点有多个儿子，儿子之间的大小保证从左到右递增。二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。&lt;/p&gt;
&lt;p&gt;你可以想象一下一棵 100 万节点的平衡二叉树，树高 20。一次查询可能需要访问 20 个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要 10 ms 左右的寻址时间。也就是说，对于一个 100 万行的表，如果使用二叉树来存储，单独访问一个行可能需要 20 个 10 ms 的时间，这个查询可真够慢的。&lt;/p&gt;
&lt;p&gt;为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用&amp;quot;N 叉&amp;quot;树。这里，&amp;ldquo;N 叉&amp;quot;树中的&amp;quot;N&amp;quot;取决于数据块的大小。&lt;/p&gt;
&lt;p&gt;以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。&lt;/p&gt;
&lt;p&gt;N 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。&lt;/p&gt;
&lt;p&gt;不管是哈希还是有序数组，或者 N 叉树，它们都是不断迭代、不断优化的产物或者解决方案。数据库技术发展到今天，跳表、LSM 树等数据结构也被用于引擎设计中，这里我就不再一一展开了。&lt;/p&gt;
&lt;p&gt;你心里要有个概念，数据库底层存储的核心就是基于这些数据模型的。每碰到一个新数据库，我们需要先关注它的数据模型，这样才能从理论上分析出这个数据库的适用场景。&lt;/p&gt;
&lt;p&gt;截止到这里，我用了半篇文章的篇幅和你介绍了不同的数据结构，以及它们的适用场景，你可能会觉得有些枯燥。但是，我建议你还是要多花一些时间来理解这部分内容，毕竟这是数据库处理数据的核心概念之一，在分析问题的时候会经常用到。当你理解了索引的模型后，就会发现在分析问题的时候会有一个更清晰的视角，体会到引擎设计的精妙之处。&lt;/p&gt;
&lt;p&gt;现在，我们一起进入相对偏实战的内容吧。&lt;/p&gt;
&lt;p&gt;在 MySQL 中，索引是在存储引擎层实现的，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样。而即使多个存储引擎支持同一种类型的索引，其底层的实现也可能不同。由于 InnoDB 存储引擎在 MySQL 数据库中使用最为广泛，所以下面我就以 InnoDB 为例，和你分析一下其中的索引模型。&lt;/p&gt;
&lt;h1 id=&#34;innodb-的索引模型&#34;&gt;InnoDB 的索引模型&lt;/h1&gt;
&lt;p&gt;在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。&lt;/p&gt;
&lt;p&gt;每一个索引在 InnoDB 里面对应一棵 B+ 树。&lt;/p&gt;
&lt;p&gt;假设，我们有一个主键列为 ID 的表，表中有字段 k，并且在 k 上有索引。&lt;/p&gt;
&lt;p&gt;这个表的建表语句是：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; create table T(
id int primary key, 
k int not null, 
name varchar(16),
index (k))engine=InnoDB;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;表中 R1~R5 的 (ID,k) 值分别为 (100,1)、(200,2)、(300,3)、(500,5) 和 (600,6)，两棵树的示例示意图如下。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/dc/8d/dcda101051f28502bd5c4402b292e38d.png&#34; alt=&#34;&#34;&gt;
图 4 InnoDB 的索引组织结构&lt;/p&gt;
&lt;p&gt;从图中不难看出，根据叶子节点的内容，索引类型分为主键索引和非主键索引。&lt;/p&gt;
&lt;p&gt;主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。&lt;/p&gt;
&lt;p&gt;非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。&lt;/p&gt;
&lt;p&gt;根据上面的索引结构说明，我们来讨论一个问题：&lt;strong&gt;基于主键索引和普通索引的查询有什么区别？&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果语句是 select * from T where ID=500，即主键查询方式，则只需要搜索 ID 这棵 B+ 树；&lt;/li&gt;
&lt;li&gt;如果语句是 select * from T where k=5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。&lt;/p&gt;
&lt;h1 id=&#34;索引维护&#34;&gt;索引维护&lt;/h1&gt;
&lt;p&gt;B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。以上面这个图为例，如果插入新的行 ID 值为 700，则只需要在 R5 的记录后面插入一个新记录。如果新插入的 ID 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。&lt;/p&gt;
&lt;p&gt;而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。&lt;/p&gt;
&lt;p&gt;除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。&lt;/p&gt;
&lt;p&gt;当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。&lt;/p&gt;
&lt;p&gt;基于上面的索引维护过程说明，我们来讨论一个案例：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;你可能在一些建表规范里面见到过类似的描述，要求建表语句里一定要有自增主键。当然事无绝对，我们来分析一下哪些场景下应该使用自增主键，而哪些场景下不应该。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： NOT NULL PRIMARY KEY AUTO_INCREMENT。&lt;/p&gt;
&lt;p&gt;插入新记录的时候可以不指定 ID 的值，系统会获取当前 ID 最大值加 1 作为下一条记录的 ID 值。&lt;/p&gt;
&lt;p&gt;也就是说，自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。&lt;/p&gt;
&lt;p&gt;而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。&lt;/p&gt;
&lt;p&gt;除了考虑性能外，我们还可以从存储空间的角度来看。假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？&lt;/p&gt;
&lt;p&gt;由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。&lt;/p&gt;
&lt;p&gt;有没有什么场景适合用业务字段直接做主键的呢？还是有的。比如，有些业务的场景需求是这样的：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;只有一个索引；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;该索引必须是唯一索引。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;你一定看出来了，这就是典型的 KV 场景。&lt;/p&gt;
&lt;p&gt;由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。&lt;/p&gt;
&lt;p&gt;这时候我们就要优先考虑上一段提到的&amp;quot;尽量使用主键查询&amp;quot;原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树。&lt;/p&gt;
&lt;h1 id=&#34;小结&#34;&gt;小结&lt;/h1&gt;
&lt;p&gt;今天，我跟你分析了数据库引擎可用的数据结构，介绍了 InnoDB 采用的 B+ 树结构，以及为什么 InnoDB 要这么选择。B+ 树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数。&lt;/p&gt;
&lt;p&gt;由于 InnoDB 是索引组织表，一般情况下我会建议你创建一个自增主键，这样非主键索引占用的空间最小。但事无绝对，我也跟你讨论了使用业务逻辑字段做主键的应用场景。&lt;/p&gt;
&lt;p&gt;最后，我给你留下一个问题吧。对于上面例子中的 InnoDB 表 T，如果你要重建索引 k，你的两个 SQL 语句可以这么写：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;alter table T drop index k;
alter table T add index(k);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果你要重建主键索引，也可以这么写：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;alter table T drop primary key;
alter table T add primary key(id);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我的问题是，对于上面这两个重建索引的作法，说出你的理解。如果有不合适的，为什么，更好的方法是什么？&lt;/p&gt;
&lt;p&gt;你可以把你的思考和观点写在留言区里，我会在下一篇文章的末尾给出我的参考答案。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。&lt;/p&gt;
&lt;h1 id=&#34;上期问题时间&#34;&gt;上期问题时间&lt;/h1&gt;
&lt;p&gt;我在上一篇文章末尾给你留下的问题是：如何避免长事务对业务的影响？&lt;/p&gt;
&lt;p&gt;这个问题，我们可以从应用开发端和数据库端来看。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;首先，从应用开发端来看：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;确认是否使用了 set autocommit=0。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin/commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种只读事务可以去掉。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。（为什么会意外？在后续的文章中会提到这类案例）&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;其次，从数据库端来看：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Percona 的 pt-kill 这个工具不错，推荐使用；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;感谢 @壹笙☞漂泊 @王凯 @易翔 留下的高质量评论。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/ce/d9/ce7f4e35916ed1aa49206a53a0547bd9.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 04丨预习篇·小鲸鱼大事记（四）：尘埃落定</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90-kubernetes/04%E4%B8%A8%E9%A2%84%E4%B9%A0%E7%AF%87%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%A4%A7%E4%BA%8B%E8%AE%B0%E5%9B%9B%E5%B0%98%E5%9F%83%E8%90%BD%E5%AE%9A/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90-kubernetes/04%E4%B8%A8%E9%A2%84%E4%B9%A0%E7%AF%87%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%A4%A7%E4%BA%8B%E8%AE%B0%E5%9B%9B%E5%B0%98%E5%9F%83%E8%90%BD%E5%AE%9A/</guid>
      <description>
        
        
        &lt;p&gt;你好，我是张磊。我今天分享的主题是：小鲸鱼大事记之尘埃落定。&lt;/p&gt;
&lt;p&gt;在上一次的分享中我提到，伴随着 Docker 公司一手打造出来的容器技术生态在云计算市场中站稳了脚跟，围绕着 Docker 项目进行的各个层次的集成与创新产品，也如雨后春笋般出现在这个新兴市场当中。而 Docker 公司，不失时机地发布了 Docker Compose、Swarm 和 Machine&amp;quot;三件套&amp;quot;，在重新定义 PaaS 的方向上走出了最关键的一步。&lt;/p&gt;
&lt;p&gt;这段时间，也正是 Docker 生态创业公司们的春天，大量围绕着 Docker 项目的网络、存储、监控、CI/CD，甚至 UI 项目纷纷出台，也涌现出了很多 Rancher、Tutum 这样在开源与商业上均取得了巨大成功的创业公司。&lt;/p&gt;
&lt;p&gt;在 2014~2015 年间，整个容器社区可谓热闹非凡。&lt;/p&gt;
&lt;p&gt;这令人兴奋的繁荣背后，却浮现出了更多的担忧。这其中最主要的负面情绪，是对 Docker 公司商业化战略的种种顾虑。&lt;/p&gt;
&lt;p&gt;事实上，很多从业者也都看得明白，Docker 项目此时已经成为 Docker 公司一个商业产品。而开源，只是 Docker 公司吸引开发者群体的一个重要手段。不过这么多年来，开源社区的商业化其实都是类似的思路，无非是高不高调、心不心急的问题罢了。&lt;/p&gt;
&lt;p&gt;而真正令大多数人不满意的是，Docker 公司在 Docker 开源项目的发展上，始终保持着绝对的权威和发言权，并在多个场合用实际行动挑战到了其他玩家（比如，CoreOS、RedHat，甚至谷歌和微软）的切身利益。&lt;/p&gt;
&lt;p&gt;那么，这个时候，大家的不满也就不再是在 GitHub 上发发牢骚这么简单了。&lt;/p&gt;
&lt;p&gt;相信很多容器领域的老玩家们都听说过，Docker 项目刚刚兴起时，Google 也开源了一个在内部使用多年、经历过生产环境验证的 Linux 容器：lmctfy（Let Me Container That For You）。&lt;/p&gt;
&lt;p&gt;然而，面对 Docker 项目的强势崛起，这个对用户没那么友好的 Google 容器项目根本没有招架之力。所以，知难而退的 Google 公司，向 Docker 公司表示了合作的愿望：关停这个项目，和 Docker 公司共同推进一个中立的容器运行时（container runtime）库作为 Docker 项目的核心依赖。&lt;/p&gt;
&lt;p&gt;不过，Docker 公司并没有认同这个明显会削弱自己地位的提议，还在不久后，自己发布了一个容器运行时库 Libcontainer。这次匆忙的、由一家主导的、并带有战略性考量的重构，成了 Libcontainer 被社区长期诟病代码可读性差、可维护性不强的一个重要原因。&lt;/p&gt;
&lt;p&gt;至此，Docker 公司在容器运行时层面上的强硬态度，以及 Docker 项目在高速迭代中表现出来的不稳定和频繁变更的问题，开始让社区叫苦不迭。&lt;/p&gt;
&lt;p&gt;这种情绪在 2015 年达到了一个小高潮，容器领域的其他几位玩家开始商议&amp;quot;切割&amp;quot;Docker 项目的话语权。而&amp;quot;切割&amp;quot;的手段也非常经典，那就是成立一个中立的基金会。&lt;/p&gt;
&lt;p&gt;于是，2015 年 6 月 22 日，由 Docker 公司牵头，CoreOS、Google、RedHat 等公司共同宣布，Docker 公司将 Libcontainer 捐出，并改名为 RunC 项目，交由一个完全中立的基金会管理，然后以 RunC 为依据，大家共同制定一套容器和镜像的标准和规范。&lt;/p&gt;
&lt;p&gt;这套标准和规范，就是 OCI（ Open Container Initiative ）。&lt;strong&gt;OCI 的提出，意在将容器运行时和镜像的实现从 Docker 项目中完全剥离出来&lt;/strong&gt;。这样做，一方面可以改善 Docker 公司在容器技术上一家独大的现状，另一方面也为其他玩家不依赖于 Docker 项目构建各自的平台层能力提供了可能。&lt;/p&gt;
&lt;p&gt;不过，不难看出，OCI 的成立更多的是这些容器玩家出于自身利益进行干涉的一个妥协结果。所以，尽管 Docker 是 OCI 的发起者和创始成员，它却很少在 OCI 的技术推进和标准制定等事务上扮演关键角色，也没有动力去积极地推进这些所谓的标准。&lt;/p&gt;
&lt;p&gt;这，也正是迄今为止 OCI 组织效率持续低下的根本原因。&lt;/p&gt;
&lt;p&gt;眼看着 OCI 并没能改变 Docker 公司在容器领域一家独大的现状，Google 和 RedHat 等公司于是把与第二把武器摆上了台面。&lt;/p&gt;
&lt;p&gt;Docker 之所以不担心 OCI 的威胁，原因就在于它的 Docker 项目是容器生态的事实标准，而它所维护的 Docker 社区也足够庞大。可是，一旦这场斗争被转移到容器之上的平台层，或者说 PaaS 层，Docker 公司的竞争优势便立刻捉襟见肘了。&lt;/p&gt;
&lt;p&gt;在这个领域里，像 Google 和 RedHat 这样的成熟公司，都拥有着深厚的技术积累；而像 CoreOS 这样的创业公司，也拥有像 Etcd 这样被广泛使用的开源基础设施项目。&lt;/p&gt;
&lt;p&gt;可是 Docker 公司呢？它却只有一个 Swarm。&lt;/p&gt;
&lt;p&gt;所以这次，Google、RedHat 等开源基础设施领域玩家们，共同牵头发起了一个名为 CNCF（Cloud Native Computing Foundation）的基金会。这个基金会的目的其实很容易理解：它希望，以 Kubernetes 项目为基础，建立一个由开源基础设施领域厂商主导的、按照独立基金会方式运营的平台级社区，来对抗以 Docker 公司为核心的容器商业生态。&lt;/p&gt;
&lt;p&gt;而为了打造出这样一个围绕 Kubernetes 项目的&amp;quot;护城河&amp;quot;，CNCF 社区就需要至少确保两件事情：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Kubernetes 项目必须能够在容器编排领域取得足够大的竞争优势；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CNCF 社区必须以 Kubernetes 项目为核心，覆盖足够多的场景。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;我们先来看看 CNCF 社区如何解决 Kubernetes 项目在编排领域的竞争力的问题。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在容器编排领域，Kubernetes 项目需要面对来自 Docker 公司和 Mesos 社区两个方向的压力。不难看出，Swarm 和 Mesos 实际上分别从两个不同的方向讲出了自己最擅长的故事：Swarm 擅长的是跟 Docker 生态的无缝集成，而 Mesos 擅长的则是大规模集群的调度与管理。&lt;/p&gt;
&lt;p&gt;这两个方向，也是大多数人做容器集群管理项目时最容易想到的两个出发点。也正因为如此，Kubernetes 项目如果继续在这两个方向上做文章恐怕就不太明智了。&lt;/p&gt;
&lt;p&gt;所以这一次，Kubernetes 选择的应对方式是：Borg。&lt;/p&gt;
&lt;p&gt;如果你看过 Kubernetes 项目早期的 GitHub Issue 和 Feature 的话，就会发现它们大多来自于 Borg 和 Omega 系统的内部特性，这些特性落到 Kubernetes 项目上，就是 Pod、Sidecar 等功能和设计模式。&lt;/p&gt;
&lt;p&gt;这就解释了，为什么 Kubernetes 发布后，很多人&amp;quot;抱怨&amp;quot;其设计思想过于&amp;quot;超前&amp;quot;的原因：Kubernetes 项目的基础特性，并不是几个工程师突然&amp;quot;拍脑袋&amp;quot;想出来的东西，而是 Google 公司在容器化基础设施领域多年来实践经验的沉淀与升华。这，正是 Kubernetes 项目能够从一开始就避免同 Swarm 和 Mesos 社区同质化的重要手段。&lt;/p&gt;
&lt;p&gt;于是，CNCF 接下来的任务就是，如何把这些先进的思想通过技术手段在开源社区落地，并培育出一个认同这些理念的生态？这时，RedHat 就发挥了重要作用。&lt;/p&gt;
&lt;p&gt;当时，Kubernetes 团队规模很小，能够投入的工程能力也十分紧张，而这恰恰是 RedHat 的长处。更难得的是，RedHat 是世界上为数不多的、能真正理解开源社区运作和项目研发真谛的合作伙伴。&lt;/p&gt;
&lt;p&gt;所以，RedHat 与 Google 联盟的成立，不仅保证了 RedHat 在 Kubernetes 项目上的影响力，也正式开启了容器编排领域&amp;quot;三国鼎立&amp;quot;的局面。&lt;/p&gt;
&lt;p&gt;这时，我们再重新审视容器生态的格局，就不难发现 Kubernetes 项目、Docker 公司和 Mesos 社区这三大玩家的关系已经发生了微妙的变化。&lt;/p&gt;
&lt;p&gt;其中，Mesos 社区与容器技术的关系，更像是&amp;quot;借势&amp;quot;，而不是这个领域真正的参与者和领导者。这个事实，加上它所属的 Apache 社区固有的封闭性，导致了 Mesos 社区虽然技术最为成熟，却在容器编排领域鲜有创新。&lt;/p&gt;
&lt;p&gt;这也是为何，Google 公司很快就把注意力转向了动作更加激进的 Docker 公司。&lt;/p&gt;
&lt;p&gt;有意思的是，Docker 公司对 Mesos 社区也是类似的看法。所以从一开始，Docker 公司就把应对 Kubernetes 项目的竞争摆在了首要位置：一方面，不断强调&amp;quot;Docker Native&amp;quot;的&amp;quot;重要性&amp;quot;，另一方面，与 Kubernetes 项目在多个场合进行了直接的碰撞。&lt;/p&gt;
&lt;p&gt;不过，这次竞争的发展态势，很快就超过了 Docker 公司的预期。&lt;/p&gt;
&lt;p&gt;Kubernetes 项目并没有跟 Swarm 项目展开同质化的竞争，所以&amp;quot;Docker Native&amp;quot;的说辞并没有太大的杀伤力。相反地，Kubernetes 项目让人耳目一新的设计理念和号召力，很快就构建出了一个与众不同的容器编排与管理的生态。&lt;/p&gt;
&lt;p&gt;就这样，Kubernetes 项目在 GitHub 上的各项指标开始一骑绝尘，将 Swarm 项目远远地甩在了身后。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;有了这个基础，CNCF 社区就可以放心地解决第二个问题了。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在已经囊括了容器监控事实标准的 Prometheus 项目之后，CNCF 社区迅速在成员项目中添加了 Fluentd、OpenTracing、CNI 等一系列容器生态的知名工具和项目。&lt;/p&gt;
&lt;p&gt;而在看到了 CNCF 社区对用户表现出来的巨大吸引力之后，大量的公司和创业团队也开始专门针对 CNCF 社区而非 Docker 公司制定推广策略。&lt;/p&gt;
&lt;p&gt;面对这样的竞争态势，Docker 公司决定更进一步。在 2016 年，Docker 公司宣布了一个震惊所有人的计划：放弃现有的 Swarm 项目，将容器编排和集群管理功能全部内置到 Docker 项目当中。&lt;/p&gt;
&lt;p&gt;显然，Docker 公司意识到了 Swarm 项目目前唯一的竞争优势，就是跟 Docker 项目的无缝集成。那么，如何让这种优势最大化呢？那就是把 Swarm 内置到 Docker 项目当中。&lt;/p&gt;
&lt;p&gt;实际上，从工程角度来看，这种做法的风险很大。内置容器编排、集群管理和负载均衡能力，固然可以使得 Docker 项目的边界直接扩大到一个完整的 PaaS 项目的范畴，但这种变更带来的技术复杂度和维护难度，长远来看对 Docker 项目是不利的。&lt;/p&gt;
&lt;p&gt;不过，在当时的大环境下，Docker 公司的选择恐怕也带有一丝孤注一掷的意味。&lt;/p&gt;
&lt;p&gt;而&lt;strong&gt;Kubernetes 的应对策略则是反其道而行之，开始在整个社区推进&amp;quot;民主化&amp;quot;架构&lt;/strong&gt;，即：从 API 到容器运行时的每一层，Kubernetes 项目都为开发者暴露出了可以扩展的插件机制，鼓励用户通过代码的方式介入到 Kubernetes 项目的每一个阶段。&lt;/p&gt;
&lt;p&gt;Kubernetes 项目的这个变革的效果立竿见影，很快在整个容器社区中催生出了大量的、基于 Kubernetes API 和扩展接口的二次创新工作，比如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;目前热度极高的微服务治理项目 Istio；&lt;/li&gt;
&lt;li&gt;被广泛采用的有状态应用部署框架 Operator；&lt;/li&gt;
&lt;li&gt;还有像 Rook 这样的开源创业项目，它通过 Kubernetes 的可扩展接口，把 Ceph 这样的重量级产品封装成了简单易用的容器存储插件。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;就这样，在这种鼓励二次创新的整体氛围当中，Kubernetes 社区在 2016 年之后得到了空前的发展。更重要的是，不同于之前局限于&amp;quot;打包、发布&amp;quot;这样的 PaaS 化路线，&lt;strong&gt;这一次容器社区的繁荣，是一次完全以 Kubernetes 项目为核心的&amp;quot;百家争鸣&amp;quot;&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;面对 Kubernetes 社区的崛起和壮大，Docker 公司也不得不面对自己豪赌失败的现实。但在早前拒绝了微软的天价收购之后，Docker 公司实际上已经没有什么回旋余地，只能选择逐步放弃开源社区而专注于自己的商业化转型。&lt;/p&gt;
&lt;p&gt;所以，从 2017 年开始，Docker 公司先是将 Docker 项目的容器运行时部分 Containerd 捐赠给 CNCF 社区，标志着 Docker 项目已经全面升级成为一个 PaaS 平台；紧接着，Docker 公司宣布将 Docker 项目改名为 Moby，然后交给社区自行维护，而 Docker 公司的商业产品将占有 Docker 这个注册商标。&lt;/p&gt;
&lt;p&gt;Docker 公司这些举措背后的含义非常明确：它将全面放弃在开源社区同 Kubernetes 生态的竞争，转而专注于自己的商业业务，并且通过将 Docker 项目改名为 Moby 的举动，将原本属于 Docker 社区的用户转化成了自己的客户。&lt;/p&gt;
&lt;p&gt;2017 年 10 月，Docker 公司出人意料地宣布，将在自己的主打产品 Docker 企业版中内置 Kubernetes 项目，这标志着持续了近两年之久的&amp;quot;编排之争&amp;quot;至此落下帷幕。&lt;/p&gt;
&lt;p&gt;2018 年 1 月 30 日，RedHat 宣布斥资 2.5 亿美元收购 CoreOS。&lt;/p&gt;
&lt;p&gt;2018 年 3 月 28 日，这一切纷争的始作俑者，Docker 公司的 CTO Solomon Hykes 宣布辞职，曾经纷纷扰扰的容器技术圈子，到此尘埃落定。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;容器技术圈子在短短几年里发生了很多变数，但很多事情其实也都在情理之中。就像 Docker 这样一家创业公司，在通过开源社区的运作取得了巨大的成功之后，就不得不面对来自整个云计算产业的竞争和围剿。而这个产业的垄断特性，对于 Docker 这样的技术型创业公司其实天生就不友好。&lt;/p&gt;
&lt;p&gt;在这种局势下，接受微软的天价收购，在大多数人看来都是一个非常明智和实际的选择。可是 Solomon Hykes 却多少带有一些理想主义的影子，既然不甘于&amp;quot;寄人篱下&amp;quot;，那他就必须带领 Docker 公司去对抗来自整个云计算产业的压力。&lt;/p&gt;
&lt;p&gt;只不过，Docker 公司最后选择的对抗方式，是将开源项目与商业产品紧密绑定，打造了一个极端封闭的技术生态。而这，其实违背了 Docker 项目与开发者保持亲密关系的初衷。相比之下，Kubernetes 社区，正是以一种更加温和的方式，承接了 Docker 项目的未尽事业，即：以开发者为核心，构建一个相对民主和开放的容器生态。&lt;/p&gt;
&lt;p&gt;这也是为何，Kubernetes 项目的成功其实是必然的。&lt;/p&gt;
&lt;p&gt;现在，我们很难想象如果 Docker 公司最初选择了跟 Kubernetes 社区合作，如今的容器生态又将会是怎样的一番景象。不过我们可以肯定的是，Docker 公司在过去五年里的风云变幻，以及 Solomon Hykes 本人的传奇经历，都已经在云计算的长河中留下了浓墨重彩的一笔。&lt;/p&gt;
&lt;h2 id=&#34;思考题&#34;&gt;思考题&lt;/h2&gt;
&lt;p&gt;你如何评价 Solomon Hykes 在 Docker 公司发展历程中的所作所为？你又是否看好 Docker 公司在今后的发展呢？&lt;/p&gt;
&lt;p&gt;欢迎你给我留言，也欢迎分享给更多的朋友一起阅读。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/47/55/47a6f3bf6b92d58512d5a2ed0a556f55.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 05丨JVM是如何执行方法调用的？（下）</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3jvm%E8%99%9A%E6%8B%9F%E6%9C%BA/05%E4%B8%A8jvm%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%E7%9A%84%E4%B8%8B/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3jvm%E8%99%9A%E6%8B%9F%E6%9C%BA/05%E4%B8%A8jvm%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%E7%9A%84%E4%B8%8B/</guid>
      <description>
        
        
        &lt;p&gt;我在读博士的时候，最怕的事情就是被问有没有新的 Idea。有一次我被老板问急了，就随口说了一个。&lt;/p&gt;
&lt;p&gt;这个 Idea 究竟是什么呢，我们知道，设计模式大量使用了虚方法来实现多态。但是虚方法的性能效率并不高，所以我就说，是否能够在此基础上写篇文章，评估每一种设计模式因为虚方法调用而造成的性能开销，并且在文章中强烈谴责一下？&lt;/p&gt;
&lt;p&gt;当时呢，我老板教的是一门高级程序设计的课，其中有好几节课刚好在讲设计模式的各种好处。所以，我说完这个 Idea，就看到老板的神色略有不悦了，脸上写满了&amp;quot;小郑啊，你这是舍本逐末啊&amp;quot;，于是，我就连忙挽尊，说我是开玩笑的。&lt;/p&gt;
&lt;p&gt;在这里呢，我犯的错误其实有两个。第一，我不应该因为虚方法的性能效率，而放弃良好的设计。第二，通常来说，Java 虚拟机中虚方法调用的性能开销并不大，有些时候甚至可以完全消除。第一个错误是原则上的，这里就不展开了。至于第二个错误，我们今天便来聊一聊 Java 虚拟机中虚方法调用的具体实现。&lt;/p&gt;
&lt;p&gt;首先，我们来看一个模拟出国边检的小例子。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;abstract class Passenger {
  abstract void passThroughImmigration();
  @Override
  public String toString() { ... }
}
class ForeignerPassenger extends Passenger {
	 @Override
 	void passThroughImmigration() { /* 进外国人通道 */ }
}
class ChinesePassenger extends Passenger {
  @Override
  void passThroughImmigration() { /* 进中国人通道 */ }
  void visitDutyFreeShops() { /* 逛免税店 */ }
}
 
Passenger passenger = ...
passenger.passThroughImmigration();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里我定义了一个抽象类，叫做 Passenger，这个类中有一个名为 passThroughImmigration 的抽象方法，以及重写自 Object 类的 toString 方法。&lt;/p&gt;
&lt;p&gt;然后，我将 Passenger 粗暴地分为两种：ChinesePassenger 和 ForeignerPassenger。&lt;/p&gt;
&lt;p&gt;两个类分别实现了 passThroughImmigration 这个方法，具体来说，就是中国人走中国人通道，外国人走外国人通道。由于咱们储蓄较多，所以我在 ChinesePassenger 这个类中，还特意添加了一个叫做 visitDutyFreeShops 的方法。&lt;/p&gt;
&lt;p&gt;那么在实际运行过程中，Java 虚拟机是如何高效地确定每个 Passenger 实例应该去哪条通道的呢？我们一起来看一下。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;虚方法调用&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;在上一篇中我曾经提到，Java 里所有非私有实例方法调用都会被编译成 invokevirtual 指令，而接口方法调用都会被编译成 invokeinterface 指令。这两种指令，均属于 Java 虚拟机中的虚方法调用。&lt;/p&gt;
&lt;p&gt;在绝大多数情况下，Java 虚拟机需要根据调用者的动态类型，来确定虚方法调用的目标方法。这个过程我们称之为动态绑定。那么，相对于静态绑定的非虚方法调用来说，虚方法调用更加耗时。&lt;/p&gt;
&lt;p&gt;在 Java 虚拟机中，静态绑定包括用于调用静态方法的 invokestatic 指令，和用于调用构造器、私有实例方法以及超类非私有实例方法的 invokespecial 指令。如果虚方法调用指向一个标记为 final 的方法，那么 Java 虚拟机也可以静态绑定该虚方法调用的目标方法。&lt;/p&gt;
&lt;p&gt;Java 虚拟机中采取了一种用空间换取时间的策略来实现动态绑定。它为每个类生成一张方法表，用以快速定位目标方法。那么方法表具体是怎样实现的呢？&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;方法表&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;在介绍那篇类加载机制的链接部分中，我曾提到类加载的准备阶段，它除了为静态字段分配内存之外，还会构造与该类相关联的方法表。&lt;/p&gt;
&lt;p&gt;这个数据结构，便是 Java 虚拟机实现动态绑定的关键所在。下面我将以 invokevirtual 所使用的虚方法表（virtual method table，vtable）为例介绍方法表的用法。invokeinterface 所使用的接口方法表（interface method table，itable）稍微复杂些，但是原理其实是类似的。&lt;/p&gt;
&lt;p&gt;方法表本质上是一个数组，每个数组元素指向一个当前类及其祖先类中非私有的实例方法。&lt;/p&gt;
&lt;p&gt;这些方法可能是具体的、可执行的方法，也可能是没有相应字节码的抽象方法。方法表满足两个特质：其一，子类方法表中包含父类方法表中的所有方法；其二，子类方法在方法表中的索引值，与它所重写的父类方法的索引值相同。&lt;/p&gt;
&lt;p&gt;我们知道，方法调用指令中的符号引用会在执行之前解析成实际引用。对于静态绑定的方法调用而言，实际引用将指向具体的目标方法。对于动态绑定的方法调用而言，实际引用则是方法表的索引值（实际上并不仅是索引值）。&lt;/p&gt;
&lt;p&gt;在执行过程中，Java 虚拟机将获取调用者的实际类型，并在该实际类型的虚方法表中，根据索引值获得目标方法。这个过程便是动态绑定。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/f1/c3/f1ff9dcb297a458981bd1d189a5b04c3.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;在我们的例子中，Passenger 类的方法表包括两个方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;toString&lt;/li&gt;
&lt;li&gt;passThroughImmigration，&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;它们分别对应 0 号和 1 号。之所以方法表调换了 toString 方法和 passThroughImmigration 方法的位置，是因为 toString 方法的索引值需要与 Object 类中同名方法的索引值一致。为了保持简洁，这里我就不考虑 Object 类中的其他方法。&lt;/p&gt;
&lt;p&gt;ForeignerPassenger 的方法表同样有两行。其中，0 号方法指向继承而来的 Passenger 类的 toString 方法。1 号方法则指向自己重写的 passThroughImmigration 方法。&lt;/p&gt;
&lt;p&gt;ChinesePassenger 的方法表则包括三个方法，除了继承而来的 Passenger 类的 toString 方法，自己重写的 passThroughImmigration 方法之外，还包括独有的 visitDutyFreeShops 方法。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Passenger passenger = ...
passenger.passThroughImmigration();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里，Java 虚拟机的工作可以想象为导航员。每当来了一个乘客需要出境，导航员会先问是中国人还是外国人（获取动态类型），然后翻出中国人 / 外国人对应的小册子（获取动态类型的方法表），小册子的第 1 页便写着应该到哪条通道办理出境手续（用 1 作为索引来查找方法表所对应的目标方法）。&lt;/p&gt;
&lt;p&gt;实际上，使用了方法表的动态绑定与静态绑定相比，仅仅多出几个内存解引用操作：访问栈上的调用者，读取调用者的动态类型，读取该类型的方法表，读取方法表中某个索引值所对应的目标方法。相对于创建并初始化 Java 栈帧来说，这几个内存解引用操作的开销简直可以忽略不计。&lt;/p&gt;
&lt;p&gt;那么我们是否可以认为虚方法调用对性能没有太大影响呢？&lt;/p&gt;
&lt;p&gt;其实是不能的，上述优化的效果看上去十分美好，但实际上仅存在于解释执行中，或者即时编译代码的最坏情况中。这是因为即时编译还拥有另外两种性能更好的优化手段：内联缓存（inlining cache）和方法内联（method inlining）。下面我便来介绍第一种内联缓存。&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;内联缓存&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;内联缓存是一种加快动态绑定的优化技术。它能够缓存虚方法调用中调用者的动态类型，以及该类型所对应的目标方法。在之后的执行过程中，如果碰到已缓存的类型，内联缓存便会直接调用该类型所对应的目标方法。如果没有碰到已缓存的类型，内联缓存则会退化至使用基于方法表的动态绑定。&lt;/p&gt;
&lt;p&gt;在我们的例子中，这相当于导航员记住了上一个出境乘客的国籍和对应的通道，例如中国人，走了左边通道出境。那么下一个乘客想要出境的时候，导航员会先问是不是中国人，是的话就走左边通道。如果不是的话，只好拿出外国人的小册子，翻到第 1 页，再告知查询结果：右边。&lt;/p&gt;
&lt;p&gt;在针对多态的优化手段中，我们通常会提及以下三个术语。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;单态（monomorphic）指的是仅有一种状态的情况。&lt;/li&gt;
&lt;li&gt;多态（polymorphic）指的是有限数量种状态的情况。二态（bimorphic）是多态的其中一种。&lt;/li&gt;
&lt;li&gt;超多态（megamorphic）指的是更多种状态的情况。通常我们用一个具体数值来区分多态和超多态。在这个数值之下，我们称之为多态。否则，我们称之为超多态。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;对于内联缓存来说，我们也有对应的单态内联缓存、多态内联缓存和超多态内联缓存。单态内联缓存，顾名思义，便是只缓存了一种动态类型以及它所对应的目标方法。它的实现非常简单：比较所缓存的动态类型，如果命中，则直接调用对应的目标方法。&lt;/p&gt;
&lt;p&gt;多态内联缓存则缓存了多个动态类型及其目标方法。它需要逐个将所缓存的动态类型与当前动态类型进行比较，如果命中，则调用对应的目标方法。&lt;/p&gt;
&lt;p&gt;一般来说，我们会将更加热门的动态类型放在前面。在实践中，大部分的虚方法调用均是单态的，也就是只有一种动态类型。为了节省内存空间，Java 虚拟机只采用单态内联缓存。&lt;/p&gt;
&lt;p&gt;前面提到，当内联缓存没有命中的情况下，Java 虚拟机需要重新使用方法表进行动态绑定。对于内联缓存中的内容，我们有两种选择。一是替换单态内联缓存中的纪录。这种做法就好比 CPU 中的数据缓存，它对数据的局部性有要求，即在替换内联缓存之后的一段时间内，方法调用的调用者的动态类型应当保持一致，从而能够有效地利用内联缓存。&lt;/p&gt;
&lt;p&gt;因此，在最坏情况下，我们用两种不同类型的调用者，轮流执行该方法调用，那么每次进行方法调用都将替换内联缓存。也就是说，只有写缓存的额外开销，而没有用缓存的性能提升。&lt;/p&gt;
&lt;p&gt;另外一种选择则是劣化为超多态状态。这也是 Java 虚拟机的具体实现方式。处于这种状态下的内联缓存，实际上放弃了优化的机会。它将直接访问方法表，来动态绑定目标方法。与替换内联缓存纪录的做法相比，它牺牲了优化的机会，但是节省了写缓存的额外开销。&lt;/p&gt;
&lt;p&gt;具体到我们的例子，如果来了一队乘客，其中外国人和中国人依次隔开，那么在重复使用的单态内联缓存中，导航员需要反复记住上个出境的乘客，而且记住的信息在处理下一乘客时又会被替换掉。因此，倒不如一直不记，以此来节省脑细胞。&lt;/p&gt;
&lt;p&gt;虽然内联缓存附带内联二字，但是它并没有内联目标方法。这里需要明确的是，任何方法调用除非被内联，否则都会有固定开销。这些开销来源于保存程序在该方法中的执行位置，以及新建、压入和弹出新方法所使用的栈帧。&lt;/p&gt;
&lt;p&gt;对于极其简单的方法而言，比如说 getter/setter，这部分固定开销占据的 CPU 时间甚至超过了方法本身。此外，在即时编译中，方法内联不仅仅能够消除方法调用的固定开销，而且还增加了进一步优化的可能性，我们会在专栏的第二部分详细介绍方法内联的内容。&lt;/p&gt;
&lt;h2 id=&#34;总结与实践&#34;&gt;总结与实践&lt;/h2&gt;
&lt;p&gt;今天我介绍了虚方法调用在 Java 虚拟机中的实现方式。&lt;/p&gt;
&lt;p&gt;虚方法调用包括 invokevirtual 指令和 invokeinterface 指令。如果这两种指令所声明的目标方法被标记为 final，那么 Java 虚拟机会采用静态绑定。&lt;/p&gt;
&lt;p&gt;否则，Java 虚拟机将采用动态绑定，在运行过程中根据调用者的动态类型，来决定具体的目标方法。&lt;/p&gt;
&lt;p&gt;Java 虚拟机的动态绑定是通过方法表这一数据结构来实现的。方法表中每一个重写方法的索引值，与父类方法表中被重写的方法的索引值一致。&lt;/p&gt;
&lt;p&gt;在解析虚方法调用时，Java 虚拟机会纪录下所声明的目标方法的索引值，并且在运行过程中根据这个索引值查找具体的目标方法。&lt;/p&gt;
&lt;p&gt;Java 虚拟机中的即时编译器会使用内联缓存来加速动态绑定。Java 虚拟机所采用的单态内联缓存将纪录调用者的动态类型，以及它所对应的目标方法。&lt;/p&gt;
&lt;p&gt;当碰到新的调用者时，如果其动态类型与缓存中的类型匹配，则直接调用缓存的目标方法。&lt;/p&gt;
&lt;p&gt;否则，Java 虚拟机将该内联缓存劣化为超多态内联缓存，在今后的执行过程中直接使用方法表进行动态绑定。&lt;/p&gt;
&lt;p&gt;在今天的实践环节，我们来观测一下单态内联缓存和超多态内联缓存的性能差距。为了消除方法内联的影响，请使用如下的命令。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Run with: java -XX:CompileCommand=&#39;dontinline,*.passThroughImmigration&#39; Passenger
public abstract class Passenger {
	 abstract void passThroughImmigration();
  public static void main(String[] args) {
  	Passenger a = new ChinesePassenger();
	Passenger b = new ForeignerPassenger();
    long current = System.currentTimeMillis();
    for (int i = 1; i &amp;lt;= 2_000_000_000; i++) {
      if (i % 100_000_000 == 0) {
        long temp = System.currentTimeMillis();
        System.out.println(temp - current);
        current = temp;
      }
      Passenger c = (i &amp;lt; 1_000_000_000) ? a : b;
      c.passThroughImmigration();
	}
  }
}
class ChinesePassenger extends Passenger {
  @Override void passThroughImmigration() {} 
}
class ForeignerPassenger extends Passenger {
  @Override void passThroughImmigration() {}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/2a/d5/2a62e58cbdf56a5dc40748567d346fd5.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 05丨何为技术领导力？</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/05%E4%B8%A8%E4%BD%95%E4%B8%BA%E6%8A%80%E6%9C%AF%E9%A2%86%E5%AF%BC%E5%8A%9B/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/05%E4%B8%A8%E4%BD%95%E4%B8%BA%E6%8A%80%E6%9C%AF%E9%A2%86%E5%AF%BC%E5%8A%9B/</guid>
      <description>
        
        
        &lt;p&gt;我先说明一下，我们要谈的并不是&amp;quot;如何成为一名管理者&amp;quot;。我想谈的是技术上的领先，技术上的优势，而不是一个职称，一个人事组织者。另外，我不想在理论上泛泛而谈这个事，我想谈得更落地、更实际一些，所以，我需要直面一些问题。&lt;/p&gt;
&lt;p&gt;首先，要考虑的问题是&amp;mdash;&amp;mdash;做技术有没有前途？我们在很多场合都能听到：技术做不长，技术无用商业才有用等这样的言论。所以，在谈技术领导力前，我需要直面这个问题，否则，技术领导力就成为一个伪命题了。&lt;/p&gt;
&lt;h1 id=&#34;技术重要吗&#34;&gt;技术重要吗？&lt;/h1&gt;
&lt;p&gt;在中国，程序员把自己称做&amp;quot;码农&amp;quot;，说自己是编程的农民工，干的都是体力活，加班很严重，认为做技术没有什么前途，好多人都拼命地想转管理或是转行。这是中国技术人员的一个现实问题。&lt;/p&gt;
&lt;p&gt;与国外相比，似乎中国的程序员在生存上遇到的问题更多。为什么会有这样的问题？我是这么理解的，在中国，需要解决的问题很多，而且人口众多。也就是说，中国目前处于加速发展中，遍地机会，公司可以通过&amp;quot;野蛮开采&amp;quot;来实现自身业务的快速拓展和扩张。而西方发达国家人口少一些，相对成熟一些，竞争比较激烈，所以，更多的是采用&amp;quot;精耕细作&amp;quot;的方式。&lt;/p&gt;
&lt;p&gt;此外，中国的基础技术还正在发展中，技术能力不足，所以，目前的状态下，销售、运营、地推等简单快速的业务手段显得更为有效一些，需要比拼的是如何拿到更多的&amp;quot;地&amp;quot;。而西方的&amp;quot;精耕细作&amp;quot;需要比拼的是在同样大小的一块田里，如何才能更快更多地种出&amp;quot;粮食&amp;quot;，这完全就是在拼技术了。&lt;/p&gt;
&lt;p&gt;每个民族、国家、公司和个人都有自己的发展过程。而总体上来说，中国公司目前还处于&amp;quot;野蛮开采&amp;quot;阶段，所以，这就是为什么很多公司为了快速扩张，要获得更多的用户和市场 ，需要通过加班、加人、烧钱、并购、广告、运营、销售等这些相对比较&amp;quot;野蛮&amp;quot;的方式发展自己，而导致技术人员在其中跟从和被驱动。这也是为什么很多中国公司要用&amp;quot;狼性&amp;quot;、要用&amp;quot;加班&amp;quot;、要用&amp;quot;打鸡血&amp;quot;来驱动员工完成更多的工作。&lt;/p&gt;
&lt;p&gt;但是，这会成为常态吗？中国和中国的公司会这样一直走下去吗？我并不觉得。&lt;/p&gt;
&lt;p&gt;这就好像人类的发展史一样。在人类发展的初期，蛮荒民族通过野蛮地掠夺来发展自己的民族更为有效，但我们知道资源是有限的，一旦没有太多可以掠夺的资源，就需要发展&amp;quot;自给自主&amp;quot;的能力，这就是所谓的&amp;quot;发展文明&amp;quot;。所以，我们也能看到，一些比较&amp;quot;文明&amp;quot;的民族在初期搞不过&amp;quot;野蛮&amp;quot;的民族，但是，一旦&amp;quot;文明&amp;quot;发展起来，就可以从质上完全超过&amp;quot;野蛮&amp;quot;民族。&lt;/p&gt;
&lt;p&gt;从人类历史的发展规律中，我们可以看到，各民族基本都是通过&amp;quot;野蛮开采&amp;quot;来获得原始积累，然后有一些民族开始通过这些原始积累发展自己的&amp;quot;文明&amp;quot;，从而达到强大，吞并弱小的民族。&lt;/p&gt;
&lt;p&gt;所以，对于一个想要发展、想要变强大的民族或公司来说，野蛮开采绝不会是常态，否则，只能赢得一时，长期来说，一定会被那些掌握先进技术的民族或公司所淘汰。&lt;/p&gt;
&lt;p&gt;从人类社会的发展过程中来看，基本上可以总结为几个发展阶段。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;第一个阶段：野蛮开采&lt;/strong&gt;。这个阶段的主要特点是资源过多，只需要开采就好了。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;第二个阶段：资源整合&lt;/strong&gt;。在这个阶段，资源已经被不同的人给占有了，但是需要对资源整合优化，提高利用率。这时通过管理手段就能实现。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;第三个阶段：精耕细作&lt;/strong&gt;。这个阶段基本上是对第二阶段的精细化运作，并且通过科学的手段来达到。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;第四个阶段：发明创造&lt;/strong&gt;。 在这个阶段，人们利用已有不足的资源来创造更好的资源，并替代已有的马上要枯竭的资源。这就需要采用高科技来达到了。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这也是为什么像亚马逊、Facebook 这样的公司，最终都会去发展自己的核心技术，提高自己的技术领导力，从早期的业务型公司转变成为技术型公司的原因。那些本来技术很好的公司，比如雅虎、百度，在发展到一定程度时，将自己定位成了一个广告公司，然后开始变味、走下坡路。&lt;/p&gt;
&lt;p&gt;同样，谷歌当年举公司之力不做技术做社交也是一个失败的案例。还好拉里·佩奇（Larry Page）看到苗头不对，重新掌权，把产品经理全部移到一边，让工程师重新掌权，于是才有了无人车和 AlphaGo 这样真正能够影响人类未来的惊世之作。&lt;/p&gt;
&lt;p&gt;微软在某段时间由一个做电视购物的销售担任 CEO，也出现了技术领导力不足的情况，导致公司走下坡路。苹果公司，在聘任了一个非技术的 CEO 后也几近破产。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;尊重技术的公司和不尊重技术的公司在初期可能还不能显现，而长期来看，差距就很明显了&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;所以，无论是一个国家，一个公司，还是一个人，在今天这样技术浪潮一浪高过一浪的形势下，拥有技术不是问题，而问题是有没有拥有技术领导力。&lt;/p&gt;
&lt;p&gt;说的直白一点，技术领导力就是，你还在用大刀长矛打战的时候，对方已经用上了洋枪大炮；你还在赶马车的时候，对方已经开上了汽车&amp;hellip;&amp;hellip;&lt;/p&gt;
&lt;h1 id=&#34;什么是技术领导力&#34;&gt;什么是技术领导力？&lt;/h1&gt;
&lt;p&gt;但是，这么说还是很模糊，还是不能清楚地说明什么是技术领导力。我认为，技术领导力不仅仅是呈现出来的技术，而是一种可以获得绝对优势的技术能力。所以，技术领导力也有一些特征，为了说清楚这些特征，先让我们来看一下人类历史上的几次工业革命。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第一次工业革命&lt;/strong&gt;。第一次工业革命开始于 18 世纪 60 年代，一直持续到 19 世纪 30 年代至 40 年代。在这段时间里，人类生产逐渐转向新的制造过程，出现了以机器取代人力、兽力的趋势，以大规模的工厂生产取代个体工厂手工生产的一场生产与科技革命。由于机器的发明及运用成为了这个时代的标志，因此历史学家称这个时代为机器时代（the Age of Machines）。&lt;/p&gt;
&lt;p&gt;这个时期的标志技术是&amp;mdash;&amp;mdash;&amp;ldquo;蒸汽机&amp;rdquo;。在瓦特改良蒸汽机之前，生产所需的动力依靠人力、畜力、水力和风力。伴随蒸汽机的发明和改进，工厂不再依河或溪流而建，很多以前依赖人力与手工完成的工作逐渐被机械化生产取代。世界被推向了一个崭新的&amp;quot;蒸汽时代&amp;quot;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第二次工业革命&lt;/strong&gt;。第二次工业革命指的是 1870 年至 1914 年期间的工业革命。英国、德国、法国、丹麦和美国以及 1870 年后的日本，在这段时间里，工业得到飞速发展。第二次工业革命紧跟着 18 世纪末的第一次工业革命，并且从英国向西欧和北美蔓延。&lt;/p&gt;
&lt;p&gt;第二次工业革命以电力的大规模应用为代表，以电灯、电报以及无线电通信的发明为标志。这些发明把人类推向了&amp;quot;电力&amp;quot;时代。电力和内燃技术的出现，让人类进入了真正的工业时代。随着这些技术的发展，工人阶级开始受到关注，并逐渐出现了有专业知识的中产阶级，而且人数众多。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第三次工业革命&lt;/strong&gt;。第三次工业革命又名信息技术革命或者数字化革命，指第二次世界大战后，因计算机和电子数据的普及和推广而在各行各业发生的从机械和模拟电路再到数字电路的变革。第三次技术革命使传统工业更加机械化、自动化。它降低了工作成本，彻底改变了整个社会的运作模式，也创造了电脑工业这一高科技产业。&lt;/p&gt;
&lt;p&gt;它是人类历史上规模最大、影响最深远的科技革命，至今仍未结束。主要技术是&amp;quot;计算机&amp;quot;。计算机的发明是人类智力发展道路上的里程碑，因为它可以代替人类进行一部分脑力活动。&lt;/p&gt;
&lt;p&gt;而且，我们还可以看到，科学技术推动生产力的发展，转化为直接生产力的速度在加快。而科学技术密切结合，相互促进，在各个领域相互渗透。&lt;/p&gt;
&lt;p&gt;近代这几百年的人类发展史，从蒸汽机时代，到电力时代，再到信息时代，我们可以看到这样的一些信息。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;关键技术&lt;/strong&gt;。蒸汽机、电、化工、原子能、炼钢、计算机，如果只看这些东西的话，似乎没什么用。但这些核心技术的突破，可以让我们建造很多更牛的工具，而这些工具能让人类干出以前干不出来的事。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;自动化&lt;/strong&gt;。这其中最重要的事就是自动化。三次革命中最重要的事就是用机器来自动化。通信、交通、军事、教育、金融等各个领域都是在拼命地自动化，以提高效率&amp;mdash;&amp;mdash;用更低的成本来完成更多的事。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;解放生产力&lt;/strong&gt;。把人从劳动密集型的工作中解放出来，去做更高层次的知识密集型的工作。说得难听一点，就是取代人类，让人失业。值得注意的是，今天的 AI 在开始取代人类的知识密集型的工作&amp;hellip;&amp;hellip;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，我们可以看到的技术领导力是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;尊重技术，追求核心基础技术。&lt;/li&gt;
&lt;li&gt;追逐自动化的高效率的工具和技术，同时避免无效率的组织架构和管理。&lt;/li&gt;
&lt;li&gt;解放生产力，追逐人效的提高。&lt;/li&gt;
&lt;li&gt;开发抽象和高质量的可以重用的技术组件。&lt;/li&gt;
&lt;li&gt;坚持高于社会主流的技术标准和要求。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;如何拥有技术领导力&#34;&gt;如何拥有技术领导力？&lt;/h1&gt;
&lt;p&gt;前面这些说的比较宏大，并不是所有的人都可以发明或创造这样的核心技术，但这不妨碍我们拥有技术领导力。因为，我认为，这世界的技术有两种，一种是像从马车时代到汽车时代这样的技术，也就是汽车的关键技术&amp;mdash;&amp;mdash;引擎，另一种则是工程方面的技术，而工程技术是如何让汽车更安全更有效率地行驶。对于后者来说**，我觉得所有的工程师都有机会**。&lt;/p&gt;
&lt;p&gt;那么作为一个软件工程师怎样才算是拥有&amp;quot;技术领导力&amp;quot;呢？我个人认为，是有下面的这些特质。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;能够发现问题&lt;/strong&gt;。能够发现现有方案的问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;能够提供解决问题的思路和方案，并能比较这些方案的优缺点&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;能够做出正确的技术决定&lt;/strong&gt;。用什么样的技术、什么解决方案、怎样实现来完成一个项目。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;能够用更优雅，更简单，更容易的方式来解决问题&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;能够提高代码或软件的扩展性、重用性和可维护性&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;能够用正确的方式管理团队&lt;/strong&gt;。所谓正确的方式，一方面是，让正确的人做正确的事，并发挥每个人的潜力；另一方面是，可以提高团队的生产力和人效，找到最有价值的需求，用最少的成本实现之。并且，可以不断地提高自身和团队的标准。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;创新能力&lt;/strong&gt;。能够使用新的方法新的方式解决问题，追逐新的工具和技术。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们可以看到，要做到这些其实并不容易，尤其，在面对不同问题的时候，这些能力也会因此不同。但是，我们不难发现，在任何一个团队中，大多数人都是在提问题，而只有少数人在回答这些人的问题，或是在提供解决问题的思路和方案。&lt;/p&gt;
&lt;p&gt;是的，一句话，总是在提供解决问题的思路和方案的人才是有技术领导力的人。&lt;/p&gt;
&lt;p&gt;那么，作为一个软件工程师，我们怎么让自己拥有技术领导力呢？总体来说，是四个方面，具体如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;扎实的基础技术&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;非同一般的学习能力&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;坚持做正确的事&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;不断得高对自己的要求标准&lt;/strong&gt;；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;好了。今天要聊的内容就是这些，希望你能从中有所收获。而对于如何才能拥有技术领导力，你不妨结合我上面分享的四个点来思考一下，欢迎在留言区给出你的想法，下一篇文章，我也将会和你继续聊这个话题。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/fc/e9/fcc761001867c60f526665e237f831e9.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 05丨数组：为什么很多编程语言中数组都从0开始编号？</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/05%E4%B8%A8%E6%95%B0%E7%BB%84%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BE%88%E5%A4%9A%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E4%B8%AD%E6%95%B0%E7%BB%84%E9%83%BD%E4%BB%8E0%E5%BC%80%E5%A7%8B%E7%BC%96%E5%8F%B7/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/05%E4%B8%A8%E6%95%B0%E7%BB%84%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BE%88%E5%A4%9A%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E4%B8%AD%E6%95%B0%E7%BB%84%E9%83%BD%E4%BB%8E0%E5%BC%80%E5%A7%8B%E7%BC%96%E5%8F%B7/</guid>
      <description>
        
        
        &lt;p&gt;提到数组，我想你肯定不陌生，甚至还会自信地说，它很简单啊。&lt;/p&gt;
&lt;p&gt;是的，在每一种编程语言中，基本都会有数组这种数据类型。不过，它不仅仅是一种编程语言中的数据类型，还是一种最基础的数据结构。尽管数组看起来非常基础、简单，但是我估计很多人都并没有理解这个基础数据结构的精髓。&lt;/p&gt;
&lt;p&gt;在大部分编程语言中，数组都是从 0 开始编号的，但你是否下意识地想过，&lt;strong&gt;为什么数组要从 0 开始编号，而不是从 1 开始呢？&lt;/strong&gt; 从 1 开始不是更符合人类的思维习惯吗？&lt;/p&gt;
&lt;p&gt;你可以带着这个问题来学习接下来的内容。&lt;/p&gt;
&lt;h2 id=&#34;如何实现随机访问&#34;&gt;如何实现随机访问？&lt;/h2&gt;
&lt;p&gt;什么是数组？我估计你心中已经有了答案。不过，我还是想用专业的话来给你做下解释。&lt;strong&gt;数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这个定义里有几个关键词，理解了这几个关键词，我想你就能彻底掌握数组的概念了。下面就从我的角度分别给你&amp;quot;点拨&amp;quot;一下。&lt;/p&gt;
&lt;p&gt;第一是&lt;strong&gt;线性表&lt;/strong&gt;（Linear List）。顾名思义，线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。其实除了数组，链表、队列、栈等也是线性表结构。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/b6/77/b6b71ec46935130dff5c4b62cf273477.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;而与它相对立的概念是&lt;strong&gt;非线性表&lt;/strong&gt;，比如二叉树、堆、图等。之所以叫非线性，是因为，在非线性表中，数据之间并不是简单的前后关系。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/6e/69/6ebf42641b5f98f912d36f6bf86f6569.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;第二个是&lt;strong&gt;连续的内存空间和相同类型的数据&lt;/strong&gt;。正是因为这两个限制，它才有了一个堪称&amp;quot;杀手锏&amp;quot;的特性：&amp;ldquo;随机访问&amp;rdquo;。但有利就有弊，这两个限制也让数组的很多操作变得非常低效，比如要想在数组中删除、插入一个数据，为了保证连续性，就需要做大量的数据搬移工作。&lt;/p&gt;
&lt;p&gt;说到数据的访问，那你知道数组是如何实现根据下标随机访问数组元素的吗？&lt;/p&gt;
&lt;p&gt;我们拿一个长度为 10 的 int 类型的数组 int[] a = new int[10] 来举例。在我画的这个图中，计算机给数组 a[10]，分配了一块连续内存空间 1000～1039，其中，内存块的首地址为 base_address = 1000。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/98/c4/98df8e702b14096e7ee4a5141260cdc4.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;我们知道，计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问数组中的某个元素时，它会首先通过下面的寻址公式，计算出该元素存储的内存地址：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;a[i]_address = base_address + i * data_type_size
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中 data_type_size 表示数组中每个元素的大小。我们举的这个例子里，数组中存储的是 int 类型数据，所以 data_type_size 就为 4 个字节。这个公式非常简单，我就不多做解释了。&lt;/p&gt;
&lt;p&gt;这里我要特别纠正一个&amp;quot;错误&amp;quot;。我在面试的时候，常常会问数组和链表的区别，很多人都回答说，&amp;ldquo;链表适合插入、删除，时间复杂度 O(1)；数组适合查找，查找时间复杂度为 O(1)&amp;quot;。&lt;/p&gt;
&lt;p&gt;实际上，这种表述是不准确的。数组是适合查找操作，但是查找的时间复杂度并不为 O(1)。即便是排好序的数组，你用二分查找，时间复杂度也是 O(logn)。所以，正确的表述应该是，数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)。&lt;/p&gt;
&lt;h2 id=&#34;低效的插入和删除&#34;&gt;低效的&amp;quot;插入&amp;quot;和&amp;quot;删除&amp;rdquo;&lt;/h2&gt;
&lt;p&gt;前面概念部分我们提到，数组为了保持内存数据的连续性，会导致插入、删除这两个操作比较低效。现在我们就来详细说一下，究竟为什么会导致低效？又有哪些改进方法呢？&lt;/p&gt;
&lt;p&gt;我们先来看&lt;strong&gt;插入操作&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;假设数组的长度为 n，现在，如果我们需要将一个数据插入到数组中的第 k 个位置。为了把第 k 个位置腾出来，给新来的数据，我们需要将第 k～n 这部分的元素都顺序地往后挪一位。那插入操作的时间复杂度是多少呢？你可以自己先试着分析一下。&lt;/p&gt;
&lt;p&gt;如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为 O(1)。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是 O(n)。 因为我们在每个位置插入元素的概率是一样的，所以平均情况时间复杂度为 (1+2+&amp;hellip;n)/n=O(n)。&lt;/p&gt;
&lt;p&gt;如果数组中的数据是有序的，我们在某个位置插入一个新的元素时，就必须按照刚才的方法搬移 k 之后的数据。但是，如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数组插入到第 k 个位置，为了避免大规模的数据搬移，我们还有一个简单的办法就是，直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置。&lt;/p&gt;
&lt;p&gt;为了更好地理解，我们举一个例子。假设数组 a[10] 中存储了如下 5 个元素：a，b，c，d，e。&lt;/p&gt;
&lt;p&gt;我们现在需要将元素 x 插入到第 3 个位置。我们只需要将 c 放入到 a[5]，将 a[2] 赋值为 x 即可。最后，数组中的元素如下： a，b，x，d，e，c。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/3f/dc/3f70b4ad9069ec568a2caaddc231b7dc.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;利用这种处理技巧，在特定场景下，在第 k 个位置插入一个元素的时间复杂度就会降为 O(1)。这个处理思想在快排中也会用到，我会在排序那一节具体来讲，这里就说到这儿。&lt;/p&gt;
&lt;p&gt;我们再来看&lt;strong&gt;删除操作&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;跟插入数据类似，如果我们要删除第 k 个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了。&lt;/p&gt;
&lt;p&gt;和插入类似，如果删除数组末尾的数据，则最好情况时间复杂度为 O(1)；如果删除开头的数据，则最坏情况时间复杂度为 O(n)；平均情况时间复杂度也为 O(n)。&lt;/p&gt;
&lt;p&gt;实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。如果我们将多次删除操作集中在一起执行，删除的效率是不是会提高很多呢？&lt;/p&gt;
&lt;p&gt;我们继续来看例子。数组 a[10] 中存储了 8 个元素：a，b，c，d，e，f，g，h。现在，我们要依次删除 a，b，c 三个元素。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/b6/e5/b69b8c5dbf6248649ddab7d3e7cfd7e5.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;为了避免 d，e，f，g，h 这几个数据会被搬移三次，我们可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。&lt;/p&gt;
&lt;p&gt;如果你了解 JVM，你会发现，这不就是 JVM 标记清除垃圾回收算法的核心思想吗？没错，数据结构和算法的魅力就在于此，&lt;strong&gt;很多时候我们并不是要去死记硬背某个数据结构或者算法，而是要学习它背后的思想和处理技巧，这些东西才是最有价值的&lt;/strong&gt;。如果你细心留意，不管是在软件开发还是架构设计中，总能找到某些算法和数据结构的影子。&lt;/p&gt;
&lt;h2 id=&#34;警惕数组的访问越界问题&#34;&gt;警惕数组的访问越界问题&lt;/h2&gt;
&lt;p&gt;了解了数组的几个基本操作后，我们来聊聊数组访问越界的问题。&lt;/p&gt;
&lt;p&gt;首先，我请你来分析一下这段 C 语言代码的运行结果：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int main(int argc, char* argv[]){
    int i = 0;
    int arr[3] = {0};
    for(; i&amp;lt;=3; i++){
        arr[i] = 0;
        printf(&amp;quot;hello world\n&amp;quot;);
    }
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;你发现问题了吗？这段代码的运行结果并非是打印三行&amp;quot;hello word&amp;quot;，而是会无限打印&amp;quot;hello world&amp;quot;，这是为什么呢？&lt;/p&gt;
&lt;p&gt;因为，数组大小为 3，a[0]，a[1]，a[2]，而我们的代码因为书写错误，导致 for 循环的结束条件错写为了 i&amp;lt;=3 而非 i&amp;lt;3，所以当 i=3 时，数组 a[3] 访问越界。&lt;/p&gt;
&lt;p&gt;我们知道，在 C 语言中，只要不是访问受限的内存，所有的内存空间都是可以自由访问的。根据我们前面讲的数组寻址公式，a[3] 也会被定位到某块不属于数组的内存地址上，而这个地址正好是存储变量 i 的内存地址，那么 a[3]=0 就相当于 i=0，所以就会导致代码无限循环。&lt;/p&gt;
&lt;p&gt;数组越界在 C 语言中是一种未决行为，并没有规定数组访问越界时编译器应该如何处理。因为，访问数组的本质就是访问一段连续内存，只要数组通过偏移计算得到的内存地址是可用的，那么程序就可能不会报任何错误。&lt;/p&gt;
&lt;p&gt;这种情况下，一般都会出现莫名其妙的逻辑错误，就像我们刚刚举的那个例子，debug 的难度非常的大。而且，很多计算机病毒也正是利用到了代码中的数组越界可以访问非法地址的漏洞，来攻击系统，所以写代码的时候一定要警惕数组越界。&lt;/p&gt;
&lt;p&gt;但并非所有的语言都像 C 一样，把数组越界检查的工作丢给程序员来做，像 Java 本身就会做越界检查，比如下面这几行 Java 代码，就会抛出 java.lang.ArrayIndexOutOfBoundsException。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int[] a = new int[3];
a[3] = 10;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;容器能否完全替代数组&#34;&gt;容器能否完全替代数组？&lt;/h2&gt;
&lt;p&gt;针对数组类型，很多语言都提供了容器类，比如 Java 中的 ArrayList、C++ STL 中的 vector。在项目开发中，什么时候适合用数组，什么时候适合用容器呢？&lt;/p&gt;
&lt;p&gt;这里我拿 Java 语言来举例。如果你是 Java 工程师，几乎天天都在用 ArrayList，对它应该非常熟悉。那它与数组相比，到底有哪些优势呢？&lt;/p&gt;
&lt;p&gt;我个人觉得，ArrayList 最大的优势就是&lt;strong&gt;可以将很多数组操作的细节封装起来&lt;/strong&gt; 。比如前面提到的数组插入、删除数据时需要搬移其他数据等。另外，它还有一个优势，就是&lt;strong&gt;支持动态扩容&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;数组本身在定义的时候需要预先指定大小，因为需要分配连续的内存空间。如果我们申请了大小为 10 的数组，当第 11 个数据需要存储到数组中时，我们就需要重新分配一块更大的空间，将原来的数据复制过去，然后再将新的数据插入。&lt;/p&gt;
&lt;p&gt;如果使用 ArrayList，我们就完全不需要关心底层的扩容逻辑，ArrayList 已经帮我们实现好了。每次存储空间不够的时候，它都会将空间自动扩容为 1.5 倍大小。&lt;/p&gt;
&lt;p&gt;不过，这里需要注意一点，因为扩容操作涉及内存申请和数据搬移，是比较耗时的。所以，如果事先能确定需要存储的数据大小，最好&lt;strong&gt;在创建 ArrayList 的时候事先指定数据大小&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;比如我们要从数据库中取出 10000 条数据放入 ArrayList。我们看下面这几行代码，你会发现，相比之下，事先指定数据大小可以省掉很多次内存申请和数据搬移操作。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ArrayList&amp;lt;User&amp;gt; users = new ArrayList(10000);
for (int i = 0; i &amp;lt; 10000; ++i) {
  users.add(xxx);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;作为高级语言编程者，是不是数组就无用武之地了呢？当然不是，有些时候，用数组会更合适些，我总结了几点自己的经验。&lt;/p&gt;
&lt;p&gt;1.Java ArrayList 无法存储基本类型，比如 int、long，需要封装为 Integer、Long 类，而 Autoboxing、Unboxing 则有一定的性能消耗，所以如果特别关注性能，或者希望使用基本类型，就可以选用数组。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;
&lt;p&gt;如果数据大小事先已知，并且对数据的操作非常简单，用不到 ArrayList 提供的大部分方法，也可以直接使用数组。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;还有一个是我个人的喜好，当要表示多维数组时，用数组往往会更加直观。比如 Object[][] array；而用容器的话则需要这样定义：ArrayList&amp;lt;ArrayList &amp;gt; array。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;br /&gt;
&lt;p&gt;我总结一下，对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。但如果你是做一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为首选。&lt;/p&gt;
&lt;h2 id=&#34;解答开篇&#34;&gt;解答开篇&lt;/h2&gt;
&lt;p&gt;现在我们来思考开篇的问题：为什么大多数编程语言中，数组要从 0 开始编号，而不是从 1 开始呢？&lt;/p&gt;
&lt;p&gt;从数组存储的内存模型上来看，&amp;ldquo;下标&amp;quot;最确切的定义应该是&amp;quot;偏移（offset）&amp;quot;。前面也讲到，如果用 a 来表示数组的首地址，a[0] 就是偏移为 0 的位置，也就是首地址，a[k] 就表示偏移 k 个 type_size 的位置，所以计算 a[k] 的内存地址只需要用这个公式：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;a[k]_address = base_address + k * type_size
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;但是，如果数组从 1 开始计数，那我们计算数组元素 a[k] 的内存地址就会变为：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;a[k]_address = base_address + (k-1)*type_size
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;对比两个公式，我们不难发现，从 1 开始编号，每次随机访问数组元素都多了一次减法运算，对于 CPU 来说，就是多了一次减法指令。&lt;/p&gt;
&lt;p&gt;数组作为非常基础的数据结构，通过下标随机访问数组元素又是其非常基础的编程操作，效率的优化就要尽可能做到极致。所以为了减少一次减法操作，数组选择了从 0 开始编号，而不是从 1 开始。&lt;/p&gt;
&lt;p&gt;不过我认为，上面解释得再多其实都算不上压倒性的证明，说数组起始编号非 0 开始不可。所以我觉得最主要的原因可能是历史原因。&lt;/p&gt;
&lt;p&gt;C 语言设计者用 0 开始计数数组下标，之后的 Java、JavaScript 等高级语言都效仿了 C 语言，或者说，为了在一定程度上减少 C 语言程序员学习 Java 的学习成本，因此继续沿用了从 0 开始计数的习惯。实际上，很多语言中数组也并不是从 0 开始计数的，比如 Matlab。甚至还有一些语言支持负数下标，比如 Python。&lt;/p&gt;
&lt;h2 id=&#34;内容小结&#34;&gt;内容小结&lt;/h2&gt;
&lt;p&gt;我们今天学习了数组。它可以说是最基础、最简单的数据结构了。数组用一块连续的内存空间，来存储相同类型的一组数据，最大的特点就是支持随机访问，但插入、删除操作也因此变得比较低效，平均情况时间复杂度为 O(n)。在平时的业务开发中，我们可以直接使用编程语言提供的容器类，但是，如果是特别底层的开发，直接使用数组可能会更合适。&lt;/p&gt;
&lt;h2 id=&#34;课后思考&#34;&gt;课后思考&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;前面我基于数组的原理引出 JVM 的标记清除垃圾回收算法的核心理念。我不知道你是否使用 Java 语言，理解 JVM，如果你熟悉，可以在评论区回顾下你理解的标记清除垃圾回收算法。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;前面我们讲到一维数组的内存寻址公式，那你可以思考一下，类比一下，二维数组的内存寻址公式是怎样的呢？&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;欢迎留言和我分享，我会第一时间给你反馈。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;我已将本节内容相关的详细代码更新到 GitHub，&lt;a href=&#34;https://github.com/wangzheng0822/algo&#34;&gt;戳此&lt;/a&gt;即可查看。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/8e/d3/8e603e3d795fc0ab2698f6f5eabf14d3.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 05丨深入浅出索引（下）</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/05%E4%B8%A8%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%B4%A2%E5%BC%95%E4%B8%8B/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/05%E4%B8%A8%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%B4%A2%E5%BC%95%E4%B8%8B/</guid>
      <description>
        
        
        &lt;p&gt;在上一篇文章中，我和你介绍了 InnoDB 索引的数据结构模型，今天我们再继续聊聊跟 MySQL 索引有关的概念。&lt;/p&gt;
&lt;p&gt;在开始这篇文章之前，我们先来看一下这个问题：&lt;/p&gt;
&lt;p&gt;在下面这个表 T 中，如果我执行 select * from T where k between 3 and 5，需要执行几次树的搜索操作，会扫描多少行？&lt;/p&gt;
&lt;p&gt;下面是这个表的初始化语句。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; create table T (
ID int primary key,
k int NOT NULL DEFAULT 0, 
s varchar(16) NOT NULL DEFAULT &#39;&#39;,
index k(k))
engine=InnoDB;
 
insert into T values(100,1, &#39;aa&#39;),(200,2,&#39;bb&#39;),(300,3,&#39;cc&#39;),(500,5,&#39;ee&#39;),(600,6,&#39;ff&#39;),(700,7,&#39;gg&#39;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/dc/8d/dcda101051f28502bd5c4402b292e38d.png&#34; alt=&#34;&#34;&gt;
图 1 InnoDB 的索引组织结构&lt;/p&gt;
&lt;p&gt;现在，我们一起来看看这条 SQL 查询语句的执行流程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;在 k 索引树上找到 k=3 的记录，取得 ID = 300；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;再到 ID 索引树查到 ID=300 对应的 R3；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在 k 索引树取下一个值 k=5，取得 ID=500；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;再回到 ID 索引树查到 ID=500 对应的 R4；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在 k 索引树取下一个值 k=6，不满足条件，循环结束。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在这个过程中，&lt;strong&gt;回到主键索引树搜索的过程，我们称为回表&lt;/strong&gt;。可以看到，这个查询过程读了 k 索引树的 3 条记录（步骤 1、3 和 5），回表了两次（步骤 2 和 4）。&lt;/p&gt;
&lt;p&gt;在这个例子中，由于查询结果所需要的数据只在主键索引上有，所以不得不回表。那么，有没有可能经过索引优化，避免回表过程呢？&lt;/p&gt;
&lt;h1 id=&#34;覆盖索引&#34;&gt;覆盖索引&lt;/h1&gt;
&lt;p&gt;如果执行的语句是 select ID from T where k between 3 and 5，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经&amp;quot;覆盖了&amp;quot;我们的查询需求，我们称为覆盖索引。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;需要注意的是，在引擎内部使用覆盖索引在索引 k 上其实读了三个记录，R3~R5（对应的索引 k 上的记录项），但是对于 MySQL 的 Server 层来说，它就是找引擎拿到了两条记录，因此 MySQL 认为扫描行数是 2。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;备注：关于如何查看扫描行数的问题，我将会在第 16 文章《如何正确地显示随机消息？》中，和你详细讨论。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;基于上面覆盖索引的说明，我们来讨论一个问题：&lt;strong&gt;在一个市民信息表上，是否有必要将身份证号和名字建立联合索引？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;假设这个市民表的定义是这样的：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE TABLE `tuser` (
  `id` int(11) NOT NULL,
  `id_card` varchar(32) DEFAULT NULL,
  `name` varchar(32) DEFAULT NULL,
  `age` int(11) DEFAULT NULL,
  `ismale` tinyint(1) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `id_card` (`id_card`),
  KEY `name_age` (`name`,`age`)
) ENGINE=InnoDB
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们知道，身份证号是市民的唯一标识。也就是说，如果有根据身份证号查询市民信息的需求，我们只要在身份证号字段上建立索引就够了。而再建立一个（身份证号、姓名）的联合索引，是不是浪费空间？&lt;/p&gt;
&lt;p&gt;如果现在有一个高频请求，要根据市民的身份证号查询他的姓名，这个联合索引就有意义了。它可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录，减少语句的执行时间。&lt;/p&gt;
&lt;p&gt;当然，索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。这正是业务 DBA，或者称为业务数据架构师的工作。&lt;/p&gt;
&lt;h1 id=&#34;最左前缀原则&#34;&gt;最左前缀原则&lt;/h1&gt;
&lt;p&gt;看到这里你一定有一个疑问，如果为每一种查询都设计一个索引，索引是不是太多了。如果我现在要按照市民的身份证号去查他的家庭地址呢？虽然这个查询需求在业务中出现的概率不高，但总不能让它走全表扫描吧？反过来说，单独为一个不频繁的请求创建一个（身份证号，地址）的索引又感觉有点浪费。应该怎么做呢？&lt;/p&gt;
&lt;p&gt;这里，我先和你说结论吧。&lt;strong&gt;B+ 树这种索引结构，可以利用索引的&amp;quot;最左前缀&amp;quot;，来定位记录。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;为了直观地说明这个概念，我们用（name，age）这个联合索引来分析。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/89/70/89f74c631110cfbc83298ef27dcd6370.jpg&#34; alt=&#34;&#34;&gt;
图 2 （name，age）索引示意图&lt;/p&gt;
&lt;p&gt;可以看到，索引项是按照索引定义里面出现的字段顺序排序的。&lt;/p&gt;
&lt;p&gt;当你的逻辑需求是查到所有名字是&amp;quot;张三&amp;quot;的人时，可以快速定位到 ID4，然后向后遍历得到所有需要的结果。&lt;/p&gt;
&lt;p&gt;如果你要查的是所有名字第一个字是&amp;quot;张&amp;quot;的人，你的 SQL 语句的条件是&amp;quot;where name like &amp;lsquo;张 %&amp;rsquo;&amp;quot;。这时，你也能够用上这个索引，查找到第一个符合条件的记录是 ID3，然后向后遍历，直到不满足条件为止。&lt;/p&gt;
&lt;p&gt;可以看到，不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。&lt;/p&gt;
&lt;p&gt;基于上面对最左前缀索引的说明，我们来讨论一个问题：&lt;strong&gt;在建立联合索引的时候，如何安排索引内的字段顺序。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这里我们的评估标准是，索引的复用能力。因为可以支持最左前缀，所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。因此，&lt;strong&gt;第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所以现在你知道了，这段开头的问题里，我们要为高频请求创建 (身份证号，姓名）这个联合索引，并用这个索引支持&amp;quot;根据身份证号查询地址&amp;quot;的需求。&lt;/p&gt;
&lt;p&gt;那么，如果既有联合查询，又有基于 a、b 各自的查询呢？查询条件里面只有 b 的语句，是无法使用 (a,b) 这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护 (a,b)、(b) 这两个索引。&lt;/p&gt;
&lt;p&gt;这时候，我们要&lt;strong&gt;考虑的原则就是空间&lt;/strong&gt;了。比如上面这个市民表的情况，name 字段是比 age 字段大的 ，那我就建议你创建一个（name,age) 的联合索引和一个 (age) 的单字段索引。&lt;/p&gt;
&lt;h1 id=&#34;索引下推&#34;&gt;索引下推&lt;/h1&gt;
&lt;p&gt;上一段我们说到满足最左前缀原则的时候，最左前缀可以用于在索引中定位记录。这时，你可能要问，那些不符合最左前缀的部分，会怎么样呢？&lt;/p&gt;
&lt;p&gt;我们还是以市民表的联合索引（name, age）为例。如果现在有一个需求：检索出表中&amp;quot;名字第一个字是张，而且年龄是 10 岁的所有男孩&amp;quot;。那么，SQL 语句是这么写的：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; select * from tuser where name like &#39;张 %&#39; and age=10 and ismale=1;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;你已经知道了前缀索引规则，所以这个语句在搜索索引树的时候，只能用 &amp;ldquo;张&amp;rdquo;，找到第一个满足条件的记录 ID3。当然，这还不错，总比全表扫描要好。&lt;/p&gt;
&lt;p&gt;然后呢？&lt;/p&gt;
&lt;p&gt;当然是判断其他条件是否满足。&lt;/p&gt;
&lt;p&gt;在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。&lt;/p&gt;
&lt;p&gt;而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。&lt;/p&gt;
&lt;p&gt;图 3 和图 4，是这两个过程的执行流程图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/b3/ac/b32aa8b1f75611e0759e52f5915539ac.jpg&#34; alt=&#34;&#34;&gt;
图 3 无索引下推执行流程&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/76/1b/76e385f3df5a694cc4238c7b65acfe1b.jpg&#34; alt=&#34;&#34;&gt;
图 4 索引下推执行流程&lt;/p&gt;
&lt;p&gt;在图 3 和 4 这两个图里面，每一个虚线箭头表示回表一次。&lt;/p&gt;
&lt;p&gt;图 3 中，在 (name,age) 索引里面我特意去掉了 age 的值，这个过程 InnoDB 并不会去看 age 的值，只是按顺序把&amp;quot;name 第一个字是&amp;rsquo;张&amp;rsquo;&amp;ldquo;的记录一条条取出来回表。因此，需要回表 4 次。&lt;/p&gt;
&lt;p&gt;图 4 跟图 3 的区别是，InnoDB 在 (name,age) 索引内部就判断了 age 是否等于 10，对于不等于 10 的记录，直接判断并跳过。在我们的这个例子中，只需要对 ID4、ID5 这两条记录回表取数据判断，就只需要回表 2 次。&lt;/p&gt;
&lt;h1 id=&#34;小结&#34;&gt;小结&lt;/h1&gt;
&lt;p&gt;今天这篇文章，我和你继续讨论了数据库索引的概念，包括了覆盖索引、前缀索引、索引下推。你可以看到，在满足语句需求的情况下， 尽量少地访问资源是数据库设计的重要原则之一。我们在使用数据库的时候，尤其是在设计表结构时，也要以减少资源消耗作为目标。&lt;/p&gt;
&lt;p&gt;接下来我给你留下一个问题吧。&lt;/p&gt;
&lt;p&gt;实际上主键索引也是可以使用多个字段的。DBA 小吕在入职新公司的时候，就发现自己接手维护的库里面，有这么一个表，表结构定义类似这样的：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE TABLE `geek` (
  `a` int(11) NOT NULL,
  `b` int(11) NOT NULL,
  `c` int(11) NOT NULL,
  `d` int(11) NOT NULL,
  PRIMARY KEY (`a`,`b`),
  KEY `c` (`c`),
  KEY `ca` (`c`,`a`),
  KEY `cb` (`c`,`b`)
) ENGINE=InnoDB;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;公司的同事告诉他说，由于历史原因，这个表需要 a、b 做联合主键，这个小吕理解了。&lt;/p&gt;
&lt;p&gt;但是，学过本章内容的小吕又纳闷了，既然主键包含了 a、b 这两个字段，那意味着单独在字段 c 上创建一个索引，就已经包含了三个字段了呀，为什么要创建&amp;quot;ca&amp;quot;&amp;ldquo;cb&amp;quot;这两个索引？&lt;/p&gt;
&lt;p&gt;同事告诉他，是因为他们的业务里面有这样的两种语句：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select * from geek where c=N order by a limit 1;
select * from geek where c=N order by b limit 1;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我给你的问题是，这位同事的解释对吗，为了这两个查询模式，这两个索引是否都是必须的？为什么呢？&lt;/p&gt;
&lt;p&gt;你可以把你的思考和观点写在留言区里，我会在下一篇文章的末尾和你讨论这个问题。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。&lt;/p&gt;
&lt;h1 id=&#34;上期问题时间&#34;&gt;上期问题时间&lt;/h1&gt;
&lt;p&gt;上期的问题是，通过两个 alter 语句重建索引 k，以及通过两个 alter 语句重建主键索引是否合理。&lt;/p&gt;
&lt;p&gt;在评论区，有同学问到为什么要重建索引。我们文章里面有提到，索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间。&lt;/p&gt;
&lt;p&gt;这道题目，我给你的&amp;quot;参考答案&amp;quot;是：&lt;/p&gt;
&lt;p&gt;重建索引 k 的做法是合理的，可以达到省空间的目的。但是，重建主键的过程不合理。不论是删除主键还是创建主键，都会将整个表重建。所以连着执行这两个语句的话，第一个语句就白做了。这两个语句，你可以用这个语句代替 ： alter table T engine=InnoDB。在专栏的第 12 篇文章《为什么表数据删掉一半，表文件大小不变？》中，我会和你分析这条语句的执行流程。&lt;/p&gt;
&lt;p&gt;评论区留言中， @壹笙☞漂泊 做了很详细的笔记，@高枕 帮同学解答了问题，@约书亚 提了一个很不错的面试问题。在这里，我要和你们道一声感谢。&lt;/p&gt;
&lt;p&gt;PS：如果你在面试中，曾有过被 MySQL 相关问题难住的经历，也可以把这个问题发到评论区，我们一起来讨论。如果解答这个问题，需要的篇幅会很长的话，我可以放到答疑文章展开。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/ce/d9/ce7f4e35916ed1aa49206a53a0547bd9.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 05丨牛刀小试：如何搭建优惠券模板服务？</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/springclouod%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/05%E4%B8%A8%E7%89%9B%E5%88%80%E5%B0%8F%E8%AF%95%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E4%BC%98%E6%83%A0%E5%88%B8%E6%A8%A1%E6%9D%BF%E6%9C%8D%E5%8A%A1/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/springclouod%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/05%E4%B8%A8%E7%89%9B%E5%88%80%E5%B0%8F%E8%AF%95%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E4%BC%98%E6%83%A0%E5%88%B8%E6%A8%A1%E6%9D%BF%E6%9C%8D%E5%8A%A1/</guid>
      <description>
        
        
        &lt;p&gt;你好，我是姚秋辰。&lt;/p&gt;
&lt;p&gt;今天我们来动手搭建优惠券平台的实战项目。为了让你体验从 0 到 1 的微服务改造过程，我们先使用 Spring Boot 搭建一个基础版的优惠券平台项目，等你学习到 Spring Cloud 的时候，我们就在这个项目之上做微服务化改造，将 Spring Cloud 的各个组件像添砖加瓦一样集成到项目里。&lt;/p&gt;
&lt;p&gt;如果你没有太多 Spring Boot 的相关开发经验，通过今天的学习，你可以掌握如何通过 Spring Boot 组件快速落地一个项目。如果你之前了解过 Spring Boot，那么今天的学习不仅可以起到温故知新的作用，你还可以从我分享的开发经验里得到一些启发。&lt;/p&gt;
&lt;p&gt;在03 讲中，我们介绍了优惠券平台的功能模块。我们说过，在用户领取优惠券的过程当中，优惠券是通过券模板来生成的，因此，优惠券模板服务是整个项目的底层基础服务。今天咱就直接上手搭建这个服务模块：coupon-template-serv。不过在此之前，我们先来看看整体的项目结构是怎样搭建的。&lt;/p&gt;
&lt;h1 id=&#34;搭建项目结构&#34;&gt;搭建项目结构&lt;/h1&gt;
&lt;p&gt;我把整个优惠券平台项目从 Maven 模块管理的角度划分为了多个模块。&lt;br&gt;
&lt;img src=&#34;https://static001.geekbang.org/resource/image/30/b1/302c801d2a82e863a75af3b803ae2db1.jpg?wh=2000x1173&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;在顶层项目 geekbang-coupon 之下有四个子模块，我先来分别解释下它们的功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;coupon-template-serv&lt;/strong&gt;： 创建、查找、克隆、删除优惠券模板；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;coupon-calculation-serv&lt;/strong&gt;：计算优惠后的订单价格、试算每个优惠券的优惠幅度；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;coupon-customer-serv&lt;/strong&gt;：通过调用 template 和 calculation 服务，实现用户领取优惠券、模拟计算最优惠的券、删除优惠券、下订单等操作；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;middleware&lt;/strong&gt;：存放一些与业务无关的平台类组件。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在大型的微服务项目里，每一个子模块通常都存放在独立的 Git 仓库中，为了方便你下载代码，我把所有模块的代码都打包放到了这个代码仓库里，你可以在这里找到课程各阶段对应的源代码。&lt;/p&gt;
&lt;p&gt;在每一个以&amp;quot;-serv&amp;quot;结尾的业务子模块中，我从内部分层的角度对其做了进一步拆分，以我们今天要搭建的 coupon-template-serv 为例，它内部包含了三个子模块：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;coupon-template-api&lt;/strong&gt;：存放公共 POJO 类或者对外接口的子模块；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;coupon-template-dao&lt;/strong&gt;：存放数据库实体类和 Dao 层的子模块；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;coupon-template-impl&lt;/strong&gt;：核心业务逻辑的实现层，对外提供 REST API。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你会发现，我把 coupon-template-api 作为一个单独的模块，这样做的好处是：&lt;strong&gt;当某个上游服务需要获取 coupon-template-serv 的接口参数时，只要导入轻量级的 coupon-template-api 模块，就能够获取接口中定义的 Request 和 Response 的类模板，不需要引入多余的依赖项（比如 Dao 层或者 Service 层）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;这就是开闭原则的应用，它使各个模块间的职责和边界划分更加清晰，降低耦合的同时也更加利于依赖管理。&lt;/p&gt;
&lt;p&gt;搭建好项目的结构之后，接下来我们借助 Maven 工具将需要的依赖包导入到项目中。&lt;/p&gt;
&lt;h1 id=&#34;添加-maven-依赖项&#34;&gt;添加 Maven 依赖项&lt;/h1&gt;
&lt;p&gt;这里你要注意一下，添加 Maven 依赖项需要遵循&amp;quot;从上到下&amp;quot;的原则，也就是从顶层项目 geekbang-coupon 开始，顺藤摸瓜直到 coupon-template-serv 下的子模块。首先，我们来看看顶层 geekbang-coupon 依赖项的编写。&lt;/p&gt;
&lt;h1 id=&#34;编写-geekbang-coupon-依赖项&#34;&gt;编写 geekbang-coupon 依赖项&lt;/h1&gt;
&lt;p&gt;geekbang-coupon 是整个实战项目的顶层项目，它不用操心具体的业务逻辑，只用完成一个任务：管理子模块和定义 Maven 依赖项的版本。这就像一个公司的大 boss 一样，只用制定方向战略，琐碎的业务就交给下面人（子模块）来办就好了。&lt;/p&gt;
&lt;p&gt;那么顶层战略在哪里制定？其实就在 pom.xml 文件里，我们看一下 geekbang-coupon 的 pom 文件中都定义了哪些内容。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;lt;!-- 已省略部分标签，完整内容请参考项目源代码 --&amp;gt;
&amp;lt;parent&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-boot-starter-parent&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;2.4.2&amp;lt;/version&amp;gt;
&amp;lt;/parent&amp;gt;
&amp;lt;groupId&amp;gt;com.geekbang&amp;lt;/groupId&amp;gt;
&amp;lt;artifactId&amp;gt;geekbang-coupon&amp;lt;/artifactId&amp;gt;
&amp;lt;packaging&amp;gt;pom&amp;lt;/packaging&amp;gt;
&amp;lt;version&amp;gt;1.0-SNAPSHOT&amp;lt;/version&amp;gt;
&amp;lt;modules&amp;gt;
    &amp;lt;module&amp;gt;coupon-template-serv&amp;lt;/module&amp;gt;
    &amp;lt;module&amp;gt;coupon-calculation-serv&amp;lt;/module&amp;gt;
    &amp;lt;module&amp;gt;coupon-customer-serv&amp;lt;/module&amp;gt;
    &amp;lt;module&amp;gt;middleware&amp;lt;/module&amp;gt;
&amp;lt;/modules&amp;gt;
&amp;lt;dependencyManagement&amp;gt;
    &amp;lt;dependencies&amp;gt;
       &amp;lt;dependency&amp;gt;
          &amp;lt;groupId&amp;gt;org.apache.commons&amp;lt;/groupId&amp;gt;
          &amp;lt;artifactId&amp;gt;commons-lang3&amp;lt;/artifactId&amp;gt;
          &amp;lt;version&amp;gt;3.0&amp;lt;/version&amp;gt;
       &amp;lt;/dependency&amp;gt;
    &amp;lt;!-- 省略部分依赖项 --&amp;gt;
    &amp;lt;/dependencies&amp;gt;
&amp;lt;/dependencyManagement&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在 pom 文件里有以下三个重点标签。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&amp;lt; parent &amp;gt; 标签&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在 parent 标签中我们指定了 geekbang-coupon 项目的&amp;quot;父级依赖&amp;quot;为 spring-boot-starter-parent，这样一来，spring-boot-starter-parent 里定义的 Spring Boot 组件版本信息就会被自动带到子模块中。这种做法也是大多数 Spring Boot 项目的通用做法，不仅降低了依赖项管理的成本，也不需要担心各个组件间的兼容性问题。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&amp;lt; packaging &amp;gt; 标签&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;maven 的打包类型有三种：jar、war 和 pom。当我们指定 packaging 类型为 pom 时，意味着当前模块是一个&amp;quot;boss&amp;quot;，它只用关注顶层战略，即定义依赖项版本和整合子模块，不包含具体的业务实现。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&amp;lt; dependencymanagement &amp;gt; 标签&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;这个标签的作用和 &amp;lt; parent &amp;gt; 标签类似，两者都是将版本信息向下传递&lt;/strong&gt;。dependencymanagement 是 boss 们定义顶层战略的地方，我们可以在这里定义各个依赖项的版本，当子项目需要引入这些依赖项的时候，只用指定 groupId 和 artifactId 即可，不用管 version 里该写哪个版本。&lt;/p&gt;
&lt;p&gt;完成了 geekbang-coupon 依赖项的编写，接下来我们看看 coupon-template-serv 依赖项的编写。&lt;/p&gt;
&lt;h1 id=&#34;编写-coupon-template-serv-依赖项&#34;&gt;编写 coupon-template-serv 依赖项&lt;/h1&gt;
&lt;p&gt;coupon-template-serv 是大 boss 下面的一个小头目，和 geekbang-coupon 一样，它的 packaging 类型也是 pom。我们说过 boss 只用管顶层战略，因此 coupon-temolate-serv 的 pom 文件内容很简单，只是定义了父级项目和子模块。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;lt;!-- 已省略部分标签，完整内容请参考项目源代码 --&amp;gt;
&amp;lt;parent&amp;gt;
    &amp;lt;artifactId&amp;gt;geekbang-coupon&amp;lt;/artifactId&amp;gt;
    &amp;lt;groupId&amp;gt;com.geekbang&amp;lt;/groupId&amp;gt;
    &amp;lt;version&amp;gt;1.0-SNAPSHOT&amp;lt;/version&amp;gt;
    &amp;lt;relativePath&amp;gt;../pom.xml&amp;lt;/relativePath&amp;gt;
&amp;lt;/parent&amp;gt;
&amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt;
&amp;lt;artifactId&amp;gt;coupon-template-serv&amp;lt;/artifactId&amp;gt;
&amp;lt;packaging&amp;gt;pom&amp;lt;/packaging&amp;gt;
&amp;lt;modules&amp;gt;
    &amp;lt;module&amp;gt;coupon-template-api&amp;lt;/module&amp;gt;
    &amp;lt;module&amp;gt;coupon-template-dao&amp;lt;/module&amp;gt;
    &amp;lt;module&amp;gt;coupon-template-impl&amp;lt;/module&amp;gt;
&amp;lt;/modules&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;我们已经把 geekbang-coupon 和 coupon-template-serv 两个父级项目的依赖项添加完毕，接下来就去搭建 coupon-template-serv 下面的三个子模块。&lt;/p&gt;
&lt;p&gt;coupon-template-api 模块存放了接口 Request 和 Response 的类模板，是另两个子模块需要依赖的公共类库，所以我就先从 coupon-template-api 开始项目构建。&lt;/p&gt;
&lt;h1 id=&#34;搭建-coupon-template-api-模块&#34;&gt;搭建 coupon-template-api 模块&lt;/h1&gt;
&lt;p&gt;coupon-template-api 模块是专门用来存放公共类的仓库，我把 REST API 接口的服务请求和服务返回对象的 POJO 类放到了里面。在微服务领域，将外部依赖的 POJO 类或者 API 接口层单独打包是一种通用做法，这样就可以给外部依赖方提供一个&amp;quot;干净&amp;quot;（不包含非必要依赖）的接口包，为远程服务调用（RPC）提供支持。&lt;/p&gt;
&lt;p&gt;在 coupon-template-api 项目的 pom 文件中，我只添加了少量的&amp;quot;工具类&amp;quot;依赖，比如 lombok、guava 和 validation-api 包等通用组件，这些工具类用来帮助我们自动生成代码并提供一些便捷的功能特性，具体的依赖项你可以参考项目源码。&lt;/p&gt;
&lt;p&gt;首先，我们需要定义一个用来表示优惠券类型的 enum 对象，在 com.geekbang.coupon.template.api.enum 包下创建一个名为 CouponType 的枚举类。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;@Getter
@AllArgsConstructor
public enum CouponType {
    UNKNOWN(&amp;#34;unknown&amp;#34;, &amp;#34;0&amp;#34;),
    MONEY_OFF(&amp;#34;满减券&amp;#34;, &amp;#34;1&amp;#34;),
    DISCOUNT(&amp;#34;打折&amp;#34;, &amp;#34;2&amp;#34;),
    RANDOM_DISCOUNT(&amp;#34;随机减&amp;#34;, &amp;#34;3&amp;#34;)
    LONELY_NIGHT_MONEY_OFF(&amp;#34;晚间双倍优惠券&amp;#34;, &amp;#34;4&amp;#34;);
    
    private String description;
    // 存在数据库里的最终code
    private String code;
    
    public static CouponType convert(String code) {
        return Stream.of(values())
                .filter(bean -&amp;gt; bean.code.equalsIgnoreCase(code))
                .findFirst()
                .orElse(UNKNOWN);
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;CouponType 类定义了多个不同类型的优惠券，convert 方法可以根据优惠券的编码返回对应的枚举对象。这里还有一个&amp;quot;Unknown&amp;quot;类型的券，它专门用来对付故意输错 code 的恶意请求。&lt;/p&gt;
&lt;p&gt;作为一个骨灰级程序员，我会认为所有需要用户输入的信息都是不可靠的，并且需要对各种意外输入做拦截、防范，这就是&amp;quot;&lt;strong&gt;防御性编程&lt;/strong&gt;&amp;ldquo;的思维。工作的时间越久，人往往会变得越怂（都是被各种故障吓大的）。&lt;/p&gt;
&lt;p&gt;接下来，我们创建两个用来定义优惠券模板规则的类，分别是 TemplateRule 和 Discount。我把它们放在 com.geekbang.coupon.template.api.beans.rules 包路径下。&lt;/p&gt;
&lt;p&gt;TemplateRule 包含了两个规则，一是领券规则，包括每个用户可领取的数量和券模板的过期时间；二是券模板的计算规则。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;@Data
@NoArgsConstructor
@AllArgsConstructor
public class TemplateRule {


    // 可以享受的折扣
    private Discount discount;
    
    // 每个人最多可以领券数量
    private Integer limitation;
    
    // 过期时间
    private Long deadline;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里我强烈推荐你&lt;strong&gt;使用一键三连的 lombok 注解自动生成基础代码&lt;/strong&gt;，它们分别是 Data、NoArgsConstructor 和 AllArgsConstructor。其中，Data 注解自动生成 getter、setter、toString 等方法，后两个注解分别生成无参构造器和全参构造器，省时省力省地盘。&lt;/p&gt;
&lt;p&gt;TemplateRule 中的 Discount 成员变量定义了使用优惠券的规则，代码如下。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;public class Discount {


    // 对于满减券 - quota是减掉的钱数，单位是分
    // 对于打折券 - quota是折扣(以100表示原价)，90就是打9折,  95就是95折
    // 对于随机立减券 - quota是最高的随机立减额
    // 对于晚间特别优惠券 - quota是日间优惠额，晚间优惠翻倍
    private Long quota;


    // 订单最低要达到多少钱才能用优惠券，单位为分
    private Long threshold;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;从上面代码中可以看出，我使用 Long 来表示&amp;quot;金额&amp;rdquo;。对于境内电商行业来说，金额往往是以分为单位的，这样我们可以直接使用 Long 类型参与金额的计算，比如 100 就代表 100 分，也就是一块钱。这比使用 Double 到处转换 BigDecimal 省了很多事儿。&lt;/p&gt;
&lt;p&gt;最后，我们在 com.geekbang.coupon.template.api.beans 包下创建一个名为 CouponTemplateInfo 的类，用来创建优惠券模板，代码如下：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;// 已省略部分内容，完整内容请参考项目源代码
public class CouponTemplateInfo {
    private Long id;
    @NotNull
    private String name; // 优惠券名称
    @NotNull
    private String desc; // 优惠券描述
    
    @NotNull
    private String type;  // 优惠券类型(引用CouponType里的code)
    
    private Long shopId; // 优惠券适用门店 - 若无则为全店通用券
   
    @NotNull
    private TemplateRule rule; // 优惠券使用规则
    
    private Boolean available; // 当前模板是否为可用状态
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在上面的代码中，我们应用了 jakarta.validate-api 组件的注解 @NotNull，对参数是否为 Null 进行了校验。如果请求参数为空，那么接口会自动返回 Bad Request 异常。当然，jakarta 组件还有很多可以用来做判定验证的注解，合理使用可以节省大量编码工作，提高代码可读性。&lt;/p&gt;
&lt;p&gt;此外，你还会发现，CouponTemplateInfo 内封装了优惠券模板的基本信息，我们可以把优惠券模板当做一个&amp;quot;模具&amp;quot;，每一张优惠券都经由模具来制造，被制造出来的优惠券则使用 CouponInfo 对象来封装。&lt;/p&gt;
&lt;p&gt;CouponInfo 对象包含了优惠券的模板信息、领券用户 ID、适用门店 ID 等属性。除此之外，我还在源码中定义了用来实现分页查找的对象，如果你特别感兴趣，可以到项目源码中查看完整的类定义。&lt;/p&gt;
&lt;p&gt;到这里我们就完成了 coupon-template-api 项目的搭建，下面我们开始搭建 Dao 层模块：coupon-template-dao。它主要负责和数据库的对接、读取。&lt;/p&gt;
&lt;h1 id=&#34;搭建-coupon-template-dao-模块&#34;&gt;搭建 coupon-template-dao 模块&lt;/h1&gt;
&lt;p&gt;首先，我们把必要的依赖项添加到 coupon-template-dao 项目中，比较关键的 maven 依赖项有以下几个。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;coupon-template-api:&lt;/strong&gt; 引入 api 包下的公共类；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;spring-boot-starter-data-jpa&lt;/strong&gt;: 添加 spring-data-jpa 的功能进行 CRUD 操作；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;mysql-connector-java&lt;/strong&gt;: 引入 mysql 驱动包，驱动版本尽量与 mysql 版本保持一致。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;接下来，我们在 com.geekbang.coupon.template.dao.entity 目录下创建了一个数据库实体对象的 Java 类：CouponTemplate。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;// 完整内容请参考源代码
@Entity
@Builder
@EntityListeners(AuditingEntityListener.class)
@Table(name = &amp;#34;coupon_template&amp;#34;)
public class CouponTemplate implements Serializable {


    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    @Column(name = &amp;#34;id&amp;#34;, nullable = false)
    private Long id;


    // 状态是否可用
    @Column(name = &amp;#34;available&amp;#34;, nullable = false)
    private Boolean available;


    @Column(name = &amp;#34;name&amp;#34;, nullable = false)
    private String name;


    @Column(name = &amp;#34;description&amp;#34;, nullable = false)
    private String description;


    // 适用门店-如果为空，则为全店满减券
    @Column(name = &amp;#34;shop_id&amp;#34;)
    private Long shopId;
    
    // 优惠券类型
    @Column(name = &amp;#34;type&amp;#34;, nullable = false)
    @Convert(converter = CouponTypeConverter.class)
    private CouponType category;


    // 创建时间，通过@CreateDate注解自动填值（需要配合@JpaAuditing注解在启动类上生效）
    @CreatedDate
    @Column(name = &amp;#34;created_time&amp;#34;, nullable = false)
    private Date createdTime;


    // 优惠券核算规则，平铺成JSON字段
    @Column(name = &amp;#34;rule&amp;#34;, nullable = false)
    @Convert(converter = RuleConverter.class)
    private TemplateRule rule;


}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在 CouponTemplate 上，我们运用了 javax.persistence 包和 Spring JPA 包的标准注解，对数据库字段进行了映射，我挑几个关键注解说道一下。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Entity：声明了&amp;quot;数据库实体&amp;quot;对象，它是数据库 Table 在程序中的映射对象；&lt;/li&gt;
&lt;li&gt;Table：指定了 CouponTemplate 对应的数据库表的名称；&lt;/li&gt;
&lt;li&gt;ID/GeneratedValue：ID 注解将某个字段定义为唯一主键，GeneratedValue 注解指定了主键生成策略；&lt;/li&gt;
&lt;li&gt;Column：指定了每个类属性和数据库字段的对应关系，该注解还支持非空检测、对 update 和 create 语句进行限制等功能；&lt;/li&gt;
&lt;li&gt;CreatedDate：自动填充当前数据的创建时间；&lt;/li&gt;
&lt;li&gt;Convert：如果数据库中存放的是 code、string、数字等等标记化对象，可以使用 Convert 注解指定一个继承自 AttributeConverter 的类，将 DB 里存的内容转化成一个 Java 对象。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里我要补充一点，其实 JPA 也支持一对多、多对多的级联关系（ManyToOne、OneToOne 等注解），但是你发现我并没有在项目中使用，原因是这些注解背后有很多隐患。**过深的级联层级所带来的 DB 层压力可能会在洪峰流量下被急剧放大，而 DB 恰恰是最不抗压的一环。**所以，我们很少在一些一二线大厂的超高并发项目中看到级联配置的身影。&lt;/p&gt;
&lt;p&gt;我的经验是&lt;strong&gt;尽可能减少级联配置，用单表查询取而代之&lt;/strong&gt;，如果一个查询需要 join 好几张表，最好的做法就通过重构业务逻辑来简化 DB 查询的复杂度。&lt;/p&gt;
&lt;p&gt;最后，我们来到定义 DAO 的地方，借助 Spring Data 的强大功能，我们只通过接口名称就可以声明一系列的 DB 层操作。我们先来看一下 CouponTemplateDao 这个类的代码。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;public interface CouponTemplateDao
        extends JpaRepository&amp;lt;CouponTemplate, Long&amp;gt; {
        
    // 根据Shop ID查询出所有券模板
    List&amp;lt;CouponTemplate&amp;gt; findAllByShopId(Long shopId);
    
    // IN查询 + 分页支持的语法
    Page&amp;lt;CouponTemplate&amp;gt; findAllByIdIn(List&amp;lt;Long&amp;gt; Id, Pageable page);
    
    // 根据shop ID + 可用状态查询店铺有多少券模板
    Integer countByShopIdAndAvailable(Long shopId, Boolean available);


    /**
     * 将优惠券设置为不可用
     */
    @Modifying
    @Query(&amp;#34;update CouponTemplate c set c.available = 0 where c.id = :id&amp;#34;)
    int makeCouponUnavailable(@Param(&amp;#34;id&amp;#34;) Long id);
    
    // 完整方法请至源码查看
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;看了这段代码，你一定在想这里都是查询数据的场景，那么&amp;quot;增删改&amp;quot;的方法在哪里？&lt;/p&gt;
&lt;p&gt;其实，这些方法都在 CouponTemplateDao 所继承的 JpaRepository 类中。这个父类就像一个百宝箱，内置了各种各样的数据操作方法。我们可以通过内置的 save 方法完成对象的创建和更新，也可以使用内置的 delete 方法删除数据。&lt;/p&gt;
&lt;p&gt;此外，它还提供了对&amp;quot;查询场景&amp;quot;的丰富支持，除了通过 ID 查询以外，我们还可以使用三种不同的方式查询数据。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;通过接口名查询&lt;/strong&gt;：将查询语句写到接口的名称中；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;通过 Example 对象查询&lt;/strong&gt;：构造一个模板对象，使用 findAll 方法来查询；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;自定义查询&lt;/strong&gt;：通过 Query 注解自定义复杂查询语句。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在 CouponTemplateDao 中，第一个方法 findAllByShopId 就是通过接口名查询的例子，jpa 使用了一种约定大于配置的思想，你只需要把要查询的字段定义在接口的方法名中，在你发起调用时后台就会自动转化成可执行的 SQL 语句。构造方法名的过程需要遵循 &amp;lt; 起手式 &amp;gt;By&amp;lt; 查询字段 &amp;gt;&amp;lt; 连接词 &amp;gt; 的结构。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;起手式&lt;/strong&gt;：以 find 开头表示查询，以 count 开头表示计数；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;查询字段&lt;/strong&gt;：字段名要保持和 Entity 类中定义的字段名称一致；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;连接词&lt;/strong&gt;：每个字段之间可以用 And、Or、Before、After 等一些列丰富的连词串成一个查询语句。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以接口名查询的方式虽然很省事儿，但它面对复杂查询却力不从心，一来容易导致接口名称过长，二来维护起来也挺吃力的。所以，&lt;strong&gt;对于复杂查询，我们可以使用自定义 SQL、或者 Example 对象查找的方式。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;关于自定义 SQL，你可以参考 CouponTemplateDao 中的 makeCouponUnavailable 方法，我将 SQL 语句定义在了 Query 注解中，通过参数绑定的方式从接口入参处获取查询参数，这种方式是最接近 SQL 编码的 CRUD 方式。&lt;/p&gt;
&lt;p&gt;Example 查询的方式也很简单，构造一个 CouponTemplate 的对象，将你想查询的字段值填入其中，做成一个查询模板，调用 Dao 层的 findAll 方法即可，这里留给你自己动手验证。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;couponTemplate.setName(&amp;#34;查询名称&amp;#34;);
templateDao.findAll(Example.of(couponTemplate));
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;现在，API 和 Dao 层都已经准备就绪，万事俱备只差最后的业务逻辑层了，接下来我们去搭建 coupon-template-impl 模块。&lt;/p&gt;
&lt;h1 id=&#34;搭建-coupon-template-impl-模块&#34;&gt;搭建 coupon-template-impl 模块&lt;/h1&gt;
&lt;p&gt;coupon-template-impl 是 coupon-template-serv 下的一个子模块，也是实现业务逻辑的地方。从依赖管理的角度，它引入了 coupon-template-api 和 coupon-template-dao 两个内部依赖项到 pom.xml。&lt;/p&gt;
&lt;p&gt;当然，我们也需要加入几个外部依赖项，你可以参考项目的 pom.xml 源代码获取完整的依赖项列表。&lt;/p&gt;
&lt;p&gt;首先，我们先来定义 Service 层的接口类：CouponTemplateService。在这个接口中，我们定义了优惠券创建、查找优惠券和修改优惠券可用状态的方法。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;public interface CouponTemplateService {
    // 创建优惠券模板
    CouponTemplateInfo createTemplate(CouponTemplateInfo request);
    
    // 通过模板ID查询优惠券模板
    CouponTemplateInfo loadTemplateInfo(Long id);
    
    // 克隆券模板
    CouponTemplateInfo cloneTemplate(Long templateId);


    // 模板查询（分页）
    PagedCouponTemplateInfo search(TemplateSearchParams request);
    
    // 删除券模板
    void deleteTemplate(Long id);
    
    //批量读取模板
    Map&amp;lt;Long, CouponTemplateInfo&amp;gt; getTemplateInfoMap(Collection&amp;lt;Long&amp;gt; ids);
     
    // 完整方法列表请至源码查看    
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;由于这部分比较简单，就是通过 CouponTemplateDao 层来实现优惠券模板的增删改查，这里我就不展开介绍实现层代码了，你可以参考源码中的 CouponTemplateServiceImpl 类。&lt;/p&gt;
&lt;p&gt;不过，我建议你不要直接 copy 源码，先尝试自己实现这几个 Service 方法，写完之后再和我的源码做比较，看一看有哪些可以改进的地方。&lt;/p&gt;
&lt;p&gt;接下来，我们创建 CouponTemplateController 类对外暴露 REST API，可以借助 spring-web 注解来完成，具体代码如下。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;@Slf4j
@RestController
@RequestMapping(&amp;#34;/template&amp;#34;)
public class CouponTemplateController {


    @Autowired
    private CouponTemplateService couponTemplateService;


    // 创建优惠券
    @PostMapping(&amp;#34;/addTemplate&amp;#34;)
    public CouponTemplateInfo addTemplate(@Valid @RequestBody CouponTemplateInfo request) {
        log.info(&amp;#34;Create coupon template: data={}&amp;#34;, request);
        return couponTemplateService.createTemplate(request);
    }
    
    // 克隆券模板
    @PostMapping(&amp;#34;/cloneTemplate&amp;#34;)
    public CouponTemplateInfo cloneTemplate(@RequestParam(&amp;#34;id&amp;#34;) Long templateId) {
        log.info(&amp;#34;Clone coupon template: data={}&amp;#34;, templateId);
        return couponTemplateService.cloneTemplate(templateId);
    }


    // 读取优惠券
    @GetMapping(&amp;#34;/getTemplate&amp;#34;)
    public CouponTemplateInfo getTemplate(@RequestParam(&amp;#34;id&amp;#34;) Long id){
        log.info(&amp;#34;Load template, id={}&amp;#34;, id);
        return couponTemplateService.loadTemplateInfo(id);
    }
    
    // 搜索模板(支持分页查询)
    @PostMapping(&amp;#34;/search&amp;#34;)
    public PagedCouponTemplateInfo search(@Valid @RequestBody TemplateSearchParams request) {
        log.info(&amp;#34;search templates, payload={}&amp;#34;, request);
        return couponTemplateService.search(request);
    }
    
    // ... 完整代码请至源码查看
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在这里，Controller 类中的注解来自 spring-boot-starter-web 依赖项，通过这些注解将服务以 RESTful 接口的方式对外暴露。现在，我们来了解下上述代码里，服务寻址过程中的三个重要注解：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;RestController&lt;/strong&gt;：用来声明一个 Controller 类，加载到 Spring Boot 上下文；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RequestMapping&lt;/strong&gt;：指定当前类中所有方法在 URL 中的访问路径的前缀；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Post/Get/PutMapping&lt;/strong&gt;：定义当前方法的 HTTP Method 和访问路径。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;项目启动类是最后的代码部分，我们在 com.geekbang.coupon.template 下创建一个 Application 类作为启动程序的入口，并在这个类的头上安上 SpringBoot 的启动注解。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;@SpringBootApplication
@EnableJpaAuditing
@ComponentScan(basePackages = {&amp;#34;com.geekbang&amp;#34;})
public class Application {
    public static void main(String[] args) {
        SpringApplication.run(Application.class, args);
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;SpringBootApplication 注解会自动开启包路径扫描，并启动一系列的自动装配流程（AutoConfig）。在默认情况下，Spring Boot 框架会扫描启动类所在 package 下的所有类，并在上下文中创建受托管的 Bean 对象，如果我们想加载额外的扫包路径，只用添加 ComponentScan 注解并指定 path 即可。&lt;/p&gt;
&lt;p&gt;所有代码环节全部完工后，我们还剩最后的画龙点睛之笔：&lt;strong&gt;创建配置文件 application.yml&lt;/strong&gt;，它位于 src/main/resources 文件夹下。Spring Boot 支持多种格式的配置文件，这里我们顺应主流，使用 yml 格式。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# 项目的启动端口
server:
  port: 20000
spring:
  application:
    # 定义项目名称
    name: coupon-template-serv
  datasource:
    # mysql数据源
    username: root
#    password: 这里写上你自己的密码
    url: jdbc:mysql://127.0.0.1:3306/geekbang_coupon_db?autoReconnect=true&amp;amp;useUnicode=true&amp;amp;characterEncoding=utf8&amp;amp;useSSL=false&amp;amp;allowPublicKeyRetrieval=true&amp;amp;zeroDateTimeBehavior=convertToNull&amp;amp;serverTimezone=UTC
    # 指定数据源DataSource类型
    type: com.zaxxer.hikari.HikariDataSource
    driver-class-name: com.mysql.cj.jdbc.Driver
    # 数据库连接池参数配置，比如池子大小、超时时间、是否自动提交等等
    hikari:
      pool-name: GeekbangCouponHikari
      connection-timeout: 5000
      idle-timeout: 30000
      maximum-pool-size: 10
      minimum-idle: 5
      max-lifetime: 60000
      auto-commit: true
  jpa:
    show-sql: true
    hibernate:
      # 在生产环境全部为none，防止ddl结构被自动执行，破坏生产数据
      ddl-auto: none
    # 在日志中打印经过格式化的SQL语句
    properties:
      hibernate.format_sql: true
      hibernate.show_sql: true
    open-in-view: false
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在配置文件中，有一个地方需要你多加注意，那就是 jdbc 连接串（spring.datasource.url）。不同版本的 MySQL 对连接串中的参数有不同的要求。&lt;/p&gt;
&lt;p&gt;如果你发现项目启动过程中抛出了 MySQL 连接报错，一定记得检查自己的 MySQL 版本，检查是否缺失了某些参数（比如 MySQL 8.x 版本下要求传入 serverTimezone 参数）。如果你本地安装的 MySQL 版本早于 8.x 系列，我推荐你重新安装和我一样的 MySQL 8.0.27 版本，这样就不会碰到兼容性问题了。&lt;/p&gt;
&lt;p&gt;好，到这里，我们优惠券平台项目的第一个模块 coupon-template-serv 就搭建完成了，你可以在本地启动项目并通过 Postman 发起调用。我已经将 Postman API 集合上传到了这个Gitee 源码库中的&amp;quot;资源文件&amp;quot;目录下，文件名为&amp;quot;Spring Boot 阶段.postman_collection.json&amp;quot;，你可以导入到自己本地的 Postman 中使用。&lt;/p&gt;
&lt;p&gt;现在，我们来回顾一下这节课的重点内容。&lt;/p&gt;
&lt;h1 id=&#34;总结&#34;&gt;总结&lt;/h1&gt;
&lt;p&gt;今天我带你搭建了整个优惠券服务的整体项目结构，并且用 Spring Boot 快速落地了优惠券模板服务。如果你在自己的项目中还在使用繁琐的 sql 资源文件来操作数据库，不妨升级成 coupon-template-dao 中使用的 spring-data-jpa 来简化 DB 操作。&lt;strong&gt;spring-data-jpa 的功能特性也折射出 Spring 框架的发展趋势：约定大于配置，且越来越轻量级。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在学习这节课的时候，我希望你不要只满足于把项目跑起来就万事大吉了，你还要做一些思考和总结沉淀，想一想如何能把课程中的一些技术点应用在自己的项目中。我在这节课分享了很多开发小技巧，比如防御性编程、代码自动生成、金额计算、如何简化数据校验、级联关系的误区等，这些都可以作为你的开发素材。&lt;/p&gt;
&lt;p&gt;希望你能够动起手来，顺着这节课程的内容动手搭建整个服务，不要直接照搬源码本地执行一下就完事儿了，只有上手实际搭建项目我们才能了解技术细节、积累排查问题的经验。要知道，纸上得来终觉浅，绝知此事要躬行。&lt;/p&gt;
&lt;p&gt;在下一节课中，我会带你搭建 coupon-calculation-ser 和 coupon-customer-serv，构建一个完整的优惠券平台 Spring Boot 项目。&lt;/p&gt;
&lt;h1 id=&#34;思考题&#34;&gt;思考题&lt;/h1&gt;
&lt;p&gt;最后，请你思考一个问题：&lt;/p&gt;
&lt;p&gt;级联查询很容易引发性能问题，你在自己的项目中遇到最复杂的 SQL 是什么？然后，请你进一步做个思考：如果这条 SQL 的调用量激增，你该如何进行优化？欢迎你&amp;quot;显摆&amp;quot;出来，我在留言区等你。&lt;/p&gt;
&lt;p&gt;好啦，这节课就结束啦。也欢迎你把这节课分享给更多对 Spring Cloud 感兴趣的朋友。我是姚秋辰，我们下节课再见！&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 05丨白话容器基础（一）：从进程说开去</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90-kubernetes/05%E4%B8%A8%E7%99%BD%E8%AF%9D%E5%AE%B9%E5%99%A8%E5%9F%BA%E7%A1%80%E4%B8%80%E4%BB%8E%E8%BF%9B%E7%A8%8B%E8%AF%B4%E5%BC%80%E5%8E%BB/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90-kubernetes/05%E4%B8%A8%E7%99%BD%E8%AF%9D%E5%AE%B9%E5%99%A8%E5%9F%BA%E7%A1%80%E4%B8%80%E4%BB%8E%E8%BF%9B%E7%A8%8B%E8%AF%B4%E5%BC%80%E5%8E%BB/</guid>
      <description>
        
        
        &lt;p&gt;你好，我是张磊。今天我和你分享的主题是：白话容器基础之从进程说开去。&lt;/p&gt;
&lt;p&gt;在前面的 4 篇预习文章中，我梳理了&amp;quot;容器&amp;quot;这项技术的来龙去脉，通过这些内容，我希望你能理解如下几个事实：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;容器技术的兴起源于 PaaS 技术的普及；&lt;/li&gt;
&lt;li&gt;Docker 公司发布的 Docker 项目具有里程碑式的意义；&lt;/li&gt;
&lt;li&gt;Docker 项目通过&amp;quot;容器镜像&amp;quot;，解决了应用打包这个根本性难题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;紧接着，我详细介绍了容器技术圈在过去五年里的&amp;quot;风云变幻&amp;quot;，而通过这部分内容，我希望你能理解这样一个道理：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;容器本身没有价值，有价值的是&amp;quot;容器编排&amp;quot;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;也正因为如此，容器技术生态才爆发了一场关于&amp;quot;容器编排&amp;quot;的&amp;quot;战争&amp;quot;。而这次战争，最终以 Kubernetes 项目和 CNCF 社区的胜利而告终。所以，这个专栏后面的内容，我会以 Docker 和 Kubernetes 项目为核心，为你详细介绍容器技术的各项实践与其中的原理。&lt;/p&gt;
&lt;p&gt;不过在此之前，你还需要搞清楚一个更为基础的问题：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;容器，到底是怎么一回事儿？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在第一篇预习文章&lt;a href=&#34;https://time.geekbang.org/column/article/14254&#34;&gt;《小鲸鱼大事记（一）：初出茅庐》&lt;/a&gt;中，我已经提到过，容器其实是一种沙盒技术。顾名思义，沙盒就是能够像一个集装箱一样，把你的应用&amp;quot;装&amp;quot;起来的技术。这样，应用与应用之间，就因为有了边界而不至于相互干扰；而被装进集装箱的应用，也可以被方便地搬来搬去，这不就是 PaaS 最理想的状态嘛。&lt;/p&gt;
&lt;p&gt;不过，这两个能力说起来简单，但要用技术手段去实现它们，可能大多数人就无从下手了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;所以，我就先来跟你说说这个&amp;quot;边界&amp;quot;的实现手段。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;假如，现在你要写一个计算加法的小程序，这个程序需要的输入来自于一个文件，计算完成后的结果则输出到另一个文件中。&lt;/p&gt;
&lt;p&gt;由于计算机只认识 0 和 1，所以无论用哪种语言编写这段代码，最后都需要通过某种方式翻译成二进制文件，才能在计算机操作系统中运行起来。&lt;/p&gt;
&lt;p&gt;而为了能够让这些代码正常运行，我们往往还要给它提供数据，比如我们这个加法程序所需要的输入文件。这些数据加上代码本身的二进制文件，放在磁盘上，就是我们平常所说的一个&amp;quot;程序&amp;quot;，也叫代码的可执行镜像（executable image）。&lt;/p&gt;
&lt;p&gt;然后，我们就可以在计算机上运行这个&amp;quot;程序&amp;quot;了。&lt;/p&gt;
&lt;p&gt;首先，操作系统从&amp;quot;程序&amp;quot;中发现输入数据保存在一个文件中，所以这些数据就被会加载到内存中待命。同时，操作系统又读取到了计算加法的指令，这时，它就需要指示 CPU 完成加法操作。而 CPU 与内存协作进行加法计算，又会使用寄存器存放数值、内存堆栈保存执行的命令和变量。同时，计算机里还有被打开的文件，以及各种各样的 I/O 设备在不断地调用中修改自己的状态。&lt;/p&gt;
&lt;p&gt;就这样，一旦&amp;quot;程序&amp;quot;被执行起来，它就从磁盘上的二进制文件，变成了计算机内存中的数据、寄存器里的值、堆栈中的指令、被打开的文件，以及各种设备的状态信息的一个集合。&lt;strong&gt;像这样一个程序运起来后的计算机执行环境的总和，就是我们今天的主角：进程。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所以，对于进程来说，它的静态表现就是程序，平常都安安静静地待在磁盘上；而一旦运行起来，它就变成了计算机里的数据和状态的总和，这就是它的动态表现。&lt;/p&gt;
&lt;p&gt;而&lt;strong&gt;容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个&amp;quot;边界&amp;quot;。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对于 Docker 等大多数 Linux 容器来说，&lt;strong&gt;Cgroups 技术&lt;/strong&gt; 是用来制造约束的主要手段，而&lt;strong&gt;Namespace 技术&lt;/strong&gt;则是用来修改进程视图的主要方法。&lt;/p&gt;
&lt;p&gt;你可能会觉得 Cgroups 和 Namespace 这两个概念很抽象，别担心，接下来我们一起动手实践一下，你就很容易理解这两项技术了。&lt;/p&gt;
&lt;p&gt;假设你已经有了一个 Linux 操作系统上的 Docker 项目在运行，比如我的环境是 Ubuntu 16.04 和 Docker CE 18.05。&lt;/p&gt;
&lt;p&gt;接下来，让我们首先创建一个容器来试试。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker run -it busybox /bin/sh
/ #
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个命令是 Docker 项目最重要的一个操作，即大名鼎鼎的 docker run。&lt;/p&gt;
&lt;p&gt;而 -it 参数告诉了 Docker 项目在启动容器后，需要给我们分配一个文本输入 / 输出环境，也就是 TTY，跟容器的标准输入相关联，这样我们就可以和这个 Docker 容器进行交互了。而 /bin/sh 就是我们要在 Docker 容器里运行的程序。&lt;/p&gt;
&lt;p&gt;所以，上面这条指令翻译成人类的语言就是：请帮我启动一个容器，在容器里执行 /bin/sh，并且给我分配一个命令行终端跟这个容器交互。&lt;/p&gt;
&lt;p&gt;这样，我的 Ubuntu 16.04 机器就变成了一个宿主机，而一个运行着 /bin/sh 的容器，就跑在了这个宿主机里面。&lt;/p&gt;
&lt;p&gt;上面的例子和原理，如果你已经玩过 Docker，一定不会感到陌生。此时，如果我们在容器里执行一下 ps 指令，就会发现一些更有趣的事情：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/ # ps
PID  USER   TIME COMMAND
  1 root   0:00 /bin/sh
  10 root   0:00 ps
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，我们在 Docker 里最开始执行的 /bin/sh，就是这个容器内部的第 1 号进程（PID=1），而这个容器里一共只有两个进程在运行。这就意味着，前面执行的 /bin/sh，以及我们刚刚执行的 ps，已经被 Docker 隔离在了一个跟宿主机完全不同的世界当中。&lt;/p&gt;
&lt;p&gt;这究竟是怎么做到呢？&lt;/p&gt;
&lt;p&gt;本来，每当我们在宿主机上运行了一个 /bin/sh 程序，操作系统都会给它分配一个进程编号，比如 PID=100。这个编号是进程的唯一标识，就像员工的工牌一样。所以 PID=100，可以粗略地理解为这个 /bin/sh 是我们公司里的第 100 号员工，而第 1 号员工就自然是比尔 · 盖茨这样统领全局的人物。&lt;/p&gt;
&lt;p&gt;而现在，我们要通过 Docker 把这个 /bin/sh 程序运行在一个容器当中。这时候，Docker 就会在这个第 100 号员工入职时给他施一个&amp;quot;障眼法&amp;quot;，让他永远看不到前面的其他 99 个员工，更看不到比尔 · 盖茨。这样，他就会错误地以为自己就是公司里的第 1 号员工。&lt;/p&gt;
&lt;p&gt;这种机制，其实就是对被隔离应用的进程空间做了手脚，使得这些进程只能看到重新计算过的进程编号，比如 PID=1。可实际上，他们在宿主机的操作系统里，还是原来的第 100 号进程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;这种技术，就是 Linux 里面的 Namespace 机制&lt;/strong&gt;。而 Namespace 的使用方式也非常有意思：它其实只是 Linux 创建新进程的一个可选参数。我们知道，在 Linux 系统中创建线程的系统调用是 clone()，比如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int pid = clone(main_function, stack_size, SIGCHLD, NULL); 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个系统调用就会为我们创建一个新的进程，并且返回它的进程号 pid。&lt;/p&gt;
&lt;p&gt;而当我们用 clone() 系统调用创建一个新进程时，就可以在参数中指定 CLONE_NEWPID 参数，比如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int pid = clone(main_function, stack_size, CLONE_NEWPID | SIGCHLD, NULL); 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这时，新创建的这个进程将会&amp;quot;看到&amp;quot;一个全新的进程空间，在这个进程空间里，它的 PID 是 1。之所以说&amp;quot;看到&amp;quot;，是因为这只是一个&amp;quot;障眼法&amp;quot;，在宿主机真实的进程空间里，这个进程的 PID 还是真实的数值，比如 100。&lt;/p&gt;
&lt;p&gt;当然，我们还可以多次执行上面的 clone() 调用，这样就会创建多个 PID Namespace，而每个 Namespace 里的应用进程，都会认为自己是当前容器里的第 1 号进程，它们既看不到宿主机里真正的进程空间，也看不到其他 PID Namespace 里的具体情况。&lt;/p&gt;
&lt;p&gt;而&lt;strong&gt;除了我们刚刚用到的 PID Namespace，Linux 操作系统还提供了 Mount、UTS、IPC、Network 和 User 这些 Namespace，用来对各种不同的进程上下文进行&amp;quot;障眼法&amp;quot;操作。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;比如，Mount Namespace，用于让被隔离进程只看到当前 Namespace 里的挂载点信息；Network Namespace，用于让被隔离进程看到当前 Namespace 里的网络设备和配置。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;这，就是 Linux 容器最基本的实现原理了。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所以，Docker 容器这个听起来玄而又玄的概念，实际上是在创建容器进程时，指定了这个进程所需要启用的一组 Namespace 参数。这样，容器就只能&amp;quot;看&amp;quot;到当前 Namespace 所限定的资源、文件、设备、状态，或者配置。而对于宿主机以及其他不相关的程序，它就完全看不到了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;所以说，容器，其实是一种特殊的进程而已。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;谈到为&amp;quot;进程划分一个独立空间&amp;quot;的思想，相信你一定会联想到虚拟机。而且，你应该还看过一张虚拟机和容器的对比图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/80/40/8089934bedd326703bf5fa6cf70f9740.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;这幅图的左边，画出了虚拟机的工作原理。其中，名为 Hypervisor 的软件是虚拟机最主要的部分。它通过硬件虚拟化功能，模拟出了运行一个操作系统需要的各种硬件，比如 CPU、内存、I/O 设备等等。然后，它在这些虚拟的硬件上安装了一个新的操作系统，即 Guest OS。&lt;/p&gt;
&lt;p&gt;这样，用户的应用进程就可以运行在这个虚拟的机器中，它能看到的自然也只有 Guest OS 的文件和目录，以及这个机器里的虚拟设备。这就是为什么虚拟机也能起到将不同的应用进程相互隔离的作用。&lt;/p&gt;
&lt;p&gt;而这幅图的右边，则用一个名为 Docker Engine 的软件替换了 Hypervisor。这也是为什么，很多人会把 Docker 项目称为&amp;quot;轻量级&amp;quot;虚拟化技术的原因，实际上就是把虚拟机的概念套在了容器上。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可是这样的说法，却并不严谨。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在理解了 Namespace 的工作方式之后，你就会明白，跟真实存在的虚拟机不同，在使用 Docker 的时候，并没有一个真正的&amp;quot;Docker 容器&amp;quot;运行在宿主机里面。Docker 项目帮助用户启动的，还是原来的应用进程，只不过在创建这些进程时，Docker 为它们加上了各种各样的 Namespace 参数。&lt;/p&gt;
&lt;p&gt;这时，这些进程就会觉得自己是各自 PID Namespace 里的第 1 号进程，只能看到各自 Mount Namespace 里挂载的目录和文件，只能访问到各自 Network Namespace 里的网络设备，就仿佛运行在一个个&amp;quot;容器&amp;quot;里面，与世隔绝。&lt;/p&gt;
&lt;p&gt;不过，相信你此刻已经会心一笑：这些不过都是&amp;quot;障眼法&amp;quot;罢了。&lt;/p&gt;
&lt;h2 id=&#34;思考题&#34;&gt;思考题&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;鉴于我对容器本质的讲解，你觉得上面这张容器和虚拟机对比图右侧关于容器的部分，怎么画才更精确？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;你是否知道最新的 Docker 项目默认会为容器启用哪些 Namespace 吗？&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;感谢你的收听，欢迎你给我留言，也欢迎分享给更多的朋友一起阅读。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/47/55/47a6f3bf6b92d58512d5a2ed0a556f55.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 06丨JVM是如何处理异常的？</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3jvm%E8%99%9A%E6%8B%9F%E6%9C%BA/06%E4%B8%A8jvm%E6%98%AF%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E5%BC%82%E5%B8%B8%E7%9A%84/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3jvm%E8%99%9A%E6%8B%9F%E6%9C%BA/06%E4%B8%A8jvm%E6%98%AF%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E5%BC%82%E5%B8%B8%E7%9A%84/</guid>
      <description>
        
        
        &lt;p&gt;今天我们来讲讲 Java 虚拟机的异常处理。首先提醒你一下，本篇文章代码较多，你可以点击文稿查看具体代码。&lt;/p&gt;
&lt;p&gt;众所周知，异常处理的两大组成要素是抛出异常和捕获异常。这两大要素共同实现程序控制流的非正常转移。&lt;/p&gt;
&lt;p&gt;抛出异常可分为显式和隐式两种。显式抛异常的主体是应用程序，它指的是在程序中使用&amp;quot;throw&amp;quot;关键字，手动将异常实例抛出。&lt;/p&gt;
&lt;p&gt;隐式抛异常的主体则是 Java 虚拟机，它指的是 Java 虚拟机在执行过程中，碰到无法继续执行的异常状态，自动抛出异常。举例来说，Java 虚拟机在执行读取数组操作时，发现输入的索引值是负数，故而抛出数组索引越界异常（ArrayIndexOutOfBoundsException）。&lt;/p&gt;
&lt;p&gt;捕获异常则涉及了如下三种代码块。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;try 代码块：用来标记需要进行异常监控的代码。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;catch 代码块：跟在 try 代码块之后，用来捕获在 try 代码块中触发的某种指定类型的异常。除了声明所捕获异常的类型之外，catch 代码块还定义了针对该异常类型的异常处理器。在 Java 中，try 代码块后面可以跟着多个 catch 代码块，来捕获不同类型的异常。Java 虚拟机会从上至下匹配异常处理器。因此，前面的 catch 代码块所捕获的异常类型不能覆盖后边的，否则编译器会报错。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;finally 代码块：跟在 try 代码块和 catch 代码块之后，用来声明一段必定运行的代码。它的设计初衷是为了避免跳过某些关键的清理代码，例如关闭已打开的系统资源。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在程序正常执行的情况下，这段代码会在 try 代码块之后运行。否则，也就是 try 代码块触发异常的情况下，如果该异常没有被捕获，finally 代码块会直接运行，并且在运行之后重新抛出该异常。&lt;/p&gt;
&lt;p&gt;如果该异常被 catch 代码块捕获，finally 代码块则在 catch 代码块之后运行。在某些不幸的情况下，catch 代码块也触发了异常，那么 finally 代码块同样会运行，并会抛出 catch 代码块触发的异常。在某些极端不幸的情况下，finally 代码块也触发了异常，那么只好中断当前 finally 代码块的执行，并往外抛异常。&lt;/p&gt;
&lt;p&gt;上面这段听起来有点绕，但是等我讲完 Java 虚拟机的异常处理机制之后，你便会明白这其中的道理。&lt;/p&gt;
&lt;h2 id=&#34;异常的基本概念&#34;&gt;异常的基本概念&lt;/h2&gt;
&lt;p&gt;在 Java 语言规范中，所有异常都是 Throwable 类或者其子类的实例。Throwable 有两大直接子类。第一个是 Error，涵盖程序不应捕获的异常。当程序触发 Error 时，它的执行状态已经无法恢复，需要中止线程甚至是中止虚拟机。第二子类则是 Exception，涵盖程序可能需要捕获并且处理的异常。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/47/93/47c8429fc30aec201286b47f3c1a5993.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Exception 有一个特殊的子类 RuntimeException，用来表示&amp;quot;程序虽然无法继续执行，但是还能抢救一下&amp;quot;的情况。前边提到的数组索引越界便是其中的一种。&lt;/p&gt;
&lt;p&gt;RuntimeException 和 Error 属于 Java 里的非检查异常（unchecked exception）。其他异常则属于检查异常（checked exception）。在 Java 语法中，所有的检查异常都需要程序显式地捕获，或者在方法声明中用 throws 关键字标注。通常情况下，程序中自定义的异常应为检查异常，以便最大化利用 Java 编译器的编译时检查。&lt;/p&gt;
&lt;p&gt;异常实例的构造十分昂贵。这是由于在构造异常实例时，Java 虚拟机便需要生成该异常的栈轨迹（stack trace）。该操作会逐一访问当前线程的 Java 栈帧，并且记录下各种调试信息，包括栈帧所指向方法的名字，方法所在的类名、文件名，以及在代码中的第几行触发该异常。&lt;/p&gt;
&lt;p&gt;当然，在生成栈轨迹时，Java 虚拟机会忽略掉异常构造器以及填充栈帧的 Java 方法（Throwable.fillInStackTrace），直接从新建异常位置开始算起。此外，Java 虚拟机还会忽略标记为不可见的 Java 方法栈帧。我们在介绍 Lambda 的时候会看到具体的例子。&lt;/p&gt;
&lt;p&gt;既然异常实例的构造十分昂贵，我们是否可以缓存异常实例，在需要用到的时候直接抛出呢？从语法角度上来看，这是允许的。然而，该异常对应的栈轨迹并非 throw 语句的位置，而是新建异常的位置。&lt;/p&gt;
&lt;p&gt;因此，这种做法可能会误导开发人员，使其定位到错误的位置。这也是为什么在实践中，我们往往选择抛出新建异常实例的原因。&lt;/p&gt;
&lt;h2 id=&#34;java-虚拟机是如何捕获异常的&#34;&gt;Java 虚拟机是如何捕获异常的？&lt;/h2&gt;
&lt;p&gt;在编译生成的字节码中，每个方法都附带一个异常表。异常表中的每一个条目代表一个异常处理器，并且由 from 指针、to 指针、target 指针以及所捕获的异常类型构成。这些指针的值是字节码索引（bytecode index，bci），用以定位字节码。&lt;/p&gt;
&lt;p&gt;其中，from 指针和 to 指针标示了该异常处理器所监控的范围，例如 try 代码块所覆盖的范围。target 指针则指向异常处理器的起始位置，例如 catch 代码块的起始位置。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public static void main(String[] args) {
  try {
    mayThrowException();
  } catch (Exception e) {
    e.printStackTrace();
  }
}
// 对应的 Java 字节码
public static void main(java.lang.String[]);
  Code:
    0: invokestatic mayThrowException:()V
    3: goto 11
    6: astore_1
    7: aload_1
    8: invokevirtual java.lang.Exception.printStackTrace
   11: return
  Exception table:
    from  to target type
      0   3   6  Class java/lang/Exception  // 异常表条目
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;举个例子，在上图的 main 方法中，我定义了一段 try-catch 代码。其中，catch 代码块所捕获的异常类型为 Exception。&lt;/p&gt;
&lt;p&gt;编译过后，该方法的异常表拥有一个条目。其 from 指针和 to 指针分别为 0 和 3，代表它的监控范围从索引为 0 的字节码开始，到索引为 3 的字节码结束（不包括 3）。该条目的 target 指针是 6，代表这个异常处理器从索引为 6 的字节码开始。条目的最后一列，代表该异常处理器所捕获的异常类型正是 Exception。&lt;/p&gt;
&lt;p&gt;当程序触发异常时，Java 虚拟机会从上至下遍历异常表中的所有条目。当触发异常的字节码的索引值在某个异常表条目的监控范围内，Java 虚拟机会判断所抛出的异常和该条目想要捕获的异常是否匹配。如果匹配，Java 虚拟机会将控制流转移至该条目 target 指针指向的字节码。&lt;/p&gt;
&lt;p&gt;如果遍历完所有异常表条目，Java 虚拟机仍未匹配到异常处理器，那么它会弹出当前方法对应的 Java 栈帧，并且在调用者（caller）中重复上述操作。在最坏情况下，Java 虚拟机需要遍历当前线程 Java 栈上所有方法的异常表。&lt;/p&gt;
&lt;p&gt;finally 代码块的编译比较复杂。当前版本 Java 编译器的做法，是复制 finally 代码块的内容，分别放在 try-catch 代码块所有正常执行路径以及异常执行路径的出口中。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/17/06/17e2a3053b06b0a4383884f106e31c06.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;针对异常执行路径，Java 编译器会生成一个或多个异常表条目，监控整个 try-catch 代码块，并且捕获所有种类的异常（在 javap 中以 any 指代）。这些异常表条目的 target 指针将指向另一份复制的 finally 代码块。并且，在这个 finally 代码块的最后，Java 编译器会重新抛出所捕获的异常。&lt;/p&gt;
&lt;p&gt;如果你感兴趣的话，可以用 javap 工具来查看下面这段包含了 try-catch-finally 代码块的编译结果。为了更好地区分每个代码块，我定义了四个实例字段：tryBlock、catchBlock、finallyBlock、以及 methodExit，并且仅在对应的代码块中访问这些字段。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class Foo {
  private int tryBlock;
  private int catchBlock;
  private int finallyBlock;
  private int methodExit;
 
  public void test() {
    try {
      tryBlock = 0;
    } catch (Exception e) {
      catchBlock = 1;
    } finally {
      finallyBlock = 2;
    }
    methodExit = 3;
  }
}
 
 
$ javap -c Foo
...
  public void test();
    Code:
       0: aload_0
       1: iconst_0
       2: putfield      #20                 // Field tryBlock:I
       5: goto          30
       8: astore_1
       9: aload_0
      10: iconst_1
      11: putfield      #22                 // Field catchBlock:I
      14: aload_0
      15: iconst_2
      16: putfield      #24                 // Field finallyBlock:I
      19: goto          35
      22: astore_2
      23: aload_0
      24: iconst_2
      25: putfield      #24                 // Field finallyBlock:I
      28: aload_2
      29: athrow
      30: aload_0
      31: iconst_2
      32: putfield      #24                 // Field finallyBlock:I
      35: aload_0
      36: iconst_3
      37: putfield      #26                 // Field methodExit:I
      40: return
    Exception table:
       from    to  target type
           0     5     8   Class java/lang/Exception
           0    14    22   any
 
  ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，编译结果包含三份 finally 代码块。其中，前两份分别位于 try 代码块和 catch 代码块的正常执行路径出口。最后一份则作为异常处理器，监控 try 代码块以及 catch 代码块。它将捕获 try 代码块触发的、未被 catch 代码块捕获的异常，以及 catch 代码块触发的异常。&lt;/p&gt;
&lt;p&gt;这里有一个小问题，如果 catch 代码块捕获了异常，并且触发了另一个异常，那么 finally 捕获并且重抛的异常是哪个呢？答案是后者。也就是说原本的异常便会被忽略掉，这对于代码调试来说十分不利。&lt;/p&gt;
&lt;h2 id=&#34;java-7-的-supressed-异常以及语法糖&#34;&gt;Java 7 的 Supressed 异常以及语法糖&lt;/h2&gt;
&lt;p&gt;Java 7 引入了 Supressed 异常来解决这个问题。这个新特性允许开发人员将一个异常附于另一个异常之上。因此，抛出的异常可以附带多个异常的信息。&lt;/p&gt;
&lt;p&gt;然而，Java 层面的 finally 代码块缺少指向所捕获异常的引用，所以这个新特性使用起来非常繁琐。&lt;/p&gt;
&lt;p&gt;为此，Java 7 专门构造了一个名为 try-with-resources 的语法糖，在字节码层面自动使用 Supressed 异常。当然，该语法糖的主要目的并不是使用 Supressed 异常，而是精简资源打开关闭的用法。&lt;/p&gt;
&lt;p&gt;在 Java 7 之前，对于打开的资源，我们需要定义一个 finally 代码块，来确保该资源在正常或者异常执行状况下都能关闭。&lt;/p&gt;
&lt;p&gt;资源的关闭操作本身容易触发异常。因此，如果同时打开多个资源，那么每一个资源都要对应一个独立的 try-finally 代码块，以保证每个资源都能够关闭。这样一来，代码将会变得十分繁琐。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  FileInputStream in0 = null;
  FileInputStream in1 = null;
  FileInputStream in2 = null;
  ...
  try {
    in0 = new FileInputStream(new File(&amp;quot;in0.txt&amp;quot;));
    ...
    try {
      in1 = new FileInputStream(new File(&amp;quot;in1.txt&amp;quot;));
      ...
      try {
        in2 = new FileInputStream(new File(&amp;quot;in2.txt&amp;quot;));
        ...
      } finally {
        if (in2 != null) in2.close();
      }
    } finally {
      if (in1 != null) in1.close();
    }
  } finally {
    if (in0 != null) in0.close();
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Java 7 的 try-with-resources 语法糖，极大地简化了上述代码。程序可以在 try 关键字后声明并实例化实现了 AutoCloseable 接口的类，编译器将自动添加对应的 close() 操作。在声明多个 AutoCloseable 实例的情况下，编译生成的字节码类似于上面手工编写代码的编译结果。与手工代码相比，try-with-resources 还会使用 Supressed 异常的功能，来避免原异常&amp;quot;被消失&amp;quot;。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class Foo implements AutoCloseable {
  private final String name;
  public Foo(String name) { this.name = name; }
 
  @Override
  public void close() {
    throw new RuntimeException(name);
  }
 
  public static void main(String[] args) {
    try (Foo foo0 = new Foo(&amp;quot;Foo0&amp;quot;); // try-with-resources
         Foo foo1 = new Foo(&amp;quot;Foo1&amp;quot;);
         Foo foo2 = new Foo(&amp;quot;Foo2&amp;quot;)) {
      throw new RuntimeException(&amp;quot;Initial&amp;quot;);
    }
  }
}
 
// 运行结果：
Exception in thread &amp;quot;main&amp;quot; java.lang.RuntimeException: Initial
        at Foo.main(Foo.java:18)
        Suppressed: java.lang.RuntimeException: Foo2
                at Foo.close(Foo.java:13)
                at Foo.main(Foo.java:19)
        Suppressed: java.lang.RuntimeException: Foo1
                at Foo.close(Foo.java:13)
                at Foo.main(Foo.java:19)
        Suppressed: java.lang.RuntimeException: Foo0
                at Foo.close(Foo.java:13)
                at Foo.main(Foo.java:19)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;除了 try-with-resources 语法糖之外，Java 7 还支持在同一 catch 代码块中捕获多种异常。实际实现非常简单，生成多个异常表条目即可。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 在同一 catch 代码块中捕获多种异常
try {
  ...
} catch (SomeException | OtherException e) {
  ...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;总结与实践&#34;&gt;总结与实践&lt;/h2&gt;
&lt;p&gt;今天我介绍了 Java 虚拟机的异常处理机制。&lt;/p&gt;
&lt;p&gt;Java 的异常分为 Exception 和 Error 两种，而 Exception 又分为 RuntimeException 和其他类型。RuntimeException 和 Error 属于非检查异常。其他的 Exception 皆属于检查异常，在触发时需要显式捕获，或者在方法头用 throws 关键字声明。&lt;/p&gt;
&lt;p&gt;Java 字节码中，每个方法对应一个异常表。当程序触发异常时，Java 虚拟机将查找异常表，并依此决定需要将控制流转移至哪个异常处理器之中。Java 代码中的 catch 代码块和 finally 代码块都会生成异常表条目。&lt;/p&gt;
&lt;p&gt;Java 7 引入了 Supressed 异常、try-with-resources，以及多异常捕获。后两者属于语法糖，能够极大地精简我们的代码。&lt;/p&gt;
&lt;p&gt;那么今天的实践环节，你可以看看其他控制流语句与 finally 代码块之间的协作。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 编译并用 javap -c 查看编译后的字节码
public class Foo {
  private int tryBlock;
  private int catchBlock;
  private int finallyBlock;
  private int methodExit;
 
  public void test() {
    for (int i = 0; i &amp;lt; 100; i++) {
      try {
        tryBlock = 0;
        if (i &amp;lt; 50) {
          continue;
        } else if (i &amp;lt; 80) {
          break;
        } else {
          return;
        }
      } catch (Exception e) {
        catchBlock = 1;
      } finally {
        finallyBlock = 2;
      }
    }
    methodExit = 3;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/2a/d5/2a62e58cbdf56a5dc40748567d346fd5.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 06丨全局锁和表锁：给表加个字段怎么有这么多阻碍？</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/06%E4%B8%A8%E5%85%A8%E5%B1%80%E9%94%81%E5%92%8C%E8%A1%A8%E9%94%81%E7%BB%99%E8%A1%A8%E5%8A%A0%E4%B8%AA%E5%AD%97%E6%AE%B5%E6%80%8E%E4%B9%88%E6%9C%89%E8%BF%99%E4%B9%88%E5%A4%9A%E9%98%BB%E7%A2%8D/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/06%E4%B8%A8%E5%85%A8%E5%B1%80%E9%94%81%E5%92%8C%E8%A1%A8%E9%94%81%E7%BB%99%E8%A1%A8%E5%8A%A0%E4%B8%AA%E5%AD%97%E6%AE%B5%E6%80%8E%E4%B9%88%E6%9C%89%E8%BF%99%E4%B9%88%E5%A4%9A%E9%98%BB%E7%A2%8D/</guid>
      <description>
        
        
        &lt;p&gt;今天我要跟你聊聊 MySQL 的锁。数据库锁设计的初衷是处理并发问题。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类&lt;/strong&gt;。今天这篇文章，我会和你分享全局锁和表级锁。而关于行锁的内容，我会留着在下一篇文章中再和你详细介绍。&lt;/p&gt;
&lt;p&gt;这里需要说明的是，锁的设计比较复杂，这两篇文章不会涉及锁的具体实现细节，主要介绍的是碰到锁时的现象和其背后的原理。&lt;/p&gt;
&lt;h1 id=&#34;全局锁&#34;&gt;全局锁&lt;/h1&gt;
&lt;p&gt;顾名思义，全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。&lt;/p&gt;
&lt;p&gt;**全局锁的典型使用场景是，做全库逻辑备份。**也就是把整库每个表都 select 出来存成文本。&lt;/p&gt;
&lt;p&gt;以前有一种做法，是通过 FTWRL 确保不会有其他线程对数据库做更新，然后对整个库做备份。注意，在备份过程中整个库完全处于只读状态。&lt;/p&gt;
&lt;p&gt;但是让整库都只读，听上去就很危险：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；&lt;/li&gt;
&lt;li&gt;如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;看来加全局锁不太好。但是细想一下，备份为什么要加锁呢？我们来看一下不加锁会有什么问题。&lt;/p&gt;
&lt;p&gt;假设你现在要维护&amp;quot;极客时间&amp;quot;的购买系统，关注的是用户账户余额表和用户课程表。&lt;/p&gt;
&lt;p&gt;现在发起一个逻辑备份。假设备份期间，有一个用户，他购买了一门课程，业务逻辑里就要扣掉他的余额，然后往已购课程里面加上一门课。&lt;/p&gt;
&lt;p&gt;如果时间顺序上是先备份账户余额表 (u_account)，然后用户购买，然后备份用户课程表 (u_course)，会怎么样呢？你可以看一下这个图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/cb/cd/cbfd4a0bbb1210792064bcea4e49b0cd.png&#34; alt=&#34;&#34;&gt;
图 1 业务和备份状态图&lt;/p&gt;
&lt;p&gt;可以看到，这个备份结果里，用户 A 的数据状态是&amp;quot;账户余额没扣，但是用户课程表里面已经多了一门课&amp;quot;。如果后面用这个备份来恢复数据的话，用户 A 就发现，自己赚了。&lt;/p&gt;
&lt;p&gt;作为用户可别觉得这样可真好啊，你可以试想一下：如果备份表的顺序反过来，先备份用户课程表再备份账户余额表，又可能会出现什么结果？&lt;/p&gt;
&lt;p&gt;也就是说，不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。&lt;/p&gt;
&lt;p&gt;说到视图你肯定想起来了，我们在前面讲事务隔离的时候，其实是有一个方法能够拿到一致性视图的，对吧？&lt;/p&gt;
&lt;p&gt;是的，就是在可重复读隔离级别下开启一个事务。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;备注：如果你对事务隔离级别的概念不是很清晰的话，可以再回顾一下第 3 篇文章&lt;a href=&#34;https://time.geekbang.org/column/article/68963&#34;&gt;《事务隔离：为什么你改了我还看不见？》&lt;/a&gt;中的相关内容。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数&amp;ndash;single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。&lt;/p&gt;
&lt;p&gt;你一定在疑惑，有了这个功能，为什么还需要 FTWRL 呢？**一致性读是好，但前提是引擎要支持这个隔离级别。**比如，对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 FTWRL 命令了。&lt;/p&gt;
&lt;p&gt;所以，**single-transaction 方法只适用于所有的表使用事务引擎的库。**如果有的表使用了不支持事务的引擎，那么备份就只能通过 FTWRL 方法。这往往是 DBA 要求业务开发人员使用 InnoDB 替代 MyISAM 的原因之一。&lt;/p&gt;
&lt;p&gt;你也许会问，&lt;strong&gt;既然要全库只读，为什么不使用 set global readonly=true 的方式呢&lt;/strong&gt;？确实 readonly 方式也可以让全库进入只读状态，但我还是会建议你用 FTWRL 方式，主要有两个原因：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一是，在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大，我不建议你使用。&lt;/li&gt;
&lt;li&gt;二是，在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;业务的更新不只是增删改数据（DML)，还有可能是加字段等修改表结构的操作（DDL）。不论是哪种方法，一个库被全局锁上以后，你要对里面任何一个表做加字段操作，都是会被锁住的。&lt;/p&gt;
&lt;p&gt;但是，即使没有被全局锁住，加字段也不是就能一帆风顺的，因为你还会碰到接下来我们要介绍的表级锁。&lt;/p&gt;
&lt;h1 id=&#34;表级锁&#34;&gt;表级锁&lt;/h1&gt;
&lt;p&gt;MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。&lt;/p&gt;
&lt;p&gt;**表锁的语法是 lock tables &amp;hellip; read/write。**与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。&lt;/p&gt;
&lt;p&gt;举个例子, 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。&lt;/p&gt;
&lt;p&gt;在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于 InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大。&lt;/p&gt;
&lt;p&gt;**另一类表级的锁是 MDL（metadata lock)。**MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。&lt;/p&gt;
&lt;p&gt;因此，在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;虽然 MDL 锁是系统默认会加的，但却是你不能忽略的一个机制。比如下面这个例子，我经常看到有人掉到这个坑里：给一个小表加个字段，导致整个库挂了。&lt;/p&gt;
&lt;p&gt;你肯定知道，给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。在对大表操作的时候，你肯定会特别小心，以免对线上服务造成影响。而实际上，即使是小表，操作不慎也会出问题。我们来看一下下面的操作序列，假设表 t 是一个小表。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;备注：这里的实验环境是 MySQL 5.6。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/7c/ce/7cf6a3bf90d72d1f0fc156ececdfb0ce.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;我们可以看到 session A 先启动，这时候会对表 t 加一个 MDL 读锁。由于 session B 需要的也是 MDL 读锁，因此可以正常执行。&lt;/p&gt;
&lt;p&gt;之后 session C 会被 blocked，是因为 session A 的 MDL 读锁还没有释放，而 session C 需要 MDL 写锁，因此只能被阻塞。&lt;/p&gt;
&lt;p&gt;如果只有 session C 自己被阻塞还没什么关系，但是之后所有要在表 t 上新申请 MDL 读锁的请求也会被 session C 阻塞。前面我们说了，所有对表的增删改查操作都需要先申请 MDL 读锁，就都被锁住，等于这个表现在完全不可读写了。&lt;/p&gt;
&lt;p&gt;如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满。&lt;/p&gt;
&lt;p&gt;你现在应该知道了，事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。&lt;/p&gt;
&lt;p&gt;基于上面的分析，我们来讨论一个问题，&lt;strong&gt;如何安全地给小表加字段？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;首先我们要解决长事务，事务不提交，就会一直占着 MDL 锁。在 MySQL 的 information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。&lt;/p&gt;
&lt;p&gt;但考虑一下这个场景。如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而你不得不加个字段，你该怎么做呢？&lt;/p&gt;
&lt;p&gt;这时候 kill 可能未必管用，因为新的请求马上就来了。比较理想的机制是，在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。&lt;/p&gt;
&lt;p&gt;MariaDB 已经合并了 AliSQL 的这个功能，所以这两个开源分支目前都支持 DDL NOWAIT/WAIT n 这个语法。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ALTER TABLE tbl_name NOWAIT add column ...
ALTER TABLE tbl_name WAIT N add column ... 
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;小结&#34;&gt;小结&lt;/h1&gt;
&lt;p&gt;今天，我跟你介绍了 MySQL 的全局锁和表级锁。&lt;/p&gt;
&lt;p&gt;全局锁主要用在逻辑备份过程中。对于全部是 InnoDB 引擎的库，我建议你选择使用&amp;ndash;single-transaction 参数，对应用会更友好。&lt;/p&gt;
&lt;p&gt;表锁一般是在数据库引擎不支持行锁的时候才会被用到的。如果你发现你的应用程序里有 lock tables 这样的语句，你需要追查一下，比较可能的情况是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;要么是你的系统现在还在用 MyISAM 这类不支持事务的引擎，那要安排升级换引擎；&lt;/li&gt;
&lt;li&gt;要么是你的引擎升级了，但是代码还没升级。我见过这样的情况，最后业务开发就是把 lock tables 和 unlock tables 改成 begin 和 commit，问题就解决了。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;MDL 会直到事务提交才释放，在做表结构变更的时候，你一定要小心不要导致锁住线上查询和更新。&lt;/p&gt;
&lt;p&gt;最后，我给你留一个问题吧。备份一般都会在备库上执行，你在用&amp;ndash;single-transaction 方法做逻辑备份的过程中，如果主库上的一个小表做了一个 DDL，比如给一个表上加了一列。这时候，从备库上会看到什么现象呢？&lt;/p&gt;
&lt;p&gt;你可以把你的思考和观点写在留言区里，我会在下一篇文章的末尾和你讨论这个问题。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。&lt;/p&gt;
&lt;p&gt;说明：这篇文章没有介绍到物理备份，物理备份会有一篇单独的文章。&lt;/p&gt;
&lt;h1 id=&#34;上期问题时间&#34;&gt;上期问题时间&lt;/h1&gt;
&lt;p&gt;上期的问题是关于对联合主键索引和 InnoDB 索引组织表的理解。&lt;/p&gt;
&lt;p&gt;我直接贴 @老杨同志 的回复略作修改如下（我修改的部分用橙色标出）：&lt;/p&gt;
&lt;p&gt;表记录&lt;br&gt;
&amp;ndash;a&amp;ndash;|&amp;ndash;b&amp;ndash;|&amp;ndash;c&amp;ndash;|&amp;ndash;d&amp;ndash;&lt;br&gt;
1 2 3 d&lt;br&gt;
1 3 2 d&lt;br&gt;
1 4 3 d&lt;br&gt;
2 1 3 d&lt;br&gt;
2 2 2 d&lt;br&gt;
2 3 4 d&lt;br&gt;
主键 a，b 的聚簇索引组织顺序相当于 order by a,b ，也就是先按 a 排序，再按 b 排序，c 无序。&lt;/p&gt;
&lt;p&gt;索引 ca 的组织是先按 c 排序，再按 a 排序，同时记录主键&lt;br&gt;
&amp;ndash;c&amp;ndash;|&amp;ndash;a&amp;ndash;|&amp;ndash;主键部分b&amp;ndash; （注意，这里不是 ab，而是只有 b）&lt;br&gt;
2 1 3&lt;br&gt;
2 2 2&lt;br&gt;
3 1 2&lt;br&gt;
3 1 4&lt;br&gt;
3 2 1&lt;br&gt;
4 2 3&lt;br&gt;
这个跟索引 c 的数据是一模一样的。&lt;/p&gt;
&lt;p&gt;索引 cb 的组织是先按 c 排序，在按 b 排序，同时记录主键&lt;br&gt;
&amp;ndash;c&amp;ndash;|&amp;ndash;b&amp;ndash;|&amp;ndash;主键部分a&amp;ndash; （同上）&lt;br&gt;
2 2 2&lt;br&gt;
2 3 1&lt;br&gt;
3 1 2&lt;br&gt;
3 2 1&lt;br&gt;
3 4 1&lt;br&gt;
4 3 2&lt;/p&gt;
&lt;p&gt;所以，结论是 ca 可以去掉，cb 需要保留。&lt;/p&gt;
&lt;p&gt;评论区留言点赞：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;@浪里白条 帮大家总结了复习要点；&lt;br&gt;
@约书亚 的问题里提到了 MRR 优化；&lt;br&gt;
@HwangZHen 留言言简意赅。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/ce/d9/ce7f4e35916ed1aa49206a53a0547bd9.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 06丨全局锁和表锁：给表加个字段怎么有这么多阻碍？_20190823_231707</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/06%E4%B8%A8%E5%85%A8%E5%B1%80%E9%94%81%E5%92%8C%E8%A1%A8%E9%94%81%E7%BB%99%E8%A1%A8%E5%8A%A0%E4%B8%AA%E5%AD%97%E6%AE%B5%E6%80%8E%E4%B9%88%E6%9C%89%E8%BF%99%E4%B9%88%E5%A4%9A%E9%98%BB%E7%A2%8D_20190823_231707/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/06%E4%B8%A8%E5%85%A8%E5%B1%80%E9%94%81%E5%92%8C%E8%A1%A8%E9%94%81%E7%BB%99%E8%A1%A8%E5%8A%A0%E4%B8%AA%E5%AD%97%E6%AE%B5%E6%80%8E%E4%B9%88%E6%9C%89%E8%BF%99%E4%B9%88%E5%A4%9A%E9%98%BB%E7%A2%8D_20190823_231707/</guid>
      <description>
        
        
        &lt;p&gt;今天我要跟你聊聊 MySQL 的锁。数据库锁设计的初衷是处理并发问题。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类&lt;/strong&gt;。今天这篇文章，我会和你分享全局锁和表级锁。而关于行锁的内容，我会留着在下一篇文章中再和你详细介绍。&lt;/p&gt;
&lt;p&gt;这里需要说明的是，锁的设计比较复杂，这两篇文章不会涉及锁的具体实现细节，主要介绍的是碰到锁时的现象和其背后的原理。&lt;/p&gt;
&lt;h1 id=&#34;全局锁&#34;&gt;全局锁&lt;/h1&gt;
&lt;p&gt;顾名思义，全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。&lt;/p&gt;
&lt;p&gt;**全局锁的典型使用场景是，做全库逻辑备份。**也就是把整库每个表都 select 出来存成文本。&lt;/p&gt;
&lt;p&gt;以前有一种做法，是通过 FTWRL 确保不会有其他线程对数据库做更新，然后对整个库做备份。注意，在备份过程中整个库完全处于只读状态。&lt;/p&gt;
&lt;p&gt;但是让整库都只读，听上去就很危险：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；&lt;/li&gt;
&lt;li&gt;如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;看来加全局锁不太好。但是细想一下，备份为什么要加锁呢？我们来看一下不加锁会有什么问题。&lt;/p&gt;
&lt;p&gt;假设你现在要维护&amp;quot;极客时间&amp;quot;的购买系统，关注的是用户账户余额表和用户课程表。&lt;/p&gt;
&lt;p&gt;现在发起一个逻辑备份。假设备份期间，有一个用户，他购买了一门课程，业务逻辑里就要扣掉他的余额，然后往已购课程里面加上一门课。&lt;/p&gt;
&lt;p&gt;如果时间顺序上是先备份账户余额表 (u_account)，然后用户购买，然后备份用户课程表 (u_course)，会怎么样呢？你可以看一下这个图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/cb/cd/cbfd4a0bbb1210792064bcea4e49b0cd.png&#34; alt=&#34;&#34;&gt;
图 1 业务和备份状态图&lt;/p&gt;
&lt;p&gt;可以看到，这个备份结果里，用户 A 的数据状态是&amp;quot;账户余额没扣，但是用户课程表里面已经多了一门课&amp;quot;。如果后面用这个备份来恢复数据的话，用户 A 就发现，自己赚了。&lt;/p&gt;
&lt;p&gt;作为用户可别觉得这样可真好啊，你可以试想一下：如果备份表的顺序反过来，先备份用户课程表再备份账户余额表，又可能会出现什么结果？&lt;/p&gt;
&lt;p&gt;也就是说，不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。&lt;/p&gt;
&lt;p&gt;说到视图你肯定想起来了，我们在前面讲事务隔离的时候，其实是有一个方法能够拿到一致性视图的，对吧？&lt;/p&gt;
&lt;p&gt;是的，就是在可重复读隔离级别下开启一个事务。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;备注：如果你对事务隔离级别的概念不是很清晰的话，可以再回顾一下第 3 篇文章&lt;a href=&#34;https://time.geekbang.org/column/article/68963&#34;&gt;《事务隔离：为什么你改了我还看不见？》&lt;/a&gt;中的相关内容。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数&amp;ndash;single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。&lt;/p&gt;
&lt;p&gt;你一定在疑惑，有了这个功能，为什么还需要 FTWRL 呢？**一致性读是好，但前提是引擎要支持这个隔离级别。**比如，对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 FTWRL 命令了。&lt;/p&gt;
&lt;p&gt;所以，**single-transaction 方法只适用于所有的表使用事务引擎的库。**如果有的表使用了不支持事务的引擎，那么备份就只能通过 FTWRL 方法。这往往是 DBA 要求业务开发人员使用 InnoDB 替代 MyISAM 的原因之一。&lt;/p&gt;
&lt;p&gt;你也许会问，&lt;strong&gt;既然要全库只读，为什么不使用 set global readonly=true 的方式呢&lt;/strong&gt;？确实 readonly 方式也可以让全库进入只读状态，但我还是会建议你用 FTWRL 方式，主要有两个原因：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一是，在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大，我不建议你使用。&lt;/li&gt;
&lt;li&gt;二是，在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;业务的更新不只是增删改数据（DML)，还有可能是加字段等修改表结构的操作（DDL）。不论是哪种方法，一个库被全局锁上以后，你要对里面任何一个表做加字段操作，都是会被锁住的。&lt;/p&gt;
&lt;p&gt;但是，即使没有被全局锁住，加字段也不是就能一帆风顺的，因为你还会碰到接下来我们要介绍的表级锁。&lt;/p&gt;
&lt;h1 id=&#34;表级锁&#34;&gt;表级锁&lt;/h1&gt;
&lt;p&gt;MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。&lt;/p&gt;
&lt;p&gt;**表锁的语法是 lock tables &amp;hellip; read/write。**与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。&lt;/p&gt;
&lt;p&gt;举个例子, 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。&lt;/p&gt;
&lt;p&gt;在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于 InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大。&lt;/p&gt;
&lt;p&gt;**另一类表级的锁是 MDL（metadata lock)。**MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。&lt;/p&gt;
&lt;p&gt;因此，在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;虽然 MDL 锁是系统默认会加的，但却是你不能忽略的一个机制。比如下面这个例子，我经常看到有人掉到这个坑里：给一个小表加个字段，导致整个库挂了。&lt;/p&gt;
&lt;p&gt;你肯定知道，给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。在对大表操作的时候，你肯定会特别小心，以免对线上服务造成影响。而实际上，即使是小表，操作不慎也会出问题。我们来看一下下面的操作序列，假设表 t 是一个小表。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;备注：这里的实验环境是 MySQL 5.6。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/7c/ce/7cf6a3bf90d72d1f0fc156ececdfb0ce.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;我们可以看到 session A 先启动，这时候会对表 t 加一个 MDL 读锁。由于 session B 需要的也是 MDL 读锁，因此可以正常执行。&lt;/p&gt;
&lt;p&gt;之后 session C 会被 blocked，是因为 session A 的 MDL 读锁还没有释放，而 session C 需要 MDL 写锁，因此只能被阻塞。&lt;/p&gt;
&lt;p&gt;如果只有 session C 自己被阻塞还没什么关系，但是之后所有要在表 t 上新申请 MDL 读锁的请求也会被 session C 阻塞。前面我们说了，所有对表的增删改查操作都需要先申请 MDL 读锁，就都被锁住，等于这个表现在完全不可读写了。&lt;/p&gt;
&lt;p&gt;如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满。&lt;/p&gt;
&lt;p&gt;你现在应该知道了，事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。&lt;/p&gt;
&lt;p&gt;基于上面的分析，我们来讨论一个问题，&lt;strong&gt;如何安全地给小表加字段？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;首先我们要解决长事务，事务不提交，就会一直占着 MDL 锁。在 MySQL 的 information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。&lt;/p&gt;
&lt;p&gt;但考虑一下这个场景。如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而你不得不加个字段，你该怎么做呢？&lt;/p&gt;
&lt;p&gt;这时候 kill 可能未必管用，因为新的请求马上就来了。比较理想的机制是，在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。&lt;/p&gt;
&lt;p&gt;MariaDB 已经合并了 AliSQL 的这个功能，所以这两个开源分支目前都支持 DDL NOWAIT/WAIT n 这个语法。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ALTER TABLE tbl_name NOWAIT add column ...
ALTER TABLE tbl_name WAIT N add column ... 
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;小结&#34;&gt;小结&lt;/h1&gt;
&lt;p&gt;今天，我跟你介绍了 MySQL 的全局锁和表级锁。&lt;/p&gt;
&lt;p&gt;全局锁主要用在逻辑备份过程中。对于全部是 InnoDB 引擎的库，我建议你选择使用&amp;ndash;single-transaction 参数，对应用会更友好。&lt;/p&gt;
&lt;p&gt;表锁一般是在数据库引擎不支持行锁的时候才会被用到的。如果你发现你的应用程序里有 lock tables 这样的语句，你需要追查一下，比较可能的情况是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;要么是你的系统现在还在用 MyISAM 这类不支持事务的引擎，那要安排升级换引擎；&lt;/li&gt;
&lt;li&gt;要么是你的引擎升级了，但是代码还没升级。我见过这样的情况，最后业务开发就是把 lock tables 和 unlock tables 改成 begin 和 commit，问题就解决了。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;MDL 会直到事务提交才释放，在做表结构变更的时候，你一定要小心不要导致锁住线上查询和更新。&lt;/p&gt;
&lt;p&gt;最后，我给你留一个问题吧。备份一般都会在备库上执行，你在用&amp;ndash;single-transaction 方法做逻辑备份的过程中，如果主库上的一个小表做了一个 DDL，比如给一个表上加了一列。这时候，从备库上会看到什么现象呢？&lt;/p&gt;
&lt;p&gt;你可以把你的思考和观点写在留言区里，我会在下一篇文章的末尾和你讨论这个问题。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。&lt;/p&gt;
&lt;p&gt;说明：这篇文章没有介绍到物理备份，物理备份会有一篇单独的文章。&lt;/p&gt;
&lt;h1 id=&#34;上期问题时间&#34;&gt;上期问题时间&lt;/h1&gt;
&lt;p&gt;上期的问题是关于对联合主键索引和 InnoDB 索引组织表的理解。&lt;/p&gt;
&lt;p&gt;我直接贴 @老杨同志 的回复略作修改如下（我修改的部分用橙色标出）：&lt;/p&gt;
&lt;p&gt;表记录&lt;br&gt;
&amp;ndash;a&amp;ndash;|&amp;ndash;b&amp;ndash;|&amp;ndash;c&amp;ndash;|&amp;ndash;d&amp;ndash;&lt;br&gt;
1 2 3 d&lt;br&gt;
1 3 2 d&lt;br&gt;
1 4 3 d&lt;br&gt;
2 1 3 d&lt;br&gt;
2 2 2 d&lt;br&gt;
2 3 4 d&lt;br&gt;
主键 a，b 的聚簇索引组织顺序相当于 order by a,b ，也就是先按 a 排序，再按 b 排序，c 无序。&lt;/p&gt;
&lt;p&gt;索引 ca 的组织是先按 c 排序，再按 a 排序，同时记录主键&lt;br&gt;
&amp;ndash;c&amp;ndash;|&amp;ndash;a&amp;ndash;|&amp;ndash;主键部分b&amp;ndash; （注意，这里不是 ab，而是只有 b）&lt;br&gt;
2 1 3&lt;br&gt;
2 2 2&lt;br&gt;
3 1 2&lt;br&gt;
3 1 4&lt;br&gt;
3 2 1&lt;br&gt;
4 2 3&lt;br&gt;
这个跟索引 c 的数据是一模一样的。&lt;/p&gt;
&lt;p&gt;索引 cb 的组织是先按 c 排序，在按 b 排序，同时记录主键&lt;br&gt;
&amp;ndash;c&amp;ndash;|&amp;ndash;b&amp;ndash;|&amp;ndash;主键部分a&amp;ndash; （同上）&lt;br&gt;
2 2 2&lt;br&gt;
2 3 1&lt;br&gt;
3 1 2&lt;br&gt;
3 2 1&lt;br&gt;
3 4 1&lt;br&gt;
4 3 2&lt;/p&gt;
&lt;p&gt;所以，结论是 ca 可以去掉，cb 需要保留。&lt;/p&gt;
&lt;p&gt;评论区留言点赞：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;@浪里白条 帮大家总结了复习要点；&lt;br&gt;
@约书亚 的问题里提到了 MRR 优化；&lt;br&gt;
@HwangZHen 留言言简意赅。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/ce/d9/ce7f4e35916ed1aa49206a53a0547bd9.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 06丨如何才能拥有技术领导力？</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/06%E4%B8%A8%E5%A6%82%E4%BD%95%E6%89%8D%E8%83%BD%E6%8B%A5%E6%9C%89%E6%8A%80%E6%9C%AF%E9%A2%86%E5%AF%BC%E5%8A%9B/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/06%E4%B8%A8%E5%A6%82%E4%BD%95%E6%89%8D%E8%83%BD%E6%8B%A5%E6%9C%89%E6%8A%80%E6%9C%AF%E9%A2%86%E5%AF%BC%E5%8A%9B/</guid>
      <description>
        
        
        &lt;p&gt;通过上篇文章，相信你现在已经理解了&amp;quot;什么才是技术领导力&amp;quot;。今天，我就要跟你继续聊聊，怎样才能拥有技术领导力。&lt;/p&gt;
&lt;p&gt;**第一，你要吃透基础技术。基础技术是各种上层技术共同的基础。**吃透基础技术是为了更好地理解程序的运行原理，并基于这些基础技术进化出更优化的产品。吃透基础技术，有很多好处，具体来说，有如下几点。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;万丈高楼平地起。一栋楼能盖多高，一座大桥能造多长，重要的是它们的地基。同样对于技术人员来说，基础知识越扎实，走得就会越远。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;计算机技术太多了，但是仔细分析你会发现，只是表现形式很多，而基础技术并不多。学好基础技术，能让你一通百通，更快地使用各种新技术，从而可以更轻松地与时代同行。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;很多分布式系统架构，以及高可用、高性能、高并发的解决方案基本都可以在基础技术上找到它们的身影。所以，学习基础技术能让你更好地掌握更高维度的技术。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;那么，哪些才是基础技术呢？我在下面罗列了一些。老实说，这些技术你学起来可能会感到枯燥无味，但是，我还是鼓励你能够克服人性的弱点，努力啃完。&lt;/p&gt;
&lt;p&gt;具体来说，可以分成两个部分：&lt;strong&gt;编程和系统&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;编程部分&#34;&gt;编程部分&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;C 语言&lt;/strong&gt;：相对于很多其他高级语言来说，C 语言更接近底层。在具备跨平台能力的前提下，它可以比较容易地被人工翻译成相应的汇编代码。它的内存管理更为直接，可以让我们直接和内存地址打交道。&lt;/p&gt;
&lt;p&gt;学习好 C 语言的好处是能掌握程序的运行情况，并能进行应用程序和操作系统编程（操作系统一般是汇编和 C 语言）。要学好 C 语言，你可以阅读 C 语言的经典书籍《C 程序设计语言（第 2 版）》，同时，肯定也要多写程序，多读一些优秀开源项目的源代码。&lt;/p&gt;
&lt;p&gt;除了让你更为了解操作系统之外，学习 C 语言还能让你更清楚地知道程序是怎么精细控制底层资源的，比如内存管理、文件操作、网络通信&amp;hellip;&amp;hellip;&lt;/p&gt;
&lt;p&gt;这里需要说明的是，我们还是需要学习汇编语言的。因为如果你想更深入地了解计算机是怎么运作的，那么你是需要了解汇编语言的。虽然我们几乎不再用汇编语言编程了，但是如果你需要写一些如 lock free 之类高并发的东西，那么了解汇编语言，就能有助于你更好地理解和思考。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;编程范式&lt;/strong&gt;：各种编程语言都有它们各自的编程范式，用于解决各种问题。比如面向对象编程（C++、Java）、泛型编程（C++、Go、C#）、函数式编程（JavaScript、 Python、Lisp、Haskell、Erlang）等。&lt;/p&gt;
&lt;p&gt;学好编程范式，有助于培养你的抽象思维，同时也可以提高编程效率，提高程序的结构合理性、可读性和可维护性，降低代码的冗余度，进而提高代码的运行效率。要学习编程范式，你还可以多了解各种程序设计语言的功能特性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;算法和数据结构&lt;/strong&gt;：算法（及其相应的数据结构）是程序设计的有力支撑。适当地应用算法，可以有效地抽象问题，提高程序的合理性和执行效率。算法是编程中最最重要的东西，也是计算机科学中最重要的基础。&lt;/p&gt;
&lt;p&gt;任何有技术含量的软件中一定有高级的算法和数据结构。比如 epoll 中使用了红黑树，数据库索引使用了 B+ 树&amp;hellip;&amp;hellip;而就算是你的业务系统中，也一定使用各种排序、过滤和查找算法。学习算法不仅是为了写出运转更为高效的代码，而且更是为了能够写出可以覆盖更多场景的正确代码。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;系统部分&#34;&gt;系统部分&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;计算机系统原理&lt;/strong&gt;：CPU 的体系结构（指令集 [CISC/RISC]、分支预测、缓存结构、总线、DMA、中断、陷阱、多任务、虚拟内存、虚拟化等），内存的原理与性能特点（SRAM、DRAM、DDR-SDRAM 等），磁盘的原理（机械硬盘 [盘面、磁头臂、磁头、启停区、寻道等]、固态硬盘 [页映射、块的合并与回收算法、TRIM 指令等]），GPU 的原理等。&lt;/p&gt;
&lt;p&gt;学习计算机系统原理的价值在于，除了能够了解计算机的原理之外，你还能举一反三地反推出高维度的分布式架构和高并发高可用的架构设计。&lt;/p&gt;
&lt;p&gt;比如虚拟化内存就和今天云计算中的虚拟化的原理是相通的，计算机总线和分布式架构中的 ESB 也有相通之处，计算机指令调度、并发控制可以让你更好地理解并发编程和程序性能调优&amp;hellip;&amp;hellip;这里，推荐书籍《深入理解计算机系统》（Randal E. Bryant）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;操作系统原理和基础&lt;/strong&gt;：进程、进程管理、线程、线程调度、多核的缓存一致性、信号量、物理内存管理、虚拟内存管理、内存分配、文件系统、磁盘管理等。&lt;/p&gt;
&lt;p&gt;学习操作系统的价值在于理解程序是怎样被管理的，操作系统对应用程序提供了怎样的支持，抽象出怎样的编程接口（比如 POSIX/Win32 API），性能特性如何（比如控制合理的上下文切换次数），怎样进行进程间通信（如管道、套接字、内存映射等），以便让不同的软件配合一起运行等。&lt;/p&gt;
&lt;p&gt;要学习操作系统知识，一是要仔细观察和探索当前使用的操作系统，二是要阅读操作系统原理相关的图书，三是要阅读 API 文档（如 man pages 和 MSDN Library），并编写调用操作系统功能的程序。这里推荐三本书《UNIX 环境高级编程》、《UNIX 网络编程》和《Windows 核心编程》。&lt;/p&gt;
&lt;p&gt;学习操作系统基础原理的好处是，这是所有程序运行的物理世界，无论上层是像 C/C++ 这样编译成机器码的语言，还是像 Java 这样有 JVM 做中间层的语言，再或者像 Python/PHP/Perl/Node.js 这样直接在运行时解释的语言，其在底层都逃离不了操作系统这个物理世界的&amp;quot;物理定律&amp;quot;。&lt;/p&gt;
&lt;p&gt;所以，了解操作系统的原理，可以让你更能从本质理解各种语言或是技术的底层原理。一眼看透本质可以让你更容易地掌握和使用高阶技术。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;网络基础&lt;/strong&gt;：计算机网络是现代计算机不可或缺的一部分。需要了解基本的网络层次结构（ISO/OSI 模型、TCP/IP 协议栈），包括物理层、数据链路层（包含错误重发机制）、网络层（包含路由机制）、传输层（包含连接保持机制）、会话层、表示层、应用层（在 TCP/IP 协议栈里，这三层可以并为一层）。&lt;/p&gt;
&lt;p&gt;比如，底层的 ARP 协议、中间的 TCP/UDP 协议，以及高层的 HTTP 协议。这里推荐书籍《TCP/IP 详解》，学习这些基础的网络协议，可以为我们的高维分布式架构中的一些技术问题提供很多的技术方案。比如 TCP 的滑动窗口限流，完全可以用于分布式服务中的限流方案。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;数据库原理&lt;/strong&gt;：数据库管理系统是管理数据库的利器。通常操作系统提供文件系统来管理文件数据，而文件比较适合保存连续的信息，如一篇文章、一个图片等。但有时需要保存一个名字等较短的信息。如果单个文件只保存名字这样的几个字节的信息的话，就会浪费大量的磁盘空间，而且无法方便地查询（除非使用索引服务）。&lt;/p&gt;
&lt;p&gt;但数据库则更适合保存这种短的数据，而且可以方便地按字段进行查询。现代流行的数据库管理系统有两大类：SQL（基于 B+ 树，强一致性）和 NoSQL（较弱的一致性，较高的存取效率，基于哈希表或其他技术）。&lt;/p&gt;
&lt;p&gt;学习了数据库原理之后便能了解数据库访问性能调优的要点，以及保证并发情况下数据操作原子性的方法。要学习数据库，你可以阅读各类数据库图书，并多做数据库操作以及数据库编程，多观察分析数据库在运行时的性能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;分布式技术架构&lt;/strong&gt;：数据库和应用程序服务器在应对互联网上数以亿计的访问量的时候，需要能进行横向扩展，这样才能提供足够高的性能。为了做到这一点，要学习分布式技术架构，包括负载均衡、DNS 解析、多子域名、无状态应用层、缓存层、数据库分片、容错和恢复机制、Paxos、Map/Reduce 操作、分布式 SQL 数据库一致性（以 Google Cloud Spanner 为代表）等知识点。&lt;/p&gt;
&lt;p&gt;学习分布式技术架构的有效途径是参与到分布式项目的开发中去，并阅读相关论文。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注意，&lt;strong&gt;上面这些基础知识通常不是可以速成的&lt;/strong&gt;。虽然说，你可以在一两年内看完相关的书籍或论文，但是，我想说的是，这些基础技术是需要你用一生的时间来学习的，因为基础上的技术和知识，会随着阅历和经验的增加而有不同的感悟。&lt;/p&gt;
&lt;p&gt;**第二，提高学习能力。所谓学习能力，就是能够很快地学习新技术，又能在关键技术上深入的能力。**只有在掌握了上述的基础原理之上，你才能拥有好的学习能力。&lt;/p&gt;
&lt;p&gt;下面是让你提升学习能力的一些做法。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;学习的信息源&lt;/strong&gt;。信息源很重要，有好的信息源就可以更快速地获取有价值的信息，并提升学习效率。常见的信息源有 Google 等搜索引擎，Stack Overflow、Quora 等社区，图书，API 文档，论文和博客等。&lt;/p&gt;
&lt;p&gt;这么说吧，如果今天使用中文搜索就可以满足你的知识需求，那么你就远远落后于这个时代了。如果用英文搜索才能找到你想要的知识，那么你才能算跟得上这个时代。而如果说有的问题你连用英文搜索都找不到，只能到社区里去找作者或者其他人交流，那么可以说你已真正和时代同频了。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;与高手交流&lt;/strong&gt;。程序员可以通过技术社区以及参加技术会议与高手交流，也可以通过参加开源项目来和高手切磋。常闻&amp;quot;听君一席话，胜读十年书&amp;quot;便是如此。与高手交流对程序员的学习和成长很有益处，不仅有助于了解热门的技术方向及关键的技术点，更可以通过观察和学习高手的技术思维及解决问题的方式，提高自己的技术前瞻性和技术决策力。&lt;/p&gt;
&lt;p&gt;我在 Amazon 的时候，就有人和我说，多和美国的 Principle SDE 以上的工程师交流，无论交流什么，你都会有收获的。其实，这里说的就是，学习这些牛人的思维方式和看问题的角度，这会让你有质的提高。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;举一反三的思考&lt;/strong&gt;。比如，了解了操作系统的缓存和网页缓存以后，你要思考其相同点和不同点。了解了 C++ 语言的面向对象特性以后，思考 Java 面向对象的相同点和不同点。遇到故障的时候，举一反三，把同类问题一次性地处理掉。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;不怕困难的态度&lt;/strong&gt;。遇到难点，有时不花一番力气，是不可能突破的。此时如果没有不怕困难的态度，你就容易打退堂鼓。但如果能坚持住，多思考，多下功夫，往往就能找到出路。绝大多数人是害怕困难的，所以，如果你能够不怕困难，并可以找到解决困难的方法和路径，时间一长，你就能拥有别人所不能拥有的能力。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;开放的心态&lt;/strong&gt;。实现一个目的通常有多种办法。带有开放的心态，不拘泥于一个平台、一种语言，往往能带来更多思考，也能得到更好的结果。而且，能在不同的方法和方案间做比较，比较它们的优缺点，那么你会知道在什么样的场景下用什么样的方案，你就会比一般人能够有更全面和更完整的思路。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;第三，坚持做正确的事。做正确的事，比用正确的方式做事更重要，因为这样才始终会向目的地靠拢&lt;/strong&gt;。哪些是正确的事呢？下面是我的观点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;提高效率的事&lt;/strong&gt;。你要学习和掌握良好的时间管理方式，管理好自己的时间，能显著提高自己的效率。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;自动化的事&lt;/strong&gt;。程序员要充分利用自己的职业特质，当看见有可以自动化的步骤时，编写程序来自动化操作，可以显著提高效率。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;掌握前沿技术的事&lt;/strong&gt;。掌握前沿的技术，有利于拓展自己的眼界，也有利于找到更好的工作。需要注意的是，有些技术虽然当下很火，但未必前沿，而是因为它比较易学易用，或者性价比高。由于学习一门技术需要花费不少时间，你应该选择自己最感兴趣的，有的放矢地去学习。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;知识密集型的事&lt;/strong&gt;。知识密集型是相对于劳动密集型来说的。基本上，劳动密集型的事都能通过程序和机器来完成，而知识密集型的事却仍需要人来完成，所以人的价值此时就显现出来了。虽然现在人工智能似乎能做一些知识密集型的事（包括下围棋的 AlphaGo），但是在开放领域中相对于人的智能来说还是相去甚远。掌握了领域知识的人的价值依然很高。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;技术驱动的事&lt;/strong&gt;。不仅是指用程序驱动的事，而且还包括一切技术改变生活的事。比如自动驾驶、火星登陆等。就算自己一时用不着，你也要了解这些，以便将来这些技术来临时能适应它们。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;第四，高标准要求自己。只有不断地提高标准 ，你才可能越走越高，所以，要以高标准要求自己，不断地反思、总结和审视自己，才能够提升自己&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Google 的自我评分卡&lt;/strong&gt;。Google 的评分卡是在面试 Google 时，要求应聘人对自己的技能做出评估的工具，它可以看出应聘人在各个领域的技术水平。我们可以参考 Google 的这个评分卡来给自己做评估，并通过它来不断地提高对自己的要求。（该评分卡见文末附录）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;敏锐的技术嗅觉&lt;/strong&gt;。这是一个相对综合的能力，你需要充分利用信息源，GET 到新的技术动态，并通过参与技术社区的讨论，丰富自己了解技术的角度。思考一下是否是自己感兴趣的，能解决哪些实际问题，以及其背后的原因，新技术也好，旧技术的重大版本变化也罢。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;强调实践，学以致用&lt;/strong&gt;。学习知识，一定要实际用一用，可以是工作中的项目，也可以是自己的项目，不仅有利于吸收理解，更有利于深入到技术的本质。并可以与现有技术对比一下，同样的问题，用新技术解决有什么不同，带来了哪些优势，还有哪些有待改进的地方。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Lead by Example&lt;/strong&gt;。永远在编程。不写代码，你就对技术细节不敏感，你无法做出可以实践的技术决策和方案。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;不要小看这些方法和习惯，坚持下来很有益处。谁说下一个改进方向或者重大修改建议，不可以是你给出的呢，尤其是在一些开源项目中。何为领导力，能力体现之一不就是指明技术未来的发展方向吗？&lt;/p&gt;
&lt;p&gt;吃透基础技术、提高学习能力、坚持做正确的事、高标准要求自己，不仅会让你全面提升技术技能，还能很好地锻炼自己的技术思维，培养技术前瞻性和决策力，进而形成技术领导力。&lt;/p&gt;
&lt;p&gt;然而，仅有技术还不够。作为一名合格的技术领导者，还需要有解决问题的各种软技能。比如，良好的沟通能力、组织能力、驱动力、团队协作能力等等。《技术领导之路》、《卓有成效的管理者》等多本经典图书中均有细致的讲解，这里不展开讲述，我后面内容也会有涉及。&lt;/p&gt;
&lt;h2 id=&#34;附-google-评分卡&#34;&gt;附 Google 评分卡&lt;/h2&gt;
&lt;p&gt;0 - you are unfamiliar with the subject area.&lt;/p&gt;
&lt;p&gt;1 - you can read / understand the most fundamental aspects of the subject area.&lt;/p&gt;
&lt;p&gt;2 - ability to implement small changes, understand basic principles and able to figure out additional details with minimal help.&lt;/p&gt;
&lt;p&gt;3 - basic proficiency in a subject area without relying on help.&lt;/p&gt;
&lt;p&gt;4 - you are comfortable with the subject area and all routine work on it:&lt;br&gt;
For software areas - ability to develop medium programs using all basic language features w/o book, awareness of more esoteric features (with book).&lt;/p&gt;
&lt;p&gt;For systems areas - understanding of many fundamentals of networking and systems administration, ability to run a small network of systems including recovery, debugging and nontrivial troubleshooting that relies on the knowledge of internals.&lt;/p&gt;
&lt;p&gt;5 - an even lower degree of reliance on reference materials. Deeper skills in a field or specific technology in the subject area.&lt;/p&gt;
&lt;p&gt;6 - ability to develop large programs and systems from scratch. Understanding of low level details and internals. Ability to design / deploy most large, distributed systems from scratch.&lt;/p&gt;
&lt;p&gt;7 - you understand and make use of most lesser known language features, technologies, and associated internals. Ability to automate significant amounts of systems administration.&lt;/p&gt;
&lt;p&gt;8 - deep understanding of corner cases, esoteric features, protocols and systems including &amp;ldquo;theory of operation&amp;rdquo;. Demonstrated ability to design, deploy and own very critical or large infrastructure, build accompanying automation.&lt;/p&gt;
&lt;p&gt;9 - could have written the book about the subject area but didn&amp;rsquo;t; works with standards committees on defining new standards and methodologies.&lt;/p&gt;
&lt;p&gt;10 - wrote the book on the subject area (there actually has to be a book). Recognized industry expert in the field, might have invented it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Subject Areas:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TCP/IP Networking (OSI stack, DNS etc)&lt;/li&gt;
&lt;li&gt;Unix/Linux internals&lt;/li&gt;
&lt;li&gt;Unix/Linux Systems administration&lt;/li&gt;
&lt;li&gt;Algorithms and Data Structures&lt;/li&gt;
&lt;li&gt;C&lt;/li&gt;
&lt;li&gt;C++&lt;/li&gt;
&lt;li&gt;Python&lt;/li&gt;
&lt;li&gt;Java&lt;/li&gt;
&lt;li&gt;Perl&lt;/li&gt;
&lt;li&gt;Go&lt;/li&gt;
&lt;li&gt;Shell Scripting (sh, Bash, ksh, csh)&lt;/li&gt;
&lt;li&gt;SQL and/or Database Admin&lt;/li&gt;
&lt;li&gt;Scripting language of your choice (not already mentioned)&lt;/li&gt;
&lt;li&gt;People Management&lt;/li&gt;
&lt;li&gt;Project Management&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/fc/e9/fcc761001867c60f526665e237f831e9.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 06丨牛刀小试：如何搭建优惠券计算服务和用户服务？</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/springclouod%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/06%E4%B8%A8%E7%89%9B%E5%88%80%E5%B0%8F%E8%AF%95%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E4%BC%98%E6%83%A0%E5%88%B8%E8%AE%A1%E7%AE%97%E6%9C%8D%E5%8A%A1%E5%92%8C%E7%94%A8%E6%88%B7%E6%9C%8D%E5%8A%A1/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/springclouod%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/06%E4%B8%A8%E7%89%9B%E5%88%80%E5%B0%8F%E8%AF%95%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E4%BC%98%E6%83%A0%E5%88%B8%E8%AE%A1%E7%AE%97%E6%9C%8D%E5%8A%A1%E5%92%8C%E7%94%A8%E6%88%B7%E6%9C%8D%E5%8A%A1/</guid>
      <description>
        
        
        &lt;p&gt;你好，我是姚秋辰。&lt;/p&gt;
&lt;p&gt;上一节课我们搭建了 coupon-template-serv 模块，实现了优惠券模板的创建和批量查询等功能，相信你已经对如何使用 Spring Boot 搭建应用驾轻就熟了。今天我们就来搭建优惠券平台项目的另外两个模块，coupon-calculation-serv（优惠计算服务）和 coupon-customer-serv（用户服务），组建一个完整的实战项目应用（middleware 模块将在 Spring Cloud 环节进行搭建）。&lt;/p&gt;
&lt;p&gt;通过今天的课程，你可以巩固并加深 Spring Boot 的实操能力，为接下来 Spring Cloud 微服务化改造打好前置知识的基础，在这节课里我也会分享一些关于设计模式和数据冗余的经验之谈。&lt;/p&gt;
&lt;p&gt;另外，这节课的源码都可以在Gitee 代码库中找到。你可不要只读爽文不动手敲代码，我建议你把代码下载到本地，对照着源码动手练习一遍，才能学为己用。&lt;/p&gt;
&lt;p&gt;闲话少叙，我们根据优惠券项目的依赖关系，先从上游服务 coupon-calculation-serv 开始动手搭建吧。&lt;/p&gt;
&lt;h1 id=&#34;搭建-coupon-calculation-serv&#34;&gt;搭建 coupon-calculation-serv&lt;/h1&gt;
&lt;p&gt;coupon-calculation-serv 提供了用于计算订单的优惠信息的接口，它是一个典型的&amp;quot;计算密集型&amp;quot;服务。所谓计算密集型服务一般具备下面的两个特征：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;不吃网络 IO 和磁盘空间&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;运行期主要占用 CPU、内存等计算资源&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在做大型应用架构的时候，我们通常会把计算密集型服务与 IO/ 存储密集型服务分割开来，这样做的一个主要原因是提高资源利用率。&lt;/p&gt;
&lt;p&gt;比如说，我们有一个计算密集型的微服务 A 和一个 IO 密集型微服务 B，大促峰值流量到来的时候，如果微服务 A 面临的压力比较大，我可以专门调配高性能 CPU 和内存等&amp;quot;计算类&amp;quot;的资源去定向扩容 A 集群；如果微服务 B 压力吃紧了，我可以定向调拨云上的存储资源分配给 B 集群，这样就实现了一种&amp;quot;按需分配&amp;quot;。&lt;/p&gt;
&lt;p&gt;假如微服务 A 和微服务 B 合二为一变成了一个服务，那么在分配资源的时候就无法做到定向调拨，全链路压测环节也难以精准定位各项性能指标，这难免出现资源浪费的情况。这也是为什么，我要把优惠计算这个服务单独拿出来的原因。&lt;/p&gt;
&lt;p&gt;现在，我们开始着手搭建 coupon-calculation-serv 下的子模块。和 coupon-template-serv 结构类似，coupon-calculation-serv 下面也分了若干个子模块，包括 API 层和业务逻辑层。API 层定义了公共的 POJO 类，业务逻辑层主要实现优惠价格计算业务。因为 calculation 服务并不需要访问数据库，所以没有 DAO 模块。&lt;/p&gt;
&lt;p&gt;根据子模块间的依赖关系，我们就先从 coupon-calculation-api 这个接口层子模块开始搭建吧。&lt;/p&gt;
&lt;h1 id=&#34;搭建-coupon-calculation-api&#34;&gt;搭建 coupon-calculation-api&lt;/h1&gt;
&lt;p&gt;如果 coupon-calculation-serv 需要计算订单的优惠价格，那就得知道当前订单用了什么优惠券。封装了优惠券信息的 Java 类 CouponInfo 位于 coupon-template-api 包下，因此我们需要把 coupon-template-api 的依赖项加入到 coupon-calculation-api 中。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;${project.groupId}&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;coupon-template-api&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;${project.version}&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;添加好了依赖项之后，接下来我们定义用于封装订单信息的 ShoppingCart 类。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;@Data
@NoArgsConstructor
@AllArgsConstructor
public class ShoppingCart {
    // 订单的商品列表 - 
    @NotEmpty
    private List&amp;lt;Product&amp;gt; products;
     
    // 封装了优惠券信息，目前计算服务只支持单张优惠券
    // 为了考虑到以后多券的扩展性，所以定义成了List
    private Long couponId;   
    private List&amp;lt;CouponInfo&amp;gt; couponInfos;

    // 订单的最终价格
    private long cost;
    // 用户ID
    @NotNull
    private Long userId;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在上面的源码中，我们看到 ShoppingCart 订单类中使用了 Product 对象，来封装当前订单的商品列表。在 Product 类中包含了商品的单价、商品数量，以及当前商品的门店 ID。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;@Data
@NoArgsConstructor
@AllArgsConstructor
public class Product {
    // 商品的价格
    private long price;
    // 商品在购物车里的数量
    private Integer count;
    // 商品销售的门店
    private Long shopId;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在电商领域中，商品的数量通常不能以 Integer 整数来表示，这是因为只有标品才能以整数计件。对于像蔬菜、肉类等非标品来说，它们的计件单位并不是&amp;quot;个&amp;quot;。所以在实际项目中，尤其是零售行业的业务系统里，计件单位要允许小数位的存在。而我们的实战项目为了简化业务，就假定所有商品都是&amp;quot;标品&amp;quot;了。&lt;/p&gt;
&lt;p&gt;在下单的时候，你可能有多张优惠券可供选择，你需要通过&amp;quot;&lt;strong&gt;价格试算&lt;/strong&gt;&amp;ldquo;来模拟计算每张优惠券可以扣减的金额，进而选择最优惠的券来使用。SimulationOrder 和 SimulationResponse 分别代表了&amp;quot;价格试算&amp;quot;的订单类，以及返回的计算结果 Response。我们来看一下这两个类的源码。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;// 优惠券价格试算
@Data
@NoArgsConstructor
@AllArgsConstructor
public class SimulationOrder {

    @NotEmpty
    private List&amp;lt;Product&amp;gt; products;

    @NotEmpty
    private List&amp;lt;Long&amp;gt; couponIDs;

    private List&amp;lt;CouponInfo&amp;gt; couponInfos;

    @NotNull
    private Long userId;
}

// 订单试算结果，可以看出哪个优惠券的优惠力度最大
@Data
@NoArgsConstructor
public class SimulationResponse {
    // 最省钱的coupon
    private Long bestCouponId;
    // 每一个coupon对应的order价格
    private Map&amp;lt;Long, Long&amp;gt; couponToOrderPrice = Maps.newHashMap();
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;到这里，coupon-calculation-api 模块就搭建好了。因为 calculation 服务不需要访问数据库，所以我们就不用搭建 dao 模块了，直接来实现 coupon-calculation-impl 业务层的代码逻辑。&lt;/p&gt;
&lt;h1 id=&#34;搭建-coupon-calculation-impl&#34;&gt;搭建 coupon-calculation-impl&lt;/h1&gt;
&lt;p&gt;首先，我们在 coupon-calculation-impl 的 pom.xml 文件中添加下面的三个依赖项。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;${project.groupId}&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;coupon-template-api&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;${project.version}&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;

&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;${project.groupId}&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;coupon-calculation-api&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;${project.version}&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;

&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;从 coupon-template-api 和 coupon-calculation-api 两个依赖项中，你可以拿到订单优惠计算过程用到的 POJO 对象。接下来，我们可以动手实现优惠计算逻辑了。&lt;/p&gt;
&lt;p&gt;在搭建优惠计算业务逻辑的过程中，我运用了模板设计模式来封装计算逻辑。模板模式是一种基于抽象类的设计模式，它的思想很简单，就是&lt;strong&gt;将共性的算法骨架部分上升到抽象层，将个性部分延迟到子类中去实现&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;优惠券类型有很多种，比如满减券、打折券、随机立减等等，这些券的计算流程（共性部分）是相同的，但具体的计算规则（个性部分）是不同的。我将共性的部分抽象成了 AbstractRuleTemplate 抽象类，将各个券的差异性计算方式做成了抽象类的子类。&lt;/p&gt;
&lt;p&gt;让我们看一下计算逻辑的类结构图。&lt;br&gt;
&lt;img src=&#34;https://static001.geekbang.org/resource/image/8b/a7/8b3bef22448b63a5db17f4a62902aaa7.jpg?wh=2000x1323&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;在这张图里，顶层接口 RuleTemplate 定义了 calculate 方法，抽象模板类 AbstractRuleTemplate 将通用的模板计算逻辑在 calculate 方法中实现，同时它还定义了一个抽象方法 calculateNewPrice 作为子类的扩展点。各个具体的优惠计算类通过继承 AbstractRuleTemplate，并实现 calculateNewPrice 来编写自己的优惠计算方式。&lt;/p&gt;
&lt;p&gt;我们先来看一下 AbstractRuleTemplate 抽象类的代码，走读 calculate 模板方法中的计算逻辑实现。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;public ShoppingCart calculate(ShoppingCart order) {
    // 获取订单总价
    Long orderTotalAmount = getTotalPrice(order.getProducts());
    // 获取以shopId为维度的总价统计
    Map&amp;lt;Long, Long&amp;gt; sumAmount = getTotalPriceGroupByShop(order.getProducts());
    CouponTemplateInfo template = order.getCouponInfos().get(0).getTemplate();
    // 最低消费限制
    Long threshold = template.getRule().getDiscount().getThreshold();
    // 优惠金额或者打折比例
    Long quota = template.getRule().getDiscount().getQuota();
    // 如果优惠券未指定shopId，则shopTotalAmount=orderTotalAmount
    // 如果指定了shopId，则shopTotalAmount=对应门店下商品总价
    Long shopId = template.getShopId();
    Long shopTotalAmount = (shopId == null) ? orderTotalAmount : sumAmount.get(shopId);
    
    // 如果不符合优惠券使用标准, 则直接按原价走，不使用优惠券
    if (shopTotalAmount == null || shopTotalAmount &amp;lt; threshold) {
        log.debug(&amp;#34;Totals of amount not meet&amp;#34;);
        order.setCost(orderTotalAmount);
        order.setCouponInfos(Collections.emptyList());
        return order;
    }
    // 子类中实现calculateNewPrice计算新的价格
    Long newCost = calculateNewPrice(orderTotalAmount, shopTotalAmount, quota);
    if (newCost &amp;lt; minCost()) {
        newCost = minCost();
    }
    order.setCost(newCost);
    log.debug(&amp;#34;original price={}, new price={}&amp;#34;, orderTotalAmount, newCost);
    return order;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在上面的源码中，我们看到大部分计算逻辑都在抽象类中做了实现，子类只要实现 calculateNewPrice 方法完成属于自己的订单价格计算就好。我们以满减规则类为例来看一下它的实现。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;@Slf4j
@Component
public class MoneyOffTemplate extends AbstractRuleTemplate implements RuleTemplate {
    @Override
    protected Long calculateNewPrice(Long totalAmount, Long shopAmount, Long quota) {
        // benefitAmount是扣减的价格
        // 如果当前门店的商品总价&amp;lt;quota，那么最多只能扣减shopAmount的钱数
        Long benefitAmount = shopAmount &amp;lt; quota ? shopAmount : quota;
        return totalAmount - benefitAmount;
    }    
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在上面的源码中，我们看到子类业务的逻辑非常简单清爽。通过模板设计模式，我在抽象类中封装了共性逻辑，在子类中扩展了可变逻辑，每个子类只用关注自己的特定实现即可，使得代码逻辑变得更加清晰，大大降低了代码冗余。&lt;/p&gt;
&lt;p&gt;随着业务发展，你的优惠券模板类型可能会进一步增加，比如赠品券、随机立减券等等，如果当前的抽象类无法满足新的需求，你可以通过建立多级抽象类的方式进一步增加抽象层次，不断将共性不变的部分抽取为抽象层。&lt;/p&gt;
&lt;p&gt;创建完优惠计算逻辑，我们接下来看一下 Service 层的代码实现逻辑。Service 层的 calculateOrderPrice 代码非常简单，通过 CouponTemplateFactory 工厂类获取到具体的计算规则，然后调用 calculate 计算订单价格就好了。simulate 方法实现了订单价格试算，帮助用户在下单之前了解每个优惠券可以扣减的金额，从而选出最省钱的那个券。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;@Slf4j
@Service
public class CouponCalculationServiceImpl implements CouponCalculationService {
    
    // 优惠券结算
    // 这里通过Factory类决定使用哪个底层Rule，底层规则对上层透明
    @Override
    public ShoppingCart calculateOrderPrice(@RequestBody ShoppingCart cart) {
        log.info(&amp;#34;calculate order price: {}&amp;#34;, JSON.toJSONString(cart));
        RuleTemplate ruleTemplate = couponTemplateFactory.getTemplate(cart);
        return ruleTemplate.calculate(cart);
    }
    
    // 试计算每个优惠券在使用后订单的价格
    // 页面上给用户提示最省钱的优惠券
    @Override
    public SimulationResponse simulate(@RequestBody SimulationOrder order) {
        SimulationResponse response = new SimulationResponse();
        Long minOrderPrice = Long.MIN_VALUE;
        // 计算每一个优惠券的订单价格
        for (CouponInfo coupon : order.getCouponInfos()) {
            ShoppingCart cart = new ShoppingCart();
            cart.setProducts(order.getProducts());
            cart.setCouponInfos(Lists.newArrayList(coupon));
            cart = couponProcessorFactory.getTemplate(cart).calculate(cart);
            Long couponId = coupon.getId();
            Long orderPrice = cart.getCost();
            // 设置当前优惠券对应的订单价格
            response.getCouponToOrderPrice().put(couponId, orderPrice);
            // 比较订单价格，设置当前最优优惠券的ID
            if (minOrderPrice &amp;gt; orderPrice) {
                response.setBestCouponId(coupon.getId());
                minOrderPrice = orderPrice;
            }
        }
        return response;
    }
    // 其它方法未列出，请至源码仓库查看完整代码 
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在上面的源码中，我们看到，优惠券结算方法不用关心订单上使用的优惠券是满减券还是打折券，因为工厂方法会将子类转为顶层接口 RuleTemplate 返回。在写代码的过程中，我们也要有这样一种意识，就是&lt;strong&gt;尽可能对上层业务屏蔽其底层业务复杂度&lt;/strong&gt;，底层具体业务逻辑的修改对上层是无感知的，这其实也是&lt;strong&gt;开闭原则&lt;/strong&gt;的思想。&lt;/p&gt;
&lt;p&gt;完成 Service 层后，我们接下来新建一个 CouponCalculationController 类，对外暴露 2 个 POST 接口，第一个接口完成订单优惠价格计算，第二个接口完成优惠券价格试算。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;@Slf4j
@RestController
@RequestMapping(&amp;#34;calculator&amp;#34;)
public class CouponCalculationController {
    @Autowired
    private CouponCalculationService couponCalculationService;
    
    // 优惠券结算
    @PostMapping(&amp;#34;/checkout&amp;#34;)
    @ResponseBody
    public ShoppingCart calculateOrderPrice(@RequestBody ShoppingCart settlement) {
        log.info(&amp;#34;do calculation: {}&amp;#34;, JSON.toJSONString(settlement));
        return couponCalculationService.calculateOrderPrice(settlement);
    }
    
    // 优惠券列表挨个试算
    // 给客户提示每个可用券的优惠额度，帮助挑选
    @PostMapping(&amp;#34;/simulate&amp;#34;)
    @ResponseBody
    public SimulationResponse simulate(@RequestBody SimulationOrder order) {
        log.info(&amp;#34;do simulation: {}&amp;#34;, JSON.toJSONString(order));
        return couponCalculationService.simulateOrder(order);
    }
    
    // 其它方法未列出，请至源码仓库查看完整代码 
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;好了，现在你已经完成了所有业务逻辑的源码。最后一步画龙点睛，你还需要为 coupon-calculation-impl 应用创建一个 Application 启动类并添加 application.yml 配置项。因为它并不需要访问数据库，所以你不需要在配置文件或者启动类注解上添加 spring-data 的相关内容。&lt;/p&gt;
&lt;p&gt;到这里，我们就完成了优惠计算服务的搭建工作，你可以到我的代码仓库中查看完整的 coupon-calculation-serv 源码实现。&lt;/p&gt;
&lt;p&gt;下面，我们去搭建优惠券项目的最后一个服务：coupon-customer-serv。&lt;/p&gt;
&lt;h1 id=&#34;搭建-coupon-customer-serv&#34;&gt;搭建 coupon-customer-serv&lt;/h1&gt;
&lt;p&gt;coupon-customer-serv 是一个服务于用户的子模块，它的结构和 coupon-template-serv 一样，包含了 API 层、DAO 层和业务逻辑层。它实现了用户领券、用户优惠券查找和订单结算功能。&lt;/p&gt;
&lt;p&gt;为了简化业务逻辑，我在源码里省略了&amp;quot;用户注册&amp;quot;等业务功能，使用 userId 来表示一个已注册的用户。&lt;/p&gt;
&lt;p&gt;按照惯例，我们先从 API 层开始搭建，搭建 coupon-customer-api 的过程非常简单。&lt;/p&gt;
&lt;h1 id=&#34;搭建-coupon-customer-api&#34;&gt;搭建 coupon-customer-api&lt;/h1&gt;
&lt;p&gt;首先，我们需要把 coupon-template-api 和 coupon-calculation-api 这两个服务的依赖项添加到 coupon-customer-api 的 pom 依赖中，这样一来 customer 服务就可以引用到这两个服务的 Request 和 Response 对象了。&lt;/p&gt;
&lt;p&gt;接下来，我们在 API 子模块中创建一个 RequestCoupon 类，作为用户领取优惠券的请求参数，通过传入用户 ID 和优惠券模板 ID，用户可以领取一张由指定模板打造的优惠券。另一个类是 SearchCoupon，用来封装优惠券查询的请求参数。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;@Data
@NoArgsConstructor
@AllArgsConstructor
public class RequestCoupon {
    // 用户领券
    @NotNull
    private Long userId;

    // 券模板ID
    @NotNull
    private Long couponTemplateId;

}

@Data
@NoArgsConstructor
@AllArgsConstructor
public class SearchCoupon {
    @NotNull
    private Long userId;
    private Long shopId;
    private Integer couponStatus;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;到这里，coupon-customer-api 就搭建完了。接下里我们去搭建 coupon-customer-dao 层，从数据层实现用户优惠券的增删改查。&lt;/p&gt;
&lt;h1 id=&#34;搭建-coupon-customer-dao&#34;&gt;搭建 coupon-customer-dao&lt;/h1&gt;
&lt;p&gt;我在 DAO 子模块中创建了一个 Coupon 数据库实体对象用于保存用户领到的优惠券，并按照 spring-data-jpa 规范创建了一个 CouponDAO 接口用来提供 CRUD 操作。&lt;/p&gt;
&lt;p&gt;我们先来看一下 Coupon 实体对象的内容。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;// 使用了lomkob注解自动生成建造者代码和getter、setter
@Builder
@Data
@NoArgsConstructor
@AllArgsConstructor
@Entity
@EntityListeners(AuditingEntityListener.class)
@Table(name = &amp;#34;coupon&amp;#34;)
public class Coupon {

    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    @Column(name = &amp;#34;id&amp;#34;, nullable = false)
    private Long id;

    // 对应的模板ID - 不使用one to one映射
    @Column(name = &amp;#34;template_id&amp;#34;, nullable = false)
    private Long templateId;

    // 拥有这张优惠券的用户的ID
    @Column(name = &amp;#34;user_id&amp;#34;, nullable = false)
    private Long userId;

    // 冗余一个shop id方便查找
    @Column(name = &amp;#34;shop_id&amp;#34;)
    private Long shopId;

    // 自动生成时间戳
    @CreatedDate
    @Column(name = &amp;#34;created_time&amp;#34;, nullable = false)
    private Date createdTime;

    // CouponStatusConverter实现了AttributeConverter接口
    // 将数据库value转化为CouponStatus类
    @Column(name = &amp;#34;status&amp;#34;, nullable = false)
    @Convert(converter = CouponStatusConverter.class)
    private CouponStatus status;

    @Transient
    private CouponTemplateInfo templateInfo;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在上面的源码中，我在 class 级别使用了 Lombok 注解自动生成代码，如果你对 Lomkob 比较感兴趣，可以从Lomkob 官网上获取更多的使用方法。&lt;/p&gt;
&lt;p&gt;从这段代码引申一下，我想和你分享一个关于&amp;rdquo;&lt;strong&gt;数据冗余&lt;/strong&gt;&amp;ldquo;的小知识点。我们看到 Coupon 实体对象中冗余保存了一个 Shop ID，之所以说它是冗余字段，是因为 Shop ID 可以从 CouponTemplate 表中获取，顺着 Coupon 对象的 templateID 字段可以关联到 CouponTemplate 表，进而获取到 ShopID 对象。&lt;/p&gt;
&lt;p&gt;那我们为什么需要在 Coupon 表中再保存一次 shop ID 呢？如果严格遵循数据库的范式，那确实不应该保存一个冗余的 shop ID 字段，但我们也不要忘了，所谓范式和规则就是留给后人打破的。&lt;/p&gt;
&lt;p&gt;数据库的标准范式是上一个时代的产物，以那个时代的眼光来看，&amp;ldquo;存储&amp;quot;是一项很宝贵的资源，在做程序设计的时候应该尽可能节省磁盘空间、内存空间，反倒&amp;quot;性能&amp;quot;和&amp;quot;高并发&amp;quot;并不是需要担心的事情。&lt;/p&gt;
&lt;p&gt;当我们用现在的眼光来审视程序设计，你会发现&amp;quot;存储资源&amp;quot;已经不再是制约生产力的瓶颈，&lt;strong&gt;为了应对高并发的场景，你必须尽可能提高系统的吞吐量和性能&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;因此，你经常可以看到一二线大厂的高并发系统大量使用了&amp;quot;数据冗余&amp;quot;和&amp;quot;数据异构&amp;quot;方案。这是一个&amp;rdquo;&lt;strong&gt;以空间换时间&lt;/strong&gt;&amp;ldquo;的路子，通过将一份数据冗余或异构到多处，提升业务的查询和处理效率。&lt;/p&gt;
&lt;p&gt;了解了数据冗余的扩展知识后，我们来看下 DAO 层的接口类的内容：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;public interface CouponDao extends JpaRepository&amp;lt;Coupon, Long&amp;gt; {
    // 根据用户ID和Template ID，统计用户从当前优惠券模板中领了多少张券
    long countByUserIdAndTemplateId(Long userId, Long templateId);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在上面的源码中，我们只创建了一个接口用于 count 计算，至于其他增删改查功能则统一由父类 JpaRepository 一手包办了。spring-data-jpa 沿袭了 spring 框架的简约风，大道至简解放双手，整个 Spring 框架从诞生至今，也一直都在朝着不断简化的方向发展。&lt;/p&gt;
&lt;p&gt;到这里，coupon-customer-dao 层的代码就写完了，接下来我们去搞定最后一个子模块 coupon-customer-impl 业务逻辑层。&lt;/p&gt;
&lt;h1 id=&#34;搭建-coupon-customer-impl&#34;&gt;搭建 coupon-customer-impl&lt;/h1&gt;
&lt;p&gt;既然 coupon-customer-impl 需要调用 template 和 calculation 两个服务，在没有进入微服务化改造之前，我们只能先暂时委屈一下 template 和 calculation，将它俩作为 customer 服务的一部分，做成一个三合一的单体应用。等你学到微服务课程的时候，这个单体应用会被拆分成独立的微服务模块。&lt;/p&gt;
&lt;p&gt;首先，你需要将 template、calculation 的依赖项添加到 coupon-customer-impl 的配置文件中，注意这里我们添加的可不是 API 接口层的依赖，而是 Impl 接口实现层的依赖。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;    &amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;${project.groupId}&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;coupon-customer-dao&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;${project.version}&amp;lt;/version&amp;gt;
    &amp;lt;/dependency&amp;gt;
    &amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;${project.groupId}&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;coupon-calculation-impl&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;${project.version}&amp;lt;/version&amp;gt;
    &amp;lt;/dependency&amp;gt;
    &amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;${project.groupId}&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;coupon-template-impl&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;${project.version}&amp;lt;/version&amp;gt;
    &amp;lt;/dependency&amp;gt;
    &amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt;
    &amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;添加完依赖项之后，我们就可以去动手实现业务逻辑层了。&lt;/p&gt;
&lt;p&gt;CouponCustomerService 是业务逻辑层的接口抽象，我添加了几个方法，用来实现用户领券、查询优惠券、下单核销优惠券、优惠券试算等功能。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;// 用户对接服务
public interface CouponCustomerService {
    // 领券接口
    Coupon requestCoupon(RequestCoupon request);
    // 核销优惠券
    ShoppingCart placeOrder( info);
    // 优惠券金额试算
    SimulationResponse simulateOrderPrice(SimulationOrder order);
    // 用户删除优惠券
    void deleteCoupon(Long userId, Long couponId);
    // 查询用户优惠券
    List&amp;lt;CouponInfo&amp;gt; findCoupon(SearchCoupon request);
    // xxx其它方法请参考源码
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里，我以 placeOrder 方法为例，带你走读一下它的源码。如果你对其它方法的源码感兴趣，可以到Gitee 源码库中找到 Spring Boot 急速落地篇的 CouponCustomerServiceImpl 类，查看源代码。&lt;/p&gt;
&lt;p&gt;placeOrder 方法实现了用户下单 + 优惠券核销的功能，我们来看一下它的实现逻辑。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;@Override
@Transactional
public ShppingCart placeOrder(ShppingCart order) {
    // 购物车为空，丢出异常
    if (CollectionUtils.isEmpty(order.getProducts())) {
        log.error(&amp;#34;invalid check out request, order={}&amp;#34;, order);
        throw new IllegalArgumentException(&amp;#34;cart is empty&amp;#34;);
    }

    Coupon coupon = null;
    if (order.getCouponId() != null) {
        // 如果有优惠券就把它查出来，看是不是属于当前用户并且可用
        Coupon example = Coupon.builder().userId(order.getUserId())
                .id(order.getCouponId())
                .status(CouponStatus.AVAILABLE)
                .build();
        coupon = couponDao.findAll(Example.of(example)).stream()
                .findFirst()
                // 如果当前用户查不到可用优惠券，就抛出错误
                .orElseThrow(() -&amp;gt; new RuntimeException(&amp;#34;Coupon not found&amp;#34;));        
        // 优惠券有了，再把它的券模板信息查出
        // 券模板里的Discount规则会在稍后用于订单价格计算
        CouponInfo couponInfo = CouponConverter.convertToCoupon(coupon);
        couponInfo.setTemplate(templateService.loadTemplateInfo(coupon.getTemplateId()));
        order.setCouponInfos(Lists.newArrayList(couponInfo));
    }

    // 调用calculation服务使用优惠后的订单价格
    ShppingCart checkoutInfo = calculationService.calculateOrderPrice(order);

    if (coupon != null) {
        // 如果优惠券没有被结算掉，而用户传递了优惠券，报错提示该订单满足不了优惠条件
        if (CollectionUtils.isEmpty(checkoutInfo.getCouponInfos())) {
            log.error(&amp;#34;cannot apply coupon to order, couponId={}&amp;#34;, coupon.getId());
            throw new IllegalArgumentException(&amp;#34;coupon is not applicable to this order&amp;#34;);
        }
        log.info(&amp;#34;update coupon status to used, couponId={}&amp;#34;, coupon.getId());
        coupon.setStatus(CouponStatus.USED);
        couponDao.save(coupon);
    }
    return checkoutInfo;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在上面的源码中，我们看到 Coupon 对象的构造使用了 Builder 链式编程的风格，这是得益于在 Coupon 类上面声明的 Lombok 的 Builder 注解，只用一个 Builder 注解就能享受链式构造的体验。&lt;/p&gt;
&lt;p&gt;搞定了业务逻辑层后，接下来轮到 Controller 部分了，我在 CouponCustomerController 中对外暴露了几个服务，这些服务调用 CouponCustomerServiceImpl 中的方法实现各自的业务逻辑。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;@Slf4j
@RestController
@RequestMapping(&amp;#34;coupon-customer&amp;#34;)
public class CouponCustomerController {
    @Autowired
    private CouponCustomerService customerService;
  
    // ....省略部分方法，完整方法列表请参考源码    

    // 用户模拟计算每个优惠券的优惠价格
    @PostMapping(&amp;#34;simulateOrder&amp;#34;)
    public SimulationResponse simulate(@Valid @RequestBody SimulationOrder order) {
        return customerService.simulateOrderPrice(order);
    }
    
    // 用户删除优惠券 - 非物理删除
    @DeleteMapping(&amp;#34;deleteCoupon&amp;#34;)
    public void deleteCoupon(@RequestParam(&amp;#34;userId&amp;#34;) Long userId,
                         @RequestParam(&amp;#34;couponId&amp;#34;) Long couponId) {
        customerService.deleteCoupon(userId, couponId);
    }
    
    // 下单核销优惠券
    @PostMapping(&amp;#34;checkout&amp;#34;)
    public ShppingCart checkout(@Valid @RequestBody ShppingCart info) {
        return customerService.placeOrder(info);
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;以上，就是所有的业务逻辑代码部分了。接下来你只需要完成启动类和配置文件，就可以启动项目做测试了。我先来带你看一下启动类的部分：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;@SpringBootApplication
@EnableJpaAuditing
@ComponentScan(basePackages = {&amp;#34;com.geekbang&amp;#34;})
@EnableTransactionManagement
//用于扫描Dao @Repository
@EnableJpaRepositories(basePackages = {&amp;#34;com.geekbang&amp;#34;})
//用于扫描JPA实体类 @Entity，默认扫本包当下路径
@EntityScan(basePackages = {&amp;#34;com.geekbang&amp;#34;})
public class Application {

    public static void main(String[] args) {
        SpringApplication.run(Application.class, args);
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在上面的源码中，我们看到很多注解上都注明了 com.geekbang 作为包路径。之所以这么做，是因为 Spring Boot 的潜规则是将当前启动类类所在 package 作为扫包路径。&lt;/p&gt;
&lt;p&gt;如果你的 Application 在 com.geekbang.customer 下，而你在项目中又需要加载来自 com.geekbang.template 下的类资源，就必须额外声明扫包路径，否则只有在 com.geekbang.customer 和其子路径之下的资源才会被加载。&lt;/p&gt;
&lt;p&gt;关于配置项的部分，你可以直接把 coupon-template-impl 的配置文件 application.yml 照搬过来，不过，&lt;strong&gt;要记得把里面配置的 spring.application.name 改成 coupon-customer-serv&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;好，到这里，我们优惠券平台项目的 Spring Boot 版本就搭建完成了。现在，coupon-customer-serv 已经成了一个三合一的单体应用，你只要在本地启动这一个应用，就可以调用 customer、template 和 calculation 三个服务的功能。&lt;/p&gt;
&lt;h1 id=&#34;总结&#34;&gt;总结&lt;/h1&gt;
&lt;p&gt;现在，我们来回顾一下这两节 Spring Boot 实战课的重点内容。通过这两节课，我带你搭建了完整的 Spring Boot 版优惠券平台的三个子模块。为了让项目结构更加清晰，我用&lt;strong&gt;分层设计&lt;/strong&gt;的思想将每个模块拆分成 API 层、DAO 层和业务层。在搭建过程中，我们使用 spring-data-jpa 搞定了数据层，短短几行代码就能实现复杂的 CRUD 操作；使用 spring-web 搭建了 Controller 层，对外暴露了 RESTFul 风格的接口。&lt;/p&gt;
&lt;p&gt;我们学习技术也分为外功修为和内功修行，讲究的是内外兼修。技术框架总会不断推陈出新，学会怎么使用一门技术，这修习的是外功。你掌握了一个功能强大的新框架，外功招式自然凌厉几分。但是能决定你武力值的上限有多高，还要靠你在工作学习中不断提高内功修为。&lt;/p&gt;
&lt;p&gt;外功见效快而内功需要长期磨炼，就像我这节课分享的设计模式一样，设计模式就是典型的内功心法，学会一两种设计模式不会让你的技术水平产生突飞猛进的提高，但是当你逐渐融会贯通把各种设计模式活学活用到代码中，境界层次就变得不一样了。&lt;/p&gt;
&lt;p&gt;从下一节课开始，我们将进入 Spring Cloud 基础篇的学习，通过基础篇的学习，你将熟练使用 Nacos、Loadbalancer 和 OpenFeign 组件来搭建基于微服务架构的跨服务调用。&lt;/p&gt;
&lt;h1 id=&#34;思考题&#34;&gt;思考题&lt;/h1&gt;
&lt;p&gt;如果我们分别把 coupon-customer-serv、coupon-template-serv 和 coupon-calculation-serv 分别部署在集群 A、B 和 C 上，你能想到几种方式，使得这几个应用可以在集群环境中互相发起调用呢？&lt;/p&gt;
&lt;p&gt;我给你一个小提示，在思考这个问题的时候，你要想到一点，服务有可能会发生上下线而且集群也可能会扩容，要尽可能让调用请求发到正常工作的机器上，提高请求成功率。欢迎你在留言区分享你的想法和收获，我在留言区等你。&lt;/p&gt;
&lt;p&gt;好啦，这节课就结束啦。也欢迎你把这节课分享给更多对 Spring Cloud 感兴趣的朋友。我是姚秋辰，我们下节课再见！&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 06丨白话容器基础（二）：隔离与限制</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90-kubernetes/06%E4%B8%A8%E7%99%BD%E8%AF%9D%E5%AE%B9%E5%99%A8%E5%9F%BA%E7%A1%80%E4%BA%8C%E9%9A%94%E7%A6%BB%E4%B8%8E%E9%99%90%E5%88%B6/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90-kubernetes/06%E4%B8%A8%E7%99%BD%E8%AF%9D%E5%AE%B9%E5%99%A8%E5%9F%BA%E7%A1%80%E4%BA%8C%E9%9A%94%E7%A6%BB%E4%B8%8E%E9%99%90%E5%88%B6/</guid>
      <description>
        
        
        &lt;p&gt;你好，我是张磊。我今天和你分享的主题是：白话容器基础之隔离与限制。&lt;/p&gt;
&lt;p&gt;在上一篇文章中，我详细介绍了 Linux 容器中用来实现&amp;quot;隔离&amp;quot;的技术手段：Namespace。而通过这些讲解，你应该能够明白，&lt;strong&gt;Namespace 技术实际上修改了应用进程看待整个计算机&amp;quot;视图&amp;quot;，即它的&amp;quot;视线&amp;quot;被操作系统做了限制，只能&amp;quot;看到&amp;quot;某些指定的内容&lt;/strong&gt;。但对于宿主机来说，这些被&amp;quot;隔离&amp;quot;了的进程跟其他进程并没有太大区别。&lt;/p&gt;
&lt;p&gt;说到这一点，相信你也能够知道我在上一篇文章最后给你留下的第一个思考题的答案了：在之前虚拟机与容器技术的对比图里，不应该把 Docker Engine 或者任何容器管理工具放在跟 Hypervisor 相同的位置，因为它们并不像 Hypervisor 那样对应用进程的隔离环境负责，也不会创建任何实体的&amp;quot;容器&amp;quot;，真正对隔离环境负责的是宿主机操作系统本身：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/9f/59/9f973d5d0faab7c6361b2b67800d0e59.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;所以，在这个对比图里，我们应该把 Docker 画在跟应用同级别并且靠边的位置。这意味着，用户运行在容器里的应用进程，跟宿主机上的其他进程一样，都由宿主机操作系统统一管理，只不过这些被隔离的进程拥有额外设置过的 Namespace 参数。而 Docker 项目在这里扮演的角色，更多的是旁路式的辅助和管理工作。&lt;/p&gt;
&lt;p&gt;我在后续分享 CRI 和容器运行时的时候还会专门介绍到，其实像 Docker 这样的角色甚至可以去掉。&lt;/p&gt;
&lt;p&gt;这样的架构也解释了为什么 Docker 项目比虚拟机更受欢迎的原因。&lt;/p&gt;
&lt;p&gt;这是因为，使用虚拟化技术作为应用沙盒，就必须要由 Hypervisor 来负责创建虚拟机，这个虚拟机是真实存在的，并且它里面必须运行一个完整的 Guest OS 才能执行用户的应用进程。这就不可避免地带来了额外的资源消耗和占用。&lt;/p&gt;
&lt;p&gt;根据实验，一个运行着 CentOS 的 KVM 虚拟机启动后，在不做优化的情况下，虚拟机自己就需要占用 100~200 MB 内存。此外，用户应用运行在虚拟机里面，它对宿主机操作系统的调用就不可避免地要经过虚拟化软件的拦截和处理，这本身又是一层性能损耗，尤其对计算资源、网络和磁盘 I/O 的损耗非常大。&lt;/p&gt;
&lt;p&gt;而相比之下，容器化后的用户应用，却依然还是一个宿主机上的普通进程，这就意味着这些因为虚拟化而带来的性能损耗都是不存在的；而另一方面，使用 Namespace 作为隔离手段的容器并不需要单独的 Guest OS，这就使得容器额外的资源占用几乎可以忽略不计。&lt;/p&gt;
&lt;p&gt;所以说，&lt;strong&gt;&amp;ldquo;敏捷&amp;quot;和&amp;quot;高性能&amp;quot;是容器相较于虚拟机最大的优势，也是它能够在 PaaS 这种更细粒度的资源管理平台上大行其道的重要原因。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;不过，有利就有弊，基于 Linux Namespace 的隔离机制相比于虚拟化技术也有很多不足之处，其中最主要的问题就是：&lt;strong&gt;隔离得不彻底。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;首先，既然容器只是运行在宿主机上的一种特殊的进程，那么多个容器之间使用的就还是同一个宿主机的操作系统内核。&lt;/p&gt;
&lt;p&gt;尽管你可以在容器里通过 Mount Namespace 单独挂载其他不同版本的操作系统文件，比如 CentOS 或者 Ubuntu，但这并不能改变共享宿主机内核的事实。这意味着，如果你要在 Windows 宿主机上运行 Linux 容器，或者在低版本的 Linux 宿主机上运行高版本的 Linux 容器，都是行不通的。&lt;/p&gt;
&lt;p&gt;而相比之下，拥有硬件虚拟化技术和独立 Guest OS 的虚拟机就要方便得多了。最极端的例子是，Microsoft 的云计算平台 Azure，实际上就是运行在 Windows 服务器集群上的，但这并不妨碍你在它上面创建各种 Linux 虚拟机出来。&lt;/p&gt;
&lt;p&gt;其次，在 Linux 内核中，有很多资源和对象是不能被 Namespace 化的，最典型的例子就是：时间。&lt;/p&gt;
&lt;p&gt;这就意味着，如果你的容器中的程序使用 settimeofday(2) 系统调用修改了时间，整个宿主机的时间都会被随之修改，这显然不符合用户的预期。相比于在虚拟机里面可以随便折腾的自由度，在容器里部署应用的时候，&amp;ldquo;什么能做，什么不能做&amp;rdquo;，就是用户必须考虑的一个问题。&lt;/p&gt;
&lt;p&gt;此外，由于上述问题，尤其是共享宿主机内核的事实，容器给应用暴露出来的攻击面是相当大的，应用&amp;quot;越狱&amp;quot;的难度自然也比虚拟机低得多。&lt;/p&gt;
&lt;p&gt;更为棘手的是，尽管在实践中我们确实可以使用 Seccomp 等技术，对容器内部发起的所有系统调用进行过滤和甄别来进行安全加固，但这种方法因为多了一层对系统调用的过滤，一定会拖累容器的性能。何况，默认情况下，谁也不知道到底该开启哪些系统调用，禁止哪些系统调用。&lt;/p&gt;
&lt;p&gt;所以，在生产环境中，没有人敢把运行在物理机上的 Linux 容器直接暴露到公网上。当然，我后续会讲到的基于虚拟化或者独立内核技术的容器实现，则可以比较好地在隔离与性能之间做出平衡。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;在介绍完容器的&amp;quot;隔离&amp;quot;技术之后，我们再来研究一下容器的&amp;quot;限制&amp;quot;问题。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;也许你会好奇，我们不是已经通过 Linux Namespace 创建了一个&amp;quot;容器&amp;quot;吗，为什么还需要对容器做&amp;quot;限制&amp;quot;呢？&lt;/p&gt;
&lt;p&gt;我还是以 PID Namespace 为例，来给你解释这个问题。&lt;/p&gt;
&lt;p&gt;虽然容器内的第 1 号进程在&amp;quot;障眼法&amp;quot;的干扰下只能看到容器里的情况，但是宿主机上，它作为第 100 号进程与其他所有进程之间依然是平等的竞争关系。这就意味着，虽然第 100 号进程表面上被隔离了起来，但是它所能够使用到的资源（比如 CPU、内存），却是可以随时被宿主机上的其他进程（或者其他容器）占用的。当然，这个 100 号进程自己也可能把所有资源吃光。这些情况，显然都不是一个&amp;quot;沙盒&amp;quot;应该表现出来的合理行为。&lt;/p&gt;
&lt;p&gt;而&lt;strong&gt;Linux Cgroups 就是 Linux 内核中用来为进程设置资源限制的一个重要功能。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;有意思的是，Google 的工程师在 2006 年发起这项特性的时候，曾将它命名为&amp;quot;进程容器&amp;rdquo;（process container）。实际上，在 Google 内部，&amp;ldquo;容器&amp;quot;这个术语长期以来都被用于形容被 Cgroups 限制过的进程组。后来 Google 的工程师们说，他们的 KVM 虚拟机也运行在 Borg 所管理的&amp;quot;容器&amp;quot;里，其实也是运行在 Cgroups&amp;quot;容器&amp;quot;当中。这和我们今天说的 Docker 容器差别很大。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Linux Cgroups 的全称是 Linux Control Group。它最主要的作用，就是限制一个进程组能够使用的资源上限，包括 CPU、内存、磁盘、网络带宽等等。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;此外，Cgroups 还能够对进程进行优先级设置、审计，以及将进程挂起和恢复等操作。在今天的分享中，我只和你重点探讨它与容器关系最紧密的&amp;quot;限制&amp;quot;能力，并通过一组实践来带你认识一下 Cgroups。&lt;/p&gt;
&lt;p&gt;在 Linux 中，Cgroups 给用户暴露出来的操作接口是文件系统，即它以文件和目录的方式组织在操作系统的 /sys/fs/cgroup 路径下。在 Ubuntu 16.04 机器里，我可以用 mount 指令把它们展示出来，这条命令是：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ mount -t cgroup 
cpuset on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)
cpu on /sys/fs/cgroup/cpu type cgroup (rw,nosuid,nodev,noexec,relatime,cpu)
cpuacct on /sys/fs/cgroup/cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpuacct)
blkio on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)
memory on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;它的输出结果，是一系列文件系统目录。如果你在自己的机器上没有看到这些目录，那你就需要自己去挂载 Cgroups，具体做法可以自行 Google。&lt;/p&gt;
&lt;p&gt;可以看到，在 /sys/fs/cgroup 下面有很多诸如 cpuset、cpu、 memory 这样的子目录，也叫子系统。这些都是我这台机器当前可以被 Cgroups 进行限制的资源种类。而在子系统对应的资源种类下，你就可以看到该类资源具体可以被限制的方法。比如，对 CPU 子系统来说，我们就可以看到如下几个配置文件，这个指令是：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ls /sys/fs/cgroup/cpu
cgroup.clone_children cpu.cfs_period_us cpu.rt_period_us  cpu.shares notify_on_release
cgroup.procs      cpu.cfs_quota_us  cpu.rt_runtime_us cpu.stat  tasks
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果熟悉 Linux CPU 管理的话，你就会在它的输出里注意到 cfs_period 和 cfs_quota 这样的关键词。这两个参数需要组合使用，可以用来限制进程在长度为 cfs_period 的一段时间内，只能被分配到总量为 cfs_quota 的 CPU 时间。&lt;/p&gt;
&lt;p&gt;而这样的配置文件又如何使用呢？&lt;/p&gt;
&lt;p&gt;你需要在对应的子系统下面创建一个目录，比如，我们现在进入 /sys/fs/cgroup/cpu 目录下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@ubuntu:/sys/fs/cgroup/cpu$ mkdir container
root@ubuntu:/sys/fs/cgroup/cpu$ ls container/
cgroup.clone_children cpu.cfs_period_us cpu.rt_period_us  cpu.shares notify_on_release
cgroup.procs      cpu.cfs_quota_us  cpu.rt_runtime_us cpu.stat  tasks
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个目录就称为一个&amp;quot;控制组&amp;rdquo;。你会发现，操作系统会在你新创建的 container 目录下，自动生成该子系统对应的资源限制文件。&lt;/p&gt;
&lt;p&gt;现在，我们在后台执行这样一条脚本：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ while : ; do : ; done &amp;amp;
[1] 226
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;显然，它执行了一个死循环，可以把计算机的 CPU 吃到 100%，根据它的输出，我们可以看到这个脚本在后台运行的进程号（PID）是 226。&lt;/p&gt;
&lt;p&gt;这样，我们可以用 top 指令来确认一下 CPU 有没有被打满：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ top
%Cpu0 :100.0 us, 0.0 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在输出里可以看到，CPU 的使用率已经 100% 了（%Cpu0 :100.0 us）。&lt;/p&gt;
&lt;p&gt;而此时，我们可以通过查看 container 目录下的文件，看到 container 控制组里的 CPU quota 还没有任何限制（即：-1），CPU period 则是默认的 100 ms（100000 us）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cat /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us 
-1
$ cat /sys/fs/cgroup/cpu/container/cpu.cfs_period_us 
100000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;接下来，我们可以通过修改这些文件的内容来设置限制。&lt;/p&gt;
&lt;p&gt;比如，向 container 组里的 cfs_quota 文件写入 20 ms（20000 us）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ echo 20000 &amp;gt; /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;结合前面的介绍，你应该能明白这个操作的含义，它意味着在每 100 ms 的时间里，被该控制组限制的进程只能使用 20 ms 的 CPU 时间，也就是说这个进程只能使用到 20% 的 CPU 带宽。&lt;/p&gt;
&lt;p&gt;接下来，我们把被限制的进程的 PID 写入 container 组里的 tasks 文件，上面的设置就会对该进程生效了：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ echo 226 &amp;gt; /sys/fs/cgroup/cpu/container/tasks 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们可以用 top 指令查看一下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ top
%Cpu0 : 20.3 us, 0.0 sy, 0.0 ni, 79.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，计算机的 CPU 使用率立刻降到了 20%（%Cpu0 : 20.3 us）。&lt;/p&gt;
&lt;p&gt;除 CPU 子系统外，Cgroups 的每一项子系统都有其独有的资源限制能力，比如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;blkio，为块设备设定I/O 限制，一般用于磁盘等设备；&lt;/li&gt;
&lt;li&gt;cpuset，为进程分配单独的 CPU 核和对应的内存节点；&lt;/li&gt;
&lt;li&gt;memory，为进程设定内存使用的限制。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Linux Cgroups 的设计还是比较易用的，简单粗暴地理解呢，它就是一个子系统目录加上一组资源限制文件的组合&lt;/strong&gt;。而对于 Docker 等 Linux 容器项目来说，它们只需要在每个子系统下面，为每个容器创建一个控制组（即创建一个新目录），然后在启动容器进程之后，把这个进程的 PID 填写到对应控制组的 tasks 文件中就可以了。&lt;/p&gt;
&lt;p&gt;而至于在这些控制组下面的资源文件里填上什么值，就靠用户执行 docker run 时的参数指定了，比如这样一条命令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker run -it --cpu-period=100000 --cpu-quota=20000 ubuntu /bin/bash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在启动这个容器后，我们可以通过查看 Cgroups 文件系统下，CPU 子系统中，&amp;ldquo;docker&amp;quot;这个控制组里的资源限制文件的内容来确认：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cat /sys/fs/cgroup/cpu/docker/5d5c9f67d/cpu.cfs_period_us 
100000
$ cat /sys/fs/cgroup/cpu/docker/5d5c9f67d/cpu.cfs_quota_us 
20000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这就意味着这个 Docker 容器，只能使用到 20% 的 CPU 带宽。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;在这篇文章中，我首先介绍了容器使用 Linux Namespace 作为隔离手段的优势和劣势，对比了 Linux 容器跟虚拟机技术的不同，进一步明确了&amp;quot;容器只是一种特殊的进程&amp;quot;这个结论。&lt;/p&gt;
&lt;p&gt;除了创建 Namespace 之外，在后续关于容器网络的分享中，我还会介绍一些其他 Namespace 的操作，比如看不见摸不着的 Linux Namespace 在计算机中到底如何表示、一个进程如何&amp;quot;加入&amp;quot;到其他进程的 Namespace 当中，等等。&lt;/p&gt;
&lt;p&gt;紧接着，我详细介绍了容器在做好了隔离工作之后，又如何通过 Linux Cgroups 实现资源的限制，并通过一系列简单的实验，模拟了 Docker 项目创建容器限制的过程。&lt;/p&gt;
&lt;p&gt;通过以上讲述，你现在应该能够理解，一个正在运行的 Docker 容器，其实就是一个启用了多个 Linux Namespace 的应用进程，而这个进程能够使用的资源量，则受 Cgroups 配置的限制。&lt;/p&gt;
&lt;p&gt;这也是容器技术中一个非常重要的概念，即：&lt;strong&gt;容器是一个&amp;quot;单进程&amp;quot;模型。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;由于一个容器的本质就是一个进程，用户的应用进程实际上就是容器里 PID=1 的进程，也是其他后续创建的所有进程的父进程。这就意味着，在一个容器中，你没办法同时运行两个不同的应用，除非你能事先找到一个公共的 PID=1 的程序来充当两个不同应用的父进程，这也是为什么很多人都会用 systemd 或者 supervisord 这样的软件来代替应用本身作为容器的启动进程。&lt;/p&gt;
&lt;p&gt;但是，在后面分享容器设计模式时，我还会推荐其他更好的解决办法。这是因为容器本身的设计，就是希望容器和应用能够&lt;strong&gt;同生命周期&lt;/strong&gt;，这个概念对后续的容器编排非常重要。否则，一旦出现类似于&amp;quot;容器是正常运行的，但是里面的应用早已经挂了&amp;quot;的情况，编排系统处理起来就非常麻烦了。&lt;/p&gt;
&lt;p&gt;另外，跟 Namespace 的情况类似，Cgroups 对资源的限制能力也有很多不完善的地方，被提及最多的自然是 /proc 文件系统的问题。&lt;/p&gt;
&lt;p&gt;众所周知，Linux 下的 /proc 目录存储的是记录当前内核运行状态的一系列特殊文件，用户可以通过访问这些文件，查看系统以及当前正在运行的进程的信息，比如 CPU 使用情况、内存占用率等，这些文件也是 top 指令查看系统信息的主要数据来源。&lt;/p&gt;
&lt;p&gt;但是，你如果在容器里执行 top 指令，就会发现，它显示的信息居然是宿主机的 CPU 和内存数据，而不是当前容器的数据。&lt;/p&gt;
&lt;p&gt;造成这个问题的原因就是，/proc 文件系统并不知道用户通过 Cgroups 给这个容器做了什么样的资源限制，即：/proc 文件系统不了解 Cgroups 限制的存在。&lt;/p&gt;
&lt;p&gt;在生产环境中，这个问题必须进行修正，否则应用程序在容器里读取到的 CPU 核数、可用内存等信息都是宿主机上的数据，这会给应用的运行带来非常大的困惑和风险。这也是在企业中，容器化应用碰到的一个常见问题，也是容器相较于虚拟机另一个不尽如人意的地方。&lt;/p&gt;
&lt;h2 id=&#34;思考题&#34;&gt;思考题&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;你是否知道如何修复容器中的 top 指令以及 /proc 文件系统中的信息呢？（提示：lxcfs）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在从虚拟机向容器环境迁移应用的过程中，你还遇到哪些容器与虚拟机的不一致问题？&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;感谢你的收听，欢迎给我留言一起讨论，也欢迎分享给更多的朋友一起阅读。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/47/55/47a6f3bf6b92d58512d5a2ed0a556f55.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 06丨链表（上）：如何实现LRU缓存淘汰算法？</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/06%E4%B8%A8%E9%93%BE%E8%A1%A8%E4%B8%8A%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0lru%E7%BC%93%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AE%97%E6%B3%95/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/06%E4%B8%A8%E9%93%BE%E8%A1%A8%E4%B8%8A%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0lru%E7%BC%93%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AE%97%E6%B3%95/</guid>
      <description>
        
        
        &lt;p&gt;今天我们来聊聊&amp;quot;链表（Linked list）&amp;ldquo;这个数据结构。学习链表有什么用呢？为了回答这个问题，我们先来讨论一个经典的链表应用场景，那就是 LRU 缓存淘汰算法。&lt;/p&gt;
&lt;p&gt;缓存是一种提高数据读取性能的技术，在硬件设计、软件开发中都有着非常广泛的应用，比如常见的 CPU 缓存、数据库缓存、浏览器缓存等等。&lt;/p&gt;
&lt;p&gt;缓存的大小有限，当缓存被用满时，哪些数据应该被清理出去，哪些数据应该被保留？这就需要缓存淘汰策略来决定。常见的策略有三种：先进先出策略 FIFO（First In，First Out）、最少使用策略 LFU（Least Frequently Used）、最近最少使用策略 LRU（Least Recently Used）。&lt;/p&gt;
&lt;p&gt;这些策略你不用死记，我打个比方你很容易就明白了。假如说，你买了很多本技术书，但有一天你发现，这些书太多了，太占书房空间了，你要做个大扫除，扔掉一些书籍。那这个时候，你会选择扔掉哪些书呢？对应一下，你的选择标准是不是和上面的三种策略神似呢？&lt;/p&gt;
&lt;p&gt;好了，回到正题，我们今天的开篇问题就是：&lt;strong&gt;如何用链表来实现 LRU 缓存淘汰策略呢？&lt;/strong&gt; 带着这个问题，我们开始今天的内容吧！&lt;/p&gt;
&lt;h2 id=&#34;五花八门的链表结构&#34;&gt;五花八门的链表结构&lt;/h2&gt;
&lt;p&gt;相比数组，链表是一种稍微复杂一点的数据结构。对于初学者来说，掌握起来也要比数组稍难一些。这两个非常基础、非常常用的数据结构，我们常常将会放到一块儿来比较。所以我们先来看，这两者有什么区别。&lt;/p&gt;
&lt;p&gt;我们先从&lt;strong&gt;底层的存储结构&lt;/strong&gt;上来看一看。&lt;/p&gt;
&lt;p&gt;为了直观地对比，我画了一张图。从图中我们看到，数组需要一块&lt;strong&gt;连续的内存空间&lt;/strong&gt;来存储，对内存的要求比较高。如果我们申请一个 100MB 大小的数组，当内存中没有连续的、足够大的存储空间时，即便内存的剩余总可用空间大于 100MB，仍然会申请失败。&lt;/p&gt;
&lt;p&gt;而链表恰恰相反，它并不需要一块连续的内存空间，它通过&amp;quot;指针&amp;quot;将一组&lt;strong&gt;零散的内存块&lt;/strong&gt;串联起来使用，所以如果我们申请的是 100MB 大小的链表，根本不会有问题。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/d5/cd/d5d5bee4be28326ba3c28373808a62cd.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;链表结构五花八门，今天我重点给你介绍三种最常见的链表结构，它们分别是：单链表、双向链表和循环链表。我们首先来看最简单、最常用的&lt;strong&gt;单链表&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;我们刚刚讲到，链表通过指针将一组零散的内存块串联在一起。其中，我们把内存块称为链表的&amp;rdquo;&lt;strong&gt;结点&lt;/strong&gt; &amp;ldquo;。为了将所有的结点串起来，每个链表的结点除了存储数据之外，还需要记录链上的下一个结点的地址。如图所示，我们把这个记录下个结点地址的指针叫作&lt;strong&gt;后继指针 next&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/b9/eb/b93e7ade9bb927baad1348d9a806ddeb.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;从我画的单链表图中，你应该可以发现，其中有两个结点是比较特殊的，它们分别是第一个结点和最后一个结点。我们习惯性地把第一个结点叫作&lt;strong&gt;头结点&lt;/strong&gt; ，把最后一个结点叫作&lt;strong&gt;尾结点&lt;/strong&gt; 。其中，头结点用来记录链表的基地址。有了它，我们就可以遍历得到整条链表。而尾结点特殊的地方是：指针不是指向下一个结点，而是指向一个&lt;strong&gt;空地址 NULL&lt;/strong&gt;，表示这是链表上最后一个结点。&lt;/p&gt;
&lt;p&gt;与数组一样，链表也支持数据的查找、插入和删除操作。&lt;/p&gt;
&lt;p&gt;我们知道，在进行数组的插入、删除操作时，为了保持内存数据的连续性，需要做大量的数据搬移，所以时间复杂度是 O(n)。而在链表中插入或者删除一个数据，我们并不需要为了保持内存的连续性而搬移结点，因为链表的存储空间本身就不是连续的。所以，在链表中插入和删除一个数据是非常快速的。&lt;/p&gt;
&lt;p&gt;为了方便你理解，我画了一张图，从图中我们可以看出，针对链表的插入和删除操作，我们只需要考虑相邻结点的指针改变，所以对应的时间复杂度是 O(1)。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/45/17/452e943788bdeea462d364389bd08a17.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;但是，有利就有弊。链表要想随机访问第 k 个元素，就没有数组那么高效了。因为链表中的数据并非连续存储的，所以无法像数组那样，根据首地址和下标，通过寻址公式就能直接计算出对应的内存地址，而是需要根据指针一个结点一个结点地依次遍历，直到找到相应的结点。&lt;/p&gt;
&lt;p&gt;你可以把链表想象成一个队伍，队伍中的每个人都只知道自己后面的人是谁，所以当我们希望知道排在第 k 位的人是谁的时候，我们就需要从第一个人开始，一个一个地往下数。所以，链表随机访问的性能没有数组好，需要 O(n) 的时间复杂度。&lt;/p&gt;
&lt;p&gt;好了，单链表我们就简单介绍完了，接着来看另外两个复杂的升级版，&lt;strong&gt;循环链表&lt;/strong&gt; 和&lt;strong&gt;双向链表&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;循环链表是一种特殊的单链表&lt;/strong&gt;。实际上，循环链表也很简单。它跟单链表唯一的区别就在尾结点。我们知道，单链表的尾结点指针指向空地址，表示这就是最后的结点了。而循环链表的尾结点指针是指向链表的头结点。从我画的循环链表图中，你应该可以看出来，它像一个环一样首尾相连，所以叫作&amp;quot;循环&amp;quot;链表。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/86/55/86cb7dc331ea958b0a108b911f38d155.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;和单链表相比，&lt;strong&gt;循环链表&lt;/strong&gt; 的优点是从链尾到链头比较方便。当要处理的数据具有环型结构特点时，就特别适合采用循环链表。比如著名的&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E7%BA%A6%E7%91%9F%E5%A4%AB%E6%96%AF%E9%97%AE%E9%A2%98&#34;&gt;约瑟夫问题&lt;/a&gt;。尽管用单链表也可以实现，但是用循环链表实现的话，代码就会简洁很多。&lt;/p&gt;
&lt;p&gt;单链表和循环链表是不是都不难？接下来我们再来看一个稍微复杂的，在实际的软件开发中，也更加常用的链表结构：&lt;strong&gt;双向链表&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;单向链表只有一个方向，结点只有一个后继指针 next 指向后面的结点。而双向链表，顾名思义，它支持两个方向，每个结点不止有一个后继指针 next 指向后面的结点，还有一个前驱指针 prev 指向前面的结点。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/cb/0b/cbc8ab20276e2f9312030c313a9ef70b.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;从我画的图中可以看出来，双向链表需要额外的两个空间来存储后继结点和前驱结点的地址。所以，如果存储同样多的数据，双向链表要比单链表占用更多的内存空间。虽然两个指针比较浪费存储空间，但可以支持双向遍历，这样也带来了双向链表操作的灵活性。那相比单链表，双向链表适合解决哪种问题呢？&lt;/p&gt;
&lt;p&gt;从结构上来看，双向链表可以支持 O(1) 时间复杂度的情况下找到前驱结点，正是这样的特点，也使双向链表在某些情况下的插入、删除等操作都要比单链表简单、高效。&lt;/p&gt;
&lt;p&gt;你可能会说，我刚讲到单链表的插入、删除操作的时间复杂度已经是 O(1) 了，双向链表还能再怎么高效呢？别着急，刚刚的分析比较偏理论，很多数据结构和算法书籍中都会这么讲，但是这种说法实际上是不准确的，或者说是有先决条件的。我再来带你分析一下链表的两个操作。&lt;/p&gt;
&lt;p&gt;我们先来看&lt;strong&gt;删除操作&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在实际的软件开发中，从链表中删除一个数据无外乎这两种情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;删除结点中&amp;quot;值等于某个给定值&amp;quot;的结点；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;删除给定指针指向的结点。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于第一种情况，不管是单链表还是双向链表，为了查找到值等于给定值的结点，都需要从头结点开始一个一个依次遍历对比，直到找到值等于给定值的结点，然后再通过我前面讲的指针操作将其删除。&lt;/p&gt;
&lt;p&gt;尽管单纯的删除操作时间复杂度是 O(1)，但遍历查找的时间是主要的耗时点，对应的时间复杂度为 O(n)。根据时间复杂度分析中的加法法则，删除值等于给定值的结点对应的链表操作的总时间复杂度为 O(n)。&lt;/p&gt;
&lt;p&gt;对于第二种情况，我们已经找到了要删除的结点，但是删除某个结点 q 需要知道其前驱结点，而单链表并不支持直接获取前驱结点，所以，为了找到前驱结点，我们还是要从头结点开始遍历链表，直到 p-&amp;gt;next=q，说明 p 是 q 的前驱结点。&lt;/p&gt;
&lt;p&gt;但是对于双向链表来说，这种情况就比较有优势了。因为双向链表中的结点已经保存了前驱结点的指针，不需要像单链表那样遍历。所以，针对第二种情况，单链表删除操作需要 O(n) 的时间复杂度，而双向链表只需要在 O(1) 的时间复杂度内就搞定了！&lt;/p&gt;
&lt;p&gt;同理，如果我们希望在链表的某个指定结点前面插入一个结点，双向链表比单链表有很大的优势。双向链表可以在 O(1) 时间复杂度搞定，而单向链表需要 O(n) 的时间复杂度。你可以参照我刚刚讲过的删除操作自己分析一下。&lt;/p&gt;
&lt;p&gt;除了插入、删除操作有优势之外，对于一个有序链表，双向链表的按值查询的效率也要比单链表高一些。因为，我们可以记录上次查找的位置 p，每次查询时，根据要查找的值与 p 的大小关系，决定是往前还是往后查找，所以平均只需要查找一半的数据。&lt;/p&gt;
&lt;p&gt;现在，你有没有觉得双向链表要比单链表更加高效呢？这就是为什么在实际的软件开发中，双向链表尽管比较费内存，但还是比单链表的应用更加广泛的原因。如果你熟悉 Java 语言，你肯定用过 LinkedHashMap 这个容器。如果你深入研究 LinkedHashMap 的实现原理，就会发现其中就用到了双向链表这种数据结构。&lt;/p&gt;
&lt;p&gt;实际上，这里有一个更加重要的知识点需要你掌握，那就是&lt;strong&gt;用空间换时间&lt;/strong&gt;的设计思想。当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单片机上，这个时候，就要反过来用时间换空间的设计思路。&lt;/p&gt;
&lt;p&gt;还是开篇缓存的例子。缓存实际上就是利用了空间换时间的设计思想。如果我们把数据存储在硬盘上，会比较节省内存，但每次查找数据都要询问一次硬盘，会比较慢。但如果我们通过缓存技术，事先将数据加载在内存中，虽然会比较耗费内存空间，但是每次数据查询的速度就大大提高了。&lt;/p&gt;
&lt;p&gt;所以我总结一下，对于执行较慢的程序，可以通过消耗更多的内存（空间换时间）来进行优化；而消耗过多内存的程序，可以通过消耗更多的时间（时间换空间）来降低内存的消耗。你还能想到其他时间换空间或者空间换时间的例子吗？&lt;/p&gt;
&lt;p&gt;了解了循环链表和双向链表，如果把这两种链表整合在一起就是一个新的版本：&lt;strong&gt;双向循环链表&lt;/strong&gt;。我想不用我多讲，你应该知道双向循环链表长什么样子了吧？你可以自己试着在纸上画一画。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/d1/91/d1665043b283ecdf79b157cfc9e5ed91.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;链表-vs-数组性能大比拼&#34;&gt;链表 VS 数组性能大比拼&lt;/h2&gt;
&lt;p&gt;通过前面内容的学习，你应该已经知道，数组和链表是两种截然不同的内存组织方式。正是因为内存存储的区别，它们插入、删除、随机访问操作的时间复杂度正好相反。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/4f/68/4f63e92598ec2551069a0eef69db7168.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;不过，数组和链表的对比，并不能局限于时间复杂度。而且，在实际的软件开发中，不能仅仅利用复杂度分析就决定使用哪个数据结构来存储数据。&lt;/p&gt;
&lt;p&gt;数组简单易用，在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对 CPU 缓存不友好，没办法有效预读。&lt;/p&gt;
&lt;p&gt;数组的缺点是大小固定，一经声明就要占用整块连续内存空间。如果声明的数组过大，系统可能没有足够的连续内存空间分配给它，导致&amp;quot;内存不足（out of memory）&amp;quot;。如果声明的数组过小，则可能出现不够用的情况。这时只能再申请一个更大的内存空间，把原数组拷贝进去，非常费时。链表本身没有大小的限制，天然地支持动态扩容，我觉得这也是它与数组最大的区别。&lt;/p&gt;
&lt;p&gt;你可能会说，我们 Java 中的 ArrayList 容器，也可以支持动态扩容啊？我们上一节课讲过，当我们往支持动态扩容的数组中插入一个数据时，如果数组中没有空闲空间了，就会申请一个更大的空间，将数据拷贝过去，而数据拷贝的操作是非常耗时的。&lt;/p&gt;
&lt;p&gt;我举一个稍微极端的例子。如果我们用 ArrayList 存储了了 1GB 大小的数据，这个时候已经没有空闲空间了，当我们再插入数据的时候，ArrayList 会申请一个 1.5GB 大小的存储空间，并且把原来那 1GB 的数据拷贝到新申请的空间上。听起来是不是就很耗时？&lt;/p&gt;
&lt;p&gt;除此之外，如果你的代码对内存的使用非常苛刻，那数组就更适合你。因为链表中的每个结点都需要消耗额外的存储空间去存储一份指向下一个结点的指针，所以内存消耗会翻倍。而且，对链表进行频繁的插入、删除操作，还会导致频繁的内存申请和释放，容易造成内存碎片，如果是 Java 语言，就有可能会导致频繁的 GC（Garbage Collection，垃圾回收）。&lt;/p&gt;
&lt;p&gt;所以，在我们实际的开发中，针对不同类型的项目，要根据具体情况，权衡究竟是选择数组还是链表。&lt;/p&gt;
&lt;h2 id=&#34;解答开篇&#34;&gt;解答开篇&lt;/h2&gt;
&lt;p&gt;好了，关于链表的知识我们就讲完了。我们现在回过头来看下开篇留给你的思考题。如何基于链表实现 LRU 缓存淘汰算法？&lt;/p&gt;
&lt;p&gt;我的思路是这样的：我们维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果此数据没有在缓存链表中，又可以分为两种情况：&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;如果此时缓存未满，则将此结点直接插入到链表的头部；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这样我们就用链表实现了一个 LRU 缓存，是不是很简单？&lt;/p&gt;
&lt;p&gt;现在我们来看下 m 缓存访问的时间复杂度是多少。因为不管缓存有没有满，我们都需要遍历一遍链表，所以这种基于链表的实现思路，缓存访问的时间复杂度为 O(n)。&lt;/p&gt;
&lt;p&gt;实际上，我们可以继续优化这个实现思路，比如引入&lt;strong&gt;散列表&lt;/strong&gt;（Hash table）来记录每个数据的位置，将缓存访问的时间复杂度降到 O(1)。因为要涉及我们还没有讲到的数据结构，所以这个优化方案，我现在就不详细说了，等讲到散列表的时候，我会再拿出来讲。&lt;/p&gt;
&lt;p&gt;除了基于链表的实现思路，实际上还可以用数组来实现 LRU 缓存淘汰策略。如何利用数组实现 LRU 缓存淘汰策略呢？我把这个问题留给你思考。&lt;/p&gt;
&lt;h2 id=&#34;内容小结&#34;&gt;内容小结&lt;/h2&gt;
&lt;p&gt;今天我们讲了一种跟数组&amp;quot;相反&amp;quot;的数据结构，链表。它跟数组一样，也是非常基础、非常常用的数据结构。不过链表要比数组稍微复杂，从普通的单链表衍生出来好几种链表结构，比如双向链表、循环链表、双向循环链表。&lt;/p&gt;
&lt;p&gt;和数组相比，链表更适合插入、删除操作频繁的场景，查询的时间复杂度较高。不过，在具体软件开发中，要对数组和链表的各种性能进行对比，综合来选择使用两者中的哪一个。&lt;/p&gt;
&lt;h2 id=&#34;课后思考&#34;&gt;课后思考&lt;/h2&gt;
&lt;p&gt;如何判断一个字符串是否是回文字符串的问题，我想你应该听过，我们今天的题目就是基于这个问题的改造版本。如果字符串是通过单链表来存储的，那该如何来判断是一个回文串呢？你有什么好的解决思路呢？相应的时间空间复杂度又是多少呢？&lt;/p&gt;
&lt;p&gt;欢迎留言和我分享，我会第一时间给你反馈。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;我已将本节内容相关的详细代码更新到 GitHub，&lt;a href=&#34;https://github.com/wangzheng0822/algo&#34;&gt;戳此&lt;/a&gt;即可查看。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/8e/d3/8e603e3d795fc0ab2698f6f5eabf14d3.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 07丨JVM是如何实现反射的？</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3jvm%E8%99%9A%E6%8B%9F%E6%9C%BA/07%E4%B8%A8jvm%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%8F%8D%E5%B0%84%E7%9A%84/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3jvm%E8%99%9A%E6%8B%9F%E6%9C%BA/07%E4%B8%A8jvm%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%8F%8D%E5%B0%84%E7%9A%84/</guid>
      <description>
        
        
        &lt;p&gt;今天我们来聊聊 Java 里的反射机制。&lt;/p&gt;
&lt;p&gt;反射是 Java 语言中一个相当重要的特性，它允许正在运行的 Java 程序观测，甚至是修改程序的动态行为。&lt;/p&gt;
&lt;p&gt;举例来说，我们可以通过 Class 对象枚举该类中的所有方法，我们还可以通过 Method.setAccessible（位于 java.lang.reflect 包，该方法继承自 AccessibleObject）绕过 Java 语言的访问权限，在私有方法所在类之外的地方调用该方法。&lt;/p&gt;
&lt;p&gt;反射在 Java 中的应用十分广泛。开发人员日常接触到的 Java 集成开发环境（IDE）便运用了这一功能：每当我们敲入点号时，IDE 便会根据点号前的内容，动态展示可以访问的字段或者方法。&lt;/p&gt;
&lt;p&gt;另一个日常应用则是 Java 调试器，它能够在调试过程中枚举某一对象所有字段的值。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/ce/75/ceeabb2dbdd80577feaecd0879e42675.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;（图中 eclipse 的自动提示使用了反射）&lt;/p&gt;
&lt;p&gt;在 Web 开发中，我们经常能够接触到各种可配置的通用框架。为了保证框架的可扩展性，它们往往借助 Java 的反射机制，根据配置文件来加载不同的类。举例来说，Spring 框架的依赖反转（IoC），便是依赖于反射机制。&lt;/p&gt;
&lt;p&gt;然而，我相信不少开发人员都嫌弃反射机制比较慢。甚至是甲骨文关于反射的教学网页 [1]，也强调了反射性能开销大的缺点。&lt;/p&gt;
&lt;p&gt;今天我们便来了解一下反射的实现机制，以及它性能糟糕的原因。如果你对反射 API 不是特别熟悉的话，你可以查阅我放在文稿末尾的附录。&lt;/p&gt;
&lt;h2 id=&#34;反射调用的实现&#34;&gt;反射调用的实现&lt;/h2&gt;
&lt;p&gt;首先，我们来看看方法的反射调用，也就是 Method.invoke，是怎么实现的。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public final class Method extends Executable {
  ...
  public Object invoke(Object obj, Object... args) throws ... {
    ... // 权限检查
    MethodAccessor ma = methodAccessor;
    if (ma == null) {
      ma = acquireMethodAccessor();
    }
    return ma.invoke(obj, args);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果你查阅 Method.invoke 的源代码，那么你会发现，它实际上委派给 MethodAccessor 来处理。MethodAccessor 是一个接口，它有两个已有的具体实现：一个通过本地方法来实现反射调用，另一个则使用了委派模式。为了方便记忆，我便用&amp;quot;本地实现&amp;quot;和&amp;quot;委派实现&amp;quot;来指代这两者。&lt;/p&gt;
&lt;p&gt;每个 Method 实例的第一次反射调用都会生成一个委派实现，它所委派的具体实现便是一个本地实现。本地实现非常容易理解。当进入了 Java 虚拟机内部之后，我们便拥有了 Method 实例所指向方法的具体地址。这时候，反射调用无非就是将传入的参数准备好，然后调用进入目标方法。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// v0 版本
import java.lang.reflect.Method;
 
public class Test {
  public static void target(int i) {
    new Exception(&amp;quot;#&amp;quot; + i).printStackTrace();
  }
 
  public static void main(String[] args) throws Exception {
    Class&amp;lt;?&amp;gt; klass = Class.forName(&amp;quot;Test&amp;quot;);
    Method method = klass.getMethod(&amp;quot;target&amp;quot;, int.class);
    method.invoke(null, 0);
  }
}
 
# 不同版本的输出略有不同，这里我使用了 Java 10。
$ java Test
java.lang.Exception: #0
        at Test.target(Test.java:5)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl .invoke0(Native Method)
 a      t java.base/jdk.internal.reflect.NativeMethodAccessorImpl. .invoke(NativeMethodAccessorImpl.java:62)
 t       java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.i .invoke(DelegatingMethodAccessorImpl.java:43)
        java.base/java.lang.reflect.Method.invoke(Method.java:564)
  t        Test.main(Test.java:131
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;为了方便理解，我们可以打印一下反射调用到目标方法时的栈轨迹。在上面的 v0 版本代码中，我们获取了一个指向 Test.target 方法的 Method 对象，并且用它来进行反射调用。在 Test.target 中，我会打印出栈轨迹。&lt;/p&gt;
&lt;p&gt;可以看到，反射调用先是调用了 Method.invoke，然后进入委派实现（DelegatingMethodAccessorImpl），再然后进入本地实现（NativeMethodAccessorImpl），最后到达目标方法。&lt;/p&gt;
&lt;p&gt;这里你可能会疑问，为什么反射调用还要采取委派实现作为中间层？直接交给本地实现不可以么？&lt;/p&gt;
&lt;p&gt;其实，Java 的反射调用机制还设立了另一种动态生成字节码的实现（下称动态实现），直接使用 invoke 指令来调用目标方法。之所以采用委派实现，便是为了能够在本地实现以及动态实现中切换。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 动态实现的伪代码，这里只列举了关键的调用逻辑，其实它还包括调用者检测、参数检测的字节码。
package jdk.internal.reflect;
 
public class GeneratedMethodAccessor1 extends ... {
  @Overrides    
  public Object invoke(Object obj, Object[] args) throws ... {
    Test.target((int) args[0]);
    return null;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;动态实现和本地实现相比，其运行效率要快上 20 倍 [2] 。这是因为动态实现无需经过 Java 到 C++ 再到 Java 的切换，但由于生成字节码十分耗时，仅调用一次的话，反而是本地实现要快上 3 到 4 倍 [3]。&lt;/p&gt;
&lt;p&gt;考虑到许多反射调用仅会执行一次，Java 虚拟机设置了一个阈值 15（可以通过 -Dsun.reflect.inflationThreshold= 来调整），当某个反射调用的调用次数在 15 之下时，采用本地实现；当达到 15 时，便开始动态生成字节码，并将委派实现的委派对象切换至动态实现，这个过程我们称之为 Inflation。&lt;/p&gt;
&lt;p&gt;为了观察这个过程，我将刚才的例子更改为下面的 v1 版本。它会将反射调用循环 20 次。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// v1 版本
import java.lang.reflect.Method;
 
public class Test {
  public static void target(int i) {
    new Exception(&amp;quot;#&amp;quot; + i).printStackTrace();
  }
 
  public static void main(String[] args) throws Exception {
    Class&amp;lt;?&amp;gt; klass = Class.forName(&amp;quot;Test&amp;quot;);
    Method method = klass.getMethod(&amp;quot;target&amp;quot;, int.class);
    for (int i = 0; i &amp;lt; 20; i++) {
      method.invoke(null, i);
    }
  }
}
 
# 使用 -verbose:class 打印加载的类
$ java -verbose:class Test
...
java.lang.Exception: #14
        at Test.target(Test.java:5)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl .invoke0(Native Method)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl .invoke(NativeMethodAccessorImpl.java:62)
        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl .invoke(DelegatingMethodAccessorImpl.java:43)
        at java.base/java.lang.reflect.Method.invoke(Method.java:564)
        at Test.main(Test.java:12)
[0.158s][info][class,load] ...
...
[0.160s][info][class,load] jdk.internal.reflect.GeneratedMethodAccessor1 source: __JVM_DefineClass__
java.lang.Exception: #15
       at Test.target(Test.java:5)
       at java.base/jdk.internal.reflect.NativeMethodAccessorImpl .invoke0(Native Method)
       at java.base/jdk.internal.reflect.NativeMethodAccessorImpl .invoke(NativeMethodAccessorImpl.java:62)
       at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl .invoke(DelegatingMethodAccessorImpl.java:43)
       at java.base/java.lang.reflect.Method.invoke(Method.java:564)
       at Test.main(Test.java:12)
java.lang.Exception: #16
       at Test.target(Test.java:5)
       at jdk.internal.reflect.GeneratedMethodAccessor1 .invoke(Unknown Source)
       at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl .invoke(DelegatingMethodAccessorImpl.java:43)
       at java.base/java.lang.reflect.Method.invoke(Method.java:564)
       at Test.main(Test.java:12)
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，在第 15 次（从 0 开始数）反射调用时，我们便触发了动态实现的生成。这时候，Java 虚拟机额外加载了不少类。其中，最重要的当属 GeneratedMethodAccessor1（第 30 行）。并且，从第 16 次反射调用开始，我们便切换至这个刚刚生成的动态实现（第 40 行）。&lt;/p&gt;
&lt;p&gt;反射调用的 Inflation 机制是可以通过参数（-Dsun.reflect.noInflation=true）来关闭的。这样一来，在反射调用一开始便会直接生成动态实现，而不会使用委派实现或者本地实现。&lt;/p&gt;
&lt;h2 id=&#34;反射调用的开销&#34;&gt;反射调用的开销&lt;/h2&gt;
&lt;p&gt;下面，我们便来拆解反射调用的性能开销。&lt;/p&gt;
&lt;p&gt;在刚才的例子中，我们先后进行了 Class.forName，Class.getMethod 以及 Method.invoke 三个操作。其中，Class.forName 会调用本地方法，Class.getMethod 则会遍历该类的公有方法。如果没有匹配到，它还将遍历父类的公有方法。可想而知，这两个操作都非常费时。&lt;/p&gt;
&lt;p&gt;值得注意的是，以 getMethod 为代表的查找方法操作，会返回查找得到结果的一份拷贝。因此，我们应当避免在热点代码中使用返回 Method 数组的 getMethods 或者 getDeclaredMethods 方法，以减少不必要的堆空间消耗。&lt;/p&gt;
&lt;p&gt;在实践中，我们往往会在应用程序中缓存 Class.forName 和 Class.getMethod 的结果。因此，下面我就只关注反射调用本身的性能开销。&lt;/p&gt;
&lt;p&gt;为了比较直接调用和反射调用的性能差距，我将前面的例子改为下面的 v2 版本。它会将反射调用循环二十亿次。此外，它还将记录下每跑一亿次的时间。&lt;/p&gt;
&lt;p&gt;我将取最后五个记录的平均值，作为预热后的峰值性能。（注：这种性能评估方式并不严谨，我会在专栏的第三部分介绍如何用 JMH 来测性能。）&lt;/p&gt;
&lt;p&gt;在我这个老笔记本上，一亿次直接调用耗费的时间大约在 120ms。这和不调用的时间是一致的。其原因在于这段代码属于热循环，同样会触发即时编译。并且，即时编译会将对 Test.target 的调用内联进来，从而消除了调用的开销。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// v2 版本
mport java.lang.reflect.Method;
 
public class Test {
  public static void target(int i) {
    // 空方法
  }
 
  public static void main(String[] args) throws Exception {
    Class&amp;lt;?&amp;gt; klass = Class.forName(&amp;quot;Test&amp;quot;);
    Method method = klass.getMethod(&amp;quot;target&amp;quot;, int.class);
 
    long current = System.currentTimeMillis();
    for (int i = 1; i &amp;lt;= 2_000_000_000; i++) {
      if (i % 100_000_000 == 0) {
        long temp = System.currentTimeMillis();
        System.out.println(temp - current);
        current = temp;
      }
 
      method.invoke(null, 128);
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;下面我将以 120ms 作为基准，来比较反射调用的性能开销。&lt;/p&gt;
&lt;p&gt;由于目标方法 Test.target 接收一个 int 类型的参数，因此我传入 128 作为反射调用的参数，测得的结果约为基准的 2.7 倍。我们暂且不管这个数字是高是低，先来看看在反射调用之前字节码都做了什么。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;   59: aload_2                         // 加载 Method 对象
   60: aconst_null                     // 反射调用的第一个参数 null
   61: iconst_1
   62: anewarray Object                // 生成一个长度为 1 的 Object 数组
   65: dup
   66: iconst_0
   67: sipush 128
   70: invokestatic Integer.valueOf    // 将 128 自动装箱成 Integer
   73: aastore                         // 存入 Object 数组中
   74: invokevirtual Method.invoke     // 反射调用
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里我截取了循环中反射调用编译而成的字节码。可以看到，这段字节码除了反射调用外，还额外做了两个操作。&lt;/p&gt;
&lt;p&gt;第一，由于 Method.invoke 是一个变长参数方法，在字节码层面它的最后一个参数会是 Object 数组（感兴趣的同学私下可以用 javap 查看）。Java 编译器会在方法调用处生成一个长度为传入参数数量的 Object 数组，并将传入参数一一存储进该数组中。&lt;/p&gt;
&lt;p&gt;第二，由于 Object 数组不能存储基本类型，Java 编译器会对传入的基本类型参数进行自动装箱。&lt;/p&gt;
&lt;p&gt;这两个操作除了带来性能开销外，还可能占用堆内存，使得 GC 更加频繁。（如果你感兴趣的话，可以用虚拟机参数 -XX:+PrintGC 试试。）那么，如何消除这部分开销呢？&lt;/p&gt;
&lt;p&gt;关于第二个自动装箱，Java 缓存了 [-128, 127] 中所有整数所对应的 Integer 对象。当需要自动装箱的整数在这个范围之内时，便返回缓存的 Integer，否则需要新建一个 Integer 对象。&lt;/p&gt;
&lt;p&gt;因此，我们可以将这个缓存的范围扩大至覆盖 128（对应参数&lt;br&gt;
-Djava.lang.Integer.IntegerCache.high=128），便可以避免需要新建 Integer 对象的场景。&lt;/p&gt;
&lt;p&gt;或者，我们可以在循环外缓存 128 自动装箱得到的 Integer 对象，并且直接传入反射调用中。这两种方法测得的结果差不多，约为基准的 1.8 倍。&lt;/p&gt;
&lt;p&gt;现在我们再回来看看第一个因变长参数而自动生成的 Object 数组。既然每个反射调用对应的参数个数是固定的，那么我们可以选择在循环外新建一个 Object 数组，设置好参数，并直接交给反射调用。改好的代码可以参照文稿中的 v3 版本。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// v3 版本
import java.lang.reflect.Method;
 
public class Test {
  public static void target(int i) {
    // 空方法
  }
 
  public static void main(String[] args) throws Exception {
    Class&amp;lt;?&amp;gt; klass = Class.forName(&amp;quot;Test&amp;quot;);
    Method method = klass.getMethod(&amp;quot;target&amp;quot;, int.class);
 
    Object[] arg = new Object[1]; // 在循环外构造参数数组
    arg[0] = 128;
 
    long current = System.currentTimeMillis();
    for (int i = 1; i &amp;lt;= 2_000_000_000; i++) {
      if (i % 100_000_000 == 0) {
        long temp = System.currentTimeMillis();
        System.out.println(temp - current);
        current = temp;
      }
 
      method.invoke(null, arg);
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;测得的结果反而更糟糕了，为基准的 2.9 倍。这是为什么呢？&lt;/p&gt;
&lt;p&gt;如果你在上一步解决了自动装箱之后查看运行时的 GC 状况，你会发现这段程序并不会触发 GC。其原因在于，原本的反射调用被内联了，从而使得即时编译器中的逃逸分析将原本新建的 Object 数组判定为不逃逸的对象。&lt;/p&gt;
&lt;p&gt;如果一个对象不逃逸，那么即时编译器可以选择栈分配甚至是虚拟分配，也就是不占用堆空间。具体我会在本专栏的第二部分详细解释。&lt;/p&gt;
&lt;p&gt;如果在循环外新建数组，即时编译器无法确定这个数组会不会中途被更改，因此无法优化掉访问数组的操作，可谓是得不偿失。&lt;/p&gt;
&lt;p&gt;到目前为止，我们的最好记录是 1.8 倍。那能不能再进一步提升呢？&lt;/p&gt;
&lt;p&gt;刚才我曾提到，可以关闭反射调用的 Inflation 机制，从而取消委派实现，并且直接使用动态实现。此外，每次反射调用都会检查目标方法的权限，而这个检查同样可以在 Java 代码里关闭，在关闭了这两项机制之后，也就得到了我们的 v4 版本，它测得的结果约为基准的 1.3 倍。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// v4 版本
import java.lang.reflect.Method;
 
// 在运行指令中添加如下两个虚拟机参数：
// -Djava.lang.Integer.IntegerCache.high=128
// -Dsun.reflect.noInflation=true
public class Test {
  public static void target(int i) {
    // 空方法
  }
 
  public static void main(String[] args) throws Exception {
    Class&amp;lt;?&amp;gt; klass = Class.forName(&amp;quot;Test&amp;quot;);
    Method method = klass.getMethod(&amp;quot;target&amp;quot;, int.class);
    method.setAccessible(true);  // 关闭权限检查
 
    long current = System.currentTimeMillis();
    for (int i = 1; i &amp;lt;= 2_000_000_000; i++) {
      if (i % 100_000_000 == 0) {
        long temp = System.currentTimeMillis();
        System.out.println(temp - current);
        current = temp;
      }
 
      method.invoke(null, 128);
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;到这里，我们基本上把反射调用的水分都榨干了。接下来，我来把反射调用的性能开销给提回去。&lt;/p&gt;
&lt;p&gt;首先，在这个例子中，之所以反射调用能够变得这么快，主要是因为即时编译器中的方法内联。在关闭了 Inflation 的情况下，内联的瓶颈在于 Method.invoke 方法中对 MethodAccessor.invoke 方法的调用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/93/b5/93dec45b7af7951a2b6daeb01941b9b5.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;我会在后面的文章中介绍方法内联的具体实现，这里先说个结论：在生产环境中，我们往往拥有多个不同的反射调用，对应多个 GeneratedMethodAccessor，也就是动态实现。&lt;/p&gt;
&lt;p&gt;由于 Java 虚拟机的关于上述调用点的类型 profile（注：对于 invokevirtual 或者 invokeinterface，Java 虚拟机会记录下调用者的具体类型，我们称之为类型 profile）无法同时记录这么多个类，因此可能造成所测试的反射调用没有被内联的情况。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// v5 版本
import java.lang.reflect.Method;
 
public class Test {
  public static void target(int i) {
    // 空方法
  }
 
  public static void main(String[] args) throws Exception {
    Class&amp;lt;?&amp;gt; klass = Class.forName(&amp;quot;Test&amp;quot;);
    Method method = klass.getMethod(&amp;quot;target&amp;quot;, int.class);
    method.setAccessible(true);  // 关闭权限检查
    polluteProfile();
 
    long current = System.currentTimeMillis();
    for (int i = 1; i &amp;lt;= 2_000_000_000; i++) {
      if (i % 100_000_000 == 0) {
        long temp = System.currentTimeMillis();
        System.out.println(temp - current);
        current = temp;
      }
 
      method.invoke(null, 128);
    }
  }
 
  public static void polluteProfile() throws Exception {
    Method method1 = Test.class.getMethod(&amp;quot;target1&amp;quot;, int.class);
    Method method2 = Test.class.getMethod(&amp;quot;target2&amp;quot;, int.class);
    for (int i = 0; i &amp;lt; 2000; i++) {
      method1.invoke(null, 0);
      method2.invoke(null, 0);
    }
  }
  public static void target1(int i) { }
  public static void target2(int i) { }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在上面的 v5 版本中，我在测试循环之前调用了 polluteProfile 的方法。该方法将反射调用另外两个方法，并且循环上 2000 遍。&lt;/p&gt;
&lt;p&gt;而测试循环则保持不变。测得的结果约为基准的 6.7 倍。也就是说，只要误扰了 Method.invoke 方法的类型 profile，性能开销便会从 1.3 倍上升至 6.7 倍。&lt;/p&gt;
&lt;p&gt;之所以这么慢，除了没有内联之外，另外一个原因是逃逸分析不再起效。这时候，我们便可以采用刚才 v3 版本中的解决方案，在循环外构造参数数组，并直接传递给反射调用。这样子测得的结果约为基准的 5.2 倍。&lt;/p&gt;
&lt;p&gt;除此之外，我们还可以提高 Java 虚拟机关于每个调用能够记录的类型数目（对应虚拟机参数 -XX:TypeProfileWidth，默认值为 2，这里设置为 3）。最终测得的结果约为基准的 2.8 倍，尽管它和原本的 1.3 倍还有一定的差距，但总算是比 6.7 倍好多了。&lt;/p&gt;
&lt;h2 id=&#34;总结与实践&#34;&gt;总结与实践&lt;/h2&gt;
&lt;p&gt;今天我介绍了 Java 里的反射机制。&lt;/p&gt;
&lt;p&gt;在默认情况下，方法的反射调用为委派实现，委派给本地实现来进行方法调用。在调用超过 15 次之后，委派实现便会将委派对象切换至动态实现。这个动态实现的字节码是自动生成的，它将直接使用 invoke 指令来调用目标方法。&lt;/p&gt;
&lt;p&gt;方法的反射调用会带来不少性能开销，原因主要有三个：变长参数方法导致的 Object 数组，基本类型的自动装箱、拆箱，还有最重要的方法内联。&lt;/p&gt;
&lt;p&gt;今天的实践环节，你可以将最后一段代码中 polluteProfile 方法的两个 Method 对象，都改成获取名字为&amp;quot;target&amp;quot;的方法。请问这两个获得的 Method 对象是同一个吗（==）？他们 equal 吗（.equals(&amp;hellip;)）？对我们的运行结果有什么影响？&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import java.lang.reflect.Method;
 
public class Test {
  public static void target(int i) {
    // 空方法
  }
 
  public static void main(String[] args) throws Exception {
    Class&amp;lt;?&amp;gt; klass = Class.forName(&amp;quot;Test&amp;quot;);
    Method method = klass.getMethod(&amp;quot;target&amp;quot;, int.class);
    method.setAccessible(true);  // 关闭权限检查
    polluteProfile();
 
    long current = System.currentTimeMillis();
    for (int i = 1; i &amp;lt;= 2_000_000_000; i++) {
      if (i % 100_000_000 == 0) {
        long temp = System.currentTimeMillis();
        System.out.println(temp - current);
        current = temp;
      }
 
      method.invoke(null, 128);
    }
  }
 
  public static void polluteProfile() throws Exception {
    Method method1 = Test.class.getMethod(&amp;quot;target&amp;quot;, int.class);
    Method method2 = Test.class.getMethod(&amp;quot;target&amp;quot;, int.class);
    for (int i = 0; i &amp;lt; 2000; i++) {
      method1.invoke(null, 0);
      method2.invoke(null, 0);
    }
  }
  public static void target1(int i) { }
  public static void target2(int i) { }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;附录反射-api-简介&#34;&gt;附录：反射 API 简介&lt;/h2&gt;
&lt;p&gt;通常来说，使用反射 API 的第一步便是获取 Class 对象。在 Java 中常见的有这么三种。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用静态方法 Class.forName 来获取。&lt;/li&gt;
&lt;li&gt;调用对象的 getClass() 方法。&lt;/li&gt;
&lt;li&gt;直接用类名 +&amp;quot;.class&amp;quot;访问。对于基本类型来说，它们的包装类型（wrapper classes）拥有一个名为&amp;quot;TYPE&amp;quot;的 final 静态字段，指向该基本类型对应的 Class 对象。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;例如，Integer.TYPE 指向 int.class。对于数组类型来说，可以使用类名 +&amp;quot;[ ].class&amp;quot;来访问，如 int[ ].class。&lt;/p&gt;
&lt;p&gt;除此之外，Class 类和 java.lang.reflect 包中还提供了许多返回 Class 对象的方法。例如，对于数组类的 Class 对象，调用 Class.getComponentType() 方法可以获得数组元素的类型。&lt;/p&gt;
&lt;p&gt;一旦得到了 Class 对象，我们便可以正式地使用反射功能了。下面我列举了较为常用的几项。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;使用 newInstance() 来生成一个该类的实例。它要求该类中拥有一个无参数的构造器。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用 isInstance(Object) 来判断一个对象是否该类的实例，语法上等同于 instanceof 关键字（JIT 优化时会有差别，我会在本专栏的第二部分详细介绍）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用 Array.newInstance(Class,int) 来构造该类型的数组。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用 getFields()/getConstructors()/getMethods() 来访问该类的成员。除了这三个之外，Class 类还提供了许多其他方法，详见 [4]。需要注意的是，方法名中带 Declared 的不会返回父类的成员，但是会返回私有成员；而不带 Declared 的则相反。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;当获得了类成员之后，我们可以进一步做如下操作。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用 Constructor/Field/Method.setAccessible(true) 来绕开 Java 语言的访问限制。&lt;/li&gt;
&lt;li&gt;使用 Constructor.newInstance(Object[]) 来生成该类的实例。&lt;/li&gt;
&lt;li&gt;使用 Field.get/set(Object) 来访问字段的值。&lt;/li&gt;
&lt;li&gt;使用 Method.invoke(Object, Object[]) 来调用方法。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;有关反射 API 的其他用法，可以参考 reflect 包的 javadoc [5] ，这里就不详细展开了。&lt;/p&gt;
&lt;p&gt;[1] : &lt;a href=&#34;https://docs.oracle.com/javase/tutorial/reflect/&#34;&gt;https://docs.oracle.com/javase/tutorial/reflect/&lt;/a&gt;&lt;br&gt;
[2]: &lt;a href=&#34;http://hg.openjdk.java.net/jdk10/jdk10/jdk/file/777356696811/src/java.base/share/classes/jdk/internal/reflect/ReflectionFactory.java#l80&#34;&gt;http://hg.openjdk.java.net/jdk10/jdk10/jdk/file/777356696811/src/java.base/share/classes/jdk/internal/reflect/ReflectionFactory.java#l80&lt;/a&gt;&lt;br&gt;
[3]: &lt;a href=&#34;http://hg.openjdk.java.net/jdk10/jdk10/jdk/file/777356696811/src/java.base/share/classes/jdk/internal/reflect/ReflectionFactory.java#l78&#34;&gt;http://hg.openjdk.java.net/jdk10/jdk10/jdk/file/777356696811/src/java.base/share/classes/jdk/internal/reflect/ReflectionFactory.java#l78&lt;/a&gt;&lt;br&gt;
[4]: &lt;a href=&#34;https://docs.oracle.com/javase/tutorial/reflect/class/classMembers.html&#34;&gt;https://docs.oracle.com/javase/tutorial/reflect/class/classMembers.html&lt;/a&gt;&lt;br&gt;
[5]: &lt;a href=&#34;https://docs.oracle.com/javase/10/docs/api/java/lang/reflect/package-summary.html&#34;&gt;https://docs.oracle.com/javase/10/docs/api/java/lang/reflect/package-summary.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/2a/d5/2a62e58cbdf56a5dc40748567d346fd5.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 07丨Nacos体系架构：什么是服务治理？</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/springclouod%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/07%E4%B8%A8nacos%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/springclouod%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/07%E4%B8%A8nacos%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86/</guid>
      <description>
        
        
        &lt;p&gt;你好，我是姚秋辰。&lt;/p&gt;
&lt;p&gt;从今天开始，我们的课程就正式进入 Spring Cloud 环节了。我先带你学习微服务架构中一个最重要的原理概念：&lt;strong&gt;服务治理&lt;/strong&gt;。在概念讲解之后，我还会向你介绍 &lt;strong&gt;Nacos 服务注册中心的体系结构&lt;/strong&gt;。通过这节课的学习，你可以了解微服务的完整生命周期，知晓服务注册中心在微服务架构中发挥了什么作用，这些内容能让你对 Nacos 的体系架构有一个比较全面的认识。&lt;/p&gt;
&lt;p&gt;首先，让我通过一个例子告诉你服务治理解决了什么问题。&lt;/p&gt;
&lt;p&gt;我的系统包含两个微服务（服务 A 和服务 B），每一个微服务有 10 个虚拟节点，两个服务组成了一个 20 台虚拟机的微服务集群。如果此时微服务 A 想要调用微服务 B，我们怎么来发起这个调用呢？&lt;/p&gt;
&lt;p&gt;一种通用做法是：在服务 A 的配置文件中添加一个指向服务 B 的地址，但这个地址并不直接指向任何一台服务 B 集群中的节点，而是指向一个 VIP（虚拟 IP 地址）或者是一个网关。这个 VIP 或网关背后维护了 B 集群的服务节点列表，VIP 层通过负载均衡策略再将请求转到后面配置的某一台服务器。我画了一幅图来描述这个服务调用过程。&lt;br&gt;
&lt;img src=&#34;https://static001.geekbang.org/resource/image/fc/0d/fcd15ed204d43fe615cb50acbe58010d.jpg?wh=2000x984&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;从上面的图中我们可以看出，服务 A 与服务 B 之间互相不直接通信，服务调用完全依靠 VIP 作为中间人来完成。我们如果想要为服务集群扩容或缩容，必须将服务器配置到对应的 VIP 地址上。如果你的应用是一个由数百个微服务组成的大型应用，光是管理这些 VIP Pool 的人力成本就够网络运维团队喝上一壶了。&lt;/p&gt;
&lt;p&gt;那在微服务架构中，怎么才能实现一种简单可靠的远程服务调用，不让 VIP 中间商赚差价呢？这就要说到我们的服务治理理论了。&lt;/p&gt;
&lt;h1 id=&#34;服务治理初探&#34;&gt;服务治理初探&lt;/h1&gt;
&lt;p&gt;如果我们要解决中间商赚差价的问题，那么最好的办法就是让双方直连。因此，服务治理要解决的首要任务就是&lt;strong&gt;服务注册&lt;/strong&gt;与&lt;strong&gt;服务发现&lt;/strong&gt;，通过这两项技术，我们就能让微服务之间发起面对面的直接调用。&lt;/p&gt;
&lt;p&gt;那么服务 A 怎么知道服务 B 中每台机器的地址呢？为了让服务 A 拿到服务 B 的机器清单，我们需要搭建一个&lt;strong&gt;中心化的服务注册中心&lt;/strong&gt;，服务 B 只要将自己的信息添加到注册中心里，服务 A 就能够从注册中心获取到服务 B 的所有节点列表。我画了一张图来帮助你更好地理解这个过程。&lt;br&gt;
&lt;img src=&#34;https://static001.geekbang.org/resource/image/81/e2/81bd88faec1dd053104c3be5b6792de2.jpg?wh=2000x984&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;从上图中的步骤中我们可以看出，首先，服务 B 集群向注册中心发起了注册，将自己的地址信息上报到注册中心，这个过程就是&lt;strong&gt;服务注册&lt;/strong&gt;。接下来，每隔一段时间，服务 A 就会从服务中心获取服务 B 集群的服务列表，或者由服务中心将服务列表的变动推送给服务 A，这个过程叫做&lt;strong&gt;服务发现&lt;/strong&gt;；最后，服务 A 根据本地负载均衡策略，从服务列表中选取某一个服务 B 的节点，发起服务调用。&lt;/p&gt;
&lt;p&gt;在这个过程中，&lt;strong&gt;注册中心的角色是一个中心化的信息管理者&lt;/strong&gt;，所有的微服务节点在启动后都会将自己的地址信息添加到注册中心。在服务注册的过程中，有两个关键信息是最为重要的，我把它们列在了这里。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;服务名称&lt;/strong&gt;：服务名称通常默认是 spring.application.name 属性，在服务注册过程中我们必须将应用服务名上报到注册中心，这样其他服务才能根据服务名称找到对应的服务节点列表；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;地址信息&lt;/strong&gt;：包括服务节点的 IP 地址和端口。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通过上面这两个信息，调用方就能精准定位到目标微服务。除此之外，服务注册请求中还包含一些额外的注册信息，我将在 Nacos 的实战环节为你详细讲解这些注册参数。&lt;/p&gt;
&lt;p&gt;通过服务注册和服务发现，我们已经能够实现端到端的服务调用链路，但这个方案似乎还并不完善，因为它缺少了&lt;strong&gt;异常容错&lt;/strong&gt;的机制。&lt;/p&gt;
&lt;p&gt;如果服务 B 集群因为未知的网络故障导致无法响应服务，这时候服务 A 向服务 B 发起了服务调用，就会发生超时或者服务无响应的异常情况。那我们如何在服务治理方案中规避这类问题呢？&lt;/p&gt;
&lt;p&gt;业界通用的解决方案是&amp;quot;heathcheck&amp;quot;或者&amp;quot;heartbeat&amp;quot;，又叫&amp;quot;服务探活&amp;quot;或&amp;quot;心跳检查&amp;quot;。注册中心可以通过这种机制来标记异常服务，这样一来，Client 端在发送服务请求的时候就能避开异常节点。&lt;/p&gt;
&lt;p&gt;我将这些异常处理的步骤添加到了服务注册流程中，并画了一个完整的微服务生命周期的图，你可以参考一下。&lt;br&gt;
&lt;img src=&#34;https://static001.geekbang.org/resource/image/f1/e7/f1ca43ff75242242a8b97b3df63a0ae7.jpg?wh=2000x984&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;看了图片，你可能会问，怎么还有一个&amp;quot;服务剔除&amp;quot;呢？它是怎么实现的？&lt;/p&gt;
&lt;p&gt;先说一个大前提。所有的服务都要在注册中心进行注册，而且每个节点都需要每隔一段时间向注册中心同步自己当前的状态，我们很形象地称这个过程为 heartbeat（心跳）。&lt;/p&gt;
&lt;p&gt;如果节点持续发送心跳信息，则一切正常，服务可以被发现；如果注册中心在一段时间内没有收到 Client 的心跳包，注册中心就会将这个节点标记为下线状态，进而将该服务从服务列表中剔除。&lt;/p&gt;
&lt;p&gt;这里我再补充一句，我们上面说的&amp;quot;服务剔除&amp;quot;是由注册中心主导的&amp;quot;被动下线&amp;quot;场景。除此之外还有一类服务&amp;quot;主动下线&amp;quot;的场景，也就是当服务节点关闭或者重启的时候，通过发送一条&amp;quot;服务下线&amp;quot;指令给到注册中心，将当前节点标记为下线状态。&lt;/p&gt;
&lt;p&gt;到这里，相信你已经完全理解了微服务生命周期各个状态间的流转，也知道了服务注册中心在微服务生命周期中扮演了什么角色。&lt;/p&gt;
&lt;p&gt;接下来，我们来了解 Spring Cloud 中的服务注册中心 Nacos。&lt;/p&gt;
&lt;h1 id=&#34;nacos-体系架构&#34;&gt;Nacos 体系架构&lt;/h1&gt;
&lt;p&gt;Nacos 有三个核心知识点：领域模型、数据模型和基本架构，这是我们整体把握 Nacos 架构的关键。下面我们来依次看看。&lt;/p&gt;
&lt;h1 id=&#34;领域模型&#34;&gt;领域模型&lt;/h1&gt;
&lt;p&gt;Nacos 领域模型描述了服务与实例之间的边界和层级关系。Nacos 的服务领域模型是以&amp;quot;服务&amp;quot;为维度构建起来的，这个服务并不是指集群中的单个服务器，而是指微服务的服务名。&lt;/p&gt;
&lt;p&gt;&amp;ldquo;服务&amp;quot;是 Nacos 中位于最上层的概念，在服务之下，还有集群和实例的概念。为了方便你理解这三者的层级关系，我画了一张图，你可以参考一下。&lt;br&gt;
&lt;img src=&#34;https://static001.geekbang.org/resource/image/21/48/21d3938ce122a48652397c329b361948.jpg?wh=2000x984&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;从上面的图中你可以看出，Nacos 的服务领域模型从上到下分为了服务、集群和实例三层，我分别介绍一下这三个层次所包含的重要数据内容。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;服务&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在服务这个层级上我们可以配置元数据和服务保护阈值等信息。服务阈值是一个 0~1 之间的数字，当服务的健康实例数与总实例的比例小于这个阈值的时候，说明能提供服务的机器已经没多少了。这时候 Nacos 会开启服务保护模式，不再主动剔除服务实例，同时还会将不健康的实例也返回给消费者。尽管这样做可能造成请求失败，但间接保证了最低限度的服务可用性。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;集群&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一个服务由很多服务实例组成，在每个服务实例启动的时候，我们可以设置它所属的集群，在集群这个层级上，我们也可以配置元数据。除此之外，我们还可以为持久化节点设置健康检查模式。&lt;/p&gt;
&lt;p&gt;所谓持久化节点，是一种会保存到 Nacos 服务端的实例，即便该实例的客户端进程没有在运行，实例也不会被服务端删除，只不过 Nacos 会将这个持久化节点状态标记为不健康，Nacos 可以采用一种&amp;quot;主动探活&amp;quot;的方式来对持久化节点做健康检查。&lt;/p&gt;
&lt;p&gt;除了持久化节点以外，大部分服务节点在 Nacos 中以&amp;quot;临时节点&amp;quot;的方式存在，它是默认的服务注册方式，从名字中我们就可以看出，这种节点不会被持久化保存在 Nacos 服务器，临时节点通过主动发送 heartbeat 请求向服务器报送自己的状态。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;实例&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里所说的实例就是指服务节点，我们可以在 Nacos 控制台查看每个实例的 IP 地址和端口、编辑实例的元数据信息、修改它的上线 / 下线状态或者配置路由权重等等。&lt;/p&gt;
&lt;p&gt;你会发现，在这三个层级上都有&amp;quot;元数据&amp;quot;这一数据结构，你可以把它理解为一组包含了服务描述信息（如服务版本等）和自定义标签的数据集合。Client 端通过服务发现技术可以获取到每个服务实例的元数据，你可以将自定义的属性加入到元数据并在 Client 端实现某些定制化的业务场景。&lt;/p&gt;
&lt;p&gt;了解了领域模型之后，你知道服务调用的发起方是如何定位到领域模型中的服务实例的吗？这就要说起 Nacos 的数据模型了。&lt;/p&gt;
&lt;h1 id=&#34;数据模型&#34;&gt;数据模型&lt;/h1&gt;
&lt;p&gt;Nacos 的数据模型有三个层次结构，分别是 Namespace、Group 和 Service/DataId，我画了一幅图，帮你理解这三个层次之间的包含关系：&lt;br&gt;
&lt;img src=&#34;https://static001.geekbang.org/resource/image/e8/ee/e89a90d5cdb2d4929a8e44cf5c747fee.jpg?wh=2000x984&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;从上图中你可以看出，Namespace、Group 和 Service/DataId 是一个依次包含的结构，我分别对每一层做一个简单介绍。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Namespace&lt;/strong&gt;：即命名空间，它是最顶层的数据结构，我们可以用它来区分开发环境、生产环境等不同环境。默认情况下，所有服务都部署到一个叫做&amp;quot;public&amp;quot;的公共命名空间；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Group&lt;/strong&gt;：在命名空间之下有一个分组结构，默认情况下所有微服务都属于&amp;quot;DEFAULT_GROUP&amp;quot;这个分组，不同分组间的微服务是相互隔离的；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Service/DataID&lt;/strong&gt;：在 Group 分组之下，就是具体的微服务了，比如订单服务、商品服务等等。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通过 &lt;strong&gt;Namespace + Group + Service/DataID&lt;/strong&gt;，我们就可以精准定位到一个具体的微服务。比如，我想调用生产环境下 A 分组的订单服务，那么对应的服务寻址的 Key 就是类似 Production.A.orderService 的组合。&lt;/p&gt;
&lt;p&gt;了解了 Nacos 的数据模型之后，我再来带你看一下 Nacos 的基本架构，这样你就对 Nacos 的功能模块有一个更全面的认识。&lt;/p&gt;
&lt;h1 id=&#34;nacos-基本架构&#34;&gt;Nacos 基本架构&lt;/h1&gt;
&lt;p&gt;Nacos 的核心功能有两个，一个是 &lt;strong&gt;Naming Service&lt;/strong&gt;，也就我们用来做服务发现的模块；另一个是 &lt;strong&gt;Config Service&lt;/strong&gt;，用来提供配置项管理、动态更新配置和元数据的功能，关于配置管理的内容我会放到课程中的配置管理阶段为你详细讲解。&lt;/p&gt;
&lt;p&gt;我这里用一张 Nacos 社区的基本架构图来作为示例，带你看一下 Nacos 在功能模块层面的基本架构。&lt;br&gt;
&lt;img src=&#34;https://static001.geekbang.org/resource/image/d3/59/d3a2227dcdab8b7ddc786c9653c6bc59.jpg?wh=2000x984&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;从上面的图中你可以看出，Provider APP 和 Consumer APP 通过 Open API 和 Nacos 服务器的核心模块进行通信。这里的 Open API 是一组对外暴露的 RESTful 风格的 HTTP 接口。如果你对 Open API 里具体的接口感兴趣，可以从Nacos 官方网站获取更多的关于 Open API 的详细信息。&lt;/p&gt;
&lt;p&gt;在 Nacos 和核心模块里，Naming Service 提供了将对象和实体的&amp;quot;名字&amp;quot;映射到元数据的功能，这是服务发现的基础功能之一。例如，我想要调用 OrderService，我手里有这个服务的 Namespace 和 Group 信息，那么我就可以通过 Naming Service 定位到这个服务对应的实例列表。同理，如果我有一个 DNS 名称，同样可以借助 Naming Service 获取 DNS 背后配置的 IP 列表。以上两个场景就分别对应了服务发现和 DNS 功能，这两个场景都是 Naming Service 的核心场景。&lt;/p&gt;
&lt;p&gt;Nacos 还有一个相当重要的模块：&lt;strong&gt;Nacos Core&lt;/strong&gt; 模块。它可以提供一系列的平台基础功能，是支撑 Nacos 上层业务场景的基石。我挑选了几个 Nacos Core 中包含的重要功能，你可以看一下。&lt;br&gt;
&lt;img src=&#34;https://static001.geekbang.org/resource/image/d0/12/d0c78d0c0f2bb72c45788a5c2d423512.jpg?wh=2000x984&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;除了 Nacos Core 提供的这些功能以外，Nacos 还有一个&amp;quot;一致性协议&amp;rdquo;，用来确保 Nacos 集群中各个节点之间的数据一致性。Nacos 内部支持两种一致性协议，一种是侧重一致性的 Raft 协议，基于集群中选举出来的 Leader 节点进行数据写入；另一种是针对临时节点的 Distro 协议，它是一个侧重可用性（或最终一致性）的分布式一致性协议。&lt;/p&gt;
&lt;p&gt;到这里，我们就完成了 Nacos 的基本架构部分的学习。&lt;/p&gt;
&lt;h1 id=&#34;总结&#34;&gt;总结&lt;/h1&gt;
&lt;p&gt;现在，我们来回顾一下这节课的重点内容。今天我带你了解了服务治理所解决的问题。在这个问题解决的过程中，你自然建立起了对微服务生命周期各个状态的了解，你也能清楚地感受到服务注册中心 Nacos 的重要程度。为了让你更全面地认识 &lt;strong&gt;Nacos 的功能体系&lt;/strong&gt;，我为你讲解了领域模型、数据模型和基础架构。&lt;/p&gt;
&lt;p&gt;此外，我要给你一个小提示，虽然这节课我并没有深入介绍 Nacos 底层一致性协议的原理，但&lt;strong&gt;一致性协议是近年来面试中常问到的热点问题&lt;/strong&gt;，我建议你借这个机会，去主动了解一些常见的经典协议。&lt;/p&gt;
&lt;p&gt;在后面的课程中，我将带你搭建一个 Nacos 服务器集群，通过对 Spring Boot 项目的 Nacos 服务化改造，将实战项目里的本地方法调用改为微服务架构下的远程调用。通过实战环节的动手练习，你将对本节课的理论内容有更深的理解。&lt;/p&gt;
&lt;h1 id=&#34;思考题&#34;&gt;思考题&lt;/h1&gt;
&lt;p&gt;如果你正在开发的业务系统采用的是微服务架构，那么你如何实现远程服务调用呢？欢迎在留言区写下你的技术方案和技术选型，最好能再描述下背后的原理。&lt;/p&gt;
&lt;p&gt;好啦，这节课就结束啦。欢迎你把这节课分享给更多对 Spring Cloud 感兴趣的朋友。我是姚秋辰，我们下节课再见！&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 07丨推荐阅读：每个程序员都该知道的知识</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/07%E4%B8%A8%E6%8E%A8%E8%8D%90%E9%98%85%E8%AF%BB%E6%AF%8F%E4%B8%AA%E7%A8%8B%E5%BA%8F%E5%91%98%E9%83%BD%E8%AF%A5%E7%9F%A5%E9%81%93%E7%9A%84%E7%9F%A5%E8%AF%86/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/07%E4%B8%A8%E6%8E%A8%E8%8D%90%E9%98%85%E8%AF%BB%E6%AF%8F%E4%B8%AA%E7%A8%8B%E5%BA%8F%E5%91%98%E9%83%BD%E8%AF%A5%E7%9F%A5%E9%81%93%E7%9A%84%E7%9F%A5%E8%AF%86/</guid>
      <description>
        
        
        &lt;p&gt;在整个为期一年的专栏内容中，我会逐步向你推荐一些有价值的内容，供你参考，这些内容有中文，有英文，也有视频，它们都是我认为对我非常有价值的信息，我也希望它们对你能有同样的帮助和启发。&lt;/p&gt;
&lt;p&gt;今天，我为你推荐的 5 篇文章，它们分别是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Stack Overflow 上推荐的一个经典书单；&lt;/li&gt;
&lt;li&gt;美国某大学教授给计算机专业学生的一些建议，其中有很多的学习资源；&lt;/li&gt;
&lt;li&gt;LinkedIn 的高效代码复查实践，很不错的方法，值得你一读；&lt;/li&gt;
&lt;li&gt;一份关于程序语言和 bug 数相关的有趣的报告，可以让你对各种语言有所了解；&lt;/li&gt;
&lt;li&gt;最后是一本关于 C++ 性能优化的电子书。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;每个程序员都应该要读的书&#34;&gt;每个程序员都应该要读的书&lt;/h4&gt;
&lt;p&gt;在 Stack Overflow 上有用户问了一个&lt;a href=&#34;https://stackoverflow.com/questions/1711/what-is-the-single-most-influential-book-every-programmer-should-read&#34;&gt;问题&lt;/a&gt;，大意是想让大家推荐一些每个程序员都应该阅读的最有影响力的图书。&lt;/p&gt;
&lt;p&gt;虽然这个问题已经被关闭了，但这真是一个非常热门的话题。排在第一位的用户给出了一大串图书的列表，看上去着实吓人，不过都是一些相当经典相当有影响力的书，在这里我重新罗列一些我觉得你必须要看的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;《代码大全》&lt;/strong&gt; 虽然这本书有点过时了，而且厚到可以垫显示器，但是这绝对是一本经典的书。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;《程序员修练之道》&lt;/strong&gt; 这本书也是相当经典，我觉得就是你的指路明灯。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;《计算机的构造和解释》&lt;/strong&gt; 经典中的经典，必读。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;《算法导论》&lt;/strong&gt; 美国的本科生教材，这本书应该也是中国计算机学生的教材。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;《设计模式》&lt;/strong&gt; 这本书是面向对象设计的经典书籍。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;《重构》&lt;/strong&gt; 代码坏味道和相应代码的最佳实践。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;《人月神话》&lt;/strong&gt; 这本书可能也有点过时了。但还是经典书。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;《代码整洁之道》&lt;/strong&gt; 细节之处的效率，完美和简单。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;《Effective C++》/《More Effective C++》&lt;/strong&gt; C++ 中两本经典得不能再经典的书。也许你觉得 C++ 复杂，但这两本书中带来对代码稳定性的探索方式让人受益，因为这种思维方式同样可以用在其它地方。以至于各种模仿者，比如《Effective Java》也是一本经典书。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;**《Unix 编程艺术》、《Unix 高级环境编程》**也是相关的经典。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;还有好多，我就不在这里一一列举了。你可以看看其它的答案，我发现自己虽然读过好多书，但同样还有好些书没有读过，这个问答对我也很有帮助。&lt;/p&gt;
&lt;h4 id=&#34;每个搞计算机专业的学生应有的知识&#34;&gt;每个搞计算机专业的学生应有的知识&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://matt.might.net/articles/what-cs-majors-should-know/&#34;&gt;What every computer science major should know&lt;/a&gt;&lt;/strong&gt;，每个搞计算机专业的学生应有的知识。&lt;/p&gt;
&lt;p&gt;本文作者马修·迈特（Matthew Might）是美国犹他大学计算机学院的副教授，2007 年于佐治亚理工学院取得博士学位。计算机专业的课程繁多，而且随着时代的变化，科目的课程组成也在不断变化。&lt;/p&gt;
&lt;p&gt;如果不经过思考，直接套用现有的计算机专业课程列表，则有可能忽略一些将来可能变得重要的知识点。为此，马修力求从四个方面来总结，得出这篇文章的内容。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;要获得一份好工作，学生需要知道什么？&lt;/li&gt;
&lt;li&gt;为了一辈子都有工作干，学生需要知道什么？&lt;/li&gt;
&lt;li&gt;学生需要知道什么，才能进入研究生院？&lt;/li&gt;
&lt;li&gt;学生需要知道什么，才能对社会有益？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这篇文章不仅仅对刚毕业的学生有用，对有工作经验的人同样有用，这里我把这篇文章的内容摘要如下。&lt;/p&gt;
&lt;p&gt;首先，对于我们每个人来说，作品集（Portfolio）会比简历（Resume）更有参考意义。所以，在自己的简历中应该放上自己的一些项目经历，或是一些开源软件的贡献，或是你完成的软件的网址等。最好有一个自己的个人网址，上面有一些你做的事、自己的技能、经历，以及你的一些文章和思考会比简历更好。&lt;/p&gt;
&lt;p&gt;其次，计算机专业工作者也要学会与人交流的技巧，包括如何写演示文稿，以及面对质疑时如何与人辩论的能力。&lt;/p&gt;
&lt;p&gt;最后，他就各个方面展开计算机专业人士所需要的硬技能：工程类数学、Unix 哲学和实践、系统管理、程序设计语言、离散数学、数据结构与算法、计算机体系结构、操作系统、网络、安全、密码学、软件测试、用户体验、可视化、并行计算、软件工程、形式化方法、图形学、机器人、人工智能、机器学习、数据库等等。详读本文可以了解计算机专业知识的全貌。&lt;/p&gt;
&lt;p&gt;这篇文章的第三部分简直就是一个知识资源向导库，给出了各个技能的方向和关键知识点，你可以跟随着这篇文章里的相关链接学到很多东西。&lt;/p&gt;
&lt;h1 id=&#34;linkedin-高效的代码复查技巧&#34;&gt;LinkedIn 高效的代码复查技巧&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://thenewstack.io/linkedin-code-review/&#34;&gt;LinkedIn&amp;rsquo;s Tips for Highly Effective Code Review&lt;/a&gt;&lt;/strong&gt;，LinkedIn 的高效代码复查技巧。&lt;/p&gt;
&lt;p&gt;对于 Code Review，我曾经写过一篇文章 《&lt;a href=&#34;https://coolshell.cn/articles/11432.html&#34;&gt;从 Code Review 谈如何做技术&lt;/a&gt;》，讲述了为什么 Code Review 是一件很重要事情。今天推荐的这篇文章是 LinkedIn 的相关实践。&lt;/p&gt;
&lt;p&gt;这篇文章介绍了 LinkedIn 内部实践的 Code Review 形式。具体来说，LinkedIn 的代码复查有以下几个特点。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;从 2011 年开始，强制要求在团队成员之间做代码复查。Code Review 带来的反馈意见让团队成员能够迅速提升自己的技能水平，这解决了 LinkedIn 各个团队近年来因迅速扩张带来的技能不足的问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通过建立公司范围的 Code Review 工具，这就可以做跨团队的 Code Review。既有利于消除 bug，提升质量，也有利于不同团队之间经验互通。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Code Review 的经验作为员工晋升的参考因素之一。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Code Review 的一个难点是，Reviewer 可能不了解某块代码修改的背景和目的。所以 LinkedIn 要求代码签入版本管理系统前，就对其做清晰的说明，以便复查者了解其目的，促进 Review 的进行。&lt;/p&gt;
&lt;p&gt;我认为，这个方法实在太赞了。因为，我看到很多时候，Reviewer 都会说不了解对方代码的背景或是代码量比较大而无法做 Code Review，然而，他们却没有找到相应的方法解决这个问题。&lt;/p&gt;
&lt;p&gt;LinkedIn 对提交代码写说明文档这个思路是一个非常不错的方法，因为代码提交人写文档的过程其实也是重新梳理的过程。我的个人经验是，写文档的时候通常会发现自己把事儿干复杂了，应该把代码再简化一下，于是就会回头去改代码。是的，写文档就是在写代码。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;有些 Code Review 工具所允许给出的反馈只是代码怎样修改以变得更好，但长此以往会让人觉得复查提出的意见都表示原先的代码不够好。为了提高员工积极性，LinkedIn 的代码复查工具允许提出&amp;quot;这段代码很棒&amp;quot;之类的话语，以便让好代码的作者得到鼓励。我认为，这个方法也很赞，正面鼓励的价值也不可小看。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;为 Code Review 的结果写出有目的性的注释。比如&amp;quot;消除重复代码&amp;quot;，&amp;ldquo;增加了测试覆盖率&amp;rdquo;，等等。长此以往也让团队的价值观得以明确。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Code Review 中，不但要 Review 提交者的代码，还要 Reivew 提交者做过的测试。除了一些单元测试，还有一些可能是手动的测试。提交者最好列出所有测试过的案例。这样可以让 Reviewer 可以做出更多的测试建议，从而提高质量。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对 Code Review 有明确的期望，不过分关注细枝末节，也不要炫技，而是对要 Review 的代码有一个明确的目标。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;编程语言和代码质量的研究报告&#34;&gt;编程语言和代码质量的研究报告&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://cacm.acm.org/magazines/2017/10/221326-a-large-scale-study-of-programming-languages-and-code-quality-in-github/&#34;&gt;A Large-Scale Study of Programming Languages and Code Quality in GitHub&lt;/a&gt;&lt;/strong&gt;，编程语言和代码质量的研究报告。&lt;/p&gt;
&lt;p&gt;这是一项有趣的研究。有四个人从 GitHub 上分析了 728 个项目，6300 万行代码，近 3 万个提交人，150 万次 commits，以及 17 种编程语言（如下图所示），他们想找到编程语言对软件质量的影响。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/83/fa/83a8e04f9d2c0725c1b519f6456349fa.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;然后，他们还对编程语言做了一个分类，想找到不同类型的编程语言的 bug 问题。如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/89/8d/896d4909cb9e980dbc48c87adb51c48d.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;以及，他们还对这众多的开源软件做了个聚类，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/b5/15/b5ff49830df9bdaabd42588a89ecb915.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;对 bug 的类型也做了一个聚类，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/70/ed/70a562303a472634cf7bf801951b72ed.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;其中分析的方法我不多说了。我们来看一下相关的结果。&lt;/p&gt;
&lt;p&gt;首先，他们得出来的第一个结果是，从查看 bug fix 的 commits 的次数情况来看，C、C++、Objective-C、PHP 和 Python 中有很多很多的 commits 都是和 bug fix 相关的，而 Clojure、Haskell、Ruby、Scala 在 bug fix 的 commits 的数上明显要少很多。&lt;/p&gt;
&lt;p&gt;下图是各个编程语言的 bug 情况。如果你看到是正数，说明高于平均水平，如果你看到是负数，则是低于平均水平。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/a6/a7/a61c4f959ce7775e3d050320638553a7.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;第二个结论是，函数式编程语言的 bug 明显比大多数其它语言要好很多。有隐式类型转换的语言明显产生的 bug 数要比强类型的语言要少很多。函数式的静态类型的语言要比函数式的动态类型语言的程序出 bug 的可能性要小很多。&lt;/p&gt;
&lt;p&gt;第三，研究者想搞清是否 bug 数会和软件的领域相关。比如，业务型、中间件型、框架、lib，或是数据库。研究表明，并没有什么相关性。下面这个图是各个语言在不同领域的 bug 率。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/65/43/65cdbf74558d61d46eda9f92b35c8e43.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;第四，研究人员想搞清楚 bug 的类型是否会和语言有关系。的确如此，bug 的类型和语言是强相关性的。下图是各个语言在不同的 bug 类型的情况。如果你看到的是正数，说明高于平均水平，如果你看到的是负数，则是低于平均水平。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/9f/e4/9fa7b680469ca450af150ff82b07a4e4.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;也许，这份报告可以在你评估编程语言时有一定的借鉴作用。&lt;/p&gt;
&lt;h1 id=&#34;电子书c-软件性能优化&#34;&gt;电子书：《C++ 软件性能优化》&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://agner.org/optimize/optimizing_cpp.pdf&#34;&gt;Optimizing Software in C++ - Agner Fog&lt;/a&gt;&lt;/strong&gt; - PDF，C++ 软件性能优化。&lt;/p&gt;
&lt;p&gt;这本书是所有 C++ 程序员都应该要读的一本书，它从事无巨细地从语言层面、编译器层面、内存访问层面、多线程层面、CPU 层面讲述了如何对软件性能调优。实在是一本经典的电子书。&lt;/p&gt;
&lt;p&gt;Agner Fog 还写了其它几本和性能调优相关的书，你可以到这个网址&lt;a href=&#34;%EF%BC%9Ahttp://www.agner.org/optimize/&#34;&gt;下载&lt;/a&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Optimizing subroutines in assembly language: An optimization guide for x86 platforms&lt;/li&gt;
&lt;li&gt;The microarchitecture of Intel, AMD and VIA CPUs: An optimization guide for assembly programmers and compiler makers&lt;/li&gt;
&lt;li&gt;Instruction tables: Lists of instruction latencies, throughputs and micro-operation breakdowns for Intel, AMD and VIA CPUs&lt;/li&gt;
&lt;li&gt;Calling conventions for different C++ compilers and operating systems&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我今天推荐的内容比较干，都需要慢慢吸收体会，当然最好是能到实践中用用，相信这样你会有更多的感悟和收获。另外，不知道你还对哪些方面的内容感兴趣，欢迎留言给我。我后面收集推荐内容的时候，会有意识地关注整理。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/fc/e9/fcc761001867c60f526665e237f831e9.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 07丨白话容器基础（三）：深入理解容器镜像</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90-kubernetes/07%E4%B8%A8%E7%99%BD%E8%AF%9D%E5%AE%B9%E5%99%A8%E5%9F%BA%E7%A1%80%E4%B8%89%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90-kubernetes/07%E4%B8%A8%E7%99%BD%E8%AF%9D%E5%AE%B9%E5%99%A8%E5%9F%BA%E7%A1%80%E4%B8%89%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F/</guid>
      <description>
        
        
        &lt;p&gt;你好，我是张磊。我在今天这篇文章的最后，放置了一张 Kubernetes 的技能图谱，希望对你有帮助。&lt;/p&gt;
&lt;p&gt;在前两次的分享中，我讲解了 Linux 容器最基础的两种技术：Namespace 和 Cgroups。希望此时，你已经彻底理解了&amp;quot;容器的本质是一种特殊的进程&amp;quot;这个最重要的概念。&lt;/p&gt;
&lt;p&gt;而正如我前面所说的，Namespace 的作用是&amp;quot;隔离&amp;quot;，它让应用进程只能看到该 Namespace 内的&amp;quot;世界&amp;quot;；而 Cgroups 的作用是&amp;quot;限制&amp;quot;，它给这个&amp;quot;世界&amp;quot;围上了一圈看不见的墙。这么一折腾，进程就真的被&amp;quot;装&amp;quot;在了一个与世隔绝的房间里，而这些房间就是 PaaS 项目赖以生存的应用&amp;quot;沙盒&amp;quot;。&lt;/p&gt;
&lt;p&gt;可是，还有一个问题不知道你有没有仔细思考过：这个房间四周虽然有了墙，但是如果容器进程低头一看地面，又是怎样一副景象呢？&lt;/p&gt;
&lt;p&gt;换句话说，&lt;strong&gt;容器里的进程看到的文件系统又是什么样子的呢？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;可能你立刻就能想到，这一定是一个关于 Mount Namespace 的问题：容器里的应用进程，理应看到一份完全独立的文件系统。这样，它就可以在自己的容器目录（比如 /tmp）下进行操作，而完全不会受宿主机以及其他容器的影响。&lt;/p&gt;
&lt;p&gt;那么，真实情况是这样吗？&lt;/p&gt;
&lt;p&gt;&amp;ldquo;左耳朵耗子&amp;quot;叔在多年前写的一篇&lt;a href=&#34;https://coolshell.cn/articles/17010.html&#34;&gt;关于 Docker 基础知识的博客&lt;/a&gt;里，曾经介绍过一段小程序。这段小程序的作用是，在创建子进程时开启指定的 Namespace。&lt;/p&gt;
&lt;p&gt;下面，我们不妨使用它来验证一下刚刚提到的问题。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#define _GNU_SOURCE
#include &amp;lt;sys/mount.h&amp;gt; 
#include &amp;lt;sys/types.h&amp;gt;
#include &amp;lt;sys/wait.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;sched.h&amp;gt;
#include &amp;lt;signal.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#define STACK_SIZE (1024 * 1024)
static char container_stack[STACK_SIZE];
char* const container_args[] = {
  &amp;quot;/bin/bash&amp;quot;,
  NULL
};
 
int container_main(void* arg)
{  
  printf(&amp;quot;Container - inside the container!\n&amp;quot;);
  execv(container_args[0], container_args);
  printf(&amp;quot;Something&#39;s wrong!\n&amp;quot;);
  return 1;
}
 
int main()
{
  printf(&amp;quot;Parent - start a container!\n&amp;quot;);
  int container_pid = clone(container_main, container_stack+STACK_SIZE, CLONE_NEWNS | SIGCHLD , NULL);
  waitpid(container_pid, NULL, 0);
  printf(&amp;quot;Parent - container stopped!\n&amp;quot;);
  return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这段代码的功能非常简单：在 main 函数里，我们通过 clone() 系统调用创建了一个新的子进程 container_main，并且声明要为它启用 Mount Namespace（即：CLONE_NEWNS 标志）。&lt;/p&gt;
&lt;p&gt;而这个子进程执行的，是一个&amp;rdquo;/bin/bash&amp;quot;程序，也就是一个 shell。所以这个 shell 就运行在了 Mount Namespace 的隔离环境中。&lt;/p&gt;
&lt;p&gt;我们来一起编译一下这个程序：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ gcc -o ns ns.c
$ ./ns
Parent - start a container!
Container - inside the container!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这样，我们就进入了这个&amp;quot;容器&amp;quot;当中。可是，如果在&amp;quot;容器&amp;quot;里执行一下 ls 指令的话，我们就会发现一个有趣的现象： /tmp 目录下的内容跟宿主机的内容是一样的。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ls /tmp
# 你会看到好多宿主机的文件
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;也就是说：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;即使开启了 Mount Namespace，容器进程看到的文件系统也跟宿主机完全一样。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这是怎么回事呢？&lt;/p&gt;
&lt;p&gt;仔细思考一下，你会发现这其实并不难理解：&lt;strong&gt;Mount Namespace 修改的，是容器进程对文件系统&amp;quot;挂载点&amp;quot;的认知&lt;/strong&gt;。但是，这也就意味着，只有在&amp;quot;挂载&amp;quot;这个操作发生之后，进程的视图才会被改变。而在此之前，新创建的容器会直接继承宿主机的各个挂载点。&lt;/p&gt;
&lt;p&gt;这时，你可能已经想到了一个解决办法：创建新进程时，除了声明要启用 Mount Namespace 之外，我们还可以告诉容器进程，有哪些目录需要重新挂载，就比如这个 /tmp 目录。于是，我们在容器进程执行前可以添加一步重新挂载 /tmp 目录的操作：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int container_main(void* arg)
{
  printf(&amp;quot;Container - inside the container!\n&amp;quot;);
  // 如果你的机器的根目录的挂载类型是 shared，那必须先重新挂载根目录
  // mount(&amp;quot;&amp;quot;, &amp;quot;/&amp;quot;, NULL, MS_PRIVATE, &amp;quot;&amp;quot;);
  mount(&amp;quot;none&amp;quot;, &amp;quot;/tmp&amp;quot;, &amp;quot;tmpfs&amp;quot;, 0, &amp;quot;&amp;quot;);
  execv(container_args[0], container_args);
  printf(&amp;quot;Something&#39;s wrong!\n&amp;quot;);
  return 1;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，在修改后的代码里，我在容器进程启动之前，加上了一句 mount(&amp;ldquo;none&amp;rdquo;, &amp;ldquo;/tmp&amp;rdquo;, &amp;ldquo;tmpfs&amp;rdquo;, 0, &amp;ldquo;&amp;rdquo;) 语句。就这样，我告诉了容器以 tmpfs（内存盘）格式，重新挂载了 /tmp 目录。&lt;/p&gt;
&lt;p&gt;这段修改后的代码，编译执行后的结果又如何呢？我们可以试验一下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ gcc -o ns ns.c
$ ./ns
Parent - start a container!
Container - inside the container!
$ ls /tmp
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，这次 /tmp 变成了一个空目录，这意味着重新挂载生效了。我们可以用 mount -l 检查一下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ mount -l | grep tmpfs
none on /tmp type tmpfs (rw,relatime)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，容器里的 /tmp 目录是以 tmpfs 方式单独挂载的。&lt;/p&gt;
&lt;p&gt;更重要的是，因为我们创建的新进程启用了 Mount Namespace，所以这次重新挂载的操作，只在容器进程的 Mount Namespace 中有效。如果在宿主机上用 mount -l 来检查一下这个挂载，你会发现它是不存在的：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 在宿主机上
$ mount -l | grep tmpfs
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;这就是 Mount Namespace 跟其他 Namespace 的使用略有不同的地方：它对容器进程视图的改变，一定是伴随着挂载操作（mount）才能生效。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;可是，作为一个普通用户，我们希望的是一个更友好的情况：每当创建一个新容器时，我希望容器进程看到的文件系统就是一个独立的隔离环境，而不是继承自宿主机的文件系统。怎么才能做到这一点呢？&lt;/p&gt;
&lt;p&gt;不难想到，我们可以在容器进程启动之前重新挂载它的整个根目录&amp;quot;/&amp;quot;。而由于 Mount Namespace 的存在，这个挂载对宿主机不可见，所以容器进程就可以在里面随便折腾了。&lt;/p&gt;
&lt;p&gt;在 Linux 操作系统里，有一个名为 chroot 的命令可以帮助你在 shell 中方便地完成这个工作。顾名思义，它的作用就是帮你&amp;quot;change root file system&amp;quot;，即改变进程的根目录到你指定的位置。它的用法也非常简单。&lt;/p&gt;
&lt;p&gt;假设，我们现在有一个 $HOME/test 目录，想要把它作为一个 /bin/bash 进程的根目录。&lt;/p&gt;
&lt;p&gt;首先，创建一个 test 目录和几个 lib 文件夹：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ mkdir -p $HOME/test
$ mkdir -p $HOME/test/{bin,lib64,lib}
$ cd $T
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;然后，把 bash 命令拷贝到 test 目录对应的 bin 路径下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cp -v /bin/{bash,ls} $HOME/test/bin
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;接下来，把 bash 命令需要的所有 so 文件，也拷贝到 test 目录对应的 lib 路径下。找到 so 文件可以用 ldd 命令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ T=$HOME/test
$ list=&amp;quot;$(ldd /bin/ls | egrep -o &#39;/lib.*\.[0-9]&#39;)&amp;quot;
$ for i in $list; do cp -v &amp;quot;$i&amp;quot; &amp;quot;${T}${i}&amp;quot;; done
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;最后，执行 chroot 命令，告诉操作系统，我们将使用 $HOME/test 目录作为 /bin/bash 进程的根目录：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ chroot $HOME/test /bin/bash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这时，你如果执行 &amp;ldquo;ls /&amp;quot;，就会看到，它返回的都是 $HOME/test 目录下面的内容，而不是宿主机的内容。&lt;/p&gt;
&lt;p&gt;更重要的是，对于被 chroot 的进程来说，它并不会感受到自己的根目录已经被&amp;quot;修改&amp;quot;成 $HOME/test 了。&lt;/p&gt;
&lt;p&gt;这种视图被修改的原理，是不是跟我之前介绍的 Linux Namespace 很类似呢？&lt;/p&gt;
&lt;p&gt;没错！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;实际上，Mount Namespace 正是基于对 chroot 的不断改良才被发明出来的，它也是 Linux 操作系统里的第一个 Namespace。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当然，为了能够让容器的这个根目录看起来更&amp;quot;真实&amp;rdquo;，我们一般会在这个容器的根目录下挂载一个完整操作系统的文件系统，比如 Ubuntu16.04 的 ISO。这样，在容器启动之后，我们在容器里通过执行 &amp;ldquo;ls /&amp;rdquo; 查看根目录下的内容，就是 Ubuntu 16.04 的所有目录和文件。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;而这个挂载在容器根目录上、用来为容器进程提供隔离后执行环境的文件系统，就是所谓的&amp;quot;容器镜像&amp;quot;。它还有一个更为专业的名字，叫作：rootfs（根文件系统）。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所以，一个最常见的 rootfs，或者说容器镜像，会包括如下所示的一些目录和文件，比如 /bin，/etc，/proc 等等：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ls /
bin dev etc home lib lib64 mnt opt proc root run sbin sys tmp usr var
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;而你进入容器之后执行的 /bin/bash，就是 /bin 目录下的可执行文件，与宿主机的 /bin/bash 完全不同。&lt;/p&gt;
&lt;p&gt;现在，你应该可以理解，对 Docker 项目来说，它最核心的原理实际上就是为待创建的用户进程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;启用 Linux Namespace 配置；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;设置指定的 Cgroups 参数；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;切换进程的根目录（Change Root）。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这样，一个完整的容器就诞生了。不过，Docker 项目在最后一步的切换上会优先使用 pivot_root 系统调用，如果系统不支持，才会使用 chroot。这两个系统调用虽然功能类似，但是也有细微的区别，这一部分小知识就交给你课后去探索了。&lt;/p&gt;
&lt;p&gt;另外，&lt;strong&gt;需要明确的是，rootfs 只是一个操作系统所包含的文件、配置和目录，并不包括操作系统内核。在 Linux 操作系统中，这两部分是分开存放的，操作系统只有在开机启动时才会加载指定版本的内核镜像。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所以说，rootfs 只包括了操作系统的&amp;quot;躯壳&amp;quot;，并没有包括操作系统的&amp;quot;灵魂&amp;quot;。&lt;/p&gt;
&lt;p&gt;那么，对于容器来说，这个操作系统的&amp;quot;灵魂&amp;quot;又在哪里呢？&lt;/p&gt;
&lt;p&gt;实际上，同一台机器上的所有容器，都共享宿主机操作系统的内核。&lt;/p&gt;
&lt;p&gt;这就意味着，如果你的应用程序需要配置内核参数、加载额外的内核模块，以及跟内核进行直接的交互，你就需要注意了：这些操作和依赖的对象，都是宿主机操作系统的内核，它对于该机器上的所有容器来说是一个&amp;quot;全局变量&amp;quot;，牵一发而动全身。&lt;/p&gt;
&lt;p&gt;这也是容器相比于虚拟机的主要缺陷之一：毕竟后者不仅有模拟出来的硬件机器充当沙盒，而且每个沙盒里还运行着一个完整的 Guest OS 给应用随便折腾。&lt;/p&gt;
&lt;p&gt;不过，&lt;strong&gt;正是由于 rootfs 的存在，容器才有了一个被反复宣传至今的重要特性：一致性。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;什么是容器的&amp;quot;一致性&amp;quot;呢？&lt;/p&gt;
&lt;p&gt;我在专栏的第一篇文章&lt;a href=&#34;https://time.geekbang.org/column/article/14254&#34;&gt;《小鲸鱼大事记（一）：初出茅庐》&lt;/a&gt;中曾经提到过：由于云端与本地服务器环境不同，应用的打包过程，一直是使用 PaaS 时最&amp;quot;痛苦&amp;quot;的一个步骤。&lt;/p&gt;
&lt;p&gt;但有了容器之后，更准确地说，有了容器镜像（即 rootfs）之后，这个问题被非常优雅地解决了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;由于 rootfs 里打包的不只是应用，而是整个操作系统的文件和目录，也就意味着，应用以及它运行所需要的所有依赖，都被封装在了一起。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;事实上，对于大多数开发者而言，他们对应用依赖的理解，一直局限在编程语言层面。比如 Golang 的 Godeps.json。但实际上，一个一直以来很容易被忽视的事实是，&lt;strong&gt;对一个应用来说，操作系统本身才是它运行所需要的最完整的&amp;quot;依赖库&amp;quot;。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;有了容器镜像&amp;quot;打包操作系统&amp;quot;的能力，这个最基础的依赖环境也终于变成了应用沙盒的一部分。这就赋予了容器所谓的一致性：无论在本地、云端，还是在一台任何地方的机器上，用户只需要解压打包好的容器镜像，那么这个应用运行所需要的完整的执行环境就被重现出来了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;这种深入到操作系统级别的运行环境一致性，打通了应用在本地开发和远端执行环境之间难以逾越的鸿沟。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;不过，这时你可能已经发现了另一个非常棘手的问题：难道我每开发一个应用，或者升级一下现有的应用，都要重复制作一次 rootfs 吗？&lt;/p&gt;
&lt;p&gt;比如，我现在用 Ubuntu 操作系统的 ISO 做了一个 rootfs，然后又在里面安装了 Java 环境，用来部署我的 Java 应用。那么，我的另一个同事在发布他的 Java 应用时，显然希望能够直接使用我安装过 Java 环境的 rootfs，而不是重复这个流程。&lt;/p&gt;
&lt;p&gt;一种比较直观的解决办法是，我在制作 rootfs 的时候，每做一步&amp;quot;有意义&amp;quot;的操作，就保存一个 rootfs 出来，这样其他同事就可以按需求去用他需要的 rootfs 了。&lt;/p&gt;
&lt;p&gt;但是，这个解决办法并不具备推广性。原因在于，一旦你的同事们修改了这个 rootfs，新旧两个 rootfs 之间就没有任何关系了。这样做的结果就是极度的碎片化。&lt;/p&gt;
&lt;p&gt;那么，既然这些修改都基于一个旧的 rootfs，我们能不能以增量的方式去做这些修改呢？这样做的好处是，所有人都只需要维护相对于 base rootfs 修改的增量内容，而不是每次修改都制造一个&amp;quot;fork&amp;quot;。&lt;/p&gt;
&lt;p&gt;答案当然是肯定的。&lt;/p&gt;
&lt;p&gt;这也正是为何，Docker 公司在实现 Docker 镜像时并没有沿用以前制作 rootfs 的标准流程，而是做了一个小小的创新：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Docker 在镜像的设计中，引入了层（layer）的概念。也就是说，用户制作镜像的每一步操作，都会生成一个层，也就是一个增量 rootfs。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;当然，这个想法不是凭空臆造出来的，而是用到了一种叫作联合文件系统（Union File System）的能力。&lt;/p&gt;
&lt;p&gt;Union File System 也叫 UnionFS，最主要的功能是将多个不同位置的目录联合挂载（union mount）到同一个目录下。比如，我现在有两个目录 A 和 B，它们分别有两个文件：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ tree
.
├── A
│  ├── a
│  └── x
└── B
  ├── b
  └── x
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;然后，我使用联合挂载的方式，将这两个目录挂载到一个公共的目录 C 上：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ mkdir C
$ mount -t aufs -o dirs=./A:./B none ./C
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这时，我再查看目录 C 的内容，就能看到目录 A 和 B 下的文件被合并到了一起：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ tree ./C
./C
├── a
├── b
└── x
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，在这个合并后的目录 C 里，有 a、b、x 三个文件，并且 x 文件只有一份。这，就是&amp;quot;合并&amp;quot;的含义。此外，如果你在目录 C 里对 a、b、x 文件做修改，这些修改也会在对应的目录 A、B 中生效。&lt;/p&gt;
&lt;p&gt;那么，在 Docker 项目中，又是如何使用这种 Union File System 的呢？&lt;/p&gt;
&lt;p&gt;我的环境是 Ubuntu 16.04 和 Docker CE 18.05，这对组合默认使用的是 AuFS 这个联合文件系统的实现。你可以通过 docker info 命令，查看到这个信息。&lt;/p&gt;
&lt;p&gt;AuFS 的全称是 Another UnionFS，后改名为 Alternative UnionFS，再后来干脆改名叫作 Advance UnionFS，从这些名字中你应该能看出这样两个事实：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;它是对 Linux 原生 UnionFS 的重写和改进；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;它的作者怨气好像很大。我猜是 Linus Torvalds（Linux 之父）一直不让 AuFS 进入 Linux 内核主干的缘故，所以我们只能在 Ubuntu 和 Debian 这些发行版上使用它。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;对于 AuFS 来说，它最关键的目录结构在 /var/lib/docker 路径下的 diff 目录：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/var/lib/docker/aufs/diff/&amp;lt;layer_id&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;而这个目录的作用，我们不妨通过一个具体例子来看一下。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;现在，我们启动一个容器，比如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker run -d ubuntu:latest sleep 3600
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这时候，Docker 就会从 Docker Hub 上拉取一个 Ubuntu 镜像到本地。&lt;/p&gt;
&lt;p&gt;这个所谓的&amp;quot;镜像&amp;quot;，实际上就是一个 Ubuntu 操作系统的 rootfs，它的内容是 Ubuntu 操作系统的所有文件和目录。不过，与之前我们讲述的 rootfs 稍微不同的是，Docker 镜像使用的 rootfs，往往由多个&amp;quot;层&amp;quot;组成：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker image inspect ubuntu:latest
...
     &amp;quot;RootFS&amp;quot;: {
      &amp;quot;Type&amp;quot;: &amp;quot;layers&amp;quot;,
      &amp;quot;Layers&amp;quot;: [
        &amp;quot;sha256:f49017d4d5ce9c0f544c...&amp;quot;,
        &amp;quot;sha256:8f2b771487e9d6354080...&amp;quot;,
        &amp;quot;sha256:ccd4d61916aaa2159429...&amp;quot;,
        &amp;quot;sha256:c01d74f99de40e097c73...&amp;quot;,
        &amp;quot;sha256:268a067217b5fe78e000...&amp;quot;
      ]
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，这个 Ubuntu 镜像，实际上由五个层组成。这五个层就是五个增量 rootfs，每一层都是 Ubuntu 操作系统文件与目录的一部分；而在使用镜像时，Docker 会把这些增量联合挂载在一个统一的挂载点上（等价于前面例子里的&amp;quot;/C&amp;quot;目录）。&lt;/p&gt;
&lt;p&gt;这个挂载点就是 /var/lib/docker/aufs/mnt/ ，比如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/var/lib/docker/aufs/mnt/6e3be5d2ecccae7cc0fcfa2a2f5c89dc21ee30e166be823ceaeba15dce645b3e
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;不出意外的，这个目录里面正是一个完整的 Ubuntu 操作系统：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ls /var/lib/docker/aufs/mnt/6e3be5d2ecccae7cc0fcfa2a2f5c89dc21ee30e166be823ceaeba15dce645b3e
bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;那么，前面提到的五个镜像层，又是如何被联合挂载成这样一个完整的 Ubuntu 文件系统的呢？&lt;/p&gt;
&lt;p&gt;这个信息记录在 AuFS 的系统目录 /sys/fs/aufs 下面。&lt;/p&gt;
&lt;p&gt;首先，通过查看 AuFS 的挂载信息，我们可以找到这个目录对应的 AuFS 的内部 ID（也叫：si）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cat /proc/mounts| grep aufs
none /var/lib/docker/aufs/mnt/6e3be5d2ecccae7cc0fc... aufs rw,relatime,si=972c6d361e6b32ba,dio,dirperm1 0 0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;即，si=972c6d361e6b32ba。&lt;/p&gt;
&lt;p&gt;然后使用这个 ID，你就可以在 /sys/fs/aufs 下查看被联合挂载在一起的各个层的信息：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cat /sys/fs/aufs/si_972c6d361e6b32ba/br[0-9]*
/var/lib/docker/aufs/diff/6e3be5d2ecccae7cc...=rw
/var/lib/docker/aufs/diff/6e3be5d2ecccae7cc...-init=ro+wh
/var/lib/docker/aufs/diff/32e8e20064858c0f2...=ro+wh
/var/lib/docker/aufs/diff/2b8858809bce62e62...=ro+wh
/var/lib/docker/aufs/diff/20707dce8efc0d267...=ro+wh
/var/lib/docker/aufs/diff/72b0744e06247c7d0...=ro+wh
/var/lib/docker/aufs/diff/a524a729adadedb90...=ro+wh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;从这些信息里，我们可以看到，镜像的层都放置在 /var/lib/docker/aufs/diff 目录下，然后被联合挂载在 /var/lib/docker/aufs/mnt 里面。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;而且，从这个结构可以看出来，这个容器的 rootfs 由如下图所示的三部分组成：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/8a/5f/8a7b5cfabaab2d877a1d4566961edd5f.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第一部分，只读层。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;它是这个容器的 rootfs 最下面的五层，对应的正是 ubuntu:latest 镜像的五层。可以看到，它们的挂载方式都是只读的（ro+wh，即 readonly+whiteout，至于什么是 whiteout，我下面马上会讲到）。&lt;/p&gt;
&lt;p&gt;这时，我们可以分别查看一下这些层的内容：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ls /var/lib/docker/aufs/diff/72b0744e06247c7d0...
etc sbin usr var
$ ls /var/lib/docker/aufs/diff/32e8e20064858c0f2...
run
$ ls /var/lib/docker/aufs/diff/a524a729adadedb900...
bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，这些层，都以增量的方式分别包含了 Ubuntu 操作系统的一部分。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第二部分，可读写层。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;它是这个容器的 rootfs 最上面的一层（6e3be5d2ecccae7cc），它的挂载方式为：rw，即 read write。在没有写入文件之前，这个目录是空的。而一旦在容器里做了写操作，你修改产生的内容就会以增量的方式出现在这个层中。&lt;/p&gt;
&lt;p&gt;可是，你有没有想到这样一个问题：如果我现在要做的，是删除只读层里的一个文件呢？&lt;/p&gt;
&lt;p&gt;为了实现这样的删除操作，AuFS 会在可读写层创建一个 whiteout 文件，把只读层里的文件&amp;quot;遮挡&amp;quot;起来。&lt;/p&gt;
&lt;p&gt;比如，你要删除只读层里一个名叫 foo 的文件，那么这个删除操作实际上是在可读写层创建了一个名叫.wh.foo 的文件。这样，当这两个层被联合挂载之后，foo 文件就会被.wh.foo 文件&amp;quot;遮挡&amp;quot;起来，&amp;ldquo;消失&amp;quot;了。这个功能，就是&amp;quot;ro+wh&amp;quot;的挂载方式，即只读 +whiteout 的含义。我喜欢把 whiteout 形象地翻译为：&amp;ldquo;白障&amp;rdquo;。&lt;/p&gt;
&lt;p&gt;所以，最上面这个可读写层的作用，就是专门用来存放你修改 rootfs 后产生的增量，无论是增、删、改，都发生在这里。而当我们使用完了这个被修改过的容器之后，还可以使用 docker commit 和 push 指令，保存这个被修改过的可读写层，并上传到 Docker Hub 上，供其他人使用；而与此同时，原先的只读层里的内容则不会有任何变化。这，就是增量 rootfs 的好处。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第三部分，Init 层。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;它是一个以&amp;rdquo;-init&amp;quot;结尾的层，夹在只读层和读写层之间。Init 层是 Docker 项目单独生成的一个内部层，专门用来存放 /etc/hosts、/etc/resolv.conf 等信息。&lt;/p&gt;
&lt;p&gt;需要这样一层的原因是，这些文件本来属于只读的 Ubuntu 镜像的一部分，但是用户往往需要在启动容器时写入一些指定的值比如 hostname，所以就需要在可读写层对它们进行修改。&lt;/p&gt;
&lt;p&gt;可是，这些修改往往只对当前的容器有效，我们并不希望执行 docker commit 时，把这些信息连同可读写层一起提交掉。&lt;/p&gt;
&lt;p&gt;所以，Docker 做法是，在修改了这些文件之后，以一个单独的层挂载了出来。而用户执行 docker commit 只会提交可读写层，所以是不包含这些内容的。&lt;/p&gt;
&lt;p&gt;最终，这 7 个层都被联合挂载到 /var/lib/docker/aufs/mnt 目录下，表现为一个完整的 Ubuntu 操作系统供容器使用。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;在今天的分享中，我着重介绍了 Linux 容器文件系统的实现方式。而这种机制，正是我们经常提到的容器镜像，也叫作：rootfs。它只是一个操作系统的所有文件和目录，并不包含内核，最多也就几百兆。而相比之下，传统虚拟机的镜像大多是一个磁盘的&amp;quot;快照&amp;quot;，磁盘有多大，镜像就至少有多大。&lt;/p&gt;
&lt;p&gt;通过结合使用 Mount Namespace 和 rootfs，容器就能够为进程构建出一个完善的文件系统隔离环境。当然，这个功能的实现还必须感谢 chroot 和 pivot_root 这两个系统调用切换进程根目录的能力。&lt;/p&gt;
&lt;p&gt;而在 rootfs 的基础上，Docker 公司创新性地提出了使用多个增量 rootfs 联合挂载一个完整 rootfs 的方案，这就是容器镜像中&amp;quot;层&amp;quot;的概念。&lt;/p&gt;
&lt;p&gt;通过&amp;quot;分层镜像&amp;quot;的设计，以 Docker 镜像为核心，来自不同公司、不同团队的技术人员被紧密地联系在了一起。而且，由于容器镜像的操作是增量式的，这样每次镜像拉取、推送的内容，比原本多个完整的操作系统的大小要小得多；而共享层的存在，可以使得所有这些容器镜像需要的总空间，也比每个镜像的总和要小。这样就使得基于容器镜像的团队协作，要比基于动则几个 GB 的虚拟机磁盘镜像的协作要敏捷得多。&lt;/p&gt;
&lt;p&gt;更重要的是，一旦这个镜像被发布，那么你在全世界的任何一个地方下载这个镜像，得到的内容都完全一致，可以完全复现这个镜像制作者当初的完整环境。这，就是容器技术&amp;quot;强一致性&amp;quot;的重要体现。&lt;/p&gt;
&lt;p&gt;而这种价值正是支撑 Docker 公司在 2014~2016 年间迅猛发展的核心动力。容器镜像的发明，不仅打通了&amp;quot;开发 - 测试 - 部署&amp;quot;流程的每一个环节，更重要的是：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;容器镜像将会成为未来软件的主流发布方式。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;思考题&#34;&gt;思考题&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;既然容器的 rootfs（比如，Ubuntu 镜像），是以只读方式挂载的，那么又如何在容器里修改 Ubuntu 镜像的内容呢？（提示：Copy-on-Write）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;除了 AuFS，你知道 Docker 项目还支持哪些 UnionFS 实现吗？你能说出不同宿主机环境下推荐使用哪种实现吗？&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;感谢你的收听，欢迎你给我留言，也欢迎分享给更多的朋友一起阅读。&lt;br&gt;
&lt;img src=&#34;https://static001.geekbang.org/resource/image/0d/cb/0da944e5bac4fe1d00d3f01a747e86cb.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;点击&lt;a href=&#34;https://time.geekbang.org/column/article/17841&#34;&gt;这里&lt;/a&gt;查看大图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/47/55/47a6f3bf6b92d58512d5a2ed0a556f55.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 07丨行锁功过：怎么减少行锁对性能的影响？</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/07%E4%B8%A8%E8%A1%8C%E9%94%81%E5%8A%9F%E8%BF%87%E6%80%8E%E4%B9%88%E5%87%8F%E5%B0%91%E8%A1%8C%E9%94%81%E5%AF%B9%E6%80%A7%E8%83%BD%E7%9A%84%E5%BD%B1%E5%93%8D/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/07%E4%B8%A8%E8%A1%8C%E9%94%81%E5%8A%9F%E8%BF%87%E6%80%8E%E4%B9%88%E5%87%8F%E5%B0%91%E8%A1%8C%E9%94%81%E5%AF%B9%E6%80%A7%E8%83%BD%E7%9A%84%E5%BD%B1%E5%93%8D/</guid>
      <description>
        
        
        &lt;p&gt;在上一篇文章中，我跟你介绍了 MySQL 的全局锁和表级锁，今天我们就来讲讲 MySQL 的行锁。&lt;/p&gt;
&lt;p&gt;MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。&lt;/p&gt;
&lt;p&gt;我们今天就主要来聊聊 InnoDB 的行锁，以及如何通过减少锁冲突来提升业务并发度。&lt;/p&gt;
&lt;p&gt;顾名思义，行锁就是针对数据表中行记录的锁。这很好理解，比如事务 A 更新了一行，而这时候事务 B 也要更新同一行，则必须等事务 A 的操作完成后才能进行更新。&lt;/p&gt;
&lt;p&gt;当然，数据库中还有一些没那么一目了然的概念和设计，这些概念如果理解和使用不当，容易导致程序出现非预期行为，比如两阶段锁。&lt;/p&gt;
&lt;h1 id=&#34;从两阶段锁说起&#34;&gt;从两阶段锁说起&lt;/h1&gt;
&lt;p&gt;我先给你举个例子。在下面的操作序列中，事务 B 的 update 语句执行时会是什么现象呢？假设字段 id 是表 t 的主键。&lt;br&gt;
&lt;img src=&#34;https://static001.geekbang.org/resource/image/51/10/51f501f718e420244b0a2ec2ce858710.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;这个问题的结论取决于事务 A 在执行完两条 update 语句后，持有哪些锁，以及在什么时候释放。你可以验证一下：实际上事务 B 的 update 语句会被阻塞，直到事务 A 执行 commit 之后，事务 B 才能继续执行。&lt;/p&gt;
&lt;p&gt;知道了这个答案，你一定知道了事务 A 持有的两个记录的行锁，都是在 commit 的时候才释放的。&lt;/p&gt;
&lt;p&gt;也就是说，&lt;strong&gt;在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;知道了这个设定，对我们使用事务有什么帮助呢？那就是，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。我给你举个例子。&lt;/p&gt;
&lt;p&gt;假设你负责实现一个电影票在线交易业务，顾客 A 要在影院 B 购买电影票。我们简化一点，这个业务需要涉及到以下操作：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;从顾客 A 账户余额中扣除电影票价；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;给影院 B 的账户余额增加这张电影票价；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;记录一条交易日志。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;也就是说，要完成这个交易，我们需要 update 两条记录，并 insert 一条记录。当然，为了保证交易的原子性，我们要把这三个操作放在一个事务中。那么，你会怎样安排这三个语句在事务中的顺序呢？&lt;/p&gt;
&lt;p&gt;试想如果同时有另外一个顾客 C 要在影院 B 买票，那么这两个事务冲突的部分就是语句 2 了。因为它们要更新同一个影院账户的余额，需要修改同一行数据。&lt;/p&gt;
&lt;p&gt;根据两阶段锁协议，不论你怎样安排语句顺序，所有的操作需要的行锁都是在事务提交的时候才释放的。所以，如果你把语句 2 安排在最后，比如按照 3、1、2 这样的顺序，那么影院账户余额这一行的锁时间就最少。这就最大程度地减少了事务之间的锁等待，提升了并发度。&lt;/p&gt;
&lt;p&gt;好了，现在由于你的正确设计，影院余额这一行的行锁在一个事务中不会停留很长时间。但是，这并没有完全解决你的困扰。&lt;/p&gt;
&lt;p&gt;如果这个影院做活动，可以低价预售一年内所有的电影票，而且这个活动只做一天。于是在活动时间开始的时候，你的 MySQL 就挂了。你登上服务器一看，CPU 消耗接近 100%，但整个数据库每秒就执行不到 100 个事务。这是什么原因呢？&lt;/p&gt;
&lt;p&gt;这里，我就要说到死锁和死锁检测了。&lt;/p&gt;
&lt;h1 id=&#34;死锁和死锁检测&#34;&gt;死锁和死锁检测&lt;/h1&gt;
&lt;p&gt;当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。这里我用数据库中的行锁举个例子。&lt;br&gt;
&lt;img src=&#34;https://static001.geekbang.org/resource/image/4d/52/4d0eeec7b136371b79248a0aed005a52.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;这时候，事务 A 在等待事务 B 释放 id=2 的行锁，而事务 B 在等待事务 A 释放 id=1 的行锁。 事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。当出现死锁以后，有两种策略：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。&lt;/li&gt;
&lt;li&gt;另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在 InnoDB 中，innodb_lock_wait_timeout 的默认值是 50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。&lt;/p&gt;
&lt;p&gt;但是，我们又不可能直接把这个时间设置成一个很小的值，比如 1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。&lt;/p&gt;
&lt;p&gt;所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且 innodb_deadlock_detect 的默认值本身就是 on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。&lt;/p&gt;
&lt;p&gt;你可以想象一下这个过程：每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。&lt;/p&gt;
&lt;p&gt;那如果是我们上面说到的所有事务都要更新同一行的场景呢？&lt;/p&gt;
&lt;p&gt;每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n) 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务。&lt;/p&gt;
&lt;p&gt;根据上面的分析，我们来讨论一下，怎么解决由这种热点行更新导致的性能问题呢？问题的症结在于，死锁检测要耗费大量的 CPU 资源。&lt;/p&gt;
&lt;p&gt;**一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。**但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。&lt;/p&gt;
&lt;p&gt;**另一个思路是控制并发度。**根据上面的分析，你会发现如果并发能够控制住，比如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。一个直接的想法就是，在客户端做并发控制。但是，你会很快发现这个方法不太可行，因为客户端很多。我见过一个应用，有 600 个客户端，这样即使每个客户端控制到只有 5 个并发线程，汇总到数据库服务端以后，峰值并发数也可能要达到 3000。&lt;/p&gt;
&lt;p&gt;因此，这个并发控制要做在数据库服务端。如果你有中间件，可以考虑在中间件实现；如果你的团队有能修改 MySQL 源码的人，也可以做在 MySQL 里面。基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了。&lt;/p&gt;
&lt;p&gt;可能你会问，&lt;strong&gt;如果团队里暂时没有数据库方面的专家，不能实现这样的方案，能不能从设计上优化这个问题呢？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;你可以考虑通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。&lt;/p&gt;
&lt;p&gt;这个方案看上去是无损的，但其实这类方案需要根据业务逻辑做详细设计。如果账户余额可能会减少，比如退票逻辑，那么这时候就需要考虑当一部分行记录变成 0 的时候，代码要有特殊处理。&lt;/p&gt;
&lt;h1 id=&#34;小结&#34;&gt;小结&lt;/h1&gt;
&lt;p&gt;今天，我和你介绍了 MySQL 的行锁，涉及了两阶段锁协议、死锁和死锁检测这两大部分内容。&lt;/p&gt;
&lt;p&gt;其中，我以两阶段协议为起点，和你一起讨论了在开发的时候如何安排正确的事务语句。这里的原则 / 我给你的建议是：如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁的申请时机尽量往后放。&lt;/p&gt;
&lt;p&gt;但是，调整语句顺序并不能完全避免死锁。所以我们引入了死锁和死锁检测的概念，以及提供了三个方案，来减少死锁对数据库的影响。减少死锁的主要方向，就是控制访问相同资源的并发事务量。&lt;/p&gt;
&lt;p&gt;最后，我给你留下一个问题吧。如果你要删除一个表里面的前 10000 行数据，有以下三种方法可以做到：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一种，直接执行 delete from T limit 10000;&lt;/li&gt;
&lt;li&gt;第二种，在一个连接中循环执行 20 次 delete from T limit 500;&lt;/li&gt;
&lt;li&gt;第三种，在 20 个连接中同时执行 delete from T limit 500。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你会选择哪一种方法呢？为什么呢？&lt;/p&gt;
&lt;p&gt;你可以把你的思考和观点写在留言区里，我会在下一篇文章的末尾和你讨论这个问题。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。&lt;/p&gt;
&lt;h1 id=&#34;上期问题时间&#34;&gt;上期问题时间&lt;/h1&gt;
&lt;p&gt;上期我给你留的问题是：当备库用&amp;ndash;single-transaction 做逻辑备份的时候，如果从主库的 binlog 传来一个 DDL 语句会怎么样？&lt;/p&gt;
&lt;p&gt;假设这个 DDL 是针对表 t1 的， 这里我把备份过程中几个关键的语句列出来：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Q1:SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;
Q2:START TRANSACTION  WITH CONSISTENT SNAPSHOT；
/* other tables */
Q3:SAVEPOINT sp;
/* 时刻 1 */
Q4:show create table `t1`;
/* 时刻 2 */
Q5:SELECT * FROM `t1`;
/* 时刻 3 */
Q6:ROLLBACK TO SAVEPOINT sp;
/* 时刻 4 */
/* other tables */
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在备份开始的时候，为了确保 RR（可重复读）隔离级别，再设置一次 RR 隔离级别 (Q1);&lt;/p&gt;
&lt;p&gt;启动事务，这里用 WITH CONSISTENT SNAPSHOT 确保这个语句执行完就可以得到一个一致性视图（Q2)；&lt;/p&gt;
&lt;p&gt;设置一个保存点，这个很重要（Q3）；&lt;/p&gt;
&lt;p&gt;show create 是为了拿到表结构 (Q4)，然后正式导数据 （Q5），回滚到 SAVEPOINT sp，在这里的作用是释放 t1 的 MDL 锁 （Q6）。当然这部分属于&amp;quot;超纲&amp;quot;，上文正文里面都没提到。&lt;/p&gt;
&lt;p&gt;DDL 从主库传过来的时间按照效果不同，我打了四个时刻。题目设定为小表，我们假定到达后，如果开始执行，则很快能够执行完成。&lt;/p&gt;
&lt;p&gt;参考答案如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;如果在 Q4 语句执行之前到达，现象：没有影响，备份拿到的是 DDL 后的表结构。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果在&amp;quot;时刻 2&amp;quot;到达，则表结构被改过，Q5 执行的时候，报 Table definition has changed, please retry transaction，现象：mysqldump 终止；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果在&amp;quot;时刻 2&amp;quot;和&amp;quot;时刻 3&amp;quot;之间到达，mysqldump 占着 t1 的 MDL 读锁，binlog 被阻塞，现象：主从延迟，直到 Q6 执行完成。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;从&amp;quot;时刻 4&amp;quot;开始，mysqldump 释放了 MDL 读锁，现象：没有影响，备份拿到的是 DDL 前的表结构。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;评论区留言点赞板：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;@Aurora 给了最接近的答案；&lt;br&gt;
@echo＿陈 问了一个好问题；&lt;br&gt;
@壹笙☞漂泊 做了很好的总结。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/ce/d9/ce7f4e35916ed1aa49206a53a0547bd9.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 07丨链表（下）：如何轻松写出正确的链表代码？</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/07%E4%B8%A8%E9%93%BE%E8%A1%A8%E4%B8%8B%E5%A6%82%E4%BD%95%E8%BD%BB%E6%9D%BE%E5%86%99%E5%87%BA%E6%AD%A3%E7%A1%AE%E7%9A%84%E9%93%BE%E8%A1%A8%E4%BB%A3%E7%A0%81/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/07%E4%B8%A8%E9%93%BE%E8%A1%A8%E4%B8%8B%E5%A6%82%E4%BD%95%E8%BD%BB%E6%9D%BE%E5%86%99%E5%87%BA%E6%AD%A3%E7%A1%AE%E7%9A%84%E9%93%BE%E8%A1%A8%E4%BB%A3%E7%A0%81/</guid>
      <description>
        
        
        &lt;p&gt;上一节我讲了链表相关的基础知识。学完之后，我看到有人留言说，基础知识我都掌握了，但是写链表代码还是很费劲。哈哈，的确是这样的！&lt;/p&gt;
&lt;p&gt;想要写好链表代码并不是容易的事儿，尤其是那些复杂的链表操作，比如链表反转、有序链表合并等，写的时候非常容易出错。从我上百场面试的经验来看，能把&amp;quot;链表反转&amp;quot;这几行代码写对的人不足 10%。&lt;/p&gt;
&lt;p&gt;为什么链表代码这么难写？究竟怎样才能比较轻松地写出正确的链表代码呢？&lt;/p&gt;
&lt;p&gt;只要愿意投入时间，我觉得大多数人都是可以学会的。比如说，如果你真的能花上一个周末或者一整天的时间，就去写链表反转这一个代码，多写几遍，一直练到能毫不费力地写出 Bug free 的代码。这个坎还会很难跨吗？&lt;/p&gt;
&lt;p&gt;当然，自己有决心并且付出精力是成功的先决条件，除此之外，我们还需要一些方法和技巧。我根据自己的学习经历和工作经验，总结了&lt;strong&gt;几个写链表代码技巧&lt;/strong&gt;。如果你能熟练掌握这几个技巧，加上你的主动和坚持，轻松拿下链表代码完全没有问题。&lt;/p&gt;
&lt;h2 id=&#34;技巧一理解指针或引用的含义&#34;&gt;技巧一：理解指针或引用的含义&lt;/h2&gt;
&lt;p&gt;事实上，看懂链表的结构并不是很难，但是一旦把它和指针混在一起，就很容易让人摸不着头脑。所以，要想写对链表代码，首先就要理解好指针。&lt;/p&gt;
&lt;p&gt;我们知道，有些语言有&amp;quot;指针&amp;quot;的概念，比如 C 语言；有些语言没有指针，取而代之的是&amp;quot;引用&amp;quot;，比如 Java、Python。不管是&amp;quot;指针&amp;quot;还是&amp;quot;引用&amp;quot;，实际上，它们的意思都是一样的，都是存储所指对象的内存地址。&lt;/p&gt;
&lt;p&gt;接下来，我会拿 C 语言中的&amp;quot;指针&amp;quot;来讲解，如果你用的是 Java 或者其他没有指针的语言也没关系，你把它理解成&amp;quot;引用&amp;quot;就可以了。&lt;/p&gt;
&lt;p&gt;实际上，对于指针的理解，你只需要记住下面这句话就可以了：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;将某个变量赋值给指针，实际上就是将这个变量的地址赋值给指针，或者反过来说，指针中存储了这个变量的内存地址，指向了这个变量，通过指针就能找到这个变量。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这句话听起来还挺拗口的，你可以先记住。我们回到链表代码的编写过程中，我来慢慢给你解释。&lt;/p&gt;
&lt;p&gt;在编写链表代码的时候，我们经常会有这样的代码：p-&amp;gt;next=q。这行代码是说，p 结点中的 next 指针存储了 q 结点的内存地址。&lt;/p&gt;
&lt;p&gt;还有一个更复杂的，也是我们写链表代码经常会用到的：p-&amp;gt;next=p-&amp;gt;next-&amp;gt;next。这行代码表示，p 结点的 next 指针存储了 p 结点的下下一个结点的内存地址。&lt;/p&gt;
&lt;p&gt;掌握了指针或引用的概念，你应该可以很轻松地看懂链表代码。恭喜你，已经离写出链表代码近了一步！&lt;/p&gt;
&lt;h2 id=&#34;技巧二警惕指针丢失和内存泄漏&#34;&gt;技巧二：警惕指针丢失和内存泄漏&lt;/h2&gt;
&lt;p&gt;不知道你有没有这样的感觉，写链表代码的时候，指针指来指去，一会儿就不知道指到哪里了。所以，我们在写的时候，一定注意不要弄丢了指针。&lt;/p&gt;
&lt;p&gt;指针往往都是怎么弄丢的呢？我拿单链表的插入操作为例来给你分析一下。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/05/6e/05a4a3b57502968930d517c934347c6e.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;如图所示，我们希望在结点 a 和相邻的结点 b 之间插入结点 x，假设当前指针 p 指向结点 a。如果我们将代码实现变成下面这个样子，就会发生指针丢失和内存泄露。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;p-&amp;gt;next = x;  // 将 p 的 next 指针指向 x 结点；
x-&amp;gt;next = p-&amp;gt;next;  // 将 x 的结点的 next 指针指向 b 结点；
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;初学者经常会在这儿犯错。p-&amp;gt;next 指针在完成第一步操作之后，已经不再指向结点 b 了，而是指向结点 x。第 2 行代码相当于将 x 赋值给 x-&amp;gt;next，自己指向自己。因此，整个链表也就断成了两半，从结点 b 往后的所有结点都无法访问到了。&lt;/p&gt;
&lt;p&gt;对于有些语言来说，比如 C 语言，内存管理是由程序员负责的，如果没有手动释放结点对应的内存空间，就会产生内存泄露。所以，我们&lt;strong&gt;插入结点时，一定要注意操作的顺序&lt;/strong&gt;，要先将结点 x 的 next 指针指向结点 b，再把结点 a 的 next 指针指向结点 x，这样才不会丢失指针，导致内存泄漏。所以，对于刚刚的插入代码，我们只需要把第 1 行和第 2 行代码的顺序颠倒一下就可以了。&lt;/p&gt;
&lt;p&gt;同理，&lt;strong&gt;删除链表结点时，也一定要记得手动释放内存空间&lt;/strong&gt;，否则，也会出现内存泄漏的问题。当然，对于像 Java 这种虚拟机自动管理内存的编程语言来说，就不需要考虑这么多了。&lt;/p&gt;
&lt;h2 id=&#34;技巧三利用哨兵简化实现难度&#34;&gt;技巧三：利用哨兵简化实现难度&lt;/h2&gt;
&lt;p&gt;首先，我们先来回顾一下单链表的插入和删除操作。如果我们在结点 p 后面插入一个新的结点，只需要下面两行代码就可以搞定。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;new_node-&amp;gt;next = p-&amp;gt;next;
p-&amp;gt;next = new_node;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;但是，当我们要向一个空链表中插入第一个结点，刚刚的逻辑就不能用了。我们需要进行下面这样的特殊处理，其中 head 表示链表的头结点。所以，从这段代码，我们可以发现，对于单链表的插入操作，第一个结点和其他结点的插入逻辑是不一样的。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if (head == null) {
  head = new_node;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们再来看单链表结点删除操作。如果要删除结点 p 的后继结点，我们只需要一行代码就可以搞定。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;p-&amp;gt;next = p-&amp;gt;next-&amp;gt;next;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;但是，如果我们要删除链表中的最后一个结点，前面的删除代码就不 work 了。跟插入类似，我们也需要对于这种情况特殊处理。写成代码是这样子的：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if (head-&amp;gt;next == null) {
   head = null;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;从前面的一步一步分析，我们可以看出，&lt;strong&gt;针对链表的插入、删除操作，需要对插入第一个结点和删除最后一个结点的情况进行特殊处理&lt;/strong&gt;。这样代码实现起来就会很繁琐，不简洁，而且也容易因为考虑不全而出错。如何来解决这个问题呢？&lt;/p&gt;
&lt;p&gt;技巧三中提到的哨兵就要登场了。哨兵，解决的是国家之间的边界问题。同理，这里说的哨兵也是解决&amp;quot;边界问题&amp;quot;的，不直接参与业务逻辑。&lt;/p&gt;
&lt;p&gt;还记得如何表示一个空链表吗？head=null 表示链表中没有结点了。其中 head 表示头结点指针，指向链表中的第一个结点。&lt;/p&gt;
&lt;p&gt;如果我们引入哨兵结点，在任何时候，不管链表是不是空，head 指针都会一直指向这个哨兵结点。我们也把这种有哨兵结点的链表叫&lt;strong&gt;带头链表&lt;/strong&gt; 。相反，没有哨兵结点的链表就叫作&lt;strong&gt;不带头链表&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;我画了一个带头链表，你可以发现，哨兵结点是不存储数据的。因为哨兵结点一直存在，所以插入第一个结点和插入其他结点，删除最后一个结点和删除其他结点，都可以统一为相同的代码实现逻辑了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/7d/c7/7d22d9428bdbba96bfe388fe1e3368c7.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;实际上，这种利用哨兵简化编程难度的技巧，在很多代码实现中都有用到，比如插入排序、归并排序、动态规划等。这些内容我们后面才会讲，现在为了让你感受更深，我再举一个非常简单的例子。代码我是用 C 语言实现的，不涉及语言方面的高级语法，很容易看懂，你可以类比到你熟悉的语言。&lt;/p&gt;
&lt;p&gt;代码一：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 在数组 a 中，查找 key，返回 key 所在的位置
// 其中，n 表示数组 a 的长度
int find(char* a, int n, char key) {
  // 边界条件处理，如果 a 为空，或者 n&amp;lt;=0，说明数组中没有数据，就不用 while 循环比较了
  if(a == null || n &amp;lt;= 0) {
    return -1;
  }
  
  int i = 0;
  // 这里有两个比较操作：i&amp;lt;n 和 a[i]==key.
  while (i &amp;lt; n) {
    if (a[i] == key) {
      return i;
    }
    ++i;
  }
  
  return -1;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;代码二：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 在数组 a 中，查找 key，返回 key 所在的位置
// 其中，n 表示数组 a 的长度
// 我举 2 个例子，你可以拿例子走一下代码
// a = {4, 2, 3, 5, 9, 6}  n=6 key = 7
// a = {4, 2, 3, 5, 9, 6}  n=6 key = 6
int find(char* a, int n, char key) {
  if(a == null || n &amp;lt;= 0) {
    return -1;
  }
  
  // 这里因为要将 a[n-1] 的值替换成 key，所以要特殊处理这个值
  if (a[n-1] == key) {
    return n-1;
  }
  
  // 把 a[n-1] 的值临时保存在变量 tmp 中，以便之后恢复。tmp=6。
  // 之所以这样做的目的是：希望 find() 代码不要改变 a 数组中的内容
  char tmp = a[n-1];
  // 把 key 的值放到 a[n-1] 中，此时 a = {4, 2, 3, 5, 9, 7}
  a[n-1] = key;
  
  int i = 0;
  // while 循环比起代码一，少了 i&amp;lt;n 这个比较操作
  while (a[i] != key) {
    ++i;
  }
  
  // 恢复 a[n-1] 原来的值, 此时 a= {4, 2, 3, 5, 9, 6}
  a[n-1] = tmp;
  
  if (i == n-1) {
    // 如果 i == n-1 说明，在 0...n-2 之间都没有 key，所以返回 -1
    return -1;
  } else {
    // 否则，返回 i，就是等于 key 值的元素的下标
    return i;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;对比两段代码，在字符串 a 很长的时候，比如几万、几十万，你觉得哪段代码运行得更快点呢？答案是代码二，因为两段代码中执行次数最多就是 while 循环那一部分。第二段代码中，我们通过一个哨兵 a[n-1] = key，成功省掉了一个比较语句 i&amp;lt;n，不要小看这一条语句，当累积执行万次、几十万次时，累积的时间就很明显了。&lt;/p&gt;
&lt;p&gt;当然，这只是为了举例说明哨兵的作用，你写代码的时候千万不要写第二段那样的代码，因为可读性太差了。大部分情况下，我们并不需要如此追求极致的性能。&lt;/p&gt;
&lt;h2 id=&#34;技巧四重点留意边界条件处理&#34;&gt;技巧四：重点留意边界条件处理&lt;/h2&gt;
&lt;p&gt;软件开发中，代码在一些边界或者异常情况下，最容易产生 Bug。链表代码也不例外。要实现没有 Bug 的链表代码，一定要在编写的过程中以及编写完成之后，检查边界条件是否考虑全面，以及代码在边界条件下是否能正确运行。&lt;/p&gt;
&lt;p&gt;我经常用来检查链表代码是否正确的边界条件有这样几个：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;如果链表为空时，代码是否能正常工作？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果链表只包含一个结点时，代码是否能正常工作？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果链表只包含两个结点时，代码是否能正常工作？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;代码逻辑在处理头结点和尾结点的时候，是否能正常工作？&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当你写完链表代码之后，除了看下你写的代码在正常的情况下能否工作，还要看下在上面我列举的几个边界条件下，代码仍然能否正确工作。如果这些边界条件下都没有问题，那基本上可以认为没有问题了。&lt;/p&gt;
&lt;p&gt;当然，边界条件不止我列举的那些。针对不同的场景，可能还有特定的边界条件，这个需要你自己去思考，不过套路都是一样的。&lt;/p&gt;
&lt;p&gt;实际上，不光光是写链表代码，你在写任何代码时，也千万不要只是实现业务正常情况下的功能就好了，一定要多想想，你的代码在运行的时候，可能会遇到哪些边界情况或者异常情况。遇到了应该如何应对，这样写出来的代码才够健壮！&lt;/p&gt;
&lt;h2 id=&#34;技巧五举例画图辅助思考&#34;&gt;技巧五：举例画图，辅助思考&lt;/h2&gt;
&lt;p&gt;对于稍微复杂的链表操作，比如前面我们提到的单链表反转，指针一会儿指这，一会儿指那，一会儿就被绕晕了。总感觉脑容量不够，想不清楚。所以这个时候就要使用大招了，&lt;strong&gt;举例法&lt;/strong&gt; 和&lt;strong&gt;画图法&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;你可以找一个具体的例子，把它画在纸上，释放一些脑容量，留更多的给逻辑思考，这样就会感觉到思路清晰很多。比如往单链表中插入一个数据这样一个操作，我一般都是把各种情况都举一个例子，画出插入前和插入后的链表变化，如图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/4a/f8/4a701dd79b59427be654261805b349f8.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;看图写代码，是不是就简单多啦？而且，当我们写完代码之后，也可以举几个例子，画在纸上，照着代码走一遍，很容易就能发现代码中的 Bug。&lt;/p&gt;
&lt;h2 id=&#34;技巧六多写多练没有捷径&#34;&gt;技巧六：多写多练，没有捷径&lt;/h2&gt;
&lt;p&gt;如果你已经理解并掌握了我前面所讲的方法，但是手写链表代码还是会出现各种各样的错误，也不要着急。因为我最开始学的时候，这种状况也持续了一段时间。&lt;/p&gt;
&lt;p&gt;现在我写这些代码，简直就和&amp;quot;玩儿&amp;quot;一样，其实也没有什么技巧，就是把常见的链表操作都自己多写几遍，出问题就一点一点调试，熟能生巧！&lt;/p&gt;
&lt;p&gt;所以，我精选了 5 个常见的链表操作。你只要把这几个操作都能写熟练，不熟就多写几遍，我保证你之后再也不会害怕写链表代码。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;单链表反转&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;链表中环的检测&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;两个有序的链表合并&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;删除链表倒数第 n 个结点&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;求链表的中间结点&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;内容小结&#34;&gt;内容小结&lt;/h2&gt;
&lt;p&gt;这节我主要和你讲了写出正确链表代码的六个技巧。分别是理解指针或引用的含义、警惕指针丢失和内存泄漏、利用哨兵简化实现难度、重点留意边界条件处理，以及举例画图、辅助思考，还有多写多练。&lt;/p&gt;
&lt;p&gt;我觉得，&lt;strong&gt;写链表代码是最考验逻辑思维能力的&lt;/strong&gt;。因为，链表代码到处都是指针的操作、边界条件的处理，稍有不慎就容易产生 Bug。链表代码写得好坏，可以看出一个人写代码是否够细心，考虑问题是否全面，思维是否缜密。所以，这也是很多面试官喜欢让人手写链表代码的原因。所以，这一节讲到的东西，你一定要自己写代码实现一下，才有效果。&lt;/p&gt;
&lt;h2 id=&#34;课后思考&#34;&gt;课后思考&lt;/h2&gt;
&lt;p&gt;今天我们讲到用哨兵来简化编码实现，你是否还能够想到其他场景，利用哨兵可以大大地简化编码难度？&lt;/p&gt;
&lt;p&gt;欢迎留言和我分享，我会第一时间给你反馈。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;我已将本节内容相关的详细代码更新到 GitHub，&lt;a href=&#34;https://github.com/wangzheng0822/algo&#34;&gt;戳此&lt;/a&gt;即可查看。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/8e/d3/8e603e3d795fc0ab2698f6f5eabf14d3.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 08丨Go语言，Docker和新技术</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/08%E4%B8%A8go%E8%AF%AD%E8%A8%80docker%E5%92%8C%E6%96%B0%E6%8A%80%E6%9C%AF/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/08%E4%B8%A8go%E8%AF%AD%E8%A8%80docker%E5%92%8C%E6%96%B0%E6%8A%80%E6%9C%AF/</guid>
      <description>
        
        
        &lt;p&gt;上个月，作为 Go 语言的三位创始人之一，Unix 老牌黑客罗勃·派克（Rob Pike）在新文章&amp;quot;Go: Ten years and climbing&amp;quot;中，回顾了 Go 语言的发展历程。文章提到，Go 语言这十年的迅猛发展快到连他们自己都没有想到，并且还成为了云计算领域新一代的开发语言。另外，文中还说到，中国程序员对 Go 语言的热爱完全超出了他们的想象，甚至他们都不敢相信是真的。&lt;/p&gt;
&lt;p&gt;这让我想起我在 2015 年 5 月拜访 Docker 公司在湾区的总部时，Docker 负责人也和我表达了相似的感叹：他们完全没有想到中国居然有那么多人喜欢 Docker，而且还有这么多人在为 Docker 做贡献，这让他们感到非常意外。此外，他还对我说，中国是除了美国本土之外的另外一个如此喜欢 Docker 技术的国家，在其它国家都没有看到。&lt;/p&gt;
&lt;p&gt;的确如他们所说，Go 语言和 Docker 这两种技术已经成为新一代的云计算技术，而且可以看到他们的发展态势非常迅猛。而中国也成为了像美国一样在强力推动这两种技术的国家。这的确是一件让人感到高兴的事儿，因为中国在跟随时代潮流这件事上已经做得相当不错了。&lt;/p&gt;
&lt;p&gt;然而就是在这样的背景下，这几年，总还是有人会问我是否要学 Go 语言，是否要学 Docker，Go 和 Docker 能否用在生产环境等等。从这些问题来看，对于 Go 语言和 Docker 这两种技术，国内的技术圈中还有相当大的一部分人在观望。&lt;/p&gt;
&lt;p&gt;所以，我想写这篇文章，并从两个方面来论述一下我的观点和看法。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;一个方面，为什么 Go 语言和 Docker 会是新一代的云计算技术。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;另一个方面，作为技术人员，我们如何识别什么样的新技术会是未来的趋势。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这两个问题是相辅相成的，所以我会把这两个问题揉在一起谈。&lt;/p&gt;
&lt;p&gt;虽然 Go 语言是在 2009 年底开源的，但我是从 2012 年才开始接触和学习 Go 语言的。当时，我只花了一个周末两天的时间就学完了，而且在这两天的时间里，我还很快地写出了一个能完美运行的网页爬虫程序，以及一个简单的高并发文件处理服务，用于提取前面抓取的网页关键内容。这两个程序都很简单，总共不到 500 行代码。&lt;/p&gt;
&lt;p&gt;综合下来，我对 Go 语言有如下几点体会。&lt;/p&gt;
&lt;p&gt;第一，&lt;strong&gt;语言简单，上手快&lt;/strong&gt;。Go 语言的语法特性简直是太简单了，简单到你几乎玩不出什么花招，直来直去的，学习难度很低，容易上手。&lt;/p&gt;
&lt;p&gt;第二，&lt;strong&gt;并行和异步编程几乎无痛点&lt;/strong&gt;。Go 语言的 Goroutine 和 Channel 这两个神器简直就是并发和异步编程的巨大福音。像 C、C++、Java、Python 和 JavaScript 这些语言的并发和异步的编程方式控制起来就比较复杂了，并且容易出错，但 Go 语言却用非常优雅和流畅的方式解决了这个问题。这对于编程多年受尽并发和异步折磨的我来说，完全就是眼前一亮的感觉。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/8d/5f/8df5fd56cbb6343a9030265a5f3a565f.png&#34; alt=&#34;&#34;&gt;
（图片来自 Medium：Why should you learn Go?）&lt;/p&gt;
&lt;p&gt;第三，&lt;strong&gt;Go 语言的 lib 库&amp;quot;麻雀虽小，五脏俱全&amp;quot;&lt;/strong&gt;。Go 语言的 lib 库中基本上有绝大多数常用的库，虽然有些库还不是很好，但我觉得这都不是主要问题，因为随着技术的发展和成熟，这些问题肯定也都会随之解决。&lt;/p&gt;
&lt;p&gt;第四，&lt;strong&gt;C 语言的理念和 Python 的姿态&lt;/strong&gt;。C 语言的理念是信任程序员，保持语言的小巧，不屏蔽底层且对底层友好，关注语言的执行效率和性能。而 Python 的姿态是用尽量少的代码完成尽量多的事。于是我能够感觉到，Go 语言是想要把 C 和 Python 统一起来，这是多棒的一件事。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/03/f7/03ea333bf7b7bb2fe350c4f433047df7.png&#34; alt=&#34;&#34;&gt;
（图片来自 Medium：Why should you learn Go?）&lt;/p&gt;
&lt;p&gt;所以，即便 Go 语言存在诸多的问题，比如垃圾回收、异常处理、泛型编程等，但相较于上面这几个优势，我认为这些问题都是些小问题。于是就毫不犹豫地入坑了。&lt;/p&gt;
&lt;p&gt;当然，一个技术能不能发展起来，关键还要看三点。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;有没有一个比较好的社区&lt;/strong&gt;。像 C、C++、Java、Python 和 JavaScript 的生态圈都是非常丰富和火爆的。尤其是有很多商业机构参与的社区那就更是人气爆棚了，比如 Linux 社区。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;有没有一个工业化的标准&lt;/strong&gt;。像 C、C++、Java 这些编程语言都是有标准化组织的。尤其是 Java，它在架构上还搞出了像 J2EE 这样的企业级标准。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;有没有一个或多个杀手级应用&lt;/strong&gt;。C、C++ 和 Java 的杀手级应用不用多说了，就算是对于 PHP 这样还不能算是一个优秀的编程语言来说，因为是 Linux 时代的第一个杀手级解决方案 LAMP 中的关键技术，所以，也发展起来了。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在我看来，上面提到的三点至关重要，新的技术只需要占到其中一到两点就已经很不错了，何况有的技术，比如 Java 三点全都满足，所以，Java 的蓬勃发展也在情理之中。当然，除了上面这三点重要的，还有一些其它的影响因素，比如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;学习难度是否低，上手是否快&lt;/strong&gt;。这点非常重要，C++ 在这点上越做越不好了。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;有没有一个不错的提高开发效率的开发框架&lt;/strong&gt;。如：Java 的 Spring 框架，C++ 的 STL 等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;是否有一个或多个巨型的技术公司作为后盾&lt;/strong&gt;。如：Java 和 Linux 后面的 IBM、Sun&amp;hellip;&amp;hellip;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;有没有解决软件开发中的痛点&lt;/strong&gt;。如：Java 解决了 C 和 C++ 的内存管理问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;用这些标尺来衡量一下 Go 语言，我们可以清楚地看到：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Go 语言容易上手；&lt;/li&gt;
&lt;li&gt;Go 语言解决了并发编程和底层应用开发效率的痛点；&lt;/li&gt;
&lt;li&gt;Go 语言有 Google 这个世界一流的技术公司在后面；&lt;/li&gt;
&lt;li&gt;Go 语言的杀手级应用是 Docker 容器，而容器的生态圈这几年可谓是发展繁荣，也是热点领域。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以，Go 语言的未来是不可限量的。当然，我个人觉得，Go 可能会吞食很多 C、C++、Java 的项目。不过，Go 语言所吞食的项目应该主要是中间层的项目，既不是非常底层也不会是业务层。&lt;/p&gt;
&lt;p&gt;也就是说，Go 语言不会吞食底层到 C 和 C++ 那个级别的，也不会吞食到上层如 Java 业务层的项目。Go 语言能吞食的一定是 PaaS 上的项目，比如一些消息缓存中间件、服务发现、服务代理、控制系统、Agent、日志收集等等，他们没有复杂的业务场景，也到不了特别底层（如操作系统）的软件项目或工具。而 C 和 C++ 会被打到更底层，Java 会被打到更上层的业务层。这是我的一个判断。&lt;/p&gt;
&lt;p&gt;好了，我们再用上面的标尺来衡量一下 Go 语言的杀手级应用 Docker，你会发现基本是一样的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Docker 容易上手。&lt;/li&gt;
&lt;li&gt;Docker 解决了运维中的环境问题以及服务调度的痛点。&lt;/li&gt;
&lt;li&gt;Docker 的生态圈中有大公司在后面助力，比如 Google。&lt;/li&gt;
&lt;li&gt;Docker 产出了工业界标准 OCI。&lt;/li&gt;
&lt;li&gt;Docker 的社区和生态圈已经出现像 Java 和 Linux 那样的态势。&lt;/li&gt;
&lt;li&gt;&amp;hellip;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以，早在三四年前我就觉得 Docker 一定会是未来的技术。虽然当时的坑儿还很多，但是，相对于这些大的因素来说，那些小坑都不是问题。只是需要一些时间，这些小坑在未来 5-10 年就可以完全被填平了。&lt;/p&gt;
&lt;p&gt;同样，我们可以看到 Kubernetes 作为服务和容器调度的关键技术一定会是最后的赢家。这点我在去年初就能够很明显地感觉到了。&lt;/p&gt;
&lt;p&gt;关于 Docker 我还想多说几句，这是云计算中 PaaS 的关键技术。虽然，这世上在出现 Docker 之前，几乎所有的要玩公有 PaaS 的公司和产品都玩不起来，比如：Google 的 GAE，国内的各种 XAE，如淘宝的 TAE，新浪的 SAE 等。但我还是想说，&lt;strong&gt;PaaS 是一个被世界或是被产业界严重低估的平台&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;PaaS 层是承上启下的关键技术，任何一个不重视 PaaS 的公司，其技术架构都不可能让这家公司成长为一个大型的公司。因为 PaaS 层的技术主要能解决下面这些问题。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;软件生产线的问题&lt;/strong&gt;。持续集成和持续发布，以及 DevOps 中的技术必须通过 PaaS。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;分布式服务化的问题&lt;/strong&gt;。分布式服务化的服务高可用、服务编排、服务调度、服务发现、服务路由，以及分布式服务化的支撑技术完全是 PaaS 的菜。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;提高服务的可用性 SLA&lt;/strong&gt;。提高服务可用性 SLA 所需要的分布式、高可用的技术架构和运维工具，也是 PaaS 层提供的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;软件能力的复用&lt;/strong&gt;。软件工程中的核心就是软件能力的复用，这一点也完美地体现在 PaaS 平台的技术上。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;老实说，这些问题的关键程度已经到了能判断一家技术驱动公司的研发能力是否靠谱的程度。没有这些技术，我认为，依托技术拓展业务的公司机会就不会很大。&lt;/p&gt;
&lt;p&gt;在后面，我会另外写几篇文章给你详细地讲一下分布式服务化和 PaaS 平台的重要程度。&lt;/p&gt;
&lt;p&gt;最后，我还要说一下，为什么要早一点地进入这些新技术，而不是等待这些技术成熟了后再进入。原因有这么几个。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;技术的发展过程非常重要&lt;/strong&gt;。我进入 Go 和 Docker 的技术不能算早，但也不算晚，从 2012 年学习 Go，再到 2013 年学习 Docker 再到今天，我清楚地看到了这两种技术的生态圈发展过程。这个过程中，我收获最大的并不是这些技术本身，而是一个技术的变迁和行业的发展。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;从中，我看到了非常具体的各种浪潮和思路，这些东西比起 Go 和 Docker 来说更有价值。因为，这不但让我重新思考我已掌握的技术以及如何更好地解决已有的问题，而且还让我看到了未来。我不但有了技术优势，而且这些知识还让我的技术生涯有了更多的可能性。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;这些关键新技术，可以让你提前抢占技术的先机&lt;/strong&gt;。这一点对一个需要技术领导力的个人或公司来说都是非常重要的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果一个公司或是个人能够占有技术先机，就会比其它公司或个人有更大的影响力。一旦未来行业需求引爆，那么这个公司或是个人的影响力就会形成一个比较大的护城河，并可以快速地从中获取经济利益。&lt;/p&gt;
&lt;p&gt;最近，在与中国移动、中国电信以及一些股份制银行交流的过程中，我看到通讯行业、金融行业对于 PaaS 平台的理解已经超过了互联网公司，而我近 3 年来在这些技术上的研究让我也从中受益匪浅。&lt;/p&gt;
&lt;p&gt;所以，Go 语言和 Docker 作为 PaaS 平台的关键技术前途是无限的，我很庆幸自己赶上了这波浪潮，也很庆幸自己在 3 年前就看到了这个趋势，所以现在我也在用这些技术开发相关的技术产品，并助力于为高速成长的公司提供这些关键技术。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/fc/e9/fcc761001867c60f526665e237f831e9.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 08丨JVM是怎么实现invokedynamic的？（上）</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3jvm%E8%99%9A%E6%8B%9F%E6%9C%BA/08%E4%B8%A8jvm%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0invokedynamic%E7%9A%84%E4%B8%8A/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3jvm%E8%99%9A%E6%8B%9F%E6%9C%BA/08%E4%B8%A8jvm%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0invokedynamic%E7%9A%84%E4%B8%8A/</guid>
      <description>
        
        
        &lt;p&gt;前不久，&amp;ldquo;虚拟机&amp;quot;赛马俱乐部来了个年轻人，标榜自己是动态语言，是先进分子。&lt;/p&gt;
&lt;p&gt;这一天，先进分子牵着一头鹿进来，说要参加赛马。咱部里的老学究 Java 就不同意了呀，鹿又不是马，哪能参加赛马。&lt;/p&gt;
&lt;p&gt;当然了，这种墨守成规的调用方式，自然是先进分子所不齿的。现在年轻人里流行的是鸭子类型（duck typing）[1]，只要是跑起来像只马的，它就是一只马，也就能够参加赛马比赛。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class Horse {
  public void race() {
    System.out.println(&amp;quot;Horse.race()&amp;quot;); 
  }
}
 
class Deer {
  public void race() {
    System.out.println(&amp;quot;Deer.race()&amp;quot;);
  }
}
 
class Cobra {
  public void race() {
    System.out.println(&amp;quot;How do you turn this on?&amp;quot;);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(如何用同一种方式调用他们的赛跑方法？)&lt;/p&gt;
&lt;p&gt;说到了这里，如果我们将赛跑定义为对赛跑方法（对应上述代码中的 race()）的调用的话，那么这个故事的关键，就在于能不能在马场中调用非马类型的赛跑方法。&lt;/p&gt;
&lt;p&gt;为了解答这个问题，我们先来回顾一下 Java 里的方法调用。在 Java 中，方法调用会被编译为 invokestatic，invokespecial，invokevirtual 以及 invokeinterface 四种指令。这些指令与包含目标方法类名、方法名以及方法描述符的符号引用捆绑。在实际运行之前，Java 虚拟机将根据这个符号引用链接到具体的目标方法。&lt;/p&gt;
&lt;p&gt;可以看到，在这四种调用指令中，Java 虚拟机明确要求方法调用需要提供目标方法的类名。在这种体系下，我们有两个解决方案。一是调用其中一种类型的赛跑方法，比如说马类的赛跑方法。对于非马的类型，则给它套一层马甲，当成马来赛跑。&lt;/p&gt;
&lt;p&gt;另外一种解决方式，是通过反射机制，来查找并且调用各个类型中的赛跑方法，以此模拟真正的赛跑。&lt;/p&gt;
&lt;p&gt;显然，比起直接调用，这两种方法都相当复杂，执行效率也可想而知。为了解决这个问题，Java 7 引入了一条新的指令 invokedynamic。该指令的调用机制抽象出调用点这一个概念，并允许应用程序将调用点链接至任意符合条件的方法上。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public static void startRace(java.lang.Object)
       0: aload_0                // 加载一个任意对象
       1: invokedynamic race     // 调用赛跑方法
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(理想的调用方式)&lt;/p&gt;
&lt;p&gt;作为 invokedynamic 的准备工作，Java 7 引入了更加底层、更加灵活的方法抽象 ：方法句柄（MethodHandle）。&lt;/p&gt;
&lt;h2 id=&#34;方法句柄的概念&#34;&gt;方法句柄的概念&lt;/h2&gt;
&lt;p&gt;方法句柄是一个强类型的，能够被直接执行的引用 [2]。该引用可以指向常规的静态方法或者实例方法，也可以指向构造器或者字段。当指向字段时，方法句柄实则指向包含字段访问字节码的虚构方法，语义上等价于目标字段的 getter 或者 setter 方法。&lt;/p&gt;
&lt;p&gt;这里需要注意的是，它并不会直接指向目标字段所在类中的 getter/setter，毕竟你无法保证已有的 getter/setter 方法就是在访问目标字段。&lt;/p&gt;
&lt;p&gt;方法句柄的类型（MethodType）是由所指向方法的参数类型以及返回类型组成的。它是用来确认方法句柄是否适配的唯一关键。当使用方法句柄时，我们其实并不关心方法句柄所指向方法的类名或者方法名。&lt;/p&gt;
&lt;p&gt;打个比方，如果兔子的&amp;quot;赛跑&amp;quot;方法和&amp;quot;睡觉&amp;quot;方法的参数类型以及返回类型一致，那么对于兔子递过来的一个方法句柄，我们并不知道会是哪一个方法。&lt;/p&gt;
&lt;p&gt;方法句柄的创建是通过 MethodHandles.Lookup 类来完成的。它提供了多个 API，既可以使用反射 API 中的 Method 来查找，也可以根据类、方法名以及方法句柄类型来查找。&lt;/p&gt;
&lt;p&gt;当使用后者这种查找方式时，用户需要区分具体的调用类型，比如说对于用 invokestatic 调用的静态方法，我们需要使用 Lookup.findStatic 方法；对于用 invokevirutal 调用的实例方法，以及用 invokeinterface 调用的接口方法，我们需要使用 findVirtual 方法；对于用 invokespecial 调用的实例方法，我们则需要使用 findSpecial 方法。&lt;/p&gt;
&lt;p&gt;调用方法句柄，和原本对应的调用指令是一致的。也就是说，对于原本用 invokevirtual 调用的方法句柄，它也会采用动态绑定；而对于原本用 invkespecial 调用的方法句柄，它会采用静态绑定。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class Foo {
  private static void bar(Object o) {
    ..
  }
  public static Lookup lookup() {
    return MethodHandles.lookup();
  }
}
 
// 获取方法句柄的不同方式
MethodHandles.Lookup l = Foo.lookup(); // 具备 Foo 类的访问权限
Method m = Foo.class.getDeclaredMethod(&amp;quot;bar&amp;quot;, Object.class);
MethodHandle mh0 = l.unreflect(m);
 
MethodType t = MethodType.methodType(void.class, Object.class);
MethodHandle mh1 = l.findStatic(Foo.class, &amp;quot;bar&amp;quot;, t);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;方法句柄同样也有权限问题。但它与反射 API 不同，其权限检查是在句柄的创建阶段完成的。在实际调用过程中，Java 虚拟机并不会检查方法句柄的权限。如果该句柄被多次调用的话，那么与反射调用相比，它将省下重复权限检查的开销。&lt;/p&gt;
&lt;p&gt;需要注意的是，方法句柄的访问权限不取决于方法句柄的创建位置，而是取决于 Lookup 对象的创建位置。&lt;/p&gt;
&lt;p&gt;举个例子，对于一个私有字段，如果 Lookup 对象是在私有字段所在类中获取的，那么这个 Lookup 对象便拥有对该私有字段的访问权限，即使是在所在类的外边，也能够通过该 Lookup 对象创建该私有字段的 getter 或者 setter。&lt;/p&gt;
&lt;p&gt;由于方法句柄没有运行时权限检查，因此，应用程序需要负责方法句柄的管理。一旦它发布了某些指向私有方法的方法句柄，那么这些私有方法便被暴露出去了。&lt;/p&gt;
&lt;h2 id=&#34;方法句柄的操作&#34;&gt;方法句柄的操作&lt;/h2&gt;
&lt;p&gt;方法句柄的调用可分为两种，一是需要严格匹配参数类型的 invokeExact。它有多严格呢？假设一个方法句柄将接收一个 Object 类型的参数，如果你直接传入 String 作为实际参数，那么方法句柄的调用会在运行时抛出方法类型不匹配的异常。正确的调用方式是将该 String 显式转化为 Object 类型。&lt;/p&gt;
&lt;p&gt;在普通 Java 方法调用中，我们只有在选择重载方法时，才会用到这种显式转化。这是因为经过显式转化后，参数的声明类型发生了改变，因此有可能匹配到不同的方法描述符，从而选取不同的目标方法。调用方法句柄也是利用同样的原理，并且涉及了一个签名多态性（signature polymorphism）的概念。（在这里我们暂且认为签名等同于方法描述符。）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  public final native @PolymorphicSignature Object invokeExact(Object... args) throws Throwable;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;方法句柄 API 有一个特殊的注解类 @PolymorphicSignature。在碰到被它注解的方法调用时，Java 编译器会根据所传入参数的声明类型来生成方法描述符，而不是采用目标方法所声明的描述符。&lt;/p&gt;
&lt;p&gt;在刚才的例子中，当传入的参数是 String 时，对应的方法描述符包含 String 类；而当我们转化为 Object 时，对应的方法描述符则包含 Object 类。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  public void test(MethodHandle mh, String s) throws Throwable {
    mh.invokeExact(s);
    mh.invokeExact((Object) s);
  }
 
  // 对应的 Java 字节码
  public void test(MethodHandle, String) throws java.lang.Throwable;
    Code:
       0: aload_1
       1: aload_2
       2: invokevirtual MethodHandle.invokeExact:(Ljava/lang/String;)V
       5: aload_1
       6: aload_2
       7: invokevirtual MethodHandle.invokeExact:(Ljava/lang/Object;)V
      10: return
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;invokeExact 会确认该 invokevirtual 指令对应的方法描述符，和该方法句柄的类型是否严格匹配。在不匹配的情况下，便会在运行时抛出异常。&lt;/p&gt;
&lt;p&gt;如果你需要自动适配参数类型，那么你可以选取方法句柄的第二种调用方式 invoke。它同样是一个签名多态性的方法。invoke 会调用 MethodHandle.asType 方法，生成一个适配器方法句柄，对传入的参数进行适配，再调用原方法句柄。调用原方法句柄的返回值同样也会先进行适配，然后再返回给调用者。&lt;/p&gt;
&lt;p&gt;方法句柄还支持增删改参数的操作，这些操作都是通过生成另一个方法句柄来实现的。这其中，改操作就是刚刚介绍的 MethodHandle.asType 方法。删操作指的是将传入的部分参数就地抛弃，再调用另一个方法句柄。它对应的 API 是 MethodHandles.dropArguments 方法。&lt;/p&gt;
&lt;p&gt;增操作则非常有意思。它会往传入的参数中插入额外的参数，再调用另一个方法句柄，它对应的 API 是 MethodHandle.bindTo 方法。Java 8 中捕获类型的 Lambda 表达式便是用这种操作来实现的，下一篇我会详细进行解释。&lt;/p&gt;
&lt;p&gt;增操作还可以用来实现方法的柯里化 [3]。举个例子，有一个指向 f(x, y) 的方法句柄，我们可以通过将 x 绑定为 4，生成另一个方法句柄 g(y) = f(4, y)。在执行过程中，每当调用 g(y) 的方法句柄，它会在参数列表最前面插入一个 4，再调用指向 f(x, y) 的方法句柄。&lt;/p&gt;
&lt;h2 id=&#34;方法句柄的实现&#34;&gt;方法句柄的实现&lt;/h2&gt;
&lt;p&gt;下面我们来看看 HotSpot 虚拟机中方法句柄调用的具体实现。（由于篇幅原因，这里只讨论 DirectMethodHandle。）&lt;/p&gt;
&lt;p&gt;前面提到，调用方法句柄所使用的 invokeExact 或者 invoke 方法具备签名多态性的特性。它们会根据具体的传入参数来生成方法描述符。那么，拥有这个描述符的方法实际存在吗？对 invokeExact 或者 invoke 的调用具体会进入哪个方法呢？&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import java.lang.invoke.*;
 
public class Foo {
  public static void bar(Object o) {
    new Exception().printStackTrace();
  }
 
  public static void main(String[] args) throws Throwable {
    MethodHandles.Lookup l = MethodHandles.lookup();
    MethodType t = MethodType.methodType(void.class, Object.class);
    MethodHandle mh = l.findStatic(Foo.class, &amp;quot;bar&amp;quot;, t);
    mh.invokeExact(new Object());
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;和查阅反射调用的方式一样，我们可以通过新建异常实例来查看栈轨迹。打印出来的占轨迹如下所示：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ java Foo
java.lang.Exception
        at Foo.bar(Foo.java:5)
        at Foo.main(Foo.java:12)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;也就是说，invokeExact 的目标方法竟然就是方法句柄指向的方法。&lt;/p&gt;
&lt;p&gt;先别高兴太早。我刚刚提到过，invokeExact 会对参数的类型进行校验，并在不匹配的情况下抛出异常。如果它直接调用了方法句柄所指向的方法，那么这部分参数类型校验的逻辑将无处安放。因此，唯一的可能便是 Java 虚拟机隐藏了部分栈信息。&lt;/p&gt;
&lt;p&gt;当我们启用了 -XX:+ShowHiddenFrames 这个参数来打印被 Java 虚拟机隐藏了的栈信息时，你会发现 main 方法和目标方法中间隔着两个貌似是生成的方法。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ java -XX:+UnlockDiagnosticVMOptions -XX:+ShowHiddenFrames Foo
java.lang.Exception
        at Foo.bar(Foo.java:5)
        at java.base/java.lang.invoke.DirectMethodHandle$Holder. invokeStatic(DirectMethodHandle$Holder:1000010)
        at java.base/java.lang.invoke.LambdaForm$MH000/766572210. invokeExact_MT000_LLL_V(LambdaForm$MH000:1000019)
        at Foo.main(Foo.java:12)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;实际上，Java 虚拟机会对 invokeExact 调用做特殊处理，调用至一个共享的、与方法句柄类型相关的特殊适配器中。这个适配器是一个 LambdaForm，我们可以通过添加虚拟机参数将之导出成 class 文件（-Djava.lang.invoke.MethodHandle.DUMP_CLASS_FILES=true）。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;final class java.lang.invoke.LambdaForm$MH000 {  static void invokeExact_MT000_LLLLV(jeava.lang.bject, jjava.lang.bject, jjava.lang.bject);
    Code:
        : aload_0
      1 : checkcast      #14                 //Mclass java/lang/invoke/ethodHandle
        : dup
      5 : astore_0
        : aload_32        : checkcast      #16                 //Mclass java/lang/invoke/ethodType
      10: invokestatic  I#22                 // Method java/lang/invoke/nvokers.checkExactType:(MLjava/lang/invoke/ethodHandle,;Ljava/lang/invoke/ethodType);V
      13: aload_0
      14: invokestatic   #26     I           // Method java/lang/invoke/nvokers.checkCustomized:(MLjava/lang/invoke/ethodHandle);V
      17: aload_0
      18: aload_1
      19: ainvakevirtudl #30             2   // Methodijava/lang/nvokev/ethodHandle.invokeBasic:(LLeava/lang/bject;;V
       23 return
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，在这个适配器中，它会调用 Invokers.checkExactType 方法来检查参数类型，然后调用 Invokers.checkCustomized 方法。后者会在方法句柄的执行次数超过一个阈值时进行优化（对应参数 -Djava.lang.invoke.MethodHandle.CUSTOMIZE_THRESHOLD，默认值为 127）。最后，它会调用方法句柄的 invokeBasic 方法。&lt;/p&gt;
&lt;p&gt;Java 虚拟机同样会对 invokeBasic 调用做特殊处理，这会将调用至方法句柄本身所持有的适配器中。这个适配器同样是一个 LambdaForm，你可以通过反射机制将其打印出来。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 该方法句柄持有的 LambdaForm 实例的 toString() 结果
DMH.invokeStatic_L_V=Lambda(a0:L,a1:L)=&amp;gt;{
  t2:L=DirectMethodHandle.internalMemberName(a0:L);
  t3:V=MethodHandle.linkToStatic(a1:L,t2:L);void}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个适配器将获取方法句柄中的 MemberName 类型的字段，并且以它为参数调用 linkToStatic 方法。估计你已经猜到了，Java 虚拟机也会对 linkToStatic 调用做特殊处理，它将根据传入的 MemberName 参数所存储的方法地址或者方法表索引，直接跳转至目标方法。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;final class MemberName implements Member, Cloneable {
...
    //@Injected JVM_Method* vmtarget;
    //@Injected int         vmindex;
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;那么前面那个适配器中的优化又是怎么回事？实际上，方法句柄一开始持有的适配器是共享的。当它被多次调用之后，Invokers.checkCustomized 方法会为该方法句柄生成一个特有的适配器。这个特有的适配器会将方法句柄作为常量，直接获取其 MemberName 类型的字段，并继续后面的 linkToStatic 调用。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;final class java.lang.invoke.LambdaForm$DMH000 {
  static void invokeStatic000_LL_V(java.lang.Object, java.lang.Object);
    Code:
       0: ldc           #14                 // String CONSTANT_PLACEHOLDER_1 &amp;lt;&amp;lt;Foo.bar(Object)void/invokeStatic&amp;gt;&amp;gt;
       2: checkcast     #16                 // class java/lang/invoke/MethodHandle
       5: astore_0     // 上面的优化代码覆盖了传入的方法句柄
       6: aload_0      // 从这里开始跟初始版本一致
       7: invokestatic  #22                 // Method java/lang/invoke/DirectMethodHandle.internalMemberName:(Ljava/lang/Object;)Ljava/lang/Object;
      10: astore_2
      11: aload_1
      12: aload_2
      13: checkcast     #24                 // class java/lang/invoke/MemberName
      16: invokestatic  #28                 // Method java/lang/invoke/MethodHandle.linkToStatic:(Ljava/lang/Object;Ljava/lang/invoke/MemberName;)V
      19: return
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，方法句柄的调用和反射调用一样，都是间接调用。因此，它也会面临无法内联的问题。不过，与反射调用不同的是，方法句柄的内联瓶颈在于即时编译器能否将该方法句柄识别为常量。具体内容我会在下一篇中进行详细的解释。&lt;/p&gt;
&lt;h2 id=&#34;总结与实践&#34;&gt;总结与实践&lt;/h2&gt;
&lt;p&gt;今天我介绍了 invokedynamic 底层机制的基石：方法句柄。&lt;/p&gt;
&lt;p&gt;方法句柄是一个强类型的、能够被直接执行的引用。它仅关心所指向方法的参数类型以及返回类型，而不关心方法所在的类以及方法名。方法句柄的权限检查发生在创建过程中，相较于反射调用节省了调用时反复权限检查的开销。&lt;/p&gt;
&lt;p&gt;方法句柄可以通过 invokeExact 以及 invoke 来调用。其中，invokeExact 要求传入的参数和所指向方法的描述符严格匹配。方法句柄还支持增删改参数的操作，这些操作是通过生成另一个充当适配器的方法句柄来实现的。&lt;/p&gt;
&lt;p&gt;方法句柄的调用和反射调用一样，都是间接调用，同样会面临无法内联的问题。&lt;/p&gt;
&lt;p&gt;今天的实践环节，我们来测量一下方法句柄的性能。你可以尝试通过重构代码，将方法句柄变成常量，来提升方法句柄调用的性能。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class Foo {
  public void bar(Object o) {
  }
 
  public static void main(String[] args) throws Throwable {
    MethodHandles.Lookup l = MethodHandles.lookup();
    MethodType t = MethodType.methodType(void.class, Object.class);
    MethodHandle mh = l.findVirtual(Foo.class, &amp;quot;bar&amp;quot;, t);
 
    long current = System.currentTimeMillis();
    for (int i = 1; i &amp;lt;= 2_000_000_000; i++) {
      if (i % 100_000_000 == 0) {
        long temp = System.currentTimeMillis();
        System.out.println(temp - current);
        current = temp;
       }
       mh.invokeExact(new Foo(), new Object());
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://en.wikipedia.org/wiki/Duck_typing&#34;&gt;https://en.wikipedia.org/wiki/Duck_typing&lt;/a&gt;&lt;br&gt;
[2]&lt;br&gt;
&lt;a href=&#34;https://docs.oracle.com/javase/10/docs/api/java/lang/invoke/MethodHandle.html&#34;&gt;https://docs.oracle.com/javase/10/docs/api/java/lang/invoke/MethodHandle.html&lt;/a&gt;&lt;br&gt;
[3]&lt;br&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Currying&#34;&gt;https://en.wikipedia.org/wiki/Currying&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/2a/d5/2a62e58cbdf56a5dc40748567d346fd5.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>极客专栏: 08丨事务到底是隔离的还是不隔离的？</title>
      <link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/08%E4%B8%A8%E4%BA%8B%E5%8A%A1%E5%88%B0%E5%BA%95%E6%98%AF%E9%9A%94%E7%A6%BB%E7%9A%84%E8%BF%98%E6%98%AF%E4%B8%8D%E9%9A%94%E7%A6%BB%E7%9A%84/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/08%E4%B8%A8%E4%BA%8B%E5%8A%A1%E5%88%B0%E5%BA%95%E6%98%AF%E9%9A%94%E7%A6%BB%E7%9A%84%E8%BF%98%E6%98%AF%E4%B8%8D%E9%9A%94%E7%A6%BB%E7%9A%84/</guid>
      <description>
        
        
        &lt;blockquote&gt;
&lt;p&gt;你好，我是林晓斌。&lt;br&gt;
你现在看到的这篇文章是我重写过的。在第一版文章发布之后，我发现在介绍事务可见性规则时，由于引入了太多概念，导致理解起来很困难。随后，我索性就重写了这篇文章。&lt;br&gt;
现在的用户留言中，还能看到第一版文章中引入的 up_limit_id 的概念，为了避免大家产生误解，再此特地和大家事先说明一下。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我在第 3 篇文章和你讲事务隔离级别的时候提到过，如果是可重复读隔离级别，事务 T 启动的时候会创建一个视图 read-view，之后事务 T 执行期间，即使有其他事务修改了数据，事务 T 看到的仍然跟在启动时看到的一样。也就是说，一个在可重复读隔离级别下执行的事务，好像与世无争，不受外界影响。&lt;/p&gt;
&lt;p&gt;但是，我在上一篇文章中，和你分享行锁的时候又提到，一个事务要更新一行，如果刚好有另外一个事务拥有这一行的行锁，它又不能这么超然了，会被锁住，进入等待状态。问题是，既然进入了等待状态，那么等到这个事务自己获取到行锁要更新数据的时候，它读到的值又是什么呢？&lt;/p&gt;
&lt;p&gt;我给你举一个例子吧。下面是一个只有两行的表的初始化语句。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `k` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;
insert into t(id, k) values(1,1),(2,2);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/82/d6/823acf76e53c0bdba7beab45e72e90d6.png&#34; alt=&#34;&#34;&gt;
图 1 事务 A、B、C 的执行流程&lt;/p&gt;
&lt;p&gt;这里，我们需要注意的是事务的启动时机。&lt;/p&gt;
&lt;p&gt;begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用 start transaction with consistent snapshot 这个命令。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;第一种启动方式，一致性视图是在第执行第一个快照读语句时创建的；&lt;br&gt;
第二种启动方式，一致性视图是在执行 start transaction with consistent snapshot 时创建的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;还需要注意的是，在整个专栏里面，我们的例子中如果没有特别说明，都是默认 autocommit=1。&lt;/p&gt;
&lt;p&gt;在这个例子中，事务 C 没有显式地使用 begin/commit，表示这个 update 语句本身就是一个事务，语句完成的时候会自动提交。事务 B 在更新了行之后查询 ; 事务 A 在一个只读事务中查询，并且时间顺序上是在事务 B 的查询之后。&lt;/p&gt;
&lt;p&gt;这时，如果我告诉你事务 B 查到的 k 的值是 3，而事务 A 查到的 k 的值是 1，你是不是感觉有点晕呢？&lt;/p&gt;
&lt;p&gt;所以，今天这篇文章，我其实就是想和你说明白这个问题，希望借由把这个疑惑解开的过程，能够帮助你对 InnoDB 的事务和锁有更进一步的理解。&lt;/p&gt;
&lt;p&gt;在 MySQL 里，有两个&amp;quot;视图&amp;quot;的概念：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一个是 view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是 create view &amp;hellip; ，而它的查询方法与表一样。&lt;/li&gt;
&lt;li&gt;另一个是 InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;它没有物理结构，作用是事务执行期间用来定义&amp;quot;我能看到什么数据&amp;quot;。&lt;/p&gt;
&lt;p&gt;在第 3 篇文章&lt;a href=&#34;https://time.geekbang.org/column/article/68963&#34;&gt;《事务隔离：为什么你改了我还看不见？》&lt;/a&gt;中，我跟你解释过一遍 MVCC 的实现逻辑。今天为了说明查询和更新的区别，我换一个方式来说明，把 read view 拆开。你可以结合这两篇文章的说明来更深一步地理解 MVCC。&lt;/p&gt;
&lt;h1 id=&#34;快照在-mvcc-里是怎么工作的&#34;&gt;&amp;ldquo;快照&amp;quot;在 MVCC 里是怎么工作的？&lt;/h1&gt;
&lt;p&gt;在可重复读隔离级别下，事务在启动的时候就&amp;quot;拍了个快照&amp;rdquo;。注意，这个快照是基于整库的。&lt;/p&gt;
&lt;p&gt;这时，你会说这看上去不太现实啊。如果一个库有 100G，那么我启动一个事务，MySQL 就要拷贝 100G 的数据出来，这个过程得多慢啊。可是，我平时的事务执行起来很快啊。&lt;/p&gt;
&lt;p&gt;实际上，我们并不需要拷贝出这 100G 的数据。我们先来看看这个快照是怎么实现的。&lt;/p&gt;
&lt;p&gt;InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。&lt;/p&gt;
&lt;p&gt;而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。&lt;/p&gt;
&lt;p&gt;也就是说，数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id。&lt;/p&gt;
&lt;p&gt;如图 2 所示，就是一个记录被多个事务连续更新后的状态。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/68/ed/68d08d277a6f7926a41cc5541d3dfced.png&#34; alt=&#34;&#34;&gt;
图 2 行状态变更图&lt;/p&gt;
&lt;p&gt;图中虚线框里是同一行数据的 4 个版本，当前最新版本是 V4，k 的值是 22，它是被 transaction id 为 25 的事务更新的，因此它的 row trx_id 也是 25。&lt;/p&gt;
&lt;p&gt;你可能会问，前面的文章不是说，语句更新会生成 undo log（回滚日志）吗？那么，&lt;strong&gt;undo log 在哪呢？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;实际上，图 2 中的三个虚线箭头，就是 undo log；而 V1、V2、V3 并不是物理上真实存在的，而是每次需要的时候根据当前版本和 undo log 计算出来的。比如，需要 V2 的时候，就是通过 V4 依次执行 U3、U2 算出来。&lt;/p&gt;
&lt;p&gt;明白了多版本和 row trx_id 的概念后，我们再来想一下，InnoDB 是怎么定义那个&amp;quot;100G&amp;quot;的快照的。&lt;/p&gt;
&lt;p&gt;按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见。&lt;/p&gt;
&lt;p&gt;因此，一个事务只需要在启动的时候声明说，&amp;ldquo;以我启动的时刻为准，如果一个数据版本是在我启动之前生成的，就认；如果是我启动以后才生成的，我就不认，我必须要找到它的上一个版本&amp;rdquo;。&lt;/p&gt;
&lt;p&gt;当然，如果&amp;quot;上一个版本&amp;quot;也不可见，那就得继续往前找。还有，如果是这个事务自己更新的数据，它自己还是要认的。&lt;/p&gt;
&lt;p&gt;在实现上， InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在&amp;quot;活跃&amp;quot;的所有事务 ID。&amp;ldquo;活跃&amp;quot;指的就是，启动了但还没提交。&lt;/p&gt;
&lt;p&gt;数组里面事务 ID 的最小值记为低水位，当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位。&lt;/p&gt;
&lt;p&gt;这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。&lt;/p&gt;
&lt;p&gt;而数据版本的可见性规则，就是基于数据的 row trx_id 和这个一致性视图的对比结果得到的。&lt;/p&gt;
&lt;p&gt;这个视图数组把所有的 row trx_id 分成了几种不同的情况。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/88/5e/882114aaf55861832b4270d44507695e.png&#34; alt=&#34;&#34;&gt;
图 3 数据版本可见性规则&lt;/p&gt;
&lt;p&gt;这样，对于当前事务的启动瞬间来说，一个数据版本的 row trx_id，有以下几种可能：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果落在黄色部分，那就包括两种情况&lt;br&gt;
a. 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见；&lt;br&gt;
b. 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;比如，对于图 2 中的数据来说，如果有一个事务，它的低水位是 18，那么当它访问这一行数据时，就会从 V4 通过 U3 计算出 V3，所以在它看来，这一行的值是 11。&lt;/p&gt;
&lt;p&gt;你看，有了这个声明后，系统里面随后发生的更新，是不是就跟这个事务看到的内容无关了呢？因为之后的更新，生成的版本一定属于上面的 2 或者 3(a) 的情况，而对它来说，这些新的数据版本是不存在的，所以这个事务的快照，就是&amp;quot;静态&amp;quot;的了。&lt;/p&gt;
&lt;p&gt;所以你现在知道了，&lt;strong&gt;InnoDB 利用了&amp;quot;所有数据都有多个版本&amp;quot;的这个特性，实现了&amp;quot;秒级创建快照&amp;quot;的能力。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;接下来，我们继续看一下图 1 中的三个事务，分析下事务 A 的语句返回的结果，为什么是 k=1。&lt;/p&gt;
&lt;p&gt;这里，我们不妨做如下假设：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;事务 A 开始前，系统里面只有一个活跃事务 ID 是 99；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;事务 A、B、C 的版本号分别是 100、101、102，且当前系统里只有这四个事务；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;三个事务开始前，(1,1）这一行数据的 row trx_id 是 90。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这样，事务 A 的视图数组就是 [99,100], 事务 B 的视图数组是 [99,100,101], 事务 C 的视图数组是 [99,100,101,102]。&lt;/p&gt;
&lt;p&gt;为了简化分析，我先把其他干扰语句去掉，只画出跟事务 A 查询逻辑有关的操作：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/94/49/9416c310e406519b7460437cb0c5c149.png&#34; alt=&#34;&#34;&gt;
图 4 事务 A 查询数据逻辑图&lt;/p&gt;
&lt;p&gt;从图中可以看到，第一个有效更新是事务 C，把数据从 (1,1) 改成了 (1,2)。这时候，这个数据的最新版本的 row trx_id 是 102，而 90 这个版本已经成为了历史版本。&lt;/p&gt;
&lt;p&gt;第二个有效更新是事务 B，把数据从 (1,2) 改成了 (1,3)。这时候，这个数据的最新版本（即 row trx_id）是 101，而 102 又成为了历史版本。&lt;/p&gt;
&lt;p&gt;你可能注意到了，在事务 A 查询的时候，其实事务 B 还没有提交，但是它生成的 (1,3) 这个版本已经变成当前版本了。但这个版本对事务 A 必须是不可见的，否则就变成脏读了。&lt;/p&gt;
&lt;p&gt;好，现在事务 A 要来读数据了，它的视图数组是 [99,100]。当然了，读数据都是从当前版本读起的。所以，事务 A 查询语句的读数据流程是这样的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;找到 (1,3) 的时候，判断出 row trx_id=101，比高水位大，处于红色区域，不可见；&lt;/li&gt;
&lt;li&gt;接着，找到上一个历史版本，一看 row trx_id=102，比高水位大，处于红色区域，不可见；&lt;/li&gt;
&lt;li&gt;再往前找，终于找到了（1,1)，它的 row trx_id=90，比低水位小，处于绿色区域，可见。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这样执行下来，虽然期间这一行数据被修改过，但是事务 A 不论在什么时候查询，看到这行数据的结果都是一致的，所以我们称之为一致性读。&lt;/p&gt;
&lt;p&gt;这个判断规则是从代码逻辑直接转译过来的，但是正如你所见，用于人肉分析可见性很麻烦。&lt;/p&gt;
&lt;p&gt;所以，我来给你翻译一下。一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;版本未提交，不可见；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;版本已提交，但是是在视图创建后提交的，不可见；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;版本已提交，而且是在视图创建前提交的，可见。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;现在，我们用这个规则来判断图 4 中的查询结果，事务 A 的查询语句的视图数组是在事务 A 启动的时候生成的，这时候：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(1,3) 还没提交，属于情况 1，不可见；&lt;/li&gt;
&lt;li&gt;(1,2) 虽然提交了，但是是在视图数组创建之后提交的，属于情况 2，不可见；&lt;/li&gt;
&lt;li&gt;(1,1) 是在视图数组创建之前提交的，可见。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你看，去掉数字对比后，只用时间先后顺序来判断，分析起来是不是轻松多了。所以，后面我们就都用这个规则来分析。&lt;/p&gt;
&lt;h1 id=&#34;更新逻辑&#34;&gt;更新逻辑&lt;/h1&gt;
&lt;p&gt;细心的同学可能有疑问了：&lt;strong&gt;事务 B 的 update 语句，如果按照一致性读，好像结果不对哦？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;你看图 5 中，事务 B 的视图数组是先生成的，之后事务 C 才提交，不是应该看不见 (1,2) 吗，怎么能算出 (1,3) 来？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/86/9f/86ad7e8abe7bf16505b97718d8ac149f.png&#34; alt=&#34;&#34;&gt;
图 5 事务 B 更新逻辑图&lt;/p&gt;
&lt;p&gt;是的，如果事务 B 在更新之前查询一次数据，这个查询返回的 k 的值确实是 1。&lt;/p&gt;
&lt;p&gt;但是，当它要去更新数据的时候，就不能再在历史版本上更新了，否则事务 C 的更新就丢失了。因此，事务 B 此时的 set k=k+1 是在（1,2）的基础上进行的操作。&lt;/p&gt;
&lt;p&gt;所以，这里就用到了这样一条规则：&lt;strong&gt;更新数据都是先读后写的，而这个读，只能读当前的值，称为&amp;quot;当前读&amp;rdquo;（current read）。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;因此，在更新的时候，当前读拿到的数据是 (1,2)，更新后生成了新版本的数据 (1,3)，这个新版本的 row trx_id 是 101。&lt;/p&gt;
&lt;p&gt;所以，在执行事务 B 查询语句的时候，一看自己的版本号是 101，最新数据的版本号也是 101，是自己的更新，可以直接使用，所以查询得到的 k 的值是 3。&lt;/p&gt;
&lt;p&gt;这里我们提到了一个概念，叫作当前读。其实，除了 update 语句外，select 语句如果加锁，也是当前读。&lt;/p&gt;
&lt;p&gt;所以，如果把事务 A 的查询语句 select * from t where id=1 修改一下，加上 lock in share mode 或 for update，也都可以读到版本号是 101 的数据，返回的 k 的值是 3。下面这两个 select 语句，就是分别加了读锁（S 锁，共享锁）和写锁（X 锁，排他锁）。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; select k from t where id=1 lock in share mode;
mysql&amp;gt; select k from t where id=1 for update;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;再往前一步，假设事务 C 不是马上提交的，而是变成了下面的事务 C&amp;rsquo;，会怎么样呢？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/cd/6e/cda2a0d7decb61e59dddc83ac51efb6e.png&#34; alt=&#34;&#34;&gt;
图 6 事务 A、B、C&amp;rsquo;的执行流程&lt;/p&gt;
&lt;p&gt;事务 C&amp;rsquo;的不同是，更新后并没有马上提交，在它提交前，事务 B 的更新语句先发起了。前面说过了，虽然事务 C&amp;rsquo;还没提交，但是 (1,2) 这个版本也已经生成了，并且是当前的最新版本。那么，事务 B 的更新语句会怎么处理呢？&lt;/p&gt;
&lt;p&gt;这时候，我们在上一篇文章中提到的&amp;quot;两阶段锁协议&amp;quot;就要上场了。事务 C&amp;rsquo;没提交，也就是说 (1,2) 这个版本上的写锁还没释放。而事务 B 是当前读，必须要读最新版本，而且必须加锁，因此就被锁住了，必须等到事务 C&amp;rsquo;释放这个锁，才能继续它的当前读。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/54/92/540967ea905e8b63630e496786d84c92.png&#34; alt=&#34;&#34;&gt;
图 7 事务 B 更新逻辑图（配合事务 C&amp;rsquo;）&lt;/p&gt;
&lt;p&gt;到这里，我们把一致性读、当前读和行锁就串起来了。&lt;/p&gt;
&lt;p&gt;现在，我们再回到文章开头的问题：&lt;strong&gt;事务的可重复读的能力是怎么实现的？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。&lt;/p&gt;
&lt;p&gt;而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；&lt;/li&gt;
&lt;li&gt;在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;那么，我们再看一下，在读提交隔离级别下，事务 A 和事务 B 的查询语句查到的 k，分别应该是多少呢？&lt;/p&gt;
&lt;p&gt;这里需要说明一下，&amp;ldquo;start transaction with consistent snapshot; &amp;ldquo;的意思是从这个语句开始，创建一个持续整个事务的一致性快照。所以，在读提交隔离级别下，这个用法就没意义了，等效于普通的 start transaction。&lt;/p&gt;
&lt;p&gt;下面是读提交时的状态图，可以看到这两个查询语句的创建视图数组的时机发生了变化，就是图中的 read view 框。（注意：这里，我们用的还是事务 C 的逻辑直接提交，而不是事务 C&amp;rsquo;）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/18/be/18fd5179b38c8c3804b313c3582cd1be.jpg&#34; alt=&#34;&#34;&gt;
图 8 读提交隔离级别下的事务状态图&lt;/p&gt;
&lt;p&gt;这时，事务 A 的查询语句的视图数组是在执行这个语句的时候创建的，时序上 (1,2)、(1,3) 的生成时间都在创建这个视图数组的时刻之前。但是，在这个时刻：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(1,3) 还没提交，属于情况 1，不可见；&lt;/li&gt;
&lt;li&gt;(1,2) 提交了，属于情况 3，可见。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以，这时候事务 A 查询语句返回的是 k=2。&lt;/p&gt;
&lt;p&gt;显然地，事务 B 查询结果 k=3。&lt;/p&gt;
&lt;h1 id=&#34;小结&#34;&gt;小结&lt;/h1&gt;
&lt;p&gt;InnoDB 的行数据有多个版本，每个数据版本有自己的 row trx_id，每个事务或者语句有自己的一致性视图。普通查询语句是一致性读，一致性读会根据 row trx_id 和一致性视图确定数据版本的可见性。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于可重复读，查询只承认在事务启动前就已经提交完成的数据；&lt;/li&gt;
&lt;li&gt;对于读提交，查询只承认在语句启动前就已经提交完成的数据；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而当前读，总是读取已经提交完成的最新版本。&lt;/p&gt;
&lt;p&gt;你也可以想一下，为什么表结构不支持&amp;quot;可重复读&amp;rdquo;？这是因为表结构没有对应的行数据，也没有 row trx_id，因此只能遵循当前读的逻辑。&lt;/p&gt;
&lt;p&gt;当然，MySQL 8.0 已经可以把表结构放在 InnoDB 字典里了，也许以后会支持表结构的可重复读。&lt;/p&gt;
&lt;p&gt;又到思考题时间了。我用下面的表结构和初始化语句作为试验环境，事务隔离级别是可重复读。现在，我要把所有&amp;quot;字段 c 和 id 值相等的行&amp;quot;的 c 值清零，但是却发现了一个&amp;quot;诡异&amp;quot;的、改不掉的情况。请你构造出这种情况，并说明其原理。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `c` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;
insert into t(id, c) values(1,1),(2,2),(3,3),(4,4);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/9b/0b/9b8fe7cf88c9ba40dc12e93e36c3060b.png&#34; alt=&#34;&#34;&gt;&lt;br&gt;
复现出来以后，请你再思考一下，在实际的业务开发中有没有可能碰到这种情况？你的应用代码会不会掉进这个&amp;quot;坑&amp;quot;里，你又是怎么解决的呢？&lt;/p&gt;
&lt;p&gt;你可以把你的思考和观点写在留言区里，我会在下一篇文章的末尾和你讨论这个问题。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。&lt;/p&gt;
&lt;h1 id=&#34;上期问题时间&#34;&gt;上期问题时间&lt;/h1&gt;
&lt;p&gt;我在上一篇文章最后，留给你的问题是：怎么删除表的前 10000 行。比较多的留言都选择了第二种方式，即：在一个连接中循环执行 20 次 delete from T limit 500。&lt;/p&gt;
&lt;p&gt;确实是这样的，第二种方式是相对较好的。&lt;/p&gt;
&lt;p&gt;第一种方式（即：直接执行 delete from T limit 10000）里面，单个语句占用时间长，锁的时间也比较长；而且大事务还会导致主从延迟。&lt;/p&gt;
&lt;p&gt;第三种方式（即：在 20 个连接中同时执行 delete from T limit 500），会人为造成锁冲突。&lt;/p&gt;
&lt;p&gt;评论区留言点赞板：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;@Tony Du 的评论，详细而且准确。&lt;br&gt;
@Knight²º¹⁸ 提到了如果可以加上特定条件，将这 10000 行天然分开，可以考虑第三种。是的，实际上在操作的时候我也建议你尽量拿到 ID 再删除。&lt;br&gt;
@荒漠甘泉 提了一个不错的问题，大家需要区分行锁、MDL 锁和表锁的区别。对 InnoDB 表更新一行，可能过了 MDL 关，却被挡在行锁阶段。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://static001.geekbang.org/resource/image/ce/d9/ce7f4e35916ed1aa49206a53a0547bd9.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
